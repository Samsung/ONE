<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.5"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ONE - On-device Neural Engine: arm_compute::NEFullyConnectedLayerEx Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">ONE - On-device Neural Engine
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.5 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('classarm__compute_1_1_n_e_fully_connected_layer_ex.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-methods">Static Public Member Functions</a>  </div>
  <div class="headertitle"><div class="title">arm_compute::NEFullyConnectedLayerEx Class Reference</div></div>
</div><!--header-->
<div class="contents">

<p><code>#include &lt;<a class="el" href="_n_e_fully_connected_layer_ex_8h_source.html">NEFullyConnectedLayerEx.h</a>&gt;</code></p>
<div class="dynheader">
Collaboration diagram for arm_compute::NEFullyConnectedLayerEx:</div>
<div class="dyncontent">
<div class="center"><img src="classarm__compute_1_1_n_e_fully_connected_layer_ex__coll__graph.png" border="0" usemap="#aarm__compute_1_1_n_e_fully_connected_layer_ex_coll__map" alt="Collaboration graph"/></div>
<map name="aarm__compute_1_1_n_e_fully_connected_layer_ex_coll__map" id="aarm__compute_1_1_n_e_fully_connected_layer_ex_coll__map">
<area shape="rect" title=" " alt="" coords="5,79,220,119"/>
<area shape="rect" title=" " alt="" coords="32,5,193,31"/>
</map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a66d353d99579d2c107b7b26360bb0736"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html#a66d353d99579d2c107b7b26360bb0736">NEFullyConnectedLayerEx</a> (std::shared_ptr&lt; IMemoryManager &gt; memory_manager=nullptr)</td></tr>
<tr class="separator:a66d353d99579d2c107b7b26360bb0736"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a526f7bc82ffc78652ac4030814ea88c4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html#a526f7bc82ffc78652ac4030814ea88c4">NEFullyConnectedLayerEx</a> (const <a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html">NEFullyConnectedLayerEx</a> &amp;)=delete</td></tr>
<tr class="separator:a526f7bc82ffc78652ac4030814ea88c4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa65ed552e199a5f477cfa57af96d06fd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html#aa65ed552e199a5f477cfa57af96d06fd">NEFullyConnectedLayerEx</a> (<a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html">NEFullyConnectedLayerEx</a> &amp;&amp;)=delete</td></tr>
<tr class="separator:aa65ed552e199a5f477cfa57af96d06fd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abd5869dbaf2c3d8ea9d0b6e33f4eb59a"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html">NEFullyConnectedLayerEx</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html#abd5869dbaf2c3d8ea9d0b6e33f4eb59a">operator=</a> (const <a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html">NEFullyConnectedLayerEx</a> &amp;)=delete</td></tr>
<tr class="separator:abd5869dbaf2c3d8ea9d0b6e33f4eb59a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab4af80fa136da5741db9f29ae6907533"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html">NEFullyConnectedLayerEx</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html#ab4af80fa136da5741db9f29ae6907533">operator=</a> (<a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html">NEFullyConnectedLayerEx</a> &amp;&amp;)=delete</td></tr>
<tr class="separator:ab4af80fa136da5741db9f29ae6907533"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a299ac8d4fc795b6a4bab48d8ac78cb5f"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html#a299ac8d4fc795b6a4bab48d8ac78cb5f">configure</a> (const ITensor *input, const ITensor *weights, const ITensor *biases, ITensor *output, FullyConnectedLayerInfo fc_info=FullyConnectedLayerInfo())</td></tr>
<tr class="separator:a299ac8d4fc795b6a4bab48d8ac78cb5f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac6e7d2d4cb03dfe15bdde9a6308a2146"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html#ac6e7d2d4cb03dfe15bdde9a6308a2146">run</a> () override</td></tr>
<tr class="separator:ac6e7d2d4cb03dfe15bdde9a6308a2146"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5110a87cacb9c69360097e0b6781512a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html#a5110a87cacb9c69360097e0b6781512a">prepare</a> () override</td></tr>
<tr class="separator:a5110a87cacb9c69360097e0b6781512a"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-static-methods" name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:aea91ae4c26ee0e042aabb4787269b59b"><td class="memItemLeft" align="right" valign="top">static Status&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html#aea91ae4c26ee0e042aabb4787269b59b">validate</a> (const ITensorInfo *input, const ITensorInfo *weights, const ITensorInfo *biases, const ITensorInfo *output, FullyConnectedLayerInfo fc_info=FullyConnectedLayerInfo())</td></tr>
<tr class="separator:aea91ae4c26ee0e042aabb4787269b59b"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p >Basic function to compute a Fully Connected layer on NEON. This function calls the following NEON kernels:</p><ol type="1">
<li>NEIm2ColKernel (called when the input comes from a convolutional layer)</li>
<li>NEFullyConnectedLayerReshapeWeights (if <code>are_weights_reshaped</code> is set to false and transpose_weights is set to true ) (called once)</li>
<li>NEGEMMMatrixMultiplyKernel or NEGEMMLowpMatrixMultiplyCore (if quantized asymmetric)</li>
<li><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_matrix_accumulate_biases_kernel.html">NEGEMMMatrixAccumulateBiasesKernel</a> or NEGEMMLowpQuantizeDownInt32ToUint8ScaleByFixedPoint (if quantized asymmetric) (if <code>biases</code> is not equal to nullptr)</li>
</ol>
<dl class="section note"><dt>Note</dt><dd>The fully connected layer accepts "weights" tensors only with 2 dimensions. </dd>
<dd>
The difference from NEFullyConnectedLayer is that this class supports weights as input with performance loss. </dd></dl>

<p class="definition">Definition at line <a class="el" href="_n_e_fully_connected_layer_ex_8h_source.html#l00074">74</a> of file <a class="el" href="_n_e_fully_connected_layer_ex_8h_source.html">NEFullyConnectedLayerEx.h</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a66d353d99579d2c107b7b26360bb0736" name="a66d353d99579d2c107b7b26360bb0736"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a66d353d99579d2c107b7b26360bb0736">&#9670;&#160;</a></span>NEFullyConnectedLayerEx() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">arm_compute::NEFullyConnectedLayerEx::NEFullyConnectedLayerEx </td>
          <td>(</td>
          <td class="paramtype">std::shared_ptr&lt; IMemoryManager &gt;&#160;</td>
          <td class="paramname"><em>memory_manager</em> = <code>nullptr</code></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Constructor </p>

<p class="definition">Definition at line <a class="el" href="_n_e_fully_connected_layer_ex_8cpp_source.html#l00087">87</a> of file <a class="el" href="_n_e_fully_connected_layer_ex_8cpp_source.html">NEFullyConnectedLayerEx.cpp</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   88</span>  : _memory_group(std::move(memory_manager)), _flatten_kernel(), _convert_weights(),</div>
<div class="line"><span class="lineno">   89</span>    _reshape_weights_function(), _mm_gemm(), _mm_gemmlowp(), _gemmlowp_output_stage(),</div>
<div class="line"><span class="lineno">   90</span>    _accumulate_biases_kernel(), _flatten_output(), _gemmlowp_output(), _converted_weights_output(),</div>
<div class="line"><span class="lineno">   91</span>    _reshape_weights_output(), _original_weights(<span class="keyword">nullptr</span>), _are_weights_converted(<span class="keyword">true</span>),</div>
<div class="line"><span class="lineno">   92</span>    _are_weights_reshaped(<span class="keyword">false</span>), _is_fc_after_conv(<span class="keyword">false</span>), _accumulate_biases(<span class="keyword">false</span>),</div>
<div class="line"><span class="lineno">   93</span>    _is_quantized(<span class="keyword">false</span>), _is_prepared(<span class="keyword">false</span>)</div>
<div class="line"><span class="lineno">   94</span>{</div>
<div class="line"><span class="lineno">   95</span>}</div>
</div><!-- fragment -->
</div>
</div>
<a id="a526f7bc82ffc78652ac4030814ea88c4" name="a526f7bc82ffc78652ac4030814ea88c4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a526f7bc82ffc78652ac4030814ea88c4">&#9670;&#160;</a></span>NEFullyConnectedLayerEx() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">arm_compute::NEFullyConnectedLayerEx::NEFullyConnectedLayerEx </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html">NEFullyConnectedLayerEx</a> &amp;&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">delete</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p >Prevent instances of this class from being copied (As this class contains pointers) </p>

</div>
</div>
<a id="aa65ed552e199a5f477cfa57af96d06fd" name="aa65ed552e199a5f477cfa57af96d06fd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa65ed552e199a5f477cfa57af96d06fd">&#9670;&#160;</a></span>NEFullyConnectedLayerEx() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">arm_compute::NEFullyConnectedLayerEx::NEFullyConnectedLayerEx </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html">NEFullyConnectedLayerEx</a> &amp;&amp;&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">delete</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p >Default move constructor </p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a299ac8d4fc795b6a4bab48d8ac78cb5f" name="a299ac8d4fc795b6a4bab48d8ac78cb5f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a299ac8d4fc795b6a4bab48d8ac78cb5f">&#9670;&#160;</a></span>configure()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void arm_compute::NEFullyConnectedLayerEx::configure </td>
          <td>(</td>
          <td class="paramtype">const ITensor *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const ITensor *&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const ITensor *&#160;</td>
          <td class="paramname"><em>biases</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ITensor *&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">FullyConnectedLayerInfo&#160;</td>
          <td class="paramname"><em>fc_info</em> = <code>FullyConnectedLayerInfo()</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Set the input and output tensors.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">input</td><td>Source tensor. Data type supported: QASYMM8/F16/F32. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">weights</td><td>Weights tensor. The weights must be 2 dimensional. If this function is called after a Convolution Layer, the (transposed) weights will have as many rows as the product of the first 3 input's dimensions. If it is called after another FullyConnected Layer, the (transposed) weights will have as many rows as the input's first dimension. Data type supported: Same as <code>input</code>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">biases</td><td>Bias tensor. Can be nullptr. Data type supported:Same as <code>input</code>. </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">output</td><td>Destination tensor. Its shape should be equal to the output of a matrix multiplication between:<ul>
<li>The output of im2col on the input and the (transposed) 2D weights, if the function is called after a Convolution Layer</li>
<li>The input tensor and the (transposed) 2D weights, if the function is called after another FullyConnected Layer. Data type supported: Same as <code>input</code>. </li>
</ul>
</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">fc_info</td><td>(Optional) Fully connected layer additional info </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="_n_e_fully_connected_layer_ex_8cpp_source.html#l00164">164</a> of file <a class="el" href="_n_e_fully_connected_layer_ex_8cpp_source.html">NEFullyConnectedLayerEx.cpp</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  167</span>{</div>
<div class="line"><span class="lineno">  168</span>  <span class="comment">// Perform validate step</span></div>
<div class="line"><span class="lineno">  169</span>  ARM_COMPUTE_ERROR_ON_NULLPTR(input, weights, output);</div>
<div class="line"><span class="lineno">  170</span>  ARM_COMPUTE_ERROR_THROW_ON(<a class="code hl_function" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html#aea91ae4c26ee0e042aabb4787269b59b">NEFullyConnectedLayerEx::validate</a>(</div>
<div class="line"><span class="lineno">  171</span>    <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;info(), weights-&gt;info(), biases != <span class="keyword">nullptr</span> ? biases-&gt;info() : <span class="keyword">nullptr</span>, <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">output</a>-&gt;info(),</div>
<div class="line"><span class="lineno">  172</span>    fc_info));</div>
<div class="line"><span class="lineno">  173</span> </div>
<div class="line"><span class="lineno">  174</span>  _are_weights_converted = <span class="keyword">true</span>;</div>
<div class="line"><span class="lineno">  175</span>  _are_weights_reshaped = fc_info.transpose_weights ? fc_info.are_weights_reshaped : <span class="keyword">true</span>;</div>
<div class="line"><span class="lineno">  176</span>  _is_fc_after_conv = <span class="keyword">true</span>;</div>
<div class="line"><span class="lineno">  177</span>  _accumulate_biases = <span class="keyword">false</span>;</div>
<div class="line"><span class="lineno">  178</span>  _is_quantized = is_data_type_quantized_asymmetric(<a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;info()-&gt;data_type());</div>
<div class="line"><span class="lineno">  179</span>  _original_weights = weights;</div>
<div class="line"><span class="lineno">  180</span> </div>
<div class="line"><span class="lineno">  181</span>  <span class="comment">// Configure gemmlowp output</span></div>
<div class="line"><span class="lineno">  182</span>  <span class="keywordflow">if</span> (_is_quantized)</div>
<div class="line"><span class="lineno">  183</span>  {</div>
<div class="line"><span class="lineno">  184</span>    _gemmlowp_output.allocator()-&gt;init(</div>
<div class="line"><span class="lineno">  185</span>      <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">output</a>-&gt;info()-&gt;clone()-&gt;set_is_resizable(<span class="keyword">true</span>).reset_padding().set_data_type(DataType::S32));</div>
<div class="line"><span class="lineno">  186</span>  }</div>
<div class="line"><span class="lineno">  187</span> </div>
<div class="line"><span class="lineno">  188</span>  <span class="comment">// Configure accumulate biases kernel for non quantized asymmetric types</span></div>
<div class="line"><span class="lineno">  189</span>  <span class="keywordflow">if</span> (biases != <span class="keyword">nullptr</span> &amp;&amp; !_is_quantized)</div>
<div class="line"><span class="lineno">  190</span>  {</div>
<div class="line"><span class="lineno">  191</span>    _accumulate_biases = <span class="keyword">true</span>;</div>
<div class="line"><span class="lineno">  192</span> </div>
<div class="line"><span class="lineno">  193</span>    <span class="comment">// Configure accumulate biases kernel</span></div>
<div class="line"><span class="lineno">  194</span>    _accumulate_biases_kernel.<a class="code hl_function" href="classarm__compute_1_1_n_e_g_e_m_m_matrix_accumulate_biases_kernel.html#aadd2d8a6457eafa93cdd0d7cae8ad0f4">configure</a>(output, biases);</div>
<div class="line"><span class="lineno">  195</span>  }</div>
<div class="line"><span class="lineno">  196</span> </div>
<div class="line"><span class="lineno">  197</span>  <span class="comment">// With the Fully Connected layer we can have 4 different cases:</span></div>
<div class="line"><span class="lineno">  198</span>  <span class="comment">//  1) Convolution layer -&gt; Fully Connected layer without batches</span></div>
<div class="line"><span class="lineno">  199</span>  <span class="comment">//  2) Fully Connected layer -&gt; Fully Connected layer without batches</span></div>
<div class="line"><span class="lineno">  200</span>  <span class="comment">//  3) Convolution layer -&gt; Fully Connected layer with batches</span></div>
<div class="line"><span class="lineno">  201</span>  <span class="comment">//  4) Fully Connected layer -&gt; Fully Connected layer with batches</span></div>
<div class="line"><span class="lineno">  202</span> </div>
<div class="line"><span class="lineno">  203</span>  <span class="keyword">const</span> ITensor *weights_to_use = weights;</div>
<div class="line"><span class="lineno">  204</span> </div>
<div class="line"><span class="lineno">  205</span>  <span class="comment">// Check if we have a fully connected layer with batches</span></div>
<div class="line"><span class="lineno">  206</span>  <span class="keyword">const</span> <span class="keywordtype">bool</span> is_batched_fc_layer = <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">output</a>-&gt;info()-&gt;dimension(1) &gt; 1;</div>
<div class="line"><span class="lineno">  207</span>  <span class="keywordflow">if</span> (is_batched_fc_layer)</div>
<div class="line"><span class="lineno">  208</span>  {</div>
<div class="line"><span class="lineno">  209</span>    _is_fc_after_conv =</div>
<div class="line"><span class="lineno">  210</span>      (TensorShape::num_max_dimensions &gt;= 4) &amp;&amp;</div>
<div class="line"><span class="lineno">  211</span>      (std::equal(<a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;info()-&gt;tensor_shape().cbegin() + 3, <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;info()-&gt;tensor_shape().cend(),</div>
<div class="line"><span class="lineno">  212</span>                  <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">output</a>-&gt;info()-&gt;tensor_shape().cbegin() + 1));</div>
<div class="line"><span class="lineno">  213</span>  }</div>
<div class="line"><span class="lineno">  214</span>  <span class="keywordflow">else</span></div>
<div class="line"><span class="lineno">  215</span>  {</div>
<div class="line"><span class="lineno">  216</span>    _is_fc_after_conv = <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;info()-&gt;num_dimensions() &gt; 1;</div>
<div class="line"><span class="lineno">  217</span>  }</div>
<div class="line"><span class="lineno">  218</span> </div>
<div class="line"><span class="lineno">  219</span>  <span class="comment">// Reshape weights if needed</span></div>
<div class="line"><span class="lineno">  220</span>  <span class="keywordflow">if</span> (!_are_weights_reshaped)</div>
<div class="line"><span class="lineno">  221</span>  {</div>
<div class="line"><span class="lineno">  222</span>    <span class="comment">// Reshape the weights</span></div>
<div class="line"><span class="lineno">  223</span>    _reshape_weights_function.configure(weights, &amp;_reshape_weights_output);</div>
<div class="line"><span class="lineno">  224</span>    weights_to_use = &amp;_reshape_weights_output;</div>
<div class="line"><span class="lineno">  225</span>  }</div>
<div class="line"><span class="lineno">  226</span> </div>
<div class="line"><span class="lineno">  227</span>  <span class="comment">// Convert weights if needed</span></div>
<div class="line"><span class="lineno">  228</span>  <span class="keywordflow">if</span> (_is_fc_after_conv &amp;&amp; (<a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;info()-&gt;data_layout() != fc_info.weights_trained_layout))</div>
<div class="line"><span class="lineno">  229</span>  {</div>
<div class="line"><span class="lineno">  230</span>    <span class="comment">// Convert weights</span></div>
<div class="line"><span class="lineno">  231</span>    _convert_weights.configure(weights_to_use, &amp;_converted_weights_output,</div>
<div class="line"><span class="lineno">  232</span>                               <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;info()-&gt;tensor_shape(), fc_info.weights_trained_layout);</div>
<div class="line"><span class="lineno">  233</span> </div>
<div class="line"><span class="lineno">  234</span>    weights_to_use = &amp;_converted_weights_output;</div>
<div class="line"><span class="lineno">  235</span>    _are_weights_converted = <span class="keyword">false</span>;</div>
<div class="line"><span class="lineno">  236</span>  }</div>
<div class="line"><span class="lineno">  237</span> </div>
<div class="line"><span class="lineno">  238</span>  ITensor *tmp_output = (_is_quantized) ? &amp;_gemmlowp_output : output;</div>
<div class="line"><span class="lineno">  239</span>  <span class="keywordflow">if</span> (_is_fc_after_conv)</div>
<div class="line"><span class="lineno">  240</span>  {</div>
<div class="line"><span class="lineno">  241</span>    <span class="comment">// Fully Connected layer after a Convolution Layer without batches</span></div>
<div class="line"><span class="lineno">  242</span>    configure_conv_fc(input, weights_to_use, tmp_output);</div>
<div class="line"><span class="lineno">  243</span>  }</div>
<div class="line"><span class="lineno">  244</span>  <span class="keywordflow">else</span></div>
<div class="line"><span class="lineno">  245</span>  {</div>
<div class="line"><span class="lineno">  246</span>    <span class="comment">// Fully Connected layer after a Fully Connected Layer without batches</span></div>
<div class="line"><span class="lineno">  247</span>    configure_fc_fc(input, weights_to_use, tmp_output);</div>
<div class="line"><span class="lineno">  248</span>  }</div>
<div class="line"><span class="lineno">  249</span> </div>
<div class="line"><span class="lineno">  250</span>  <span class="comment">// Configure output stage for asymmetric quantized types</span></div>
<div class="line"><span class="lineno">  251</span>  <span class="keywordflow">if</span> (_is_quantized)</div>
<div class="line"><span class="lineno">  252</span>  {</div>
<div class="line"><span class="lineno">  253</span>    <span class="keywordtype">float</span> multiplier = <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;info()-&gt;quantization_info().uniform().scale *</div>
<div class="line"><span class="lineno">  254</span>                       weights-&gt;info()-&gt;quantization_info().uniform().scale /</div>
<div class="line"><span class="lineno">  255</span>                       <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">output</a>-&gt;info()-&gt;quantization_info().uniform().scale;</div>
<div class="line"><span class="lineno">  256</span>    <span class="keywordtype">int</span> output_multiplier;</div>
<div class="line"><span class="lineno">  257</span>    <span class="keywordtype">int</span> output_shift;</div>
<div class="line"><span class="lineno">  258</span>    quantization::calculate_quantized_multiplier_less_than_one(multiplier, &amp;output_multiplier,</div>
<div class="line"><span class="lineno">  259</span>                                                               &amp;output_shift);</div>
<div class="line"><span class="lineno">  260</span>    _gemmlowp_output_stage.configure(&amp;_gemmlowp_output, biases, output, output_multiplier,</div>
<div class="line"><span class="lineno">  261</span>                                     output_shift,</div>
<div class="line"><span class="lineno">  262</span>                                     <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">output</a>-&gt;info()-&gt;quantization_info().uniform().offset);</div>
<div class="line"><span class="lineno">  263</span>    _gemmlowp_output.allocator()-&gt;allocate();</div>
<div class="line"><span class="lineno">  264</span>  }</div>
<div class="line"><span class="lineno">  265</span> </div>
<div class="line"><span class="lineno">  266</span>  _are_weights_reshaped = _are_weights_reshaped || fc_info.retain_internal_weights;</div>
<div class="line"><span class="lineno">  267</span>}</div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_fully_connected_layer_ex_html_aea91ae4c26ee0e042aabb4787269b59b"><div class="ttname"><a href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html#aea91ae4c26ee0e042aabb4787269b59b">arm_compute::NEFullyConnectedLayerEx::validate</a></div><div class="ttdeci">static Status validate(const ITensorInfo *input, const ITensorInfo *weights, const ITensorInfo *biases, const ITensorInfo *output, FullyConnectedLayerInfo fc_info=FullyConnectedLayerInfo())</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_fully_connected_layer_ex_8cpp_source.html#l00269">NEFullyConnectedLayerEx.cpp:269</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_g_e_m_m_matrix_accumulate_biases_kernel_html_aadd2d8a6457eafa93cdd0d7cae8ad0f4"><div class="ttname"><a href="classarm__compute_1_1_n_e_g_e_m_m_matrix_accumulate_biases_kernel.html#aadd2d8a6457eafa93cdd0d7cae8ad0f4">arm_compute::NEGEMMMatrixAccumulateBiasesKernel::configure</a></div><div class="ttdeci">void configure(ITensor *accum, const ITensor *biases)</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_g_e_m_m_matrix_accumulate_biases_kernel_8cpp_source.html#l00109">NEGEMMMatrixAccumulateBiasesKernel.cpp:109</a></div></div>
<div class="ttc" id="anamespacegen__h5__explicit__inputs_html_a48dd077479f23bb4552c2d7d6a7a4d37"><div class="ttname"><a href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">gen_h5_explicit_inputs.input</a></div><div class="ttdeci">input</div><div class="ttdef"><b>Definition:</b> <a href="gen__h5__explicit__inputs_8py_source.html#l00034">gen_h5_explicit_inputs.py:34</a></div></div>
<div class="ttc" id="anamespacegen__h5__explicit__inputs_html_acd1aa9ba45d45c6b619b723e6e34c576"><div class="ttname"><a href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">gen_h5_explicit_inputs.output</a></div><div class="ttdeci">output</div><div class="ttdef"><b>Definition:</b> <a href="gen__h5__explicit__inputs_8py_source.html#l00035">gen_h5_explicit_inputs.py:35</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="_n_e_g_e_m_m_matrix_accumulate_biases_kernel_8cpp_source.html#l00109">arm_compute::NEGEMMMatrixAccumulateBiasesKernel::configure()</a>, and <a class="el" href="_n_e_fully_connected_layer_ex_8cpp_source.html#l00269">validate()</a>.</p>

</div>
</div>
<a id="abd5869dbaf2c3d8ea9d0b6e33f4eb59a" name="abd5869dbaf2c3d8ea9d0b6e33f4eb59a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abd5869dbaf2c3d8ea9d0b6e33f4eb59a">&#9670;&#160;</a></span>operator=() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html">NEFullyConnectedLayerEx</a> &amp; arm_compute::NEFullyConnectedLayerEx::operator= </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html">NEFullyConnectedLayerEx</a> &amp;&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">delete</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p >Prevent instances of this class from being copied (As this class contains pointers) </p>

</div>
</div>
<a id="ab4af80fa136da5741db9f29ae6907533" name="ab4af80fa136da5741db9f29ae6907533"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab4af80fa136da5741db9f29ae6907533">&#9670;&#160;</a></span>operator=() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html">NEFullyConnectedLayerEx</a> &amp; arm_compute::NEFullyConnectedLayerEx::operator= </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html">NEFullyConnectedLayerEx</a> &amp;&amp;&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">delete</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p >Default move assignment operator </p>

<p class="reference">References <a class="el" href="_n_e_fully_connected_layer_ex_8cpp_source.html#l00269">validate()</a>.</p>

</div>
</div>
<a id="a5110a87cacb9c69360097e0b6781512a" name="a5110a87cacb9c69360097e0b6781512a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5110a87cacb9c69360097e0b6781512a">&#9670;&#160;</a></span>prepare()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void arm_compute::NEFullyConnectedLayerEx::prepare </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="_n_e_fully_connected_layer_ex_8cpp_source.html#l00441">441</a> of file <a class="el" href="_n_e_fully_connected_layer_ex_8cpp_source.html">NEFullyConnectedLayerEx.cpp</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  442</span>{</div>
<div class="line"><span class="lineno">  443</span><span class="preprocessor">#if 0 </span><span class="comment">// TODO Remove this block</span></div>
<div class="line"><span class="lineno">  444</span>  <span class="keywordflow">if</span> (!_is_prepared)</div>
<div class="line"><span class="lineno">  445</span>  {</div>
<div class="line"><span class="lineno">  446</span>    ARM_COMPUTE_ERROR_ON(!_original_weights-&gt;is_used());</div>
<div class="line"><span class="lineno">  447</span> </div>
<div class="line"><span class="lineno">  448</span>    <span class="keyword">auto</span> release_unused = [](<a class="code hl_class" href="class_tensor.html">Tensor</a> *<a class="code hl_variable" href="namespacejpeg2hdf5.html#ac7eea56215106b0908497982f6eed453">w</a>) {</div>
<div class="line"><span class="lineno">  449</span>      <span class="keywordflow">if</span> (!<a class="code hl_variable" href="namespacejpeg2hdf5.html#ac7eea56215106b0908497982f6eed453">w</a>-&gt;is_used())</div>
<div class="line"><span class="lineno">  450</span>      {</div>
<div class="line"><span class="lineno">  451</span>        <a class="code hl_variable" href="namespacejpeg2hdf5.html#ac7eea56215106b0908497982f6eed453">w</a>-&gt;allocator()-&gt;free();</div>
<div class="line"><span class="lineno">  452</span>      }</div>
<div class="line"><span class="lineno">  453</span>    };</div>
<div class="line"><span class="lineno">  454</span> </div>
<div class="line"><span class="lineno">  455</span>    <span class="comment">// Pointer to current weights</span></div>
<div class="line"><span class="lineno">  456</span>    <span class="keyword">const</span> ITensor *cur_weights = _original_weights;</div>
<div class="line"><span class="lineno">  457</span> </div>
<div class="line"><span class="lineno">  458</span>    <span class="comment">// Reshape of the weights (happens only once)</span></div>
<div class="line"><span class="lineno">  459</span>    <span class="keywordflow">if</span> (!_are_weights_reshaped)</div>
<div class="line"><span class="lineno">  460</span>    {</div>
<div class="line"><span class="lineno">  461</span>      <span class="comment">// Run reshape weights kernel and mark weights as unused</span></div>
<div class="line"><span class="lineno">  462</span>      _reshape_weights_output.allocator()-&gt;allocate();</div>
<div class="line"><span class="lineno">  463</span>      _reshape_weights_function.run();</div>
<div class="line"><span class="lineno">  464</span> </div>
<div class="line"><span class="lineno">  465</span>      cur_weights-&gt;mark_as_unused();</div>
<div class="line"><span class="lineno">  466</span>      cur_weights = &amp;_reshape_weights_output;</div>
<div class="line"><span class="lineno">  467</span>      _are_weights_reshaped = <span class="keyword">true</span>;</div>
<div class="line"><span class="lineno">  468</span>    }</div>
<div class="line"><span class="lineno">  469</span> </div>
<div class="line"><span class="lineno">  470</span>    <span class="comment">// Convert weights if needed (happens only once)</span></div>
<div class="line"><span class="lineno">  471</span>    <span class="keywordflow">if</span> (!_are_weights_converted)</div>
<div class="line"><span class="lineno">  472</span>    {</div>
<div class="line"><span class="lineno">  473</span>      _converted_weights_output.allocator()-&gt;allocate();</div>
<div class="line"><span class="lineno">  474</span>      _convert_weights.run();</div>
<div class="line"><span class="lineno">  475</span> </div>
<div class="line"><span class="lineno">  476</span>      cur_weights-&gt;mark_as_unused();</div>
<div class="line"><span class="lineno">  477</span>      _are_weights_converted = <span class="keyword">true</span>;</div>
<div class="line"><span class="lineno">  478</span>    }</div>
<div class="line"><span class="lineno">  479</span> </div>
<div class="line"><span class="lineno">  480</span>    <span class="comment">// Release reshaped weights if unused</span></div>
<div class="line"><span class="lineno">  481</span>    release_unused(&amp;_reshape_weights_output);</div>
<div class="line"><span class="lineno">  482</span> </div>
<div class="line"><span class="lineno">  483</span>    <span class="comment">// Prepare GEMM prepare and release unused weights</span></div>
<div class="line"><span class="lineno">  484</span>    <span class="keywordflow">if</span> (!_is_quantized)</div>
<div class="line"><span class="lineno">  485</span>    {</div>
<div class="line"><span class="lineno">  486</span>      _mm_gemm.prepare();</div>
<div class="line"><span class="lineno">  487</span>    }</div>
<div class="line"><span class="lineno">  488</span> </div>
<div class="line"><span class="lineno">  489</span>    <span class="comment">// Release converted weights if unused</span></div>
<div class="line"><span class="lineno">  490</span>    release_unused(&amp;_reshape_weights_output);</div>
<div class="line"><span class="lineno">  491</span>    release_unused(&amp;_converted_weights_output);</div>
<div class="line"><span class="lineno">  492</span> </div>
<div class="line"><span class="lineno">  493</span>    _is_prepared = <span class="keyword">true</span>;</div>
<div class="line"><span class="lineno">  494</span>  }</div>
<div class="line"><span class="lineno">  495</span><span class="preprocessor">#endif</span></div>
<div class="line"><span class="lineno">  496</span>}</div>
<div class="ttc" id="aclass_tensor_html"><div class="ttname"><a href="class_tensor.html">Tensor</a></div><div class="ttdef"><b>Definition:</b> <a href="tensor__gen_8cpp_source.html#l00031">tensor_gen.cpp:32</a></div></div>
<div class="ttc" id="anamespacejpeg2hdf5_html_ac7eea56215106b0908497982f6eed453"><div class="ttname"><a href="namespacejpeg2hdf5.html#ac7eea56215106b0908497982f6eed453">jpeg2hdf5.w</a></div><div class="ttdeci">w</div><div class="ttdef"><b>Definition:</b> <a href="jpeg2hdf5_8py_source.html#l00102">jpeg2hdf5.py:102</a></div></div>
</div><!-- fragment -->
</div>
</div>
<a id="ac6e7d2d4cb03dfe15bdde9a6308a2146" name="ac6e7d2d4cb03dfe15bdde9a6308a2146"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac6e7d2d4cb03dfe15bdde9a6308a2146">&#9670;&#160;</a></span>run()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void arm_compute::NEFullyConnectedLayerEx::run </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="_n_e_fully_connected_layer_ex_8cpp_source.html#l00372">372</a> of file <a class="el" href="_n_e_fully_connected_layer_ex_8cpp_source.html">NEFullyConnectedLayerEx.cpp</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  373</span>{</div>
<div class="line"><span class="lineno">  374</span>  <span class="keywordflow">if</span> (!_is_prepared)</div>
<div class="line"><span class="lineno">  375</span>  {</div>
<div class="line"><span class="lineno">  376</span>    <span class="keywordflow">if</span> (!_are_weights_reshaped)</div>
<div class="line"><span class="lineno">  377</span>    {</div>
<div class="line"><span class="lineno">  378</span>      _reshape_weights_output.allocator()-&gt;allocate();</div>
<div class="line"><span class="lineno">  379</span>    }</div>
<div class="line"><span class="lineno">  380</span>    <span class="keywordflow">if</span> (!_are_weights_converted)</div>
<div class="line"><span class="lineno">  381</span>    {</div>
<div class="line"><span class="lineno">  382</span>      _converted_weights_output.allocator()-&gt;allocate();</div>
<div class="line"><span class="lineno">  383</span>    }</div>
<div class="line"><span class="lineno">  384</span>    _is_prepared = <span class="keyword">true</span>;</div>
<div class="line"><span class="lineno">  385</span>  }</div>
<div class="line"><span class="lineno">  386</span> </div>
<div class="line"><span class="lineno">  387</span>  {</div>
<div class="line"><span class="lineno">  388</span>    ARM_COMPUTE_ERROR_ON(!_original_weights-&gt;is_used());</div>
<div class="line"><span class="lineno">  389</span> </div>
<div class="line"><span class="lineno">  390</span>    <span class="comment">// Reshape of the weights</span></div>
<div class="line"><span class="lineno">  391</span>    <span class="keywordflow">if</span> (!_are_weights_reshaped)</div>
<div class="line"><span class="lineno">  392</span>    {</div>
<div class="line"><span class="lineno">  393</span>      _reshape_weights_function.run();</div>
<div class="line"><span class="lineno">  394</span>    }</div>
<div class="line"><span class="lineno">  395</span> </div>
<div class="line"><span class="lineno">  396</span>    <span class="comment">// Convert weights if needed</span></div>
<div class="line"><span class="lineno">  397</span>    <span class="keywordflow">if</span> (!_are_weights_converted)</div>
<div class="line"><span class="lineno">  398</span>    {</div>
<div class="line"><span class="lineno">  399</span>      _convert_weights.run();</div>
<div class="line"><span class="lineno">  400</span>    }</div>
<div class="line"><span class="lineno">  401</span> </div>
<div class="line"><span class="lineno">  402</span>    <span class="comment">// Prepare GEMM prepare</span></div>
<div class="line"><span class="lineno">  403</span>    <span class="keywordflow">if</span> (!_is_quantized)</div>
<div class="line"><span class="lineno">  404</span>    {</div>
<div class="line"><span class="lineno">  405</span>      _mm_gemm.prepare();</div>
<div class="line"><span class="lineno">  406</span>    }</div>
<div class="line"><span class="lineno">  407</span>  }</div>
<div class="line"><span class="lineno">  408</span> </div>
<div class="line"><span class="lineno">  409</span>  MemoryGroupResourceScope scope_mg(_memory_group);</div>
<div class="line"><span class="lineno">  410</span> </div>
<div class="line"><span class="lineno">  411</span>  <span class="comment">// Linearize input if it comes from a convolutional layer</span></div>
<div class="line"><span class="lineno">  412</span>  <span class="keywordflow">if</span> (_is_fc_after_conv)</div>
<div class="line"><span class="lineno">  413</span>  {</div>
<div class="line"><span class="lineno">  414</span>    _flatten_kernel.run();</div>
<div class="line"><span class="lineno">  415</span>  }</div>
<div class="line"><span class="lineno">  416</span> </div>
<div class="line"><span class="lineno">  417</span>  <span class="comment">// Run matrix multiply</span></div>
<div class="line"><span class="lineno">  418</span>  <span class="keywordflow">if</span> (_is_quantized)</div>
<div class="line"><span class="lineno">  419</span>  {</div>
<div class="line"><span class="lineno">  420</span>    _mm_gemmlowp.run();</div>
<div class="line"><span class="lineno">  421</span>  }</div>
<div class="line"><span class="lineno">  422</span>  <span class="keywordflow">else</span></div>
<div class="line"><span class="lineno">  423</span>  {</div>
<div class="line"><span class="lineno">  424</span>    _mm_gemm.run();</div>
<div class="line"><span class="lineno">  425</span>  }</div>
<div class="line"><span class="lineno">  426</span> </div>
<div class="line"><span class="lineno">  427</span>  <span class="comment">// Accumulate biases if provided</span></div>
<div class="line"><span class="lineno">  428</span>  <span class="keywordflow">if</span> (_is_quantized)</div>
<div class="line"><span class="lineno">  429</span>  {</div>
<div class="line"><span class="lineno">  430</span>    _gemmlowp_output_stage.run();</div>
<div class="line"><span class="lineno">  431</span>  }</div>
<div class="line"><span class="lineno">  432</span>  <span class="keywordflow">else</span></div>
<div class="line"><span class="lineno">  433</span>  {</div>
<div class="line"><span class="lineno">  434</span>    <span class="keywordflow">if</span> (_accumulate_biases)</div>
<div class="line"><span class="lineno">  435</span>    {</div>
<div class="line"><span class="lineno">  436</span>      NEScheduler::get().schedule(&amp;_accumulate_biases_kernel, Window::DimY);</div>
<div class="line"><span class="lineno">  437</span>    }</div>
<div class="line"><span class="lineno">  438</span>  }</div>
<div class="line"><span class="lineno">  439</span>}</div>
</div><!-- fragment -->
</div>
</div>
<a id="aea91ae4c26ee0e042aabb4787269b59b" name="aea91ae4c26ee0e042aabb4787269b59b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aea91ae4c26ee0e042aabb4787269b59b">&#9670;&#160;</a></span>validate()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Status arm_compute::NEFullyConnectedLayerEx::validate </td>
          <td>(</td>
          <td class="paramtype">const ITensorInfo *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const ITensorInfo *&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const ITensorInfo *&#160;</td>
          <td class="paramname"><em>biases</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const ITensorInfo *&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">FullyConnectedLayerInfo&#160;</td>
          <td class="paramname"><em>fc_info</em> = <code>FullyConnectedLayerInfo()</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p >Static function to check if given info will lead to a valid configuration of <a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html">NEFullyConnectedLayerEx</a></p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">input</td><td>Source tensor info. Data type supported: QASYMM8/F16/F32. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">weights</td><td>Weights tensor info. The weights must be 2 dimensional. If this function is called after a Convolution Layer, the (transposed) weights will have as many rows as the product of the first 3 input's dimensions. If it is called after another FullyConnected Layer, the (transposed) weights will have as many rows as the input's first dimension. Data type supported: Same as <code>input</code>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">biases</td><td>Bias tensor info. Can be nullptr. Data type supported:Same as <code>input</code>. </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">output</td><td>Destination tensor info. Its shape should be equal to the output of a matrix multiplication between:<ul>
<li>The output of im2col on the input and the (transposed) 2D weights, if the function is called after a Convolution Layer</li>
<li>The input tensor and the (transposed) 2D weights, if the function is called after another FullyConnected Layer. Data type supported: Same as <code>input</code>. </li>
</ul>
</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">fc_info</td><td>(Optional) Fully connected layer additional info</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a status </dd></dl>

<p class="definition">Definition at line <a class="el" href="_n_e_fully_connected_layer_ex_8cpp_source.html#l00269">269</a> of file <a class="el" href="_n_e_fully_connected_layer_ex_8cpp_source.html">NEFullyConnectedLayerEx.cpp</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  272</span>{</div>
<div class="line"><span class="lineno">  273</span>  ARM_COMPUTE_UNUSED(fc_info.retain_internal_weights);</div>
<div class="line"><span class="lineno">  274</span>  ARM_COMPUTE_RETURN_ERROR_ON_NULLPTR(input, weights, output);</div>
<div class="line"><span class="lineno">  275</span>  ARM_COMPUTE_RETURN_ERROR_ON_DATA_TYPE_CHANNEL_NOT_IN(input, 1, DataType::QASYMM8, DataType::F16,</div>
<div class="line"><span class="lineno">  276</span>                                                       DataType::F32);</div>
<div class="line"><span class="lineno">  277</span>  ARM_COMPUTE_RETURN_ERROR_ON_MISMATCHING_DATA_TYPES(input, weights, output);</div>
<div class="line"><span class="lineno">  278</span>  ARM_COMPUTE_RETURN_ERROR_ON(weights-&gt;num_dimensions() &gt; 2);</div>
<div class="line"><span class="lineno">  279</span> </div>
<div class="line"><span class="lineno">  280</span>  <span class="keywordtype">bool</span> weights_reshaped = fc_info.transpose_weights ? fc_info.are_weights_reshaped : <span class="keyword">true</span>;</div>
<div class="line"><span class="lineno">  281</span>  <span class="keywordtype">bool</span> is_fc_after_conv = <span class="keyword">true</span>;</div>
<div class="line"><span class="lineno">  282</span>  <span class="keywordtype">bool</span> <a class="code hl_function" href="namespaceluci.html#a92c776392acf3d65c602775dcf6078e8">is_quantized</a> = is_data_type_quantized_asymmetric(<a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;data_type());</div>
<div class="line"><span class="lineno">  283</span> </div>
<div class="line"><span class="lineno">  284</span>  <span class="keyword">const</span> ITensorInfo &amp;flatten_input =</div>
<div class="line"><span class="lineno">  285</span>    TensorInfo(<a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;clone()-&gt;set_is_resizable(<span class="keyword">true</span>).reset_padding().set_tensor_shape(</div>
<div class="line"><span class="lineno">  286</span>      compute_flatten_shape(input)));</div>
<div class="line"><span class="lineno">  287</span>  <span class="keyword">const</span> ITensorInfo &amp;reshaped_weights =</div>
<div class="line"><span class="lineno">  288</span>    TensorInfo(weights-&gt;clone()-&gt;set_is_resizable(<span class="keyword">true</span>).reset_padding().set_tensor_shape(</div>
<div class="line"><span class="lineno">  289</span>      compute_transposed_shape(*weights)));</div>
<div class="line"><span class="lineno">  290</span>  <span class="keyword">const</span> ITensorInfo &amp;converted_weights =</div>
<div class="line"><span class="lineno">  291</span>    weights_reshaped ? TensorInfo(weights-&gt;clone()-&gt;set_is_resizable(<span class="keyword">true</span>).reset_padding())</div>
<div class="line"><span class="lineno">  292</span>                     : TensorInfo(*reshaped_weights.<a class="code hl_function" href="namespaceluci.html#a8984ba83d6f0e6d0dc99b25ee3b5d04b">clone</a>());</div>
<div class="line"><span class="lineno">  293</span>  <span class="keyword">const</span> ITensorInfo &amp;gemmlowp_output = TensorInfo(</div>
<div class="line"><span class="lineno">  294</span>    <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">output</a>-&gt;clone()-&gt;set_is_resizable(<span class="keyword">true</span>).reset_padding().set_data_type(DataType::S32));</div>
<div class="line"><span class="lineno">  295</span> </div>
<div class="line"><span class="lineno">  296</span>  <span class="comment">// Configure accumulate biases kernel for non quantized asymmetric types</span></div>
<div class="line"><span class="lineno">  297</span>  <span class="keywordflow">if</span> (biases != <span class="keyword">nullptr</span> &amp;&amp; !is_quantized)</div>
<div class="line"><span class="lineno">  298</span>  {</div>
<div class="line"><span class="lineno">  299</span>    ARM_COMPUTE_RETURN_ERROR_ON_MISMATCHING_DATA_TYPES(input, biases);</div>
<div class="line"><span class="lineno">  300</span>    ARM_COMPUTE_RETURN_ON_ERROR(<a class="code hl_function" href="classarm__compute_1_1_n_e_g_e_m_m_matrix_accumulate_biases_kernel.html#ac1e699389d0d66079432ea110b2682a9">NEGEMMMatrixAccumulateBiasesKernel::validate</a>(output, biases));</div>
<div class="line"><span class="lineno">  301</span>  }</div>
<div class="line"><span class="lineno">  302</span> </div>
<div class="line"><span class="lineno">  303</span>  <span class="comment">// With the Fully Connected layer we can have 4 different cases:</span></div>
<div class="line"><span class="lineno">  304</span>  <span class="comment">//  1) Convolution layer -&gt; Fully Connected layer without batches</span></div>
<div class="line"><span class="lineno">  305</span>  <span class="comment">//  2) Fully Connected layer -&gt; Fully Connected layer without batches</span></div>
<div class="line"><span class="lineno">  306</span>  <span class="comment">//  3) Convolution layer -&gt; Fully Connected layer with batches</span></div>
<div class="line"><span class="lineno">  307</span>  <span class="comment">//  4) Fully Connected layer -&gt; Fully Connected layer with batches</span></div>
<div class="line"><span class="lineno">  308</span> </div>
<div class="line"><span class="lineno">  309</span>  <span class="keyword">const</span> ITensorInfo *input_to_use = <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>;</div>
<div class="line"><span class="lineno">  310</span>  <span class="keyword">const</span> ITensorInfo *weights_to_use = weights;</div>
<div class="line"><span class="lineno">  311</span>  <span class="keyword">const</span> ITensorInfo *tmp_output = (<a class="code hl_function" href="namespaceluci.html#a92c776392acf3d65c602775dcf6078e8">is_quantized</a>) ? &amp;gemmlowp_output : output;</div>
<div class="line"><span class="lineno">  312</span> </div>
<div class="line"><span class="lineno">  313</span>  <span class="comment">// Check if we have a fully connected layer with batches</span></div>
<div class="line"><span class="lineno">  314</span>  <span class="keyword">const</span> <span class="keywordtype">bool</span> is_batched_fc_layer = <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">output</a>-&gt;dimension(1) &gt; 1;</div>
<div class="line"><span class="lineno">  315</span> </div>
<div class="line"><span class="lineno">  316</span>  <span class="keywordflow">if</span> (is_batched_fc_layer)</div>
<div class="line"><span class="lineno">  317</span>  {</div>
<div class="line"><span class="lineno">  318</span>    is_fc_after_conv = (TensorShape::num_max_dimensions &gt;= 4) &amp;&amp;</div>
<div class="line"><span class="lineno">  319</span>                       (std::equal(<a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;tensor_shape().cbegin() + 3, <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;tensor_shape().cend(),</div>
<div class="line"><span class="lineno">  320</span>                                   <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">output</a>-&gt;tensor_shape().cbegin() + 1));</div>
<div class="line"><span class="lineno">  321</span>  }</div>
<div class="line"><span class="lineno">  322</span>  <span class="keywordflow">else</span></div>
<div class="line"><span class="lineno">  323</span>  {</div>
<div class="line"><span class="lineno">  324</span>    is_fc_after_conv = <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;num_dimensions() &gt; 1;</div>
<div class="line"><span class="lineno">  325</span>  }</div>
<div class="line"><span class="lineno">  326</span> </div>
<div class="line"><span class="lineno">  327</span>  <span class="keywordflow">if</span> (!weights_reshaped)</div>
<div class="line"><span class="lineno">  328</span>  {</div>
<div class="line"><span class="lineno">  329</span>    <span class="comment">// Validate reshape weights kernel</span></div>
<div class="line"><span class="lineno">  330</span>    ARM_COMPUTE_RETURN_ON_ERROR(</div>
<div class="line"><span class="lineno">  331</span>      NEFullyConnectedLayerReshapeWeights::validate(weights, &amp;reshaped_weights));</div>
<div class="line"><span class="lineno">  332</span>    weights_to_use = &amp;reshaped_weights;</div>
<div class="line"><span class="lineno">  333</span>  }</div>
<div class="line"><span class="lineno">  334</span> </div>
<div class="line"><span class="lineno">  335</span>  <span class="keywordflow">if</span> (is_fc_after_conv &amp;&amp; (<a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;data_layout() != fc_info.weights_trained_layout))</div>
<div class="line"><span class="lineno">  336</span>  {</div>
<div class="line"><span class="lineno">  337</span>    <span class="comment">// Validate convert weights kernel</span></div>
<div class="line"><span class="lineno">  338</span>    ARM_COMPUTE_RETURN_ON_ERROR(NEConvertFullyConnectedWeights::validate(</div>
<div class="line"><span class="lineno">  339</span>      weights_to_use, &amp;converted_weights, <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;tensor_shape(), fc_info.weights_trained_layout));</div>
<div class="line"><span class="lineno">  340</span>    weights_to_use = &amp;converted_weights;</div>
<div class="line"><span class="lineno">  341</span>  }</div>
<div class="line"><span class="lineno">  342</span> </div>
<div class="line"><span class="lineno">  343</span>  <span class="keywordflow">if</span> (is_fc_after_conv)</div>
<div class="line"><span class="lineno">  344</span>  {</div>
<div class="line"><span class="lineno">  345</span>    <span class="comment">// Fully Connected layer after a Convolution Layer without batches</span></div>
<div class="line"><span class="lineno">  346</span>    ARM_COMPUTE_RETURN_ERROR_ON(</div>
<div class="line"><span class="lineno">  347</span>      (weights_to_use-&gt;dimension(1) !=</div>
<div class="line"><span class="lineno">  348</span>       (<a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;dimension(0) * <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;dimension(1) * <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;dimension(2))));</div>
<div class="line"><span class="lineno">  349</span> </div>
<div class="line"><span class="lineno">  350</span>    <span class="comment">// Validate flatten kernel</span></div>
<div class="line"><span class="lineno">  351</span>    ARM_COMPUTE_RETURN_ON_ERROR(NEFlattenLayer::validate(input, &amp;flatten_input));</div>
<div class="line"><span class="lineno">  352</span>    input_to_use = &amp;flatten_input;</div>
<div class="line"><span class="lineno">  353</span>  }</div>
<div class="line"><span class="lineno">  354</span>  <span class="keywordflow">else</span></div>
<div class="line"><span class="lineno">  355</span>  {</div>
<div class="line"><span class="lineno">  356</span>    <span class="comment">// Fully Connected layer after a Fully Connected Layer without batches</span></div>
<div class="line"><span class="lineno">  357</span>    ARM_COMPUTE_RETURN_ERROR_ON(<a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;dimension(0) != weights_to_use-&gt;dimension(1));</div>
<div class="line"><span class="lineno">  358</span>  }</div>
<div class="line"><span class="lineno">  359</span>  <span class="comment">// Validate matrix multiply kernel</span></div>
<div class="line"><span class="lineno">  360</span>  ARM_COMPUTE_RETURN_ON_ERROR(validate_mm(*input_to_use, *weights_to_use, *tmp_output));</div>
<div class="line"><span class="lineno">  361</span> </div>
<div class="line"><span class="lineno">  362</span>  <span class="comment">// Validate output stage for asymmetric quantized types</span></div>
<div class="line"><span class="lineno">  363</span>  <span class="keywordflow">if</span> (is_quantized)</div>
<div class="line"><span class="lineno">  364</span>  {</div>
<div class="line"><span class="lineno">  365</span>    ARM_COMPUTE_RETURN_ON_ERROR(NEGEMMLowpQuantizeDownInt32ToUint8ScaleByFixedPoint::validate(</div>
<div class="line"><span class="lineno">  366</span>      &amp;gemmlowp_output, biases, output));</div>
<div class="line"><span class="lineno">  367</span>  }</div>
<div class="line"><span class="lineno">  368</span> </div>
<div class="line"><span class="lineno">  369</span>  <span class="keywordflow">return</span> Status{};</div>
<div class="line"><span class="lineno">  370</span>}</div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_g_e_m_m_matrix_accumulate_biases_kernel_html_ac1e699389d0d66079432ea110b2682a9"><div class="ttname"><a href="classarm__compute_1_1_n_e_g_e_m_m_matrix_accumulate_biases_kernel.html#ac1e699389d0d66079432ea110b2682a9">arm_compute::NEGEMMMatrixAccumulateBiasesKernel::validate</a></div><div class="ttdeci">static Status validate(const ITensorInfo *accum, const ITensorInfo *biases)</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_g_e_m_m_matrix_accumulate_biases_kernel_8cpp_source.html#l00125">NEGEMMMatrixAccumulateBiasesKernel.cpp:125</a></div></div>
<div class="ttc" id="anamespaceluci_html_a8984ba83d6f0e6d0dc99b25ee3b5d04b"><div class="ttname"><a href="namespaceluci.html#a8984ba83d6f0e6d0dc99b25ee3b5d04b">luci::clone</a></div><div class="ttdeci">luci::CircleConst * clone(luci::CircleConst *node)</div><div class="ttdoc">Return cloned object of CircleConst node.</div><div class="ttdef"><b>Definition:</b> <a href="service_2src_2_nodes_2_circle_const_8cpp_source.html#l00099">CircleConst.cpp:99</a></div></div>
<div class="ttc" id="anamespaceluci_html_a92c776392acf3d65c602775dcf6078e8"><div class="ttname"><a href="namespaceluci.html#a92c776392acf3d65c602775dcf6078e8">luci::is_quantized</a></div><div class="ttdeci">bool is_quantized(const CircleNode *node)</div><div class="ttdef"><b>Definition:</b> <a href="_quantization_utils_8cpp_source.html#l00028">QuantizationUtils.cpp:28</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="_n_e_g_e_m_m_matrix_accumulate_biases_kernel_8cpp_source.html#l00125">arm_compute::NEGEMMMatrixAccumulateBiasesKernel::validate()</a>.</p>

<p class="reference">Referenced by <a class="el" href="_n_e_fully_connected_layer_ex_8cpp_source.html#l00164">configure()</a>, and <a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html#ab4af80fa136da5741db9f29ae6907533">operator=()</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>compute/ARMComputeEx/arm_compute/runtime/NEON/functions/<a class="el" href="_n_e_fully_connected_layer_ex_8h_source.html">NEFullyConnectedLayerEx.h</a></li>
<li>compute/ARMComputeEx/src/runtime/NEON/functions/<a class="el" href="_n_e_fully_connected_layer_ex_8cpp_source.html">NEFullyConnectedLayerEx.cpp</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespacearm__compute.html">arm_compute</a></li><li class="navelem"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_layer_ex.html">NEFullyConnectedLayerEx</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.5 </li>
  </ul>
</div>
</body>
</html>
