; To activate a step (or task),
; set True for the step in [onecc] section and fill options in the corresponding section
[onecc]
; neural network model to circle
one-import-tf=False
one-import-tflite=False
one-import-bcq=False
one-import-onnx=True
; circle to circle with optimization
one-optimize=True
; circle to circle with quantization
one-quantize=True
; partition circle
one-partition=False
; package circle and metadata into nnpackage
one-pack=False
; generate code for backend
one-codegen=False
; profile
one-profile=False

[one-import-tf]
# mandatory
; pb file
input_path=
; circle file
output_path=
# optional
; v1 or v2
converter_version=v2
; graph_def(default), saved_model or keras_model
model_format=graph_def
# optional but mandatory for model_format=graph_def
; input tensor names of the input arrays, comma-separated
input_arrays=
; output tensor names of the input arrays, comma-separated
output_arrays=
; input shapes corresponding to --input_arrays, colon-separated.(ex:1,4,4,3:1,20,20,3)
input_shapes=

[one-import-tflite]
# mandatory
; tflite file
input_path=
; circle file
output_path=

[one-import-bcq]
# mandatory
; bcq file
input_path=
; circle file
output_path=
# optional
; v1 or v2
converter_version=v2
; graph_def(default), saved_model or keras_model
model_format=graph_def
# optional but mandatory for model_format=graph_def
; input tensor names of the input arrays, comma-separated
input_arrays=
; output tensor names of the input arrays, comma-separated
output_arrays=
; input shapes corresponding to --input_arrays, colon-separated.(ex:1,4,4,3:1,20,20,3)
input_shapes=

[one-import-onnx]
# mandatory
; onnx file
input_path=model_onnx.onnx
; circle file
output_path=model_onnx.circle
# optional
; True or False
unroll_rnn=
; True or False
unroll_lstm=

[one-optimize]
# mandatory
; circle file
input_path=model_onnx.circle
; circle file
output_path=model_onnx.opt.circle
# //TODO: Add available options

[one-quantize]
# mandatory
; circle file
input_path=model_onnx.opt.circle
; circle file
output_path=model_onnx.q8.circle
# optional arguments for quantization
; input data file (if not given, random data will be used for calibration)
input_data=
; h5/hdf5(default), list/filelist, or dir/directory
input_data_format=
; dtype of quantized model (uint8(default), int16)
quantized_dtype=uint8
; granularity of quantization (layer(default), channel)
granularity=layer
; dtype of model's input (uint8, int16, float32). Same with quantized_dtype by default.
input_type=uint8
; dtype of model's output (uint8, int16, float32). Same with quantized_dtype by default.
output_type=uint8

[one-partition]
# mandatory
; partition file which provides backend to assign
part_file=
; circle file
input_file=
# //TODO: Add available options

[one-pack]
# mandatory
; input path
input_path=
; output path
output_path=
# //TODO: Add available options

[one-codegen]
# mandatory
; backend name
backend=
; commands for each backend
command=

[one-profile]
# mandatory
; backend name
backend=
# //TODO: Add available options
