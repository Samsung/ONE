# This configuration file is used to configure the parameters and initial settings for ONE command driver.

# NOTE You must specify the parameters for the driver you want to run, 
#      and other options are left blank.
#
# NOTE Sometimes you need the intermediate output of each driver. 
#      You can get it by specifying each driver's output path(*_output_path), i.e., import_tf_output_path.

# input_path                    Path to input
input_path="/path/to/incepV3/inception_v3.pb"
# output_path                   Path to output
output_path="inception_v3.circle"

# driver to use
use_one_import_tf="true"
use_one_import_bcq="false"
use_one_import_tflite="false"
use_one_optimize="true"
use_one_quantize="false"
use_one_pack="true"
use_one_codegen="false"

# ----------------------------OPTIONS_FOR_EACH_DRIVER---------------------------- #

# ------------------------[one-import-tf, one-import-bcq]------------------------ #
# input_arrays                  Names of the input arrays, comma-separated
import_input_arrays="input"
# input_shapes                  Input shapes, colon-separated
import_input_shapes=""
# output_arrays                 Names of the output arrays, comma-separated
import_output_arrays="InceptionV3/Predictions/Reshape_1"
# v2                            Use TensorFlow 2.x interface (default is 1.x interface)
import_v2="false"
# import_tf_output_path         (Optional) Path to intermediate output of one-import-tf
import_tf_output_path=""
# import_bcq_output_path        (Optional) Path to intermeidate output of one-import-bcq
import_bcq_output_path=""

# ------------------------------[one-import-tflite]------------------------------ #
# import_tflite_output_path     (Optional) Path to intermediate output of one-import-tflite
import_tflite_output_path=""

# --------------------------------[one-optimize]--------------------------------- #
# all                           Enable all optimization algorithms
optimize_all="true"
# fuse_bcq                      Enable FuseBCQ Pass
optimize_fuse_bcq="false"
# fuse_instnorm                 Enable FuseInstanceNormalization Pass
optimize_fuse_instnorm="false"
# resolve_customop_add          Enable ResolveCustomOpAddPass Pass
optimize_resolve_customop_add="false"
# resolve_customop_batchmatmul  Enable ResolveCustomOpBatchMatMulPass Pass
optimize_resolve_customop_batchmatmul="false"
# resolve_customop_matmul       Enable ResolveCustomOpMatMulPass Pass
optimize_resolve_customop_matmul="false"
# optimize_output_path          (Optional) Path to intermediate output of one-optimize
optimize_optimize_output_path=""

# --------------------------------[one-quantize]--------------------------------- #
# input_dtype                   Input data type (supported: float32, default=float32)
quantize_input_dtype=""
# quantized_dtype               Output quantized data type (supported: uint8, int16, default=uint8)
quantize_quantized_dtype=""
# granularity                   Quantize granularity (supported: layer, channel, default=layer)
quantize_granularity=""
# min_percentile                Minimum percentile (0.0~100.0, default=1.0)
quantize_min_percentile=""
# max_percentile                Maximum percentile (0.0~100.0, default=99.0)
quantize_max_percentile=""
# mode                          Record mode (supported: percentile/moving_average, default=percentile)
quantize_mode=""
# input_data                    Path to input data
quantize_input_data=""
# quantize_output_path          (Optional) Path to intermediate output of one-quantize
quantize_output_path=""

# ----------------------------------[one-pack]----------------------------------- #
# TO BE FILLED

# ---------------------------------[one-codegen]--------------------------------- #
# BACKEND dirvers
# TO BE FILLED
