#!/usr/bin/env bash
''''export SCRIPT_PATH="$(cd "$(dirname "$(readlink -f "${BASH_SOURCE[0]}")")" && pwd)" # '''
''''export PY_PATH=${SCRIPT_PATH}/venv/bin/python                                       # '''
''''test -f ${PY_PATH} && exec ${PY_PATH} "$0" "$@"                                     # '''
''''echo "Error: Virtual environment not found. Please run 'one-prepare-venv' command." # '''
''''exit 255                                                                            # '''

# Copyright (c) 2022 Samsung Electronics Co., Ltd. All Rights Reserved
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import argparse
import copy
import glob
import itertools
import ntpath
import os
import sys
import configparser

import configparser
import utils as _utils

# TODO Find better way to suppress trackback on error
sys.tracebacklimit = 0
'''
NOTE

Assume that there is foo backend.
- one-init requires foo-init to have `-o` option.
- one-init requires foo-init to have exit code in specific range (0 or 16 <= exitcode <= 32).
- one-init requires foo-init to have complete "[onecc]" section.
- Example of cfg generated by foo-init could be the following:

  $ foo-init ... -o foo.cfg ...
  $ cat foo.cfg
  [onecc]
  one-import-tflite = True
  one-optimize = True
  one-quantize = True
  one-codegen = True

  ; add [one-import-tflite] section

  [one-optimize]
  ; add input and output
  replace_sub_with_add = True
  ; add more optimizaiton options

  [one-quantize]
  ; add input and output
  quantized_dtype = uint16
  granularity = layer
  ; add more quantization options

  [one-codegen]
  backend = foo
  command = --input model.q.circle --output model.foo
'''


class InputOutputPath:
    '''
    Class that remembers input circle file and output circle file of section k,
    where section k + 1 can reuse output circle file in previous section
    '''

    def __init__(self, initial_input_path: str):
        self._first_step = True
        self._input_path = initial_input_path
        self._output_path = ''

    def enter_new_section(self, section_output_path: str):
        '''
        Call this when starting a section
        '''
        if self._first_step == True:
            self._output_path = section_output_path
        else:
            self._input_path = self._output_path
            self._output_path = section_output_path

        self._first_step = False

    def input_path(self):
        return self._input_path

    def output_path(self):
        return self._output_path


class CommentableConfigParser(configparser.ConfigParser):
    """
    ConfigParser where comment can be stored
    In Python ConfigParser, comment in ini file ( starting with ';') is considered a key of which
    value is None.
    Ref: https://stackoverflow.com/questions/6620637/writing-comments-to-files-with-configparser
    """

    def __init__(self):
        # allow_no_value=True to add comment
        # ref: https://stackoverflow.com/a/19432072
        configparser.ConfigParser.__init__(self, allow_no_value=True)
        self.optionxform = str

    def add_comment(self, section, comment):
        comment_sign = ';'
        self[section][f'{comment_sign} {comment}'] = None


def _get_backends_list():
    """
    [one hierarchy]
    one
    ├── backends
    ├── bin
    ├── doc
    ├── include
    ├── lib
    ├── optimization
    └── test

    The list where `one-init` finds its backends
    - `bin` folder where `one-init` exists
    - `backends` folder

    NOTE If there are backends of the same name in different places,
     the closer to the top in the list, the higher the priority.
    """
    dir_path = os.path.dirname(os.path.realpath(__file__))
    backend_set = set()

    # bin folder
    files = [f for f in glob.glob(dir_path + '/*-init')]
    # backends folder
    files += [f for f in glob.glob(dir_path + '/../backends/**/*-init', recursive=True)]
    # TODO find backends in `$PATH`

    backends_list = []
    for cand in files:
        base = ntpath.basename(cand)
        if (not base in backend_set) and os.path.isfile(cand) and os.access(
                cand, os.X_OK):
            backend_set.add(base)
            backends_list.append(cand)

    return backends_list


# TODO Add support for TF graphdef and bcq
def _get_parser(backends_list):
    init_usage = (
        'one-init [-h] [-v] [-V] '
        '[-i INPUT_PATH] '
        '[-o OUTPUT_PATH] '
        '[-m MODEL_TYPE] '
        '[-b BACKEND] '
        # args for onnx model
        '[--convert_nchw_to_nhwc] '
        '[--nchw_to_nhwc_input_shape] '
        '[--nchw_to_nhwc_output_shape] '
        # args for backend driver
        '[--] [COMMANDS FOR BACKEND DRIVER]')
    """
    NOTE
    layout options for onnx model could be difficult to users.
    In one-init, we could consider easier args for the the above three:
    For example, we could have another option, e.g., --input_img_layout LAYOUT
      - When LAYOUT is NHWC, apply 'nchw_to_nhwc_input_shape=True' into cfg
      - When LAYOUT is NCHW, apply 'nchw_to_nhwc_input_shape=False' into cfg
    """

    parser = argparse.ArgumentParser(
        description='Command line tool to generate initial cfg file. '
        'Currently tflite and onnx models are supported',
        usage=init_usage)

    _utils._add_default_arg_no_CS(parser)

    parser.add_argument(
        '-i', '--input_path', type=str, help='full filepath of the input model file')
    parser.add_argument(
        '-o', '--output_path', type=str, help='full filepath of the output cfg file')
    parser.add_argument(
        '-m',
        '--model_type',
        type=str,
        help=('type of input model: "onnx", "tflite". '
              'If the file extension passed to --input_path is '
              '".tflite" or ".onnx", this arg can be omitted.'))

    onnx_group = parser.add_argument_group('arguments when model type is onnx')
    onnx_group.add_argument(
        '--convert_nchw_to_nhwc',
        action='store_true',
        help=
        'Convert NCHW operators to NHWC under the assumption that input model is NCHW.')
    onnx_group.add_argument(
        '--nchw_to_nhwc_input_shape',
        action='store_true',
        help='Convert the input shape of the model (argument for convert_nchw_to_nhwc)')
    onnx_group.add_argument(
        '--nchw_to_nhwc_output_shape',
        action='store_true',
        help='Convert the output shape of the model (argument for convert_nchw_to_nhwc)')

    # get backend list in the directory
    backends_name = [ntpath.basename(f) for f in backends_list]
    if not backends_name:
        backends_name_message = '(There is no available backend drivers)'
    else:
        backends_name_message = '(available backend drivers: ' + ', '.join(
            backends_name) + ')'
    backend_help_message = 'backend name to use ' + backends_name_message
    parser.add_argument('-b', '--backend', type=str, help=backend_help_message)

    return parser


def _verify_arg(parser, args):
    # check if required arguments is given
    missing = []
    if not _utils._is_valid_attr(args, 'input_path'):
        missing.append('-i/--input_path')
    if not _utils._is_valid_attr(args, 'output_path'):
        missing.append('-o/--output_path')
    if not _utils._is_valid_attr(args, 'backend'):
        missing.append('-b/--backend')

    if _utils._is_valid_attr(args, 'model_type'):
        # TODO Support model types other than onnx and tflite (e.g., TF)
        if getattr(args, 'model_type') not in ['onnx', 'tflite']:
            parser.error('Allowed value for --model_type: "onnx" or "tflite"')

    if _utils._is_valid_attr(args, 'nchw_to_nhwc_input_shape'):
        if not _utils._is_valid_attr(args, 'convert_nchw_to_nhwc'):
            missing.append('--convert_nchw_to_nhwc')
    if _utils._is_valid_attr(args, 'nchw_to_nhwc_output_shape'):
        if not _utils._is_valid_attr(args, 'convert_nchw_to_nhwc'):
            missing.append('--convert_nchw_to_nhwc')

    if len(missing):
        parser.error('the following arguments are required: ' + ' '.join(missing))


def _parse_arg(parser):
    init_args = []
    backend_args = []
    argv = copy.deepcopy(sys.argv)
    # delete file name
    del argv[0]
    # split by '--'
    args = [list(y) for x, y in itertools.groupby(argv, lambda z: z == '--') if not x]

    # one-init [-h] [-v] ...
    if len(args):
        init_args = args[0]
        init_args = parser.parse_args(init_args)
        backend_args = backend_args if len(args) < 2 else args[1]
    # print version
    if len(args) and init_args.version:
        _utils._print_version_and_exit(__file__)

    return init_args, backend_args


def _get_executable(args, backends_list):
    if _utils._is_valid_attr(args, 'backend'):
        backend_base = getattr(args, 'backend') + '-init'
        for cand in backends_list:
            if ntpath.basename(cand) == backend_base:
                return cand
        raise FileNotFoundError(backend_base + ' not found')


def _generate(args, model_type: str, inout_path: InputOutputPath):
    config = configparser.ConfigParser()
    model_name = os.path.basename(args.input_path).split('.')[0]
    model_dir = os.path.dirname(args.input_path)

    def _assert_section(section: str):
        if not config.has_section(section):
            raise RuntimeError(f'Cannot find section: {section}')

    def _add_onecc_sections():
        '''
        This adds all sections
        '''
        config.add_section('onecc')
        sections = [
            f'one-import-{model_type}', 'one-optimize', 'one-quantize', 'one-codegen'
        ]

        for section in sections:
            config['onecc'][section] = 'True'
            # add empty section as a preperation of next procedure
            config.add_section(section)

    def _gen_import():
        section = f'one-import-{model_type}'
        _assert_section(section)

        output_path = os.path.join(model_dir, f'{model_name}.circle')
        inout_path.enter_new_section(section_output_path=output_path)
        config[section]['input_path'] = inout_path.input_path()
        config[section]['output_path'] = inout_path.output_path()

    def _gen_optimize():
        section = 'one-optimize'
        _assert_section(section)

        output_path = os.path.join(model_dir, f'{model_name}.opt.circle')
        inout_path.enter_new_section(section_output_path=output_path)
        config[section]['input_path'] = inout_path.input_path()
        config[section]['output_path'] = inout_path.output_path()

        # This applies for all input model types (tflite, onnx, tf, etc)
        # List was chosen from https://github.com/Samsung/ONE/issues/9369#issuecomment-1172005559
        # Note: args originated from onnx models are not in this list but in default_options_onnx[]
        default_options = [
            "fold_dequantize",
            "fold_dwconv",
            "fold_gather",
            "fuse_activation_function",
            "fuse_add_with_fully_connected",
            "fuse_add_with_tconv",
            "fuse_batchnorm_with_conv",
            "fuse_batchnorm_with_dwconv",
            "fuse_batchnorm_with_tconv",
            "fuse_bcq",
            "fuse_instnorm",
            "remove_redundant_quantize",
            "remove_unnecessary_strided_slice",
            "resolve_customop_add",
            "resolve_customop_batchmatmul",
            "resolve_customop_matmul",
            "resolve_customop_max_pool_with_argmax",
            "substitute_pack_to_reshape",
            "substitute_splitv_to_split",
            "generate_profile_data",
        ]

        for option in default_options:
            config[section][option] = "True"

        # ONNX: default option (except --convert_nchw_to_nhwc)
        #
        # Options for onnx models only
        # The patterns for these args might rarely occur in tflite models.
        # So we thought that adding those args could increase compilation time for tflite models
        # but show small impact on optimization.
        # ref: https://github.com/Samsung/ONE/issues/9369#issuecomment-1182739358
        #
        # TODO Consider adding these into default_option[]
        default_options_onnx = [
            "fold_add_v2",
            "fold_cast",
            "fold_sparse_to_dense",
            "forward_reshape_to_unaryop",
            "fuse_batchnorm_with_dwconv",
            "fuse_mean_with_mean",
            "fuse_transpose_with_mean",
            "remove_redundant_reshape",
            "remove_redundant_transpose",
            "remove_unnecessary_reshape",
            "remove_unnecessary_slice",
            "remove_unnecessary_split",
            "substitute_transpose_to_reshape",
            "substitute_squeeze_to_reshape",
            "substitute_padv2_to_pad",
            "substitute_strided_slice_to_reshape",
            "transform_min_max_to_relu6",
            "transform_min_relu_to_relu6",
        ]

        if model_type == 'onnx':
            for onnx_option in default_options_onnx:
                config[section][onnx_option] = "True"

            if args.convert_nchw_to_nhwc:
                config[section]['convert_nchw_to_nhwc'] = "True"

                if args.nchw_to_nhwc_input_shape:
                    config[section]['nchw_to_nhwc_input_shape'] = "True"
                if args.nchw_to_nhwc_output_shape:
                    config[section]['nchw_to_nhwc_output_shape '] = "True"

    def _gen_quantize():
        '''
        one-quantizer provides default values for some args if the args are not provided
            The following is list of such args
            --input_dtype float32
            --quantized_dtype uint8
            --granularity layer
            --input_type quantized_dtype
            --output_type quantized_dtype
            --min_percentile 1.0
            --max_percentile 99.0
            --mode percentile

        if --input_data is not provided, random data will be used.
        '''
        section = 'one-quantize'
        _assert_section(section)

        output_path = os.path.join(model_dir, f'{model_name}.q.circle')
        inout_path.enter_new_section(section_output_path=output_path)
        config[section]['input_path'] = inout_path.input_path()
        config[section]['output_path'] = inout_path.output_path()

    def _gen_codegen():
        section = 'one-codegen'
        _assert_section(section)

        # [backend]-init must provide default value for 'command'
        config[section]['backend'] = args.backend

    #
    # NYI: one-profile, one-partition, one-pack, one-infer
    #

    _add_onecc_sections()

    _gen_import()
    _gen_optimize()
    _gen_quantize()
    _gen_codegen()

    with open(args.output_path, 'w') as f:
        config.write(f)


def _get_model_type(parser, args):
    if _utils._is_valid_attr(args, 'model_type'):
        return args.model_type

    if _utils._is_valid_attr(args, 'input_path'):
        _, ext = os.path.splitext(args.input_path)

        # ext would be, e.g., '.tflite' or '.onnx'.
        # Note: when args.input_path does not have an extension, e.g., '/home/foo'
        # ext after os.path.splitext() is '' and ''[1:] is still ''.
        ext = ext[1:]
        if ext in ["tflite", "onnx"]:
            return ext

    parser.error(f'the following argument is required: --input_path')


def _add_comments(cfg_path: str, model_type: str, backend: str):
    config = CommentableConfigParser()
    config.read(cfg_path)

    section = 'one-optimize'
    config.add_comment(
        section,
        f'Add or modify the above options (generated for {model_type} and {backend})')

    section = 'one-quantize'
    config.add_comment(
        section,
        f'Add or modify the above options (generated for {model_type} and {backend})')
    config.add_comment(
        section,
        'When "input_data" is not specified, random input data will be used for post-training quantization.'
    )
    config.add_comment(
        section, 'For better accuracy, it would be better if "input_data" is provided.')

    with open(cfg_path, 'w') as f:
        config.write(f)


def main():

    # get backend list for one-init
    backends_list = _get_backends_list()

    # parse arguments
    parser = _get_parser(backends_list)
    args, backend_args = _parse_arg(parser)

    # verify arguments
    _verify_arg(parser, args)

    # make a command to run given backend driver
    driver_path = _get_executable(args, backends_list)
    init_cmd = [driver_path] + backend_args

    # generate cfg file
    model_type = _get_model_type(parser, args)
    inout_path = InputOutputPath(args.input_path)
    _generate(args, model_type, inout_path)

    # run backend-init and update cfg file
    _utils._run(init_cmd, err_prefix=ntpath.basename(driver_path))

    # adds comments
    _add_comments(args.output_path, model_type, args.backend)


if __name__ == '__main__':
    _utils._safemain(main, __file__)
