#!/usr/bin/env bash
''''export SCRIPT_PATH="$(cd "$(dirname "$(readlink -f "${BASH_SOURCE[0]}")")" && pwd)" # '''
''''export PY_PATH=${SCRIPT_PATH}/venv/bin/python                                       # '''
''''test -f ${PY_PATH} && exec ${PY_PATH} "$0" "$@"                                     # '''
''''echo "Error: Virtual environment not found. Please run 'one-prepare-venv' command." # '''
''''exit 255                                                                            # '''

# Copyright (c) 2020 Samsung Electronics Co., Ltd. All Rights Reserved
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import h5py as h5
import numpy as np
import argparse
import glob
import os


def get_parser():
    """Create and return given the argument parser"""
    parser = argparse.ArgumentParser(
        description='command line tool to convert raw data files to hdf5 file')
    parser.add_argument(
        "-l",
        "--data_list",
        type=str,
        help=
        "Path to the text file which lists the absolute paths of the raw data files to be converted.",
        required=True)
    parser.add_argument(
        "-o",
        "--output_path",
        type=str,
        help="Path to the output hdf5 file.",
        required=True)
    return parser


def verify_args(parser, args):
    """Verify the given arguments"""

    def is_valid_attr(args, attr):
        return hasattr(args, attr) and getattr(args, attr)

    # check if required arguments is given
    missing = []
    if not is_valid_attr(args, 'data_list'):
        missing.append('-l/--data_list')
    if not is_valid_attr(args, 'output_path'):
        missing.append('-o/--output_path')
    if len(missing):
        parser.error('the following arguments are required: ' + ' '.join(missing))


def create_hdf5(data_list, output_path):
    """Create the hdf5 file using raw data files listed in data_list"""
    h5_file = h5.File(output_path, 'w')
    group = h5_file.create_group("value")
    # We assume the raw input data have the correct type/shape for the corresponding model
    # If this flag is set in the hdf5 file, record-minmax will skip type/shape check
    group.attrs['rawData'] = '1'

    if os.path.isfile(data_list) == False:
        raise FileNotFoundError("No such file. " + data_list)

    # Data list
    datalist = []
    with open(data_list, 'r') as f:
        lines = f.readlines()
        for line in lines:
            if line.strip():
                filenames = line.rstrip().split(' ')
                # A single line can indicate multiple files (multi-input)
                for filename in filenames:
                    if not os.path.isfile(filename):
                        raise FileNotFoundError("No such file. " + filename)
                datalist.append(filenames)

    # Input files
    num_converted = 0
    for input_files in datalist:
        sample = group.create_group(str(num_converted))
        for idx, input_file in enumerate(input_files):
            with open(input_file, 'rb') as f:
                raw_data = bytearray(f.read())
                sample.create_dataset(str(idx), data=raw_data)
        sample.attrs['desc'] = ','.join(
            list(map(lambda x: os.path.basename(x), input_files)))
        num_converted += 1

    h5_file.close()

    print("Raw data have been packaged to " + output_path)
    print("Number of packaged data: " + str(num_converted))


def main():
    parser = get_parser()

    args = parser.parse_args()

    verify_args(parser, args)

    create_hdf5(args.data_list, args.output_path)

if __name__ == '__main__':
    main()
