/*
 * Copyright (c) 2018 Samsung Electronics Co., Ltd. All Rights Reserved
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/*
 * This test set checks correctness of MIR to DOM transformation
 */

// system
#include <functional>
#include <vector>

// ACL backend
#include "ArtifactModel.h"
#include "AclCppOpGenerator.h"

// MIR
#include "mir/Graph.h"
#include "mir/ops/CappedReluOp.h"
#include "mir/ops/ConcatOp.h"
#include "mir/ops/ConstantOp.h"
#include "mir/ops/Conv2DOp.h"
#include "mir/ops/Deconv2DOp.h"
#include "mir/ops/DepthwiseConv2DOp.h"
#include "mir/ops/EluOp.h"
#include "mir/ops/FullyConnectedOp.h"
#include "mir/ops/InputOp.h"
#include "mir/ops/MaxPool2DOp.h"
#include "mir/ops/OutputOp.h"
#include "mir/ops/PadOp.h"
#include "mir/ops/ReduceMeanOp.h"
#include "mir/ops/ReluOp.h"
#include "mir/ops/ReshapeOp.h"
#include "mir/ops/SigmoidOp.h"
#include "mir/ops/SoftmaxOp.h"
#include "mir/ops/TanhOp.h"
#include "mir/ops/TransposeOp.h"

#include "gtest/gtest.h"

using namespace std;
using namespace nnc;
using namespace mir;

namespace
{

using OpConstructor = function<Operation *(Graph &g, vector<Operation::Output *> &inputs)>;

const char *artifactName = "nnmodel";

/**
 * @brief Creates graph with one operation generated by opGen function and returns this operation
 * node
 * @param g reference to graph which should be filled with operations
 * @param op_constr functor which creates main operations of graph
 * @param input_shapes vector of network input shapes
 * */
void fillGraph(Graph &g, const OpConstructor &op_constr, const vector<Shape> &input_shapes)
{
  // Create graph inputs.
  vector<mir::Operation::Output *> inputs;
  for (std::size_t i = 0; i < input_shapes.size(); ++i)
  {
    mir::TensorType input_type{mir::DataType::FLOAT32, input_shapes[i]};
    auto input = g.create<ops::InputOp>(input_type)->getOutput(0);
    input->setName("x" + to_string(i));
    inputs.push_back(input);
  }

  // Create the operation.
  Operation *op = op_constr(g, inputs);

  // Create graph outputs.
  for (std::size_t i = 0; i < op->getNumOutputs(); ++i)
  {
    op->getOutput(i)->setName("y" + to_string(i));
    g.create<ops::OutputOp>(op->getOutput(i));
  }
}

/**
 * @brief Checks that list of includes contains all and only desired headers
 * @param artifact_headers List of headers stored in ArtifaceModule
 * @param expected_headers Reference set of desired headers
 * @param message Message to print in case of check failure
 */
void checkHeadersSetsEqual(const list<string> &artifact_headers,
                           const set<string> &expected_headers, const char *message)
{
  set<string> artifact_set(artifact_headers.begin(), artifact_headers.end());
  ASSERT_EQ(artifact_set, expected_headers) << message;
}

/**
 * @brief Check that artifact DOM has all needed includes
 * @param m Root module of DOM
 */
void checkDomIncludes(const ArtifactModule &m)
{
  // check system includes, like '#include  <vector>'
  checkHeadersSetsEqual(m.headerSysIncludes(), {"fstream"}, "header includes diverged");

  checkHeadersSetsEqual(m.sourceIncludes(), {}, "source includes diverged");

  // check ordinary includes, like '#include  "artifact_data.h"'
  checkHeadersSetsEqual(
    m.headerIncludes(),
    {"arm_compute/core/Types.h", "arm_compute/runtime/BlobLifetimeManager.h",
     "arm_compute/runtime/CL/CLBufferAllocator.h", "arm_compute/runtime/CL/CLFunctions.h",
     "arm_compute/runtime/CL/CLScheduler.h", "arm_compute/runtime/MemoryManagerOnDemand.h",
     "arm_compute/runtime/PoolManager.h"},
    "system header includes diverged");

  checkHeadersSetsEqual(m.sourceSysIncludes(), {}, "system source includes diverged");
}

/**
 * @brief Check that artifact DOM contains appropriate getters
 * @param c Main artifact class
 * @param tensors List of values accessible via getters
 */
void checkDomArtifactGetters(const ArtifactClass &c, const vector<string> &tensors)
{
  // TODO
}

/**
 * @brief Check that artifact class constructor initializes all layers
 * @param c Main artifact class
 * @param tensors List of NN layers
 */
void checkDomArtifactConstructor(const ArtifactClass &c, const vector<string> &tensors)
{
  // TODO
}

/**
 * @brief Check that inference executes layers in appropriate order
 * @param f Inference function description
 * @param layers List of layers in inference
 */
void checkDomInference(const ArtifactFunction &f, const vector<string> &layers)
{
  // TODO
}

/**
 * @brief Check that artifact DOM contains appropriate class
 * @param m Root module of DOM
 * @param layers Names of NN layers in inference sequence
 * @param tensors Names of tensors in artifact
 */
void checkArtifactClass(const ArtifactClass &c, const vector<string> &layers,
                        const vector<string> &tensors)
{
  checkDomArtifactGetters(c, tensors);
  checkDomArtifactConstructor(c, tensors);
  const ArtifactFunction *inf_func = nullptr;
  for (const shared_ptr<ArtifactClassFunction> &method : c.publicFunctions())
  {
    if (method->name() == "Inference")
    {
      inf_func = method.get();
      break;
    }
  }
  ASSERT_NE(inf_func, nullptr);
  checkDomInference(*inf_func, layers);
}

/**
 * @brief Root of check functions
 * @param m Main artifact module
 * @param layers Names of NN layers in inference sequence
 * @param tensors Names of tensors in artifact
 */
void checkDomStructure(const ArtifactModule &m, const vector<string> &layers,
                       const vector<string> &tensors)
{
  ASSERT_EQ(m.name(), artifactName);
  checkDomIncludes(m);
  ASSERT_EQ(m.entities().size(), 1);
  ArtifactClass *cls = dynamic_cast<ArtifactClass *>(m.entities().front().get());
  ASSERT_NE(cls, nullptr);
  checkArtifactClass(*cls, layers, tensors);
}

/**
 * @brief Creates TensorVariant with specified shape
 * @param shape Desired shape of TV
 * @return TensorVariant with specified shape
 */
TensorVariant createTensorVariant(const Shape &shape)
{
  auto num_elems = shape.numElements();

  unique_ptr<float[]> data(new float[num_elems]);
  float *data_ptr = data.get();
  for (int32_t i = 0; i < num_elems; ++i)
    data_ptr[i] = i;
  return TensorVariant(DataType::FLOAT32, shape, data_ptr);
}
} // namespace

// Actual tests

TEST(acl_backend_mir_to_dom, constant)
{
  Shape shape{3, 4};
  TensorVariant constant_data = createTensorVariant(shape);

  Graph g;
  OpConstructor op_generator = [&constant_data](Graph &g,
                                                const vector<Operation::Output *> &inputs) {
    return g.create<mir::ops::ConstantOp>(constant_data);
  };

  fillGraph(g, op_generator, {});

  stringstream params_out;
  AclCppOpGenerator dom_gen(artifactName, params_out);

  const ArtifactModule &m = dom_gen.generate(&g);

  checkDomStructure(m, {}, {});
}

TEST(acl_backend_mir_to_dom, concat)
{
  Graph g;
  OpConstructor op_generator = [](Graph &g, const vector<Operation::Output *> &inputs) {
    return g.create<mir::ops::ConcatOp>(inputs, 3);
  };
  vector<Shape> input_shapes{{2, 3, 5, 1}, {2, 3, 5, 3}};

  fillGraph(g, op_generator, input_shapes);

  stringstream params_out;
  AclCppOpGenerator dom_gen(artifactName, params_out);

  const ArtifactModule &m = dom_gen.generate(&g);

  checkDomStructure(m, {}, {});

  stringstream code_out;
  ArtifactGeneratorCppCode code_gen(code_out);
}

TEST(acl_backend_mir_to_dom, DISABLED_add)
{
  // TODO
}

TEST(acl_backend_mir_to_dom, DISABLED_mul)
{
  // TODO
}

TEST(acl_backend_mir_to_dom, DISABLED_max)
{
  // TODO
}

TEST(acl_backend_mir_to_dom, DISABLED_conv_transposed2d)
{
  // TODO
}

TEST(acl_backend_mir_to_dom, conv2d)
{
  const int32_t channels = 3;
  mir::Shape kernel_shape{1, 3, 3, channels}; // output Channels, Height, Width, input Channels
  mir::TensorVariant kernel_tensor = createTensorVariant(kernel_shape);

  Graph g;
  OpConstructor op_generator =
    [kernel_tensor](mir::Graph &g, const std::vector<mir::Operation::Output *> &inputs) {
      auto kernel = g.create<mir::ops::ConstantOp>(kernel_tensor)->getOutput(0);
      return g.create<mir::ops::Conv2DOp>(inputs[0], kernel, mir::Conv2DOpAttributes());
    };

  vector<Shape> input_shapes{{1, 10, 10, channels}};

  fillGraph(g, op_generator, input_shapes);

  stringstream params_out;
  AclCppOpGenerator dom_gen(artifactName, params_out);

  const ArtifactModule &m = dom_gen.generate(&g);

  checkDomStructure(m, {}, {});
}

TEST(acl_backend_mir_to_dom, depthwise_conv)
{
  const int32_t channels = 3;
  mir::Shape kernel_shape{3, 3, channels, 1}; // Height, Width, Channels, Channel multiplier
  mir::TensorVariant kernel_tensor = createTensorVariant(kernel_shape);

  Graph g;
  OpConstructor op_generator =
    [kernel_tensor](mir::Graph &g, const std::vector<mir::Operation::Output *> &inputs) {
      Conv2DOpAttributes attributes;
      auto kernel = g.create<mir::ops::ConstantOp>(kernel_tensor)->getOutput(0);
      return g.create<mir::ops::DepthwiseConv2DOp>(inputs[0], kernel, attributes);
    };

  vector<Shape> input_shapes{{1, 10, 10, channels}};

  fillGraph(g, op_generator, input_shapes);

  stringstream params_out;
  AclCppOpGenerator dom_gen(artifactName, params_out);

  const ArtifactModule &m = dom_gen.generate(&g);

  checkDomStructure(m, {}, {});

  stringstream code_out;
  ArtifactGeneratorCppCode code_gen(code_out);
}

TEST(acl_backend_mir_to_dom, fully_connected)
{
  const int32_t in_size = 13;
  const int32_t out_size = 7;
  Shape input_shape_data{1, in_size};
  Shape weights_shape{in_size, out_size};
  TensorVariant weights_tensor = createTensorVariant(weights_shape);

  Graph g;
  OpConstructor opGenerator = [weights_tensor](Graph &g,
                                               const vector<Operation::Output *> &inputs) {
    auto weights = g.create<mir::ops::ConstantOp>(weights_tensor)->getOutput(0);
    return g.create<mir::ops::FullyConnectedOp>(inputs[0], weights);
  };

  fillGraph(g, opGenerator, {input_shape_data});

  stringstream params_out;
  AclCppOpGenerator dom_gen(artifactName, params_out);

  const ArtifactModule &m = dom_gen.generate(&g);

  checkDomStructure(m, {}, {});

  stringstream code_out;
  ArtifactGeneratorCppCode code_gen(code_out);
}

TEST(acl_backend_mir_to_dom, maxpool)
{
  mir::MaxPool2DOpAttributes attributes;
  attributes.window = {3, 3};

  Graph g;
  OpConstructor op_generator = [&attributes](mir::Graph &g,
                                             const std::vector<mir::Operation::Output *> &inputs) {
    return g.create<mir::ops::MaxPool2DOp>(inputs[0], attributes);
  };

  vector<Shape> input_shapes{{1, 10, 10, 3}};

  fillGraph(g, op_generator, input_shapes);

  stringstream params_out;
  AclCppOpGenerator dom_gen(artifactName, params_out);

  const ArtifactModule &m = dom_gen.generate(&g);

  checkDomStructure(m, {}, {});

  stringstream code_out;
  ArtifactGeneratorCppCode code_gen(code_out);
}

TEST(acl_backend_mir_to_dom, DISABLED_avgpool)
{
  // TODO
}

/**
 * @brief Function to test simple activation operations
 * @param op_generator functor that generates target operator
 */
static void testActivationOp(const OpConstructor &op_generator)
{
  Graph g;
  vector<Shape> input_shapes{{1, 10, 10, 3}};

  fillGraph(g, op_generator, input_shapes);

  stringstream params_out;
  AclCppOpGenerator dom_gen(artifactName, params_out);

  const ArtifactModule &m = dom_gen.generate(&g);

  checkDomStructure(m, {}, {});

  stringstream code_out;
  ArtifactGeneratorCppCode code_gen(code_out);
}

TEST(acl_backend_mir_to_dom, relu)
{
  OpConstructor op_generator = [](Graph &g, const std::vector<Operation::Output *> &inputs) {
    return g.create<mir::ops::ReluOp>(inputs[0]);
  };

  testActivationOp(op_generator);
}

TEST(acl_backend_mir_to_dom, capped_relu)
{
  float cap = 6;
  OpConstructor op_generator = [cap](Graph &g, const std::vector<Operation::Output *> &inputs) {
    return g.create<mir::ops::CappedReluOp>(inputs[0], cap);
  };

  testActivationOp(op_generator);
}

TEST(acl_backend_mir_to_dom, sigmoid)
{
  OpConstructor op_generator = [](Graph &g, const std::vector<Operation::Output *> &inputs) {
    return g.create<mir::ops::SigmoidOp>(inputs[0]);
  };

  testActivationOp(op_generator);
}

TEST(acl_backend_mir_to_dom, DISABLED_elu)
{
  // TODO
}

TEST(acl_backend_mir_to_dom, tanh)
{
  OpConstructor op_generator = [](Graph &g, const std::vector<Operation::Output *> &inputs) {
    return g.create<mir::ops::TanhOp>(inputs[0]);
  };

  testActivationOp(op_generator);
}

TEST(acl_backend_mir_to_dom, DISABLED_reduce_mean)
{
  // TODO
}

TEST(acl_backend_mir_to_dom, softmax)
{
  Graph g;
  OpConstructor op_generator = [](Graph &g, const vector<Operation::Output *> &inputs) {
    return g.create<mir::ops::SoftmaxOp>(inputs[0], 3);
  };
  vector<Shape> input_shapes{{1, 1, 1, 3}};

  fillGraph(g, op_generator, input_shapes);

  stringstream params_out;
  AclCppOpGenerator dom_gen(artifactName, params_out);

  const ArtifactModule &m = dom_gen.generate(&g);

  checkDomStructure(m, {}, {});

  stringstream code_out;
  ArtifactGeneratorCppCode code_gen(code_out);
}

TEST(acl_backend_mir_to_dom, reshape)
{
  Graph g;

  const int32_t h = 10;
  const int32_t w = 10;
  const int32_t c = 3;

  Shape input_shape{1, h, w, c};
  Shape output_shape{1, h * w * c};

  OpConstructor op_generator = [output_shape](Graph &g, const vector<Operation::Output *> &inputs) {
    return g.create<mir::ops::ReshapeOp>(inputs[0], output_shape);
  };

  fillGraph(g, op_generator, {input_shape});

  stringstream params_out;
  AclCppOpGenerator dom_gen(artifactName, params_out);

  const ArtifactModule &m = dom_gen.generate(&g);

  checkDomStructure(m, {}, {});

  stringstream code_out;
  ArtifactGeneratorCppCode code_gen(code_out);
}

TEST(acl_backend_mir_to_dom, DISABLED_pad)
{
  // TODO
}

TEST(acl_backend_mir_to_dom, transpose)
{
  const int32_t channels = 2;
  TensorVariant w = createTensorVariant({channels});

  vector<size_t> perm{0, 3, 1, 2};

  Graph g;
  OpConstructor op_generator = [&perm](Graph &g, const vector<Operation::Output *> &inputs) {
    return g.create<mir::ops::TransposeOp>(inputs[0], perm);
  };
  vector<Shape> input_shapes{{1, 10, 10, channels}};

  fillGraph(g, op_generator, input_shapes);

  stringstream params_out;
  AclCppOpGenerator dom_gen(artifactName, params_out);

  const ArtifactModule &m = dom_gen.generate(&g);

  checkDomStructure(m, {}, {});
}
