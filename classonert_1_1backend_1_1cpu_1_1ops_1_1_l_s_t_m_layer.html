<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.5"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ONE - On-device Neural Engine: onert::backend::cpu::ops::LSTMLayer Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">ONE - On-device Neural Engine
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.5 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('classonert_1_1backend_1_1cpu_1_1ops_1_1_l_s_t_m_layer.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a>  </div>
  <div class="headertitle"><div class="title">onert::backend::cpu::ops::LSTMLayer Class Reference</div></div>
</div><!--header-->
<div class="contents">

<p><code>#include &lt;<a class="el" href="_l_s_t_m_layer_8h_source.html">LSTMLayer.h</a>&gt;</code></p>
<div class="dynheader">
Collaboration diagram for onert::backend::cpu::ops::LSTMLayer:</div>
<div class="dyncontent">
<div class="center"><img src="classonert_1_1backend_1_1cpu_1_1ops_1_1_l_s_t_m_layer__coll__graph.png" border="0" usemap="#aonert_1_1backend_1_1cpu_1_1ops_1_1_l_s_t_m_layer_coll__map" alt="Collaboration graph"/></div>
<map name="aonert_1_1backend_1_1cpu_1_1ops_1_1_l_s_t_m_layer_coll__map" id="aonert_1_1backend_1_1cpu_1_1ops_1_1_l_s_t_m_layer_coll__map">
<area shape="rect" title=" " alt="" coords="11,79,144,119"/>
<area shape="rect" href="classonert_1_1exec_1_1_i_function.html" title=" " alt="" coords="5,5,149,31"/>
</map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a929b39ef91606841d7b7ec8c3be078a5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_l_s_t_m_layer.html#a929b39ef91606841d7b7ec8c3be078a5">LSTMLayer</a> ()=default</td></tr>
<tr class="separator:a929b39ef91606841d7b7ec8c3be078a5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9735342fe4c78544b5c36eb5d99767b4"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_l_s_t_m_layer.html#a9735342fe4c78544b5c36eb5d99767b4">LSTMFloat</a> ()</td></tr>
<tr class="separator:a9735342fe4c78544b5c36eb5d99767b4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aac4981a87b460f58f8db5f99f657b2a3"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_l_s_t_m_layer.html#aac4981a87b460f58f8db5f99f657b2a3">configure</a> (const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *input, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *input_to_input_weights, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *input_to_forget_weights, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *input_to_cell_weights, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *input_to_output_weights, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *recurrent_to_input_weights, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *recurrent_to_forget_weights, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *recurrent_to_cell_weights, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *recurrent_to_output_weights, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *cell_to_input_weights, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *cell_to_forget_weights, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *cell_to_output_weights, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *input_layer_norm_weights, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *forget_layer_norm_weights, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *cell_layer_norm_weights, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *output_layer_norm_weights, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *aux_input, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *aux_input_to_input_weights, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *aux_input_to_forget_weights, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *aux_input_to_cell_weights, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *aux_input_to_output_weights, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *input_gate_bias, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *forget_gate_bias, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *cell_gate_bias, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *output_gate_bias, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *projection_weights, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *projection_bias, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *output_state_in, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *cell_state_in, const <a class="el" href="structonert_1_1ir_1_1operation_1_1_l_s_t_m_1_1_param.html">ir::operation::LSTM::Param</a> &amp;params, bool forward_sequence, bool time_major, int32_t output_offset, <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *scratch_buffer, <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *output_state, <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *cell_state, <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *output, bool has_output_state_data, bool has_cell_state_data)</td></tr>
<tr class="separator:aac4981a87b460f58f8db5f99f657b2a3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a22e2633b3009ae6b31d63815749b37c3"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_l_s_t_m_layer.html#a22e2633b3009ae6b31d63815749b37c3">run</a> () override</td></tr>
<tr class="separator:a22e2633b3009ae6b31d63815749b37c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classonert_1_1exec_1_1_i_function"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classonert_1_1exec_1_1_i_function')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classonert_1_1exec_1_1_i_function.html">onert::exec::IFunction</a></td></tr>
<tr class="memitem:ae05c7341d5ee2cac795f17d4b735cbfd inherit pub_methods_classonert_1_1exec_1_1_i_function"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1exec_1_1_i_function.html#ae05c7341d5ee2cac795f17d4b735cbfd">~IFunction</a> ()=default</td></tr>
<tr class="separator:ae05c7341d5ee2cac795f17d4b735cbfd inherit pub_methods_classonert_1_1exec_1_1_i_function"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aedd6f5e12852d808abb97327b9d229e2 inherit pub_methods_classonert_1_1exec_1_1_i_function"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1exec_1_1_i_function.html#aedd6f5e12852d808abb97327b9d229e2">run</a> ()=0</td></tr>
<tr class="separator:aedd6f5e12852d808abb97327b9d229e2 inherit pub_methods_classonert_1_1exec_1_1_i_function"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a901ae0973ef08a6ca59f6a00bd3bac4c inherit pub_methods_classonert_1_1exec_1_1_i_function"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1exec_1_1_i_function.html#a901ae0973ef08a6ca59f6a00bd3bac4c">prepare</a> ()</td></tr>
<tr class="separator:a901ae0973ef08a6ca59f6a00bd3bac4c inherit pub_methods_classonert_1_1exec_1_1_i_function"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock">
<p class="definition">Definition at line <a class="el" href="_l_s_t_m_layer_8h_source.html#l00044">44</a> of file <a class="el" href="_l_s_t_m_layer_8h_source.html">LSTMLayer.h</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a929b39ef91606841d7b7ec8c3be078a5" name="a929b39ef91606841d7b7ec8c3be078a5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a929b39ef91606841d7b7ec8c3be078a5">&#9670;&#160;</a></span>LSTMLayer()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">onert::backend::cpu::ops::LSTMLayer::LSTMLayer </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">default</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="aac4981a87b460f58f8db5f99f657b2a3" name="aac4981a87b460f58f8db5f99f657b2a3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aac4981a87b460f58f8db5f99f657b2a3">&#9670;&#160;</a></span>configure()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void onert::backend::cpu::ops::LSTMLayer::configure </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>input_to_input_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>input_to_forget_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>input_to_cell_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>input_to_output_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>recurrent_to_input_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>recurrent_to_forget_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>recurrent_to_cell_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>recurrent_to_output_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>cell_to_input_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>cell_to_forget_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>cell_to_output_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>input_layer_norm_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>forget_layer_norm_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>cell_layer_norm_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>output_layer_norm_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>aux_input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>aux_input_to_input_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>aux_input_to_forget_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>aux_input_to_cell_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>aux_input_to_output_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>input_gate_bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>forget_gate_bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>cell_gate_bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>output_gate_bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>projection_weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>projection_bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>output_state_in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>cell_state_in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structonert_1_1ir_1_1operation_1_1_l_s_t_m_1_1_param.html">ir::operation::LSTM::Param</a> &amp;&#160;</td>
          <td class="paramname"><em>params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>forward_sequence</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>time_major</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>output_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>scratch_buffer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>output_state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>cell_state</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>has_output_state_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>has_cell_state_data</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="_l_s_t_m_layer_8cc_source.html#l00242">242</a> of file <a class="el" href="_l_s_t_m_layer_8cc_source.html">LSTMLayer.cc</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  263</span>{</div>
<div class="line"><span class="lineno">  264</span>  _input = <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>;</div>
<div class="line"><span class="lineno">  265</span>  _input_to_input_weights = input_to_input_weights;</div>
<div class="line"><span class="lineno">  266</span>  _input_to_forget_weights = input_to_forget_weights;</div>
<div class="line"><span class="lineno">  267</span>  _input_to_cell_weights = input_to_cell_weights;</div>
<div class="line"><span class="lineno">  268</span>  _input_to_output_weights = input_to_output_weights;</div>
<div class="line"><span class="lineno">  269</span>  _recurrent_to_input_weights = recurrent_to_input_weights;</div>
<div class="line"><span class="lineno">  270</span>  _recurrent_to_forget_weights = recurrent_to_forget_weights;</div>
<div class="line"><span class="lineno">  271</span>  _recurrent_to_cell_weights = recurrent_to_cell_weights;</div>
<div class="line"><span class="lineno">  272</span>  _recurrent_to_output_weights = recurrent_to_output_weights;</div>
<div class="line"><span class="lineno">  273</span>  _cell_to_input_weights = cell_to_input_weights;</div>
<div class="line"><span class="lineno">  274</span>  _cell_to_forget_weights = cell_to_forget_weights;</div>
<div class="line"><span class="lineno">  275</span>  _cell_to_output_weights = cell_to_output_weights;</div>
<div class="line"><span class="lineno">  276</span>  _input_layer_norm_coefficients = input_layer_norm_weights;</div>
<div class="line"><span class="lineno">  277</span>  _forget_layer_norm_coefficients = forget_layer_norm_weights;</div>
<div class="line"><span class="lineno">  278</span>  _cell_layer_norm_coefficients = cell_layer_norm_weights;</div>
<div class="line"><span class="lineno">  279</span>  _output_layer_norm_coefficients = output_layer_norm_weights;</div>
<div class="line"><span class="lineno">  280</span>  _aux_input = aux_input, _aux_input_to_input_weights = aux_input_to_input_weights,</div>
<div class="line"><span class="lineno">  281</span>  _aux_input_to_forget_weights = aux_input_to_forget_weights,</div>
<div class="line"><span class="lineno">  282</span>  _aux_input_to_cell_weights = aux_input_to_cell_weights,</div>
<div class="line"><span class="lineno">  283</span>  _aux_input_to_output_weights = aux_input_to_output_weights, _input_gate_bias = input_gate_bias;</div>
<div class="line"><span class="lineno">  284</span>  _forget_gate_bias = forget_gate_bias;</div>
<div class="line"><span class="lineno">  285</span>  _cell_gate_bias = cell_gate_bias;</div>
<div class="line"><span class="lineno">  286</span>  _output_gate_bias = output_gate_bias;</div>
<div class="line"><span class="lineno">  287</span>  _projection_weights = projection_weights;</div>
<div class="line"><span class="lineno">  288</span>  _projection_bias = projection_bias;</div>
<div class="line"><span class="lineno">  289</span>  _output_state_in = output_state_in;</div>
<div class="line"><span class="lineno">  290</span>  _cell_state_in = cell_state_in;</div>
<div class="line"><span class="lineno">  291</span>  _params = params;</div>
<div class="line"><span class="lineno">  292</span>  _forward_sequence = forward_sequence;</div>
<div class="line"><span class="lineno">  293</span>  _time_major = time_major;</div>
<div class="line"><span class="lineno">  294</span>  _output_offset = output_offset;</div>
<div class="line"><span class="lineno">  295</span>  _scratch_buffer = scratch_buffer;</div>
<div class="line"><span class="lineno">  296</span>  _output_state = output_state;</div>
<div class="line"><span class="lineno">  297</span>  _cell_state = cell_state;</div>
<div class="line"><span class="lineno">  298</span>  _output = <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">output</a>;</div>
<div class="line"><span class="lineno">  299</span>  _has_output_state_data = has_output_state_data;</div>
<div class="line"><span class="lineno">  300</span>  _has_cell_state_data = has_cell_state_data;</div>
<div class="line"><span class="lineno">  301</span>}</div>
<div class="ttc" id="anamespacegen__h5__explicit__inputs_html_a48dd077479f23bb4552c2d7d6a7a4d37"><div class="ttname"><a href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">gen_h5_explicit_inputs.input</a></div><div class="ttdeci">input</div><div class="ttdef"><b>Definition:</b> <a href="gen__h5__explicit__inputs_8py_source.html#l00034">gen_h5_explicit_inputs.py:34</a></div></div>
<div class="ttc" id="anamespacegen__h5__explicit__inputs_html_acd1aa9ba45d45c6b619b723e6e34c576"><div class="ttname"><a href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">gen_h5_explicit_inputs.output</a></div><div class="ttdeci">output</div><div class="ttdef"><b>Definition:</b> <a href="gen__h5__explicit__inputs_8py_source.html#l00035">gen_h5_explicit_inputs.py:35</a></div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a9735342fe4c78544b5c36eb5d99767b4" name="a9735342fe4c78544b5c36eb5d99767b4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9735342fe4c78544b5c36eb5d99767b4">&#9670;&#160;</a></span>LSTMFloat()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void onert::backend::cpu::ops::LSTMLayer::LSTMFloat </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="_l_s_t_m_layer_8cc_source.html#l00063">63</a> of file <a class="el" href="_l_s_t_m_layer_8cc_source.html">LSTMLayer.cc</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   64</span>{</div>
<div class="line"><span class="lineno">   65</span>  <span class="keyword">auto</span> in_shape = _input-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#aca51cb2522739092a25ca8813bf5e2f5">getShape</a>();</div>
<div class="line"><span class="lineno">   66</span>  assert(in_shape.rank() &gt;= 2 &amp;&amp; in_shape.rank() &lt;= 3);</div>
<div class="line"><span class="lineno">   67</span>  <span class="keywordtype">int</span> max_time, n_batch;</div>
<div class="line"><span class="lineno">   68</span>  <span class="keywordflow">if</span> (in_shape.rank() == 3)</div>
<div class="line"><span class="lineno">   69</span>  {</div>
<div class="line"><span class="lineno">   70</span>    max_time = (_time_major) ? in_shape.dim(0) : in_shape.dim(1);</div>
<div class="line"><span class="lineno">   71</span>    n_batch = (_time_major) ? in_shape.dim(1) : in_shape.dim(0);</div>
<div class="line"><span class="lineno">   72</span>  }</div>
<div class="line"><span class="lineno">   73</span>  <span class="keywordflow">else</span></div>
<div class="line"><span class="lineno">   74</span>  {</div>
<div class="line"><span class="lineno">   75</span>    max_time = 1;</div>
<div class="line"><span class="lineno">   76</span>    n_batch = in_shape.dim(0);</div>
<div class="line"><span class="lineno">   77</span>  }</div>
<div class="line"><span class="lineno">   78</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> n_input = in_shape.dim(_input-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#aca51cb2522739092a25ca8813bf5e2f5">getShape</a>().rank() - 1);</div>
<div class="line"><span class="lineno">   79</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> aux_input_size = 0;</div>
<div class="line"><span class="lineno">   80</span> </div>
<div class="line"><span class="lineno">   81</span>  <span class="comment">// n_cell and n_output will be the same size when there is no projection.</span></div>
<div class="line"><span class="lineno">   82</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> n_cell = _input_to_output_weights-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#aca51cb2522739092a25ca8813bf5e2f5">getShape</a>().dim(0);</div>
<div class="line"><span class="lineno">   83</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> n_output = _recurrent_to_output_weights-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#aca51cb2522739092a25ca8813bf5e2f5">getShape</a>().dim(1);</div>
<div class="line"><span class="lineno">   84</span> </div>
<div class="line"><span class="lineno">   85</span>  <span class="comment">// Since we have already checked that weights are all there or none, we can</span></div>
<div class="line"><span class="lineno">   86</span>  <span class="comment">// check the existence of only one to the get the condition.</span></div>
<div class="line"><span class="lineno">   87</span>  <span class="keyword">const</span> <span class="keywordtype">bool</span> use_cifg = (_input_to_input_weights == <span class="keyword">nullptr</span>);</div>
<div class="line"><span class="lineno">   88</span> </div>
<div class="line"><span class="lineno">   89</span>  <span class="comment">// Optional outputs</span></div>
<div class="line"><span class="lineno">   90</span>  <span class="keywordtype">float</span> *output_state_buf = getOptionalOutputBuffer&lt;float&gt;(_output_state, &amp;_output_state_vec,</div>
<div class="line"><span class="lineno">   91</span>                                                           _output_state_in-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#ae4d0d8bbbe8f7263f820914888ef3141">total_size</a>());</div>
<div class="line"><span class="lineno">   92</span>  <span class="keywordtype">float</span> *cell_state_buf =</div>
<div class="line"><span class="lineno">   93</span>    getOptionalOutputBuffer&lt;float&gt;(_cell_state, &amp;_cell_state_vec, _cell_state_in-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#ae4d0d8bbbe8f7263f820914888ef3141">total_size</a>());</div>
<div class="line"><span class="lineno">   94</span> </div>
<div class="line"><span class="lineno">   95</span>  initializeStateBuffer(_output_state_in, output_state_buf, _has_output_state_data);</div>
<div class="line"><span class="lineno">   96</span>  initializeStateBuffer(_cell_state_in, cell_state_buf, _has_cell_state_data);</div>
<div class="line"><span class="lineno">   97</span> </div>
<div class="line"><span class="lineno">   98</span>  <span class="comment">// Index the scratch buffers pointers to the global scratch buffer.</span></div>
<div class="line"><span class="lineno">   99</span>  <span class="keywordtype">float</span> *scratch_buffer_buf = getOptionalOutputBuffer&lt;float&gt;(</div>
<div class="line"><span class="lineno">  100</span>    _scratch_buffer, &amp;_scratch_vec, n_batch * n_cell * (use_cifg ? 3 : 4) * <span class="keyword">sizeof</span>(<span class="keywordtype">float</span>));</div>
<div class="line"><span class="lineno">  101</span>  <span class="keywordtype">float</span> *input_gate_scratch = <span class="keyword">nullptr</span>;</div>
<div class="line"><span class="lineno">  102</span>  <span class="keywordtype">float</span> *cell_gate_scratch = <span class="keyword">nullptr</span>;</div>
<div class="line"><span class="lineno">  103</span>  <span class="keywordtype">float</span> *forget_gate_scratch = <span class="keyword">nullptr</span>;</div>
<div class="line"><span class="lineno">  104</span>  <span class="keywordtype">float</span> *output_gate_scratch = <span class="keyword">nullptr</span>;</div>
<div class="line"><span class="lineno">  105</span>  <span class="keywordflow">if</span> (use_cifg)</div>
<div class="line"><span class="lineno">  106</span>  {</div>
<div class="line"><span class="lineno">  107</span>    cell_gate_scratch = scratch_buffer_buf;</div>
<div class="line"><span class="lineno">  108</span>    forget_gate_scratch = scratch_buffer_buf + n_cell * n_batch;</div>
<div class="line"><span class="lineno">  109</span>    output_gate_scratch = scratch_buffer_buf + 2 * n_cell * n_batch;</div>
<div class="line"><span class="lineno">  110</span>  }</div>
<div class="line"><span class="lineno">  111</span>  <span class="keywordflow">else</span></div>
<div class="line"><span class="lineno">  112</span>  {</div>
<div class="line"><span class="lineno">  113</span>    input_gate_scratch = scratch_buffer_buf;</div>
<div class="line"><span class="lineno">  114</span>    cell_gate_scratch = scratch_buffer_buf + n_cell * n_batch;</div>
<div class="line"><span class="lineno">  115</span>    forget_gate_scratch = scratch_buffer_buf + 2 * n_cell * n_batch;</div>
<div class="line"><span class="lineno">  116</span>    output_gate_scratch = scratch_buffer_buf + 3 * n_cell * n_batch;</div>
<div class="line"><span class="lineno">  117</span>  }</div>
<div class="line"><span class="lineno">  118</span> </div>
<div class="line"><span class="lineno">  119</span>  <span class="keyword">auto</span> optional_tensor_ptr = [](<span class="keyword">const</span> IPortableTensor *<a class="code hl_variable" href="namespace_gen_h5_random_inputs.html#a8ccc67c6dabd22b5465400b73929c0fc">tensor</a>) {</div>
<div class="line"><span class="lineno">  120</span>    <span class="comment">// If tensor is not given or the tensor size is 0, consider it was not given</span></div>
<div class="line"><span class="lineno">  121</span>    <span class="keywordflow">return</span> (tensor &amp;&amp; <a class="code hl_variable" href="namespace_gen_h5_random_inputs.html#a8ccc67c6dabd22b5465400b73929c0fc">tensor</a>-&gt;total_size() &gt; 0) ? getBuffer&lt;float&gt;(tensor) : <span class="keyword">nullptr</span>;</div>
<div class="line"><span class="lineno">  122</span>  };</div>
<div class="line"><span class="lineno">  123</span>  <span class="comment">// Optional inputs</span></div>
<div class="line"><span class="lineno">  124</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> *input_to_input_weights_ptr = optional_tensor_ptr(_input_to_input_weights);</div>
<div class="line"><span class="lineno">  125</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> *recurrent_to_input_weights_ptr = optional_tensor_ptr(_recurrent_to_input_weights);</div>
<div class="line"><span class="lineno">  126</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> *cell_to_input_weights_ptr = optional_tensor_ptr(_cell_to_input_weights);</div>
<div class="line"><span class="lineno">  127</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> *cell_to_forget_weights_ptr = optional_tensor_ptr(_cell_to_forget_weights);</div>
<div class="line"><span class="lineno">  128</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> *cell_to_output_weights_ptr = optional_tensor_ptr(_cell_to_output_weights);</div>
<div class="line"><span class="lineno">  129</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> *input_gate_bias_ptr = optional_tensor_ptr(_input_gate_bias);</div>
<div class="line"><span class="lineno">  130</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> *projection_weights_ptr = optional_tensor_ptr(_projection_weights);</div>
<div class="line"><span class="lineno">  131</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> *projection_bias_ptr = optional_tensor_ptr(_projection_bias);</div>
<div class="line"><span class="lineno">  132</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> *input_layer_norm_coefficients_ptr =</div>
<div class="line"><span class="lineno">  133</span>    optional_tensor_ptr(_input_layer_norm_coefficients);</div>
<div class="line"><span class="lineno">  134</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> *forget_layer_norm_coefficients_ptr =</div>
<div class="line"><span class="lineno">  135</span>    optional_tensor_ptr(_forget_layer_norm_coefficients);</div>
<div class="line"><span class="lineno">  136</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> *cell_layer_norm_coefficients_ptr =</div>
<div class="line"><span class="lineno">  137</span>    optional_tensor_ptr(_cell_layer_norm_coefficients);</div>
<div class="line"><span class="lineno">  138</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> *output_layer_norm_coefficients_ptr =</div>
<div class="line"><span class="lineno">  139</span>    optional_tensor_ptr(_output_layer_norm_coefficients);</div>
<div class="line"><span class="lineno">  140</span> </div>
<div class="line"><span class="lineno">  141</span>  <span class="comment">// Copy out the LSTM specific params so they can be passed in the function.</span></div>
<div class="line"><span class="lineno">  142</span>  <a class="code hl_struct" href="structnnfw_1_1cker_1_1_l_s_t_m_params.html">nnfw::cker::LSTMParams</a> lstm_params;</div>
<div class="line"><span class="lineno">  143</span>  lstm_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_l_s_t_m_params.html#ab3a9e171f2b52072433b8da3935ab740">activation</a> = <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a0e7672ebf55bbaa7e1d86a46cfd53c5e">convertActivationType</a>(_params.<a class="code hl_variable" href="structonert_1_1ir_1_1operation_1_1_l_s_t_m_1_1_param.html#a8ab9d799a18524ddc00afbe22d9aaff1">activation</a>);</div>
<div class="line"><span class="lineno">  144</span>  lstm_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_l_s_t_m_params.html#a0138a9307034d1fbd0f44aae19d29151">cell_clip</a> = _params.<a class="code hl_variable" href="structonert_1_1ir_1_1operation_1_1_l_s_t_m_1_1_param.html#a189a1ffcd89a7fb8b35c8267098cb5c5">cell_threshold</a>;</div>
<div class="line"><span class="lineno">  145</span>  lstm_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_l_s_t_m_params.html#a3d44ac1967b70bcb414a130952a47a0f">proj_clip</a> = _params.<a class="code hl_variable" href="structonert_1_1ir_1_1operation_1_1_l_s_t_m_1_1_param.html#a5553526ec8e4f070ee7e0642e23fb990">projection_threshold</a>;</div>
<div class="line"><span class="lineno">  146</span> </div>
<div class="line"><span class="lineno">  147</span>  <span class="keyword">auto</span> out_shape = _output-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#aca51cb2522739092a25ca8813bf5e2f5">getShape</a>();</div>
<div class="line"><span class="lineno">  148</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> output_batch_leading_dim = out_shape.dim(out_shape.rank() - 1);</div>
<div class="line"><span class="lineno">  149</span>  <span class="keywordflow">if</span> (_time_major)</div>
<div class="line"><span class="lineno">  150</span>  {</div>
<div class="line"><span class="lineno">  151</span>    <span class="comment">// Loop through the sequence.</span></div>
<div class="line"><span class="lineno">  152</span>    <span class="keyword">const</span> <span class="keywordtype">int</span> input_step = n_batch * n_input;</div>
<div class="line"><span class="lineno">  153</span>    <span class="keyword">const</span> <span class="keywordtype">int</span> output_step = n_batch * output_batch_leading_dim;</div>
<div class="line"><span class="lineno">  154</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> t = 0; t &lt; max_time; t++)</div>
<div class="line"><span class="lineno">  155</span>    {</div>
<div class="line"><span class="lineno">  156</span>      <span class="comment">// If this is the forward_sequence, step forward, otherwise step</span></div>
<div class="line"><span class="lineno">  157</span>      <span class="comment">// backwards.</span></div>
<div class="line"><span class="lineno">  158</span>      <span class="keyword">const</span> <span class="keywordtype">int</span> t_rel = _forward_sequence ? t : max_time - t - 1;</div>
<div class="line"><span class="lineno">  159</span>      <span class="keyword">const</span> <span class="keywordtype">float</span> *input_ptr = getBuffer&lt;float&gt;(_input) + t_rel * input_step;</div>
<div class="line"><span class="lineno">  160</span>      <span class="keyword">const</span> <span class="keywordtype">float</span> *aux_input_ptr = <span class="keyword">nullptr</span>;</div>
<div class="line"><span class="lineno">  161</span>      <span class="keywordflow">if</span> (_aux_input)</div>
<div class="line"><span class="lineno">  162</span>      {</div>
<div class="line"><span class="lineno">  163</span>        aux_input_ptr = getBuffer&lt;float&gt;(_aux_input) + t_rel * input_step;</div>
<div class="line"><span class="lineno">  164</span>      }</div>
<div class="line"><span class="lineno">  165</span>      <span class="keywordtype">float</span> *output_ptr = getBuffer&lt;float&gt;(_output) + t_rel * output_step + _output_offset;</div>
<div class="line"><span class="lineno">  166</span> </div>
<div class="line"><span class="lineno">  167</span>      <a class="code hl_function" href="namespacennfw_1_1cker.html#ae6c06b361e57b13dd187ca45ed5fc737">LstmStepFloat</a>(</div>
<div class="line"><span class="lineno">  168</span>        input_ptr, input_to_input_weights_ptr, getBuffer&lt;float&gt;(_input_to_forget_weights),</div>
<div class="line"><span class="lineno">  169</span>        getBuffer&lt;float&gt;(_input_to_cell_weights), getBuffer&lt;float&gt;(_input_to_output_weights),</div>
<div class="line"><span class="lineno">  170</span>        aux_input_ptr,</div>
<div class="line"><span class="lineno">  171</span>        <span class="comment">/*aux_input_to_input_weights=*/</span><span class="keyword">nullptr</span>,</div>
<div class="line"><span class="lineno">  172</span>        <span class="comment">/*aux_input_to_forget_weights=*/</span><span class="keyword">nullptr</span>,</div>
<div class="line"><span class="lineno">  173</span>        <span class="comment">/*aux_input_to_cell_weights=*/</span><span class="keyword">nullptr</span>,</div>
<div class="line"><span class="lineno">  174</span>        <span class="comment">/*aux_input_to_output_weights=*/</span><span class="keyword">nullptr</span>, recurrent_to_input_weights_ptr,</div>
<div class="line"><span class="lineno">  175</span>        getBuffer&lt;float&gt;(_recurrent_to_forget_weights),</div>
<div class="line"><span class="lineno">  176</span>        getBuffer&lt;float&gt;(_recurrent_to_cell_weights),</div>
<div class="line"><span class="lineno">  177</span>        getBuffer&lt;float&gt;(_recurrent_to_output_weights), cell_to_input_weights_ptr,</div>
<div class="line"><span class="lineno">  178</span>        cell_to_forget_weights_ptr, cell_to_output_weights_ptr, input_layer_norm_coefficients_ptr,</div>
<div class="line"><span class="lineno">  179</span>        forget_layer_norm_coefficients_ptr, cell_layer_norm_coefficients_ptr,</div>
<div class="line"><span class="lineno">  180</span>        output_layer_norm_coefficients_ptr, input_gate_bias_ptr,</div>
<div class="line"><span class="lineno">  181</span>        getBuffer&lt;float&gt;(_forget_gate_bias), getBuffer&lt;float&gt;(_cell_gate_bias),</div>
<div class="line"><span class="lineno">  182</span>        getBuffer&lt;float&gt;(_output_gate_bias), projection_weights_ptr, projection_bias_ptr,</div>
<div class="line"><span class="lineno">  183</span>        &amp;lstm_params, n_batch, n_cell, n_input, aux_input_size, n_output, output_batch_leading_dim,</div>
<div class="line"><span class="lineno">  184</span>        output_state_buf, cell_state_buf, input_gate_scratch, forget_gate_scratch,</div>
<div class="line"><span class="lineno">  185</span>        cell_gate_scratch, output_gate_scratch, output_ptr);</div>
<div class="line"><span class="lineno">  186</span>    }</div>
<div class="line"><span class="lineno">  187</span>  }</div>
<div class="line"><span class="lineno">  188</span>  <span class="keywordflow">else</span></div>
<div class="line"><span class="lineno">  189</span>  {</div>
<div class="line"><span class="lineno">  190</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> b = 0; <a class="code hl_variable" href="namespacejpeg2hdf5.html#a1a0fe2ec4c2bc8757bcf4f0fcd4f74c1">b</a> &lt; n_batch; <a class="code hl_variable" href="namespacejpeg2hdf5.html#a1a0fe2ec4c2bc8757bcf4f0fcd4f74c1">b</a>++)</div>
<div class="line"><span class="lineno">  191</span>    {</div>
<div class="line"><span class="lineno">  192</span>      <span class="keyword">const</span> <span class="keywordtype">int</span> input_step = n_input;</div>
<div class="line"><span class="lineno">  193</span>      <span class="keyword">const</span> <span class="keywordtype">int</span> output_step = output_batch_leading_dim;</div>
<div class="line"><span class="lineno">  194</span>      <span class="keywordflow">for</span> (<span class="keywordtype">int</span> t = 0; t &lt; max_time; t++)</div>
<div class="line"><span class="lineno">  195</span>      {</div>
<div class="line"><span class="lineno">  196</span>        <span class="comment">// If this is the forward_sequence, step forward, otherwise step</span></div>
<div class="line"><span class="lineno">  197</span>        <span class="comment">// backwards.</span></div>
<div class="line"><span class="lineno">  198</span>        <span class="keyword">const</span> <span class="keywordtype">int</span> t_rel = _forward_sequence ? t : max_time - t - 1;</div>
<div class="line"><span class="lineno">  199</span>        <span class="keyword">const</span> <span class="keywordtype">int</span> time_offset = <a class="code hl_variable" href="namespacejpeg2hdf5.html#a1a0fe2ec4c2bc8757bcf4f0fcd4f74c1">b</a> * max_time + t_rel;</div>
<div class="line"><span class="lineno">  200</span>        <span class="keyword">const</span> <span class="keywordtype">float</span> *input_ptr = getBuffer&lt;float&gt;(_input) + time_offset * input_step;</div>
<div class="line"><span class="lineno">  201</span>        <span class="keyword">const</span> <span class="keywordtype">float</span> *aux_input_ptr = <span class="keyword">nullptr</span>;</div>
<div class="line"><span class="lineno">  202</span>        <span class="keywordflow">if</span> (_aux_input)</div>
<div class="line"><span class="lineno">  203</span>        {</div>
<div class="line"><span class="lineno">  204</span>          aux_input_ptr = getBuffer&lt;float&gt;(_aux_input) + time_offset * input_step;</div>
<div class="line"><span class="lineno">  205</span>        }</div>
<div class="line"><span class="lineno">  206</span>        <span class="keywordtype">float</span> *output_ptr = getBuffer&lt;float&gt;(_output) + time_offset * output_step + _output_offset;</div>
<div class="line"><span class="lineno">  207</span> </div>
<div class="line"><span class="lineno">  208</span>        <span class="comment">// Offset the {output,cell}_state pointers to the right batch.</span></div>
<div class="line"><span class="lineno">  209</span>        <span class="keywordtype">float</span> *output_state_ptr = output_state_buf + <a class="code hl_variable" href="namespacejpeg2hdf5.html#a1a0fe2ec4c2bc8757bcf4f0fcd4f74c1">b</a> * output_batch_leading_dim;</div>
<div class="line"><span class="lineno">  210</span>        <span class="keywordtype">float</span> *cell_state_ptr = cell_state_buf + <a class="code hl_variable" href="namespacejpeg2hdf5.html#a1a0fe2ec4c2bc8757bcf4f0fcd4f74c1">b</a> * n_cell;</div>
<div class="line"><span class="lineno">  211</span>        <span class="comment">// Offset the scratch pointers to the right batch.</span></div>
<div class="line"><span class="lineno">  212</span>        <span class="keywordtype">float</span> *input_gate_scratch_ptr =</div>
<div class="line"><span class="lineno">  213</span>          input_gate_scratch ? input_gate_scratch + <a class="code hl_variable" href="namespacejpeg2hdf5.html#a1a0fe2ec4c2bc8757bcf4f0fcd4f74c1">b</a> * n_cell : <span class="keyword">nullptr</span>;</div>
<div class="line"><span class="lineno">  214</span>        <span class="keywordtype">float</span> *forget_gate_scratch_ptr = forget_gate_scratch + <a class="code hl_variable" href="namespacejpeg2hdf5.html#a1a0fe2ec4c2bc8757bcf4f0fcd4f74c1">b</a> * n_cell;</div>
<div class="line"><span class="lineno">  215</span>        <span class="keywordtype">float</span> *cell_gate_scratch_ptr = cell_gate_scratch + <a class="code hl_variable" href="namespacejpeg2hdf5.html#a1a0fe2ec4c2bc8757bcf4f0fcd4f74c1">b</a> * n_cell;</div>
<div class="line"><span class="lineno">  216</span>        <span class="keywordtype">float</span> *output_gate_scratch_ptr = output_gate_scratch + <a class="code hl_variable" href="namespacejpeg2hdf5.html#a1a0fe2ec4c2bc8757bcf4f0fcd4f74c1">b</a> * n_cell;</div>
<div class="line"><span class="lineno">  217</span> </div>
<div class="line"><span class="lineno">  218</span>        <a class="code hl_function" href="namespacennfw_1_1cker.html#ae6c06b361e57b13dd187ca45ed5fc737">LstmStepFloat</a>(</div>
<div class="line"><span class="lineno">  219</span>          input_ptr, input_to_input_weights_ptr, getBuffer&lt;float&gt;(_input_to_forget_weights),</div>
<div class="line"><span class="lineno">  220</span>          getBuffer&lt;float&gt;(_input_to_cell_weights), getBuffer&lt;float&gt;(_input_to_output_weights),</div>
<div class="line"><span class="lineno">  221</span>          aux_input_ptr,</div>
<div class="line"><span class="lineno">  222</span>          <span class="comment">/*aux_input_to_input_weights=*/</span><span class="keyword">nullptr</span>,</div>
<div class="line"><span class="lineno">  223</span>          <span class="comment">/*aux_input_to_forget_weights=*/</span><span class="keyword">nullptr</span>,</div>
<div class="line"><span class="lineno">  224</span>          <span class="comment">/*aux_input_to_cell_weights=*/</span><span class="keyword">nullptr</span>,</div>
<div class="line"><span class="lineno">  225</span>          <span class="comment">/*aux_input_to_output_weights=*/</span><span class="keyword">nullptr</span>, recurrent_to_input_weights_ptr,</div>
<div class="line"><span class="lineno">  226</span>          getBuffer&lt;float&gt;(_recurrent_to_forget_weights),</div>
<div class="line"><span class="lineno">  227</span>          getBuffer&lt;float&gt;(_recurrent_to_cell_weights),</div>
<div class="line"><span class="lineno">  228</span>          getBuffer&lt;float&gt;(_recurrent_to_output_weights), cell_to_input_weights_ptr,</div>
<div class="line"><span class="lineno">  229</span>          cell_to_forget_weights_ptr, cell_to_output_weights_ptr, input_layer_norm_coefficients_ptr,</div>
<div class="line"><span class="lineno">  230</span>          forget_layer_norm_coefficients_ptr, cell_layer_norm_coefficients_ptr,</div>
<div class="line"><span class="lineno">  231</span>          output_layer_norm_coefficients_ptr, input_gate_bias_ptr,</div>
<div class="line"><span class="lineno">  232</span>          getBuffer&lt;float&gt;(_forget_gate_bias), getBuffer&lt;float&gt;(_cell_gate_bias),</div>
<div class="line"><span class="lineno">  233</span>          getBuffer&lt;float&gt;(_output_gate_bias), projection_weights_ptr, projection_bias_ptr,</div>
<div class="line"><span class="lineno">  234</span>          &amp;lstm_params, <span class="comment">/*n_batch=*/</span>1, n_cell, n_input, aux_input_size, n_output,</div>
<div class="line"><span class="lineno">  235</span>          output_batch_leading_dim, output_state_ptr, cell_state_ptr, input_gate_scratch_ptr,</div>
<div class="line"><span class="lineno">  236</span>          forget_gate_scratch_ptr, cell_gate_scratch_ptr, output_gate_scratch_ptr, output_ptr);</div>
<div class="line"><span class="lineno">  237</span>      }</div>
<div class="line"><span class="lineno">  238</span>    }</div>
<div class="line"><span class="lineno">  239</span>  }</div>
<div class="line"><span class="lineno">  240</span>}</div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_tensor_html_aca51cb2522739092a25ca8813bf5e2f5"><div class="ttname"><a href="classonert_1_1backend_1_1_i_tensor.html#aca51cb2522739092a25ca8813bf5e2f5">onert::backend::ITensor::getShape</a></div><div class="ttdeci">virtual ir::Shape getShape() const =0</div><div class="ttdoc">Get ir::Shape of tensor.</div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_tensor_html_ae4d0d8bbbe8f7263f820914888ef3141"><div class="ttname"><a href="classonert_1_1backend_1_1_i_tensor.html#ae4d0d8bbbe8f7263f820914888ef3141">onert::backend::ITensor::total_size</a></div><div class="ttdeci">virtual size_t total_size() const =0</div></div>
<div class="ttc" id="anamespace_gen_h5_random_inputs_html_a8ccc67c6dabd22b5465400b73929c0fc"><div class="ttname"><a href="namespace_gen_h5_random_inputs.html#a8ccc67c6dabd22b5465400b73929c0fc">GenH5RandomInputs.tensor</a></div><div class="ttdeci">tensor</div><div class="ttdef"><b>Definition:</b> <a href="_gen_h5_random_inputs_8py_source.html#l00061">GenH5RandomInputs.py:61</a></div></div>
<div class="ttc" id="anamespacejpeg2hdf5_html_a1a0fe2ec4c2bc8757bcf4f0fcd4f74c1"><div class="ttname"><a href="namespacejpeg2hdf5.html#a1a0fe2ec4c2bc8757bcf4f0fcd4f74c1">jpeg2hdf5.b</a></div><div class="ttdeci">b</div><div class="ttdef"><b>Definition:</b> <a href="jpeg2hdf5_8py_source.html#l00105">jpeg2hdf5.py:105</a></div></div>
<div class="ttc" id="anamespacennfw_1_1cker_html_ae6c06b361e57b13dd187ca45ed5fc737"><div class="ttname"><a href="namespacennfw_1_1cker.html#ae6c06b361e57b13dd187ca45ed5fc737">nnfw::cker::LstmStepFloat</a></div><div class="ttdeci">void LstmStepFloat(const float *input_ptr, const float *input_to_input_weights_ptr, const float *input_to_forget_weights_ptr, const float *input_to_cell_weights_ptr, const float *input_to_output_weights_ptr, const float *aux_input_ptr, const float *aux_input_to_input_weights_ptr, const float *aux_input_to_forget_weights_ptr, const float *aux_input_to_cell_weights_ptr, const float *aux_input_to_output_weights_ptr, const float *recurrent_to_input_weights_ptr, const float *recurrent_to_forget_weights_ptr, const float *recurrent_to_cell_weights_ptr, const float *recurrent_to_output_weights_ptr, const float *cell_to_input_weights_ptr, const float *cell_to_forget_weights_ptr, const float *cell_to_output_weights_ptr, const float *input_layer_norm_coefficients_ptr, const float *forget_layer_norm_coefficients_ptr, const float *cell_layer_norm_coefficients_ptr, const float *output_layer_norm_coefficients_ptr, const float *input_gate_bias_ptr, const float *forget_gate_bias_ptr, const float *cell_gate_bias_ptr, const float *output_gate_bias_ptr, const float *projection_weights_ptr, const float *projection_bias_ptr, const LSTMParams *params, int n_batch, int n_cell, int n_input, int n_aux_input, int n_output, int output_batch_leading_dim, float *output_state_ptr, float *cell_state_ptr, float *scratch0, float *scratch1, float *scratch2, float *scratch3, float *output_ptr)</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2operation_2_l_s_t_m_8h_source.html#l00285">LSTM.h:285</a></div></div>
<div class="ttc" id="anamespaceonert_1_1backend_1_1cpu_1_1ops_html_a0e7672ebf55bbaa7e1d86a46cfd53c5e"><div class="ttname"><a href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a0e7672ebf55bbaa7e1d86a46cfd53c5e">onert::backend::cpu::ops::convertActivationType</a></div><div class="ttdeci">nnfw::cker::FusedActivationFunctionType convertActivationType(const ir::Activation activation)</div><div class="ttdef"><b>Definition:</b> <a href="cpu_2ops_2_operation_utils_8h_source.html#l00114">OperationUtils.h:114</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_l_s_t_m_params_html"><div class="ttname"><a href="structnnfw_1_1cker_1_1_l_s_t_m_params.html">nnfw::cker::LSTMParams</a></div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00279">Types.h:280</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_l_s_t_m_params_html_a0138a9307034d1fbd0f44aae19d29151"><div class="ttname"><a href="structnnfw_1_1cker_1_1_l_s_t_m_params.html#a0138a9307034d1fbd0f44aae19d29151">nnfw::cker::LSTMParams::cell_clip</a></div><div class="ttdeci">float cell_clip</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00283">Types.h:283</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_l_s_t_m_params_html_a3d44ac1967b70bcb414a130952a47a0f"><div class="ttname"><a href="structnnfw_1_1cker_1_1_l_s_t_m_params.html#a3d44ac1967b70bcb414a130952a47a0f">nnfw::cker::LSTMParams::proj_clip</a></div><div class="ttdeci">float proj_clip</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00284">Types.h:284</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_l_s_t_m_params_html_ab3a9e171f2b52072433b8da3935ab740"><div class="ttname"><a href="structnnfw_1_1cker_1_1_l_s_t_m_params.html#ab3a9e171f2b52072433b8da3935ab740">nnfw::cker::LSTMParams::activation</a></div><div class="ttdeci">FusedActivationFunctionType activation</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00282">Types.h:282</a></div></div>
<div class="ttc" id="astructonert_1_1ir_1_1operation_1_1_l_s_t_m_1_1_param_html_a189a1ffcd89a7fb8b35c8267098cb5c5"><div class="ttname"><a href="structonert_1_1ir_1_1operation_1_1_l_s_t_m_1_1_param.html#a189a1ffcd89a7fb8b35c8267098cb5c5">onert::ir::operation::LSTM::Param::cell_threshold</a></div><div class="ttdeci">float cell_threshold</div><div class="ttdef"><b>Definition:</b> <a href="runtime_2onert_2core_2include_2ir_2operation_2_l_s_t_m_8h_source.html#l00072">LSTM.h:72</a></div></div>
<div class="ttc" id="astructonert_1_1ir_1_1operation_1_1_l_s_t_m_1_1_param_html_a5553526ec8e4f070ee7e0642e23fb990"><div class="ttname"><a href="structonert_1_1ir_1_1operation_1_1_l_s_t_m_1_1_param.html#a5553526ec8e4f070ee7e0642e23fb990">onert::ir::operation::LSTM::Param::projection_threshold</a></div><div class="ttdeci">float projection_threshold</div><div class="ttdef"><b>Definition:</b> <a href="runtime_2onert_2core_2include_2ir_2operation_2_l_s_t_m_8h_source.html#l00073">LSTM.h:73</a></div></div>
<div class="ttc" id="astructonert_1_1ir_1_1operation_1_1_l_s_t_m_1_1_param_html_a8ab9d799a18524ddc00afbe22d9aaff1"><div class="ttname"><a href="structonert_1_1ir_1_1operation_1_1_l_s_t_m_1_1_param.html#a8ab9d799a18524ddc00afbe22d9aaff1">onert::ir::operation::LSTM::Param::activation</a></div><div class="ttdeci">Activation activation</div><div class="ttdef"><b>Definition:</b> <a href="runtime_2onert_2core_2include_2ir_2operation_2_l_s_t_m_8h_source.html#l00071">LSTM.h:71</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00282">nnfw::cker::LSTMParams::activation</a>, <a class="el" href="runtime_2onert_2core_2include_2ir_2operation_2_l_s_t_m_8h_source.html#l00071">onert::ir::operation::LSTM::Param::activation</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00283">nnfw::cker::LSTMParams::cell_clip</a>, <a class="el" href="runtime_2onert_2core_2include_2ir_2operation_2_l_s_t_m_8h_source.html#l00072">onert::ir::operation::LSTM::Param::cell_threshold</a>, <a class="el" href="cpu_2ops_2_operation_utils_8h_source.html#l00114">onert::backend::cpu::ops::convertActivationType()</a>, <a class="el" href="classonert_1_1backend_1_1_i_tensor.html#aca51cb2522739092a25ca8813bf5e2f5">onert::backend::ITensor::getShape()</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00284">nnfw::cker::LSTMParams::proj_clip</a>, <a class="el" href="runtime_2onert_2core_2include_2ir_2operation_2_l_s_t_m_8h_source.html#l00073">onert::ir::operation::LSTM::Param::projection_threshold</a>, and <a class="el" href="classonert_1_1backend_1_1_i_tensor.html#ae4d0d8bbbe8f7263f820914888ef3141">onert::backend::ITensor::total_size()</a>.</p>

<p class="reference">Referenced by <a class="el" href="_l_s_t_m_layer_8cc_source.html#l00303">run()</a>.</p>

</div>
</div>
<a id="a22e2633b3009ae6b31d63815749b37c3" name="a22e2633b3009ae6b31d63815749b37c3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a22e2633b3009ae6b31d63815749b37c3">&#9670;&#160;</a></span>run()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void onert::backend::cpu::ops::LSTMLayer::run </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Implements <a class="el" href="classonert_1_1exec_1_1_i_function.html#aedd6f5e12852d808abb97327b9d229e2">onert::exec::IFunction</a>.</p>

<p class="definition">Definition at line <a class="el" href="_l_s_t_m_layer_8cc_source.html#l00303">303</a> of file <a class="el" href="_l_s_t_m_layer_8cc_source.html">LSTMLayer.cc</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  304</span>{</div>
<div class="line"><span class="lineno">  305</span> </div>
<div class="line"><span class="lineno">  306</span>  <span class="keywordflow">if</span> (_input-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#a6d57b178316225a9e08f1191ce489ad9">data_type</a>() == OperandType::FLOAT32)</div>
<div class="line"><span class="lineno">  307</span>  {</div>
<div class="line"><span class="lineno">  308</span>    <a class="code hl_function" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_l_s_t_m_layer.html#a9735342fe4c78544b5c36eb5d99767b4">LSTMFloat</a>();</div>
<div class="line"><span class="lineno">  309</span>  }</div>
<div class="line"><span class="lineno">  310</span>  <span class="keywordflow">else</span></div>
<div class="line"><span class="lineno">  311</span>  {</div>
<div class="line"><span class="lineno">  312</span>    <span class="keywordflow">throw</span> std::runtime_error{<span class="stringliteral">&quot;LSTMLayer: unsupported data type&quot;</span>};</div>
<div class="line"><span class="lineno">  313</span>  }</div>
<div class="line"><span class="lineno">  314</span>}</div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_tensor_html_a6d57b178316225a9e08f1191ce489ad9"><div class="ttname"><a href="classonert_1_1backend_1_1_i_tensor.html#a6d57b178316225a9e08f1191ce489ad9">onert::backend::ITensor::data_type</a></div><div class="ttdeci">virtual ir::DataType data_type() const =0</div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_l_s_t_m_layer_html_a9735342fe4c78544b5c36eb5d99767b4"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_l_s_t_m_layer.html#a9735342fe4c78544b5c36eb5d99767b4">onert::backend::cpu::ops::LSTMLayer::LSTMFloat</a></div><div class="ttdeci">void LSTMFloat()</div><div class="ttdef"><b>Definition:</b> <a href="_l_s_t_m_layer_8cc_source.html#l00063">LSTMLayer.cc:63</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="classonert_1_1backend_1_1_i_tensor.html#a6d57b178316225a9e08f1191ce489ad9">onert::backend::ITensor::data_type()</a>, and <a class="el" href="_l_s_t_m_layer_8cc_source.html#l00063">LSTMFloat()</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>runtime/onert/backend/cpu/ops/<a class="el" href="_l_s_t_m_layer_8h_source.html">LSTMLayer.h</a></li>
<li>runtime/onert/backend/cpu/ops/<a class="el" href="_l_s_t_m_layer_8cc_source.html">LSTMLayer.cc</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespaceonert.html">onert</a></li><li class="navelem"><a class="el" href="namespaceonert_1_1backend.html">backend</a></li><li class="navelem"><a class="el" href="namespaceonert_1_1backend_1_1cpu.html">cpu</a></li><li class="navelem"><a class="el" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html">ops</a></li><li class="navelem"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_l_s_t_m_layer.html">LSTMLayer</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.5 </li>
  </ul>
</div>
</body>
</html>
