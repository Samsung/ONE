<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ONE - On-device Neural Engine: runtime/onert/backend/train/ops/FullyConnectedLayer.cc Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">ONE - On-device Neural Engine
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function() { init_codefold(0); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('train_2ops_2_fully_connected_layer_8cc_source.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">FullyConnectedLayer.cc</div></div>
</div><!--header-->
<div class="contents">
<a href="train_2ops_2_fully_connected_layer_8cc.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno">    1</span><span class="comment">/*</span></div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="comment"> * Copyright (c) 2023 Samsung Electronics Co., Ltd. All Rights Reserved</span></div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span><span class="comment"> *</span></div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span><span class="comment"> * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span><span class="comment"> * you may not use this file except in compliance with the License.</span></div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span><span class="comment"> * You may obtain a copy of the License at</span></div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span><span class="comment"> *</span></div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno">    8</span><span class="comment"> *      http://www.apache.org/licenses/LICENSE-2.0</span></div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span><span class="comment"> *</span></div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span><span class="comment"> * Unless required by applicable law or agreed to in writing, software</span></div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span><span class="comment"> * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span><span class="comment"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span><span class="comment"> * See the License for the specific language governing permissions and</span></div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="comment"> * limitations under the License.</span></div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span><span class="comment"> */</span></div>
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno">   16</span> </div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span><span class="preprocessor">#include &quot;<a class="code" href="xnnpack_2ops_2_fully_connected_layer_8h.html">FullyConnectedLayer.h</a>&quot;</span></div>
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno">   18</span> </div>
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno">   19</span><span class="preprocessor">#include &quot;<a class="code" href="xnnpack_2ops_2_operation_utils_8h.html">OperationUtils.h</a>&quot;</span></div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span> </div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno">   21</span><span class="preprocessor">#include &lt;<a class="code" href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h.html">cker/operation/FullyConnected.h</a>&gt;</span></div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span><span class="preprocessor">#include &lt;<a class="code" href="compute_2cker_2include_2cker_2operation_2_transpose_8h.html">cker/operation/Transpose.h</a>&gt;</span></div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno">   23</span><span class="preprocessor">#include &lt;<a class="code" href="compute_2cker_2include_2cker_2train_2operation_2_fully_connected_8h.html">cker/train/operation/FullyConnected.h</a>&gt;</span></div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno">   24</span><span class="preprocessor">#include &lt;<a class="code" href="compute_2cker_2include_2cker_2train_2operation_2_re_l_u_8h.html">cker/train/operation/ReLU.h</a>&gt;</span></div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno">   25</span> </div>
<div class="line"><a id="l00026" name="l00026"></a><span class="lineno">   26</span><span class="keyword">namespace</span></div>
<div class="line"><a id="l00027" name="l00027"></a><span class="lineno">   27</span>{</div>
<div class="line"><a id="l00028" name="l00028"></a><span class="lineno">   28</span> </div>
<div class="line"><a id="l00029" name="l00029"></a><span class="lineno">   29</span><span class="keyword">using namespace </span><a class="code hl_namespace" href="namespaceonert.html">onert</a>;</div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno">   30</span> </div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno">   31</span>std::unique_ptr&lt;backend::train::Tensor&gt;</div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno">   32</span>createTransposedTensor(<span class="keyword">const</span> <a class="code hl_class" href="classonert_1_1backend_1_1_i_portable_tensor.html">backend::IPortableTensor</a> *origin_tensor)</div>
<div class="line"><a id="l00033" name="l00033"></a><span class="lineno">   33</span>{</div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno">   34</span>  <span class="keyword">const</span> <span class="keyword">auto</span> &amp;origin_shape = origin_tensor-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#ad010d0f248f6e0e400485d81410ac158">getShape</a>();</div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno">   35</span>  assert(origin_shape.rank() == 2);</div>
<div class="line"><a id="l00036" name="l00036"></a><span class="lineno">   36</span> </div>
<div class="line"><a id="l00037" name="l00037"></a><span class="lineno">   37</span>  <span class="keyword">auto</span> transposed_info = origin_tensor-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#a5aa2cfeb527066e9bee0316f67f67b1d">get_info</a>();</div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno">   38</span>  <span class="keyword">auto</span> transposed_shape = <a class="code hl_struct" href="structonert_1_1ir_1_1_shape.html">ir::Shape</a>{origin_shape.<a class="code hl_function" href="structonert_1_1ir_1_1_shape.html#a3c78b1b9d3b66da28ddacb66cd1ea305">dim</a>(1), origin_shape.dim(0)};</div>
<div class="line"><a id="l00039" name="l00039"></a><span class="lineno">   39</span>  transposed_info.shape(transposed_shape);</div>
<div class="line"><a id="l00040" name="l00040"></a><span class="lineno">   40</span> </div>
<div class="line"><a id="l00041" name="l00041"></a><span class="lineno">   41</span>  <span class="keywordflow">return</span> std::make_unique&lt;backend::train::Tensor&gt;(transposed_info);</div>
<div class="line"><a id="l00042" name="l00042"></a><span class="lineno">   42</span>}</div>
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno">   43</span> </div>
<div class="line"><a id="l00044" name="l00044"></a><span class="lineno">   44</span>} <span class="comment">// namespace</span></div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno">   45</span> </div>
<div class="line"><a id="l00046" name="l00046"></a><span class="lineno">   46</span><span class="keyword">namespace </span><a class="code hl_namespace" href="namespaceonert.html">onert</a></div>
<div class="line"><a id="l00047" name="l00047"></a><span class="lineno">   47</span>{</div>
<div class="line"><a id="l00048" name="l00048"></a><span class="lineno">   48</span><span class="keyword">namespace </span>backend</div>
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno">   49</span>{</div>
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno">   50</span><span class="keyword">namespace </span>train</div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno">   51</span>{</div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno">   52</span><span class="keyword">namespace </span><a class="code hl_namespace" href="namespacemir_1_1ops.html">ops</a></div>
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno">   53</span>{</div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno">   54</span> </div>
<div class="foldopen" id="foldopen00055" data-start="{" data-end="}">
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno"><a class="line" href="classonert_1_1backend_1_1train_1_1ops_1_1_fully_connected_layer.html#a0784d539b5d213d69cbcb397957573e2">   55</a></span><a class="code hl_function" href="classonert_1_1backend_1_1train_1_1ops_1_1_fully_connected_layer.html#a0784d539b5d213d69cbcb397957573e2">FullyConnectedLayer::FullyConnectedLayer</a>()</div>
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno">   56</span>  : cpu::<a class="code hl_namespace" href="namespacemir_1_1ops.html">ops</a>::<a class="code hl_class" href="classonert_1_1backend_1_1train_1_1ops_1_1_fully_connected_layer.html">FullyConnectedLayer</a>{}, _grad_weights{nullptr}, _grad_bias{nullptr},</div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno">   57</span>    _back_prop_input{nullptr}, _back_prop_output{nullptr}, _transposed_weights{nullptr},</div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span>    _transposed_input{nullptr}, _transposed_back_prop_output{nullptr},</div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno">   59</span>    _act_back_prop_output{nullptr}</div>
<div class="line"><a id="l00060" name="l00060"></a><span class="lineno">   60</span>{</div>
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno">   61</span>  <span class="comment">// DO NOTHING</span></div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span>}</div>
</div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno">   63</span> </div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span><a class="code hl_function" href="classonert_1_1backend_1_1train_1_1ops_1_1_fully_connected_layer.html#add469f12cce0d7ad3159039290dd24b5">FullyConnectedLayer::~FullyConnectedLayer</a>() = <span class="keywordflow">default</span>;</div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span> </div>
<div class="foldopen" id="foldopen00066" data-start="{" data-end="}">
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno"><a class="line" href="classonert_1_1backend_1_1train_1_1ops_1_1_fully_connected_layer.html#a787f949076a4bb526b1997895eafb9cf">   66</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classonert_1_1backend_1_1train_1_1ops_1_1_fully_connected_layer.html#a787f949076a4bb526b1997895eafb9cf">FullyConnectedLayer::configureBackward</a>(</div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span>  <span class="keyword">const</span> <a class="code hl_class" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *input, <span class="keyword">const</span> <a class="code hl_class" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *weights, <a class="code hl_class" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *output,</div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno">   68</span>  <a class="code hl_class" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *back_prop_input, <a class="code hl_class" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *grad_weights, <a class="code hl_class" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *grad_bias,</div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span>  <span class="keyword">const</span> <a class="code hl_class" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *back_prop_output, <a class="code hl_enumeration" href="namespaceonert_1_1ir.html#a8ce6c92ea138aca1332e4be9531bd5d4">ir::Activation</a> activation,</div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span>  <a class="code hl_enumeration" href="namespaceonert_1_1ir.html#a4dc82d1ced0dff0fcabe7e74d6c76c19">ir::FullyConnectedWeightsFormat</a> weights_format)</div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno">   71</span>{</div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno">   72</span>  _back_prop_input = back_prop_input;</div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span>  _grad_weights = grad_weights;</div>
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span>  _grad_bias = grad_bias;</div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span>  _back_prop_output = back_prop_output;</div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span> </div>
<div class="line"><a id="l00077" name="l00077"></a><span class="lineno">   77</span>  <span class="keywordflow">if</span> (weights_format != <a class="code hl_enumvalue" href="namespaceonert_1_1ir.html#a4dc82d1ced0dff0fcabe7e74d6c76c19a7a1920d61156abc05a60135aefe8bc67">ir::FullyConnectedWeightsFormat::Default</a>)</div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno">   78</span>    <span class="keywordflow">throw</span> std::runtime_error{</div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno">   79</span>      <span class="stringliteral">&quot;train FullyConnectedLayer: Weight formats other than default are not supported.&quot;</span>};</div>
<div class="line"><a id="l00080" name="l00080"></a><span class="lineno">   80</span> </div>
<div class="line"><a id="l00081" name="l00081"></a><span class="lineno">   81</span>  <span class="keywordflow">if</span> (input-&gt;get_info().shape().rank() != 2 || weights-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#a5aa2cfeb527066e9bee0316f67f67b1d">get_info</a>().<a class="code hl_function" href="classonert_1_1ir_1_1_operand_info.html#aed6ade449a1b0e5d296c66a99b1725d4">shape</a>().rank() != 2 ||</div>
<div class="line"><a id="l00082" name="l00082"></a><span class="lineno">   82</span>      output-&gt;get_info().shape().rank() != 2 || back_prop_input-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#a5aa2cfeb527066e9bee0316f67f67b1d">get_info</a>().<a class="code hl_function" href="classonert_1_1ir_1_1_operand_info.html#aed6ade449a1b0e5d296c66a99b1725d4">shape</a>().rank() != 2 ||</div>
<div class="line"><a id="l00083" name="l00083"></a><span class="lineno">   83</span>      grad_weights-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#a5aa2cfeb527066e9bee0316f67f67b1d">get_info</a>().<a class="code hl_function" href="classonert_1_1ir_1_1_operand_info.html#aed6ade449a1b0e5d296c66a99b1725d4">shape</a>().rank() != 2 ||</div>
<div class="line"><a id="l00084" name="l00084"></a><span class="lineno">   84</span>      back_prop_output-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#a5aa2cfeb527066e9bee0316f67f67b1d">get_info</a>().<a class="code hl_function" href="classonert_1_1ir_1_1_operand_info.html#aed6ade449a1b0e5d296c66a99b1725d4">shape</a>().rank() != 2)</div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno">   85</span>    <span class="keywordflow">throw</span> std::runtime_error{</div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno">   86</span>      <span class="stringliteral">&quot;train FullyConnectedLayer: Input other ranks than 2 are not supported.&quot;</span>};</div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span> </div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span>  _transposed_weights = createTransposedTensor(weights);</div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span>  _transposed_weights-&gt;setBuffer(std::make_shared&lt;basic::Allocator&gt;(weights-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#a52fa5a71552928aebcb47eafa1a7b182">total_size</a>()));</div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno">   90</span> </div>
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno">   91</span>  _transposed_input = createTransposedTensor(input);</div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno">   92</span>  _transposed_input-&gt;setBuffer(std::make_shared&lt;basic::Allocator&gt;(input-&gt;total_size()));</div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno">   93</span> </div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span>  _transposed_back_prop_output = createTransposedTensor(back_prop_output);</div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span>  _transposed_back_prop_output-&gt;setBuffer(</div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span>    std::make_shared&lt;basic::Allocator&gt;(back_prop_output-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#a52fa5a71552928aebcb47eafa1a7b182">total_size</a>()));</div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno">   97</span> </div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno">   98</span>  <span class="keywordflow">if</span> (activation != <a class="code hl_enumvalue" href="namespaceonert_1_1ir.html#a8ce6c92ea138aca1332e4be9531bd5d4ab50339a10e1de285ac99d4c3990b8693">ir::Activation::NONE</a>)</div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno">   99</span>  {</div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno">  100</span>    _act_back_prop_output = std::make_unique&lt;Tensor&gt;(_back_prop_output-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#a5aa2cfeb527066e9bee0316f67f67b1d">get_info</a>());</div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span>    _act_back_prop_output-&gt;setBuffer(</div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno">  102</span>      std::make_shared&lt;basic::Allocator&gt;(_back_prop_output-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#a52fa5a71552928aebcb47eafa1a7b182">total_size</a>()));</div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno">  103</span>  }</div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno">  104</span>}</div>
</div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span> </div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno"><a class="line" href="classonert_1_1backend_1_1train_1_1ops_1_1_fully_connected_layer.html#a4e1fcfae1fb174deef27e52e877b5764">  106</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classonert_1_1backend_1_1train_1_1ops_1_1_fully_connected_layer.html#a4e1fcfae1fb174deef27e52e877b5764">FullyConnectedLayer::forward</a>(<span class="keywordtype">bool</span>) { <a class="code hl_function" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aff0e02437f1e864effa060ca8ea19bc1">cpu::ops::FullyConnectedLayer::run</a>(); }</div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span> </div>
<div class="foldopen" id="foldopen00108" data-start="{" data-end="}">
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno"><a class="line" href="classonert_1_1backend_1_1train_1_1ops_1_1_fully_connected_layer.html#a5637befbfa54cfb1795e496e5b93c710">  108</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classonert_1_1backend_1_1train_1_1ops_1_1_fully_connected_layer.html#a5637befbfa54cfb1795e496e5b93c710">FullyConnectedLayer::backward</a>()</div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno">  109</span>{</div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno">  110</span>  <span class="keyword">const</span> <span class="keyword">auto</span> data_type = _back_prop_output-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#aae73f75c41fa15f5ae2c391918fa09c5">data_type</a>();</div>
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno">  111</span>  assert(data_type == <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#aae73f75c41fa15f5ae2c391918fa09c5">data_type</a>());</div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno">  112</span>  <span class="keywordflow">switch</span> (data_type)</div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span>  {</div>
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno">  114</span>    <span class="keywordflow">case</span> OperandType::FLOAT32:</div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span>    {</div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno">  116</span>      assert(data_type == _grad_weights-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#aae73f75c41fa15f5ae2c391918fa09c5">data_type</a>());</div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno">  117</span>      assert(_grad_bias == <span class="keyword">nullptr</span> || data_type == _grad_bias-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#aae73f75c41fa15f5ae2c391918fa09c5">data_type</a>());</div>
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno">  118</span>      backwardFloat32();</div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno">  120</span>    }</div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span>    <span class="keywordflow">default</span>:</div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno">  122</span>      <span class="keywordflow">throw</span> std::runtime_error{<span class="stringliteral">&quot;train FullyConnectedLayer: unsupported data type&quot;</span>};</div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno">  123</span>  }</div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno">  124</span>}</div>
</div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span> </div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno">  126</span><span class="keywordtype">void</span> FullyConnectedLayer::backwardFloat32()</div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span>{</div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span>  <span class="comment">// Calculate gradient for activation</span></div>
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno">  129</span>  <span class="keyword">const</span> <a class="code hl_class" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *backprop_act;</div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno">  130</span>  <span class="keywordflow">try</span></div>
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno">  131</span>  {</div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span>    backprop_act =</div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span>      <a class="code hl_function" href="namespaceonert_1_1backend_1_1train_1_1ops.html#a6d9e6c6534c3e65e1aaf3adec0a379dc">backpropActivation</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a0c9bd8a18a3685d051e1b1a0d1f287f6">_activation</a>, <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">_output</a>, _back_prop_output, _act_back_prop_output.get());</div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span>  }</div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span>  <span class="keywordflow">catch</span> (<span class="keyword">const</span> std::exception &amp;e)</div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span>  {</div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span>    <span class="keywordflow">throw</span> std::runtime_error{<span class="stringliteral">&quot;train FullyConnectedLayer: &quot;</span> + std::string(e.what())};</div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span>  }</div>
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno">  139</span>  assert(backprop_act != <span class="keyword">nullptr</span>);</div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span> </div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span>  <span class="comment">// Initialize TransposeParams</span></div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno">  142</span>  <a class="code hl_struct" href="structnnfw_1_1cker_1_1_transpose_params.html">nnfw::cker::TransposeParams</a> transpose_param;</div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno">  143</span>  transpose_param.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_transpose_params.html#afc9f2a98af7f384482355576589671f0">perm_count</a> = 2;</div>
<div class="line"><a id="l00144" name="l00144"></a><span class="lineno">  144</span>  transpose_param.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_transpose_params.html#a8cffe02d521411a44e650d7edf660fa9">perm</a>[0] = 1;</div>
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno">  145</span>  transpose_param.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_transpose_params.html#a8cffe02d521411a44e650d7edf660fa9">perm</a>[1] = 0;</div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span> </div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span>  <span class="comment">// Initialize FullyConnectedParams</span></div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span>  <a class="code hl_struct" href="structnnfw_1_1cker_1_1_fully_connected_params.html">nnfw::cker::FullyConnectedParams</a> op_params;</div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span>  <span class="keywordtype">float</span> output_activation_min = 0;</div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno">  150</span>  <span class="keywordtype">float</span> output_activation_max = 0;</div>
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno">  151</span>  CalculateActivationRange(<a class="code hl_enumvalue" href="namespaceonert_1_1ir.html#a8ce6c92ea138aca1332e4be9531bd5d4ab50339a10e1de285ac99d4c3990b8693">ir::Activation::NONE</a>, &amp;output_activation_min, &amp;output_activation_max);</div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno">  152</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a15410fd240c7d16cdeaca54856b712c8">activation</a> = <a class="code hl_enumvalue" href="namespacennfw_1_1cker.html#af09a114337895158c72fde6226b568a2a35c3ace1970663a16e5c65baa5941b13">nnfw::cker::FusedActivationFunctionType::kNone</a>;</div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno">  153</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a54122b18164d003566b614b051ec6682">float_activation_min</a> = output_activation_min;</div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno">  154</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a18880d1a910e57f9bc486ff6aa9bd43b">float_activation_max</a> = output_activation_max;</div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a0be6785579faac1ca4e009d2943e65d9">lhs_cacheable</a> = <span class="keyword">false</span>;</div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a0b3e0916c736a1eca2b85ed046d6433f">rhs_cacheable</a> = <span class="keyword">false</span>;</div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span> </div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno">  158</span>  <span class="comment">// Transpose and compute gradient for input</span></div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span>  <span class="comment">// ∂L/∂X = fc(Incoming gradient, transposed W)</span></div>
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno">  160</span>  <span class="keyword">auto</span> transposed_weights = _transposed_weights.get();</div>
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno">  161</span>  assert(transposed_weights-&gt;getShape().rank() == 2);</div>
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno">  162</span>  <a class="code hl_function" href="namespacennfw_1_1cker.html#ad2b289ed016012d8dae4044f1ec1ba19">nnfw::cker::Transpose</a>(transpose_param, <a class="code hl_function" href="namespaceonert_1_1backend_1_1train_1_1ops.html#a9a41239d90a397bd0f075ddedfa72322">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>), getBuffer&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>),</div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno">  163</span>                        <a class="code hl_function" href="namespaceonert_1_1backend_1_1train_1_1ops.html#a9a41239d90a397bd0f075ddedfa72322">getShape</a>(transposed_weights), getBuffer&lt;float&gt;(transposed_weights));</div>
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno">  164</span> </div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno">  165</span>  <a class="code hl_function" href="namespacennfw_1_1cker.html#a893434782a43556a99989be14e599d63">nnfw::cker::FullyConnected</a>(op_params, <a class="code hl_function" href="namespaceonert_1_1backend_1_1train_1_1ops.html#a9a41239d90a397bd0f075ddedfa72322">getShape</a>(backprop_act), getBuffer&lt;float&gt;(backprop_act),</div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno">  166</span>                             <a class="code hl_function" href="namespaceonert_1_1backend_1_1train_1_1ops.html#a9a41239d90a397bd0f075ddedfa72322">getShape</a>(transposed_weights), getBuffer&lt;float&gt;(transposed_weights),</div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno">  167</span>                             <a class="code hl_function" href="namespaceonert_1_1backend_1_1train_1_1ops.html#a9a41239d90a397bd0f075ddedfa72322">getShape</a>(<span class="keyword">nullptr</span>), <span class="keyword">nullptr</span>, <a class="code hl_function" href="namespaceonert_1_1backend_1_1train_1_1ops.html#a9a41239d90a397bd0f075ddedfa72322">getShape</a>(_back_prop_input),</div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span>                             getBuffer&lt;float&gt;(_back_prop_input));</div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno">  169</span> </div>
<div class="line"><a id="l00170" name="l00170"></a><span class="lineno">  170</span>  <span class="comment">// Transpose and compute gradient for weights</span></div>
<div class="line"><a id="l00171" name="l00171"></a><span class="lineno">  171</span>  <span class="comment">// ∂L/∂W = fc(transposed incomming gradient, transposed X)</span></div>
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno">  172</span>  <span class="keyword">auto</span> transposed_input = _transposed_input.get();</div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno">  173</span>  assert(transposed_input-&gt;getShape().rank() == 2);</div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno">  174</span>  <a class="code hl_function" href="namespacennfw_1_1cker.html#ad2b289ed016012d8dae4044f1ec1ba19">nnfw::cker::Transpose</a>(transpose_param, <a class="code hl_function" href="namespaceonert_1_1backend_1_1train_1_1ops.html#a9a41239d90a397bd0f075ddedfa72322">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>), getBuffer&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>),</div>
<div class="line"><a id="l00175" name="l00175"></a><span class="lineno">  175</span>                        <a class="code hl_function" href="namespaceonert_1_1backend_1_1train_1_1ops.html#a9a41239d90a397bd0f075ddedfa72322">getShape</a>(transposed_input), getBuffer&lt;float&gt;(transposed_input));</div>
<div class="line"><a id="l00176" name="l00176"></a><span class="lineno">  176</span> </div>
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno">  177</span>  <span class="keyword">auto</span> transposed_back_prop_output = _transposed_back_prop_output.get();</div>
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno">  178</span>  assert(transposed_back_prop_output-&gt;getShape().rank() == 2);</div>
<div class="line"><a id="l00179" name="l00179"></a><span class="lineno">  179</span>  <a class="code hl_function" href="namespacennfw_1_1cker.html#ad2b289ed016012d8dae4044f1ec1ba19">nnfw::cker::Transpose</a>(transpose_param, <a class="code hl_function" href="namespaceonert_1_1backend_1_1train_1_1ops.html#a9a41239d90a397bd0f075ddedfa72322">getShape</a>(backprop_act), getBuffer&lt;float&gt;(backprop_act),</div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span>                        <a class="code hl_function" href="namespaceonert_1_1backend_1_1train_1_1ops.html#a9a41239d90a397bd0f075ddedfa72322">getShape</a>(transposed_back_prop_output),</div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span>                        getBuffer&lt;float&gt;(transposed_back_prop_output));</div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span> </div>
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno">  183</span>  <a class="code hl_function" href="namespacennfw_1_1cker.html#a893434782a43556a99989be14e599d63">nnfw::cker::FullyConnected</a>(</div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span>    op_params, <a class="code hl_function" href="namespaceonert_1_1backend_1_1train_1_1ops.html#a9a41239d90a397bd0f075ddedfa72322">getShape</a>(transposed_back_prop_output), getBuffer&lt;float&gt;(transposed_back_prop_output),</div>
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno">  185</span>    <a class="code hl_function" href="namespaceonert_1_1backend_1_1train_1_1ops.html#a9a41239d90a397bd0f075ddedfa72322">getShape</a>(transposed_input), getBuffer&lt;float&gt;(transposed_input), <a class="code hl_function" href="namespaceonert_1_1backend_1_1train_1_1ops.html#a9a41239d90a397bd0f075ddedfa72322">getShape</a>(<span class="keyword">nullptr</span>), <span class="keyword">nullptr</span>,</div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span>    <a class="code hl_function" href="namespaceonert_1_1backend_1_1train_1_1ops.html#a9a41239d90a397bd0f075ddedfa72322">getShape</a>(_grad_weights), getBuffer&lt;float&gt;(_grad_weights));</div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno">  187</span> </div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno">  188</span>  <span class="comment">// Compute gradient for bias</span></div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno">  189</span>  <span class="keywordflow">if</span> (<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a>)</div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span>  {</div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span>    assert(_grad_bias);</div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span>    <a class="code hl_function" href="namespacennfw_1_1cker_1_1train.html#ae451e8541f4091a1c41c54ba240824f4">nnfw::cker::train::FullyConnectedBiasGrad</a>(<a class="code hl_function" href="namespaceonert_1_1backend_1_1train_1_1ops.html#a9a41239d90a397bd0f075ddedfa72322">getShape</a>(backprop_act),</div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span>                                              getBuffer&lt;float&gt;(backprop_act), <a class="code hl_function" href="namespaceonert_1_1backend_1_1train_1_1ops.html#a9a41239d90a397bd0f075ddedfa72322">getShape</a>(_grad_bias),</div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span>                                              getBuffer&lt;float&gt;(_grad_bias));</div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span>  }</div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span>}</div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span> </div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span>} <span class="comment">// namespace ops</span></div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span>} <span class="comment">// namespace train</span></div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span>} <span class="comment">// namespace backend</span></div>
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno">  201</span>} <span class="comment">// namespace onert</span></div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_portable_tensor_html"><div class="ttname"><a href="classonert_1_1backend_1_1_i_portable_tensor.html">onert::backend::IPortableTensor</a></div><div class="ttdoc">A tensor class that is portable for other backends.</div><div class="ttdef"><b>Definition</b> <a href="_i_portable_tensor_8h_source.html#l00038">IPortableTensor.h:39</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_portable_tensor_html_a52fa5a71552928aebcb47eafa1a7b182"><div class="ttname"><a href="classonert_1_1backend_1_1_i_portable_tensor.html#a52fa5a71552928aebcb47eafa1a7b182">onert::backend::IPortableTensor::total_size</a></div><div class="ttdeci">size_t total_size() const override final</div><div class="ttdef"><b>Definition</b> <a href="_i_portable_tensor_8h_source.html#l00054">IPortableTensor.h:54</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_portable_tensor_html_a5aa2cfeb527066e9bee0316f67f67b1d"><div class="ttname"><a href="classonert_1_1backend_1_1_i_portable_tensor.html#a5aa2cfeb527066e9bee0316f67f67b1d">onert::backend::IPortableTensor::get_info</a></div><div class="ttdeci">const ir::OperandInfo &amp; get_info() const</div><div class="ttdef"><b>Definition</b> <a href="_i_portable_tensor_8h_source.html#l00050">IPortableTensor.h:50</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_portable_tensor_html_aae73f75c41fa15f5ae2c391918fa09c5"><div class="ttname"><a href="classonert_1_1backend_1_1_i_portable_tensor.html#aae73f75c41fa15f5ae2c391918fa09c5">onert::backend::IPortableTensor::data_type</a></div><div class="ttdeci">ir::DataType data_type() const override final</div><div class="ttdef"><b>Definition</b> <a href="_i_portable_tensor_8h_source.html#l00056">IPortableTensor.h:56</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_portable_tensor_html_ad010d0f248f6e0e400485d81410ac158"><div class="ttname"><a href="classonert_1_1backend_1_1_i_portable_tensor.html#ad010d0f248f6e0e400485d81410ac158">onert::backend::IPortableTensor::getShape</a></div><div class="ttdeci">ir::Shape getShape() const override final</div><div class="ttdoc">Get ir::Shape of tensor.</div><div class="ttdef"><b>Definition</b> <a href="_i_portable_tensor_8h_source.html#l00066">IPortableTensor.h:66</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_a0c9bd8a18a3685d051e1b1a0d1f287f6"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a0c9bd8a18a3685d051e1b1a0d1f287f6">onert::backend::cpu::ops::FullyConnectedLayer::_activation</a></div><div class="ttdeci">ir::Activation _activation</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00075">FullyConnectedLayer.h:75</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_a2b1775533510102ae7787082bc588439"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">onert::backend::cpu::ops::FullyConnectedLayer::_weights</a></div><div class="ttdeci">const IPortableTensor * _weights</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00071">FullyConnectedLayer.h:71</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_a351b6a5cfcc2725297d58b5ee21fd938"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">onert::backend::cpu::ops::FullyConnectedLayer::_bias</a></div><div class="ttdeci">const IPortableTensor * _bias</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00072">FullyConnectedLayer.h:72</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_a77947469291a9e32a6daa860cc1de1de"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">onert::backend::cpu::ops::FullyConnectedLayer::_output</a></div><div class="ttdeci">IPortableTensor * _output</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00073">FullyConnectedLayer.h:73</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_ad20b91c5fd9f048ca2b7b650b4e9d95e"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">onert::backend::cpu::ops::FullyConnectedLayer::_input</a></div><div class="ttdeci">const IPortableTensor * _input</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00070">FullyConnectedLayer.h:70</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_aff0e02437f1e864effa060ca8ea19bc1"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aff0e02437f1e864effa060ca8ea19bc1">onert::backend::cpu::ops::FullyConnectedLayer::run</a></div><div class="ttdeci">void run() override</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00222">FullyConnectedLayer.cc:222</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1train_1_1ops_1_1_fully_connected_layer_html"><div class="ttname"><a href="classonert_1_1backend_1_1train_1_1ops_1_1_fully_connected_layer.html">onert::backend::train::ops::FullyConnectedLayer</a></div><div class="ttdef"><b>Definition</b> <a href="train_2ops_2_fully_connected_layer_8h_source.html#l00035">FullyConnectedLayer.h:37</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1train_1_1ops_1_1_fully_connected_layer_html_a0784d539b5d213d69cbcb397957573e2"><div class="ttname"><a href="classonert_1_1backend_1_1train_1_1ops_1_1_fully_connected_layer.html#a0784d539b5d213d69cbcb397957573e2">onert::backend::train::ops::FullyConnectedLayer::FullyConnectedLayer</a></div><div class="ttdeci">FullyConnectedLayer()</div><div class="ttdef"><b>Definition</b> <a href="train_2ops_2_fully_connected_layer_8cc_source.html#l00055">FullyConnectedLayer.cc:55</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1train_1_1ops_1_1_fully_connected_layer_html_a4e1fcfae1fb174deef27e52e877b5764"><div class="ttname"><a href="classonert_1_1backend_1_1train_1_1ops_1_1_fully_connected_layer.html#a4e1fcfae1fb174deef27e52e877b5764">onert::backend::train::ops::FullyConnectedLayer::forward</a></div><div class="ttdeci">void forward(bool training) override</div><div class="ttdef"><b>Definition</b> <a href="train_2ops_2_fully_connected_layer_8cc_source.html#l00106">FullyConnectedLayer.cc:106</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1train_1_1ops_1_1_fully_connected_layer_html_a5637befbfa54cfb1795e496e5b93c710"><div class="ttname"><a href="classonert_1_1backend_1_1train_1_1ops_1_1_fully_connected_layer.html#a5637befbfa54cfb1795e496e5b93c710">onert::backend::train::ops::FullyConnectedLayer::backward</a></div><div class="ttdeci">void backward() override</div><div class="ttdef"><b>Definition</b> <a href="train_2ops_2_fully_connected_layer_8cc_source.html#l00108">FullyConnectedLayer.cc:108</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1train_1_1ops_1_1_fully_connected_layer_html_a787f949076a4bb526b1997895eafb9cf"><div class="ttname"><a href="classonert_1_1backend_1_1train_1_1ops_1_1_fully_connected_layer.html#a787f949076a4bb526b1997895eafb9cf">onert::backend::train::ops::FullyConnectedLayer::configureBackward</a></div><div class="ttdeci">void configureBackward(const IPortableTensor *input, const IPortableTensor *weights, IPortableTensor *output, IPortableTensor *back_prop_input, IPortableTensor *grad_weights, IPortableTensor *grad_bias, const IPortableTensor *back_prop_output, ir::Activation activation, ir::FullyConnectedWeightsFormat weights_format)</div><div class="ttdef"><b>Definition</b> <a href="train_2ops_2_fully_connected_layer_8cc_source.html#l00066">FullyConnectedLayer.cc:66</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1train_1_1ops_1_1_fully_connected_layer_html_add469f12cce0d7ad3159039290dd24b5"><div class="ttname"><a href="classonert_1_1backend_1_1train_1_1ops_1_1_fully_connected_layer.html#add469f12cce0d7ad3159039290dd24b5">onert::backend::train::ops::FullyConnectedLayer::~FullyConnectedLayer</a></div><div class="ttdeci">~FullyConnectedLayer()</div></div>
<div class="ttc" id="aclassonert_1_1ir_1_1_operand_info_html_aed6ade449a1b0e5d296c66a99b1725d4"><div class="ttname"><a href="classonert_1_1ir_1_1_operand_info.html#aed6ade449a1b0e5d296c66a99b1725d4">onert::ir::OperandInfo::shape</a></div><div class="ttdeci">const Shape &amp; shape() const</div><div class="ttdoc">Return tensor shape.</div><div class="ttdef"><b>Definition</b> <a href="_operand_info_8h_source.html#l00095">OperandInfo.h:95</a></div></div>
<div class="ttc" id="acompute_2cker_2include_2cker_2operation_2_fully_connected_8h_html"><div class="ttname"><a href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h.html">FullyConnected.h</a></div></div>
<div class="ttc" id="acompute_2cker_2include_2cker_2operation_2_transpose_8h_html"><div class="ttname"><a href="compute_2cker_2include_2cker_2operation_2_transpose_8h.html">Transpose.h</a></div></div>
<div class="ttc" id="acompute_2cker_2include_2cker_2train_2operation_2_fully_connected_8h_html"><div class="ttname"><a href="compute_2cker_2include_2cker_2train_2operation_2_fully_connected_8h.html">FullyConnected.h</a></div></div>
<div class="ttc" id="acompute_2cker_2include_2cker_2train_2operation_2_re_l_u_8h_html"><div class="ttname"><a href="compute_2cker_2include_2cker_2train_2operation_2_re_l_u_8h.html">ReLU.h</a></div></div>
<div class="ttc" id="anamespacemir_1_1ops_html"><div class="ttname"><a href="namespacemir_1_1ops.html">mir::ops</a></div><div class="ttdef"><b>Definition</b> <a href="_abs_op_8h_source.html#l00024">AbsOp.h:25</a></div></div>
<div class="ttc" id="anamespacennfw_1_1cker_1_1train_html_ae451e8541f4091a1c41c54ba240824f4"><div class="ttname"><a href="namespacennfw_1_1cker_1_1train.html#ae451e8541f4091a1c41c54ba240824f4">nnfw::cker::train::FullyConnectedBiasGrad</a></div><div class="ttdeci">void FullyConnectedBiasGrad(const Shape &amp;incomming_shape, const T *incomming_data, const Shape &amp;grad_shape, T *grad_data)</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2train_2operation_2_fully_connected_8h_source.html#l00031">FullyConnected.h:31</a></div></div>
<div class="ttc" id="anamespacennfw_1_1cker_html_a893434782a43556a99989be14e599d63"><div class="ttname"><a href="namespacennfw_1_1cker.html#a893434782a43556a99989be14e599d63">nnfw::cker::FullyConnected</a></div><div class="ttdeci">void FullyConnected(const FullyConnectedParams &amp;params, const Shape &amp;input_shape, const float *input_data, const Shape &amp;weights_shape, const float *weights_data, const Shape &amp;, const float *bias_data, const Shape &amp;, float *output_data)</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h_source.html#l00098">FullyConnected.h:98</a></div></div>
<div class="ttc" id="anamespacennfw_1_1cker_html_ad2b289ed016012d8dae4044f1ec1ba19"><div class="ttname"><a href="namespacennfw_1_1cker.html#ad2b289ed016012d8dae4044f1ec1ba19">nnfw::cker::Transpose</a></div><div class="ttdeci">void Transpose(const TransposeParams &amp;unshrunk_params, const Shape &amp;unshrunk_input_shape, const T *input_data, const Shape &amp;unshrunk_output_shape, T *output_data)</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2operation_2_transpose_8h_source.html#l00510">Transpose.h:510</a></div></div>
<div class="ttc" id="anamespacennfw_1_1cker_html_af09a114337895158c72fde6226b568a2a35c3ace1970663a16e5c65baa5941b13"><div class="ttname"><a href="namespacennfw_1_1cker.html#af09a114337895158c72fde6226b568a2a35c3ace1970663a16e5c65baa5941b13">nnfw::cker::FusedActivationFunctionType::kNone</a></div><div class="ttdeci">@ kNone</div></div>
<div class="ttc" id="anamespaceonert_1_1backend_1_1train_1_1ops_html_a6d9e6c6534c3e65e1aaf3adec0a379dc"><div class="ttname"><a href="namespaceonert_1_1backend_1_1train_1_1ops.html#a6d9e6c6534c3e65e1aaf3adec0a379dc">onert::backend::train::ops::backpropActivation</a></div><div class="ttdeci">const IPortableTensor * backpropActivation(const ir::Activation &amp;activation, const IPortableTensor *output, const IPortableTensor *input_backprop, IPortableTensor *output_backprop)</div><div class="ttdoc">backpropagate acitvation</div><div class="ttdef"><b>Definition</b> <a href="train_2ops_2_operation_utils_8cc_source.html#l00050">OperationUtils.cc:50</a></div></div>
<div class="ttc" id="anamespaceonert_1_1backend_1_1train_1_1ops_html_a9a41239d90a397bd0f075ddedfa72322"><div class="ttname"><a href="namespaceonert_1_1backend_1_1train_1_1ops.html#a9a41239d90a397bd0f075ddedfa72322">onert::backend::train::ops::getShape</a></div><div class="ttdeci">nnfw::cker::Shape getShape(const IPortableTensor *tensor)</div><div class="ttdoc">Get shape of tensor.</div><div class="ttdef"><b>Definition</b> <a href="train_2ops_2_operation_utils_8cc_source.html#l00032">OperationUtils.cc:32</a></div></div>
<div class="ttc" id="anamespaceonert_1_1ir_html_a4dc82d1ced0dff0fcabe7e74d6c76c19"><div class="ttname"><a href="namespaceonert_1_1ir.html#a4dc82d1ced0dff0fcabe7e74d6c76c19">onert::ir::FullyConnectedWeightsFormat</a></div><div class="ttdeci">FullyConnectedWeightsFormat</div><div class="ttdef"><b>Definition</b> <a href="_internal_type_8h_source.html#l00049">InternalType.h:50</a></div></div>
<div class="ttc" id="anamespaceonert_1_1ir_html_a4dc82d1ced0dff0fcabe7e74d6c76c19a7a1920d61156abc05a60135aefe8bc67"><div class="ttname"><a href="namespaceonert_1_1ir.html#a4dc82d1ced0dff0fcabe7e74d6c76c19a7a1920d61156abc05a60135aefe8bc67">onert::ir::FullyConnectedWeightsFormat::Default</a></div><div class="ttdeci">@ Default</div></div>
<div class="ttc" id="anamespaceonert_1_1ir_html_a8ce6c92ea138aca1332e4be9531bd5d4"><div class="ttname"><a href="namespaceonert_1_1ir.html#a8ce6c92ea138aca1332e4be9531bd5d4">onert::ir::Activation</a></div><div class="ttdeci">Activation</div><div class="ttdef"><b>Definition</b> <a href="_internal_type_8h_source.html#l00027">InternalType.h:28</a></div></div>
<div class="ttc" id="anamespaceonert_1_1ir_html_a8ce6c92ea138aca1332e4be9531bd5d4ab50339a10e1de285ac99d4c3990b8693"><div class="ttname"><a href="namespaceonert_1_1ir.html#a8ce6c92ea138aca1332e4be9531bd5d4ab50339a10e1de285ac99d4c3990b8693">onert::ir::Activation::NONE</a></div><div class="ttdeci">@ NONE</div></div>
<div class="ttc" id="anamespaceonert_html"><div class="ttname"><a href="namespaceonert.html">onert</a></div><div class="ttdef"><b>Definition</b> <a href="_custom_kernel_8cc_source.html#l00019">CustomKernel.cc:20</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html">nnfw::cker::FullyConnectedParams</a></div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00249">Types.h:250</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_a0b3e0916c736a1eca2b85ed046d6433f"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#a0b3e0916c736a1eca2b85ed046d6433f">nnfw::cker::FullyConnectedParams::rhs_cacheable</a></div><div class="ttdeci">bool rhs_cacheable</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00268">Types.h:268</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_a0be6785579faac1ca4e009d2943e65d9"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#a0be6785579faac1ca4e009d2943e65d9">nnfw::cker::FullyConnectedParams::lhs_cacheable</a></div><div class="ttdeci">bool lhs_cacheable</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00267">Types.h:267</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_a15410fd240c7d16cdeaca54856b712c8"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#a15410fd240c7d16cdeaca54856b712c8">nnfw::cker::FullyConnectedParams::activation</a></div><div class="ttdeci">FusedActivationFunctionType activation</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00251">Types.h:251</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_a18880d1a910e57f9bc486ff6aa9bd43b"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#a18880d1a910e57f9bc486ff6aa9bd43b">nnfw::cker::FullyConnectedParams::float_activation_max</a></div><div class="ttdeci">float float_activation_max</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00265">Types.h:265</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_a54122b18164d003566b614b051ec6682"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#a54122b18164d003566b614b051ec6682">nnfw::cker::FullyConnectedParams::float_activation_min</a></div><div class="ttdeci">float float_activation_min</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00264">Types.h:264</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_transpose_params_html"><div class="ttname"><a href="structnnfw_1_1cker_1_1_transpose_params.html">nnfw::cker::TransposeParams</a></div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00209">Types.h:210</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_transpose_params_html_a8cffe02d521411a44e650d7edf660fa9"><div class="ttname"><a href="structnnfw_1_1cker_1_1_transpose_params.html#a8cffe02d521411a44e650d7edf660fa9">nnfw::cker::TransposeParams::perm</a></div><div class="ttdeci">int32_t perm[4]</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00212">Types.h:212</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_transpose_params_html_afc9f2a98af7f384482355576589671f0"><div class="ttname"><a href="structnnfw_1_1cker_1_1_transpose_params.html#afc9f2a98af7f384482355576589671f0">nnfw::cker::TransposeParams::perm_count</a></div><div class="ttdeci">int8_t perm_count</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00211">Types.h:211</a></div></div>
<div class="ttc" id="astructonert_1_1ir_1_1_shape_html"><div class="ttname"><a href="structonert_1_1ir_1_1_shape.html">onert::ir::Shape</a></div><div class="ttdef"><b>Definition</b> <a href="runtime_2onert_2core_2include_2ir_2_shape_8h_source.html#l00070">Shape.h:71</a></div></div>
<div class="ttc" id="astructonert_1_1ir_1_1_shape_html_a3c78b1b9d3b66da28ddacb66cd1ea305"><div class="ttname"><a href="structonert_1_1ir_1_1_shape.html#a3c78b1b9d3b66da28ddacb66cd1ea305">onert::ir::Shape::dim</a></div><div class="ttdeci">int32_t dim(int i) const</div><div class="ttdef"><b>Definition</b> <a href="runtime_2onert_2core_2include_2ir_2_shape_8h_source.html#l00086">Shape.h:86</a></div></div>
<div class="ttc" id="axnnpack_2ops_2_fully_connected_layer_8h_html"><div class="ttname"><a href="xnnpack_2ops_2_fully_connected_layer_8h.html">FullyConnectedLayer.h</a></div></div>
<div class="ttc" id="axnnpack_2ops_2_operation_utils_8h_html"><div class="ttname"><a href="xnnpack_2ops_2_operation_utils_8h.html">OperationUtils.h</a></div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_cb031e414f281a658b23dddb30bb9d2c.html">runtime</a></li><li class="navelem"><a class="el" href="dir_e8e2d335b1be314b4aeca39d410c6e2f.html">onert</a></li><li class="navelem"><a class="el" href="dir_e3c1c6f396287f59b9861978effe28d3.html">backend</a></li><li class="navelem"><a class="el" href="dir_860f072ac8a2e43fe3b8432afdc5d5b6.html">train</a></li><li class="navelem"><a class="el" href="dir_504e02a0f7d8c51a809a1972aae7e644.html">ops</a></li><li class="navelem"><a class="el" href="train_2ops_2_fully_connected_layer_8cc.html">FullyConnectedLayer.cc</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
