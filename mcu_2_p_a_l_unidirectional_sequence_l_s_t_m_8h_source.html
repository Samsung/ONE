<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.5"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ONE - On-device Neural Engine: onert-micro/luci-interpreter/pal/mcu/PALUnidirectionalSequenceLSTM.h Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">ONE - On-device Neural Engine
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.5 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">PALUnidirectionalSequenceLSTM.h</div></div>
</div><!--header-->
<div class="contents">
<a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno">    1</span><span class="comment">/*</span></div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="comment"> * Copyright (c) 2023 Samsung Electronics Co., Ltd. All Rights Reserved</span></div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span><span class="comment"> * Copyright 2017 The TensorFlow Authors. All Rights Reserved.</span></div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span><span class="comment"> *</span></div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span><span class="comment"> * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span><span class="comment"> * you may not use this file except in compliance with the License.</span></div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span><span class="comment"> * You may obtain a copy of the License at</span></div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno">    8</span><span class="comment"> *</span></div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span><span class="comment"> *    http://www.apache.org/licenses/LICENSE-2.0</span></div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span><span class="comment"> *</span></div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span><span class="comment"> * Unless required by applicable law or agreed to in writing, software</span></div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span><span class="comment"> * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span><span class="comment"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="comment"> * See the License for the specific language governing permissions and</span></div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span><span class="comment"> * limitations under the License.</span></div>
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno">   16</span><span class="comment"> */</span></div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span> </div>
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno">   18</span><span class="preprocessor">#ifndef LUCI_INTERPRETER_PAL_UNIDIRECTIONAL_SEQUENCE_LSTM_H</span></div>
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno">   19</span><span class="preprocessor">#define LUCI_INTERPRETER_PAL_UNIDIRECTIONAL_SEQUENCE_LSTM_H</span></div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span> </div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno">   21</span><span class="preprocessor">#include &quot;core/KernelParams.h&quot;</span></div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span><span class="preprocessor">#include &quot;tensorflow/lite/kernels/internal/reference/integer_ops/logistic.h&quot;</span></div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno">   23</span><span class="preprocessor">#include &quot;tensorflow/lite/kernels/internal/reference/integer_ops/tanh.h&quot;</span></div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno">   24</span><span class="preprocessor">#include &quot;fixedpoint/fixedpoint.h&quot;</span></div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno">   25</span> </div>
<div class="line"><a id="l00026" name="l00026"></a><span class="lineno">   26</span><span class="keyword">namespace </span><a class="code hl_namespace" href="namespaceluci__interpreter__pal.html">luci_interpreter_pal</a></div>
<div class="line"><a id="l00027" name="l00027"></a><span class="lineno">   27</span>{</div>
<div class="line"><a id="l00028" name="l00028"></a><span class="lineno">   28</span><span class="keyword">namespace </span>lstm</div>
<div class="line"><a id="l00029" name="l00029"></a><span class="lineno">   29</span>{</div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno">   30</span><span class="comment">// Possible fused activation functions.</span></div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63">   31</a></span><span class="keyword">typedef</span> <span class="keyword">enum</span></div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno">   32</span>{</div>
<div class="line"><a id="l00033" name="l00033"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63a611f6492ff91826833d1b9e42f7f9a5e">   33</a></span>  <a class="code hl_enumvalue" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63a611f6492ff91826833d1b9e42f7f9a5e">kTfLiteActNone</a> = 0,</div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63a06a35e36dd2f10a2e82095f663eb7cb7">   34</a></span>  <a class="code hl_enumvalue" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63a06a35e36dd2f10a2e82095f663eb7cb7">kTfLiteActRelu</a>,</div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63a9f385b0941a619677310da5deb8c0751">   35</a></span>  <a class="code hl_enumvalue" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63a9f385b0941a619677310da5deb8c0751">kTfLiteActReluN1To1</a>, <span class="comment">// min(max(-1, x), 1)</span></div>
<div class="line"><a id="l00036" name="l00036"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63adcc6c589b6ffe8ff89fd701c70b38342">   36</a></span>  <a class="code hl_enumvalue" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63adcc6c589b6ffe8ff89fd701c70b38342">kTfLiteActRelu6</a>,     <span class="comment">// min(max(0, x), 6)</span></div>
<div class="line"><a id="l00037" name="l00037"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63a60bdd9a337a5f1f2866fd65c7d8ffdce">   37</a></span>  <a class="code hl_enumvalue" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63a60bdd9a337a5f1f2866fd65c7d8ffdce">kTfLiteActTanh</a>,</div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63ad5ee29be46ddc348e9865b96129a533a">   38</a></span>  <a class="code hl_enumvalue" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63ad5ee29be46ddc348e9865b96129a533a">kTfLiteActSignBit</a>,</div>
<div class="line"><a id="l00039" name="l00039"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63ab211c831f880a63ebc80994bb0cf2dc2">   39</a></span>  <a class="code hl_enumvalue" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63ab211c831f880a63ebc80994bb0cf2dc2">kTfLiteActSigmoid</a>,</div>
<div class="line"><a id="l00040" name="l00040"></a><span class="lineno">   40</span>} <a class="code hl_enumeration" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63">TfLiteFusedActivation</a>;</div>
<div class="line"><a id="l00041" name="l00041"></a><span class="lineno">   41</span> </div>
<div class="line"><a id="l00042" name="l00042"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#acbe525077503e0d3f37d59b7fc8276e2">   42</a></span><span class="keyword">inline</span> int32_t <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#acbe525077503e0d3f37d59b7fc8276e2">multiply_by_quantized_multiplier</a>(int32_t x, int32_t quantized_multiplier, <span class="keywordtype">int</span> shift)</div>
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno">   43</span>{</div>
<div class="line"><a id="l00044" name="l00044"></a><span class="lineno">   44</span>  <span class="keyword">using </span>gemmlowp::RoundingDivideByPOT;</div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno">   45</span>  <span class="keyword">using </span>gemmlowp::SaturatingRoundingDoublingHighMul;</div>
<div class="line"><a id="l00046" name="l00046"></a><span class="lineno">   46</span>  <span class="keywordtype">int</span> left_shift = shift &gt; 0 ? shift : 0;</div>
<div class="line"><a id="l00047" name="l00047"></a><span class="lineno">   47</span>  <span class="keywordtype">int</span> right_shift = shift &gt; 0 ? 0 : -shift;</div>
<div class="line"><a id="l00048" name="l00048"></a><span class="lineno">   48</span>  <span class="keywordflow">return</span> RoundingDivideByPOT(</div>
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno">   49</span>    SaturatingRoundingDoublingHighMul(x * (1 &lt;&lt; left_shift), quantized_multiplier), right_shift);</div>
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno">   50</span>}</div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno">   51</span> </div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#a13269908e5cbb4827f974e782b98f6b2">   52</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#a13269908e5cbb4827f974e782b98f6b2">cwise_mul</a>(<span class="keyword">const</span> int16_t *input_1, <span class="keyword">const</span> int16_t *input_2, int32_t multiplier, int32_t shift,</div>
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno">   53</span>               int32_t n_batch, int32_t n_input, int32_t output_zp, int8_t *output)</div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno">   54</span>{</div>
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno">   55</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> batch = 0; batch &lt; n_batch; ++batch)</div>
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno">   56</span>  {</div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno">   57</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; n_input; ++i)</div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span>    {</div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno">   59</span>      <span class="keyword">const</span> <span class="keywordtype">int</span> index = batch * n_input + i;</div>
<div class="line"><a id="l00060" name="l00060"></a><span class="lineno">   60</span>      <span class="keyword">const</span> int16_t a = input_1[index];</div>
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno">   61</span>      <span class="keyword">const</span> int16_t b = input_2[index];</div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span>      int32_t value = <span class="keyword">static_cast&lt;</span>int32_t<span class="keyword">&gt;</span>(a) * <span class="keyword">static_cast&lt;</span>int32_t<span class="keyword">&gt;</span>(b);</div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno">   63</span>      value = <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#acbe525077503e0d3f37d59b7fc8276e2">multiply_by_quantized_multiplier</a>(value, multiplier, shift);</div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span>      value -= output_zp;</div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span>      value = std::min(std::max(<span class="keyword">static_cast&lt;</span>int32_t<span class="keyword">&gt;</span>(-128), value), <span class="keyword">static_cast&lt;</span>int32_t<span class="keyword">&gt;</span>(127));</div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span> </div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span>      output[index] = <span class="keyword">static_cast&lt;</span>int8_t<span class="keyword">&gt;</span>(value);</div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno">   68</span>    }</div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span>  }</div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span>}</div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno">   71</span> </div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#a7b3a8ce5736307c9146154fd4639e0cb">   72</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#a7b3a8ce5736307c9146154fd4639e0cb">sub1_vector</a>(<span class="keyword">const</span> int16_t *vector, <span class="keywordtype">int</span> v_size, int16_t *result)</div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span>{</div>
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span>  <span class="keyword">static</span> <span class="keyword">const</span> int16_t kOne = 32767;</div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> v = 0; v &lt; v_size; v++)</div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span>  {</div>
<div class="line"><a id="l00077" name="l00077"></a><span class="lineno">   77</span>    *result++ = kOne - *vector++;</div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno">   78</span>  }</div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno">   79</span>}</div>
<div class="line"><a id="l00080" name="l00080"></a><span class="lineno">   80</span> </div>
<div class="line"><a id="l00081" name="l00081"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#a4e414d74814834c72b789c80e68e843b">   81</a></span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt; <span class="keywordtype">void</span> <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#a4e414d74814834c72b789c80e68e843b">cwise_clipping</a>(T *vector, <span class="keyword">const</span> <span class="keywordtype">int</span> v_size, <span class="keyword">const</span> T &amp;clipping_value)</div>
<div class="line"><a id="l00082" name="l00082"></a><span class="lineno">   82</span>{</div>
<div class="line"><a id="l00083" name="l00083"></a><span class="lineno">   83</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; v_size; i++)</div>
<div class="line"><a id="l00084" name="l00084"></a><span class="lineno">   84</span>  {</div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno">   85</span>    vector[i] = std::max(std::min(clipping_value, vector[i]), <span class="keyword">static_cast&lt;</span>T<span class="keyword">&gt;</span>(-clipping_value));</div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno">   86</span>  }</div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span>}</div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span> </div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#af4923cae88d2f75c29b49c78c9a00f99">   89</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#af4923cae88d2f75c29b49c78c9a00f99">cwise_add</a>(<span class="keyword">const</span> int16_t *input_1, <span class="keyword">const</span> int16_t *input_2, <span class="keywordtype">int</span> n_batch, <span class="keywordtype">int</span> n_input,</div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno">   90</span>               int16_t *output)</div>
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno">   91</span>{</div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno">   92</span>  <span class="keyword">const</span> int32_t kInt16Max = std::numeric_limits&lt;int16_t&gt;::max();</div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno">   93</span>  <span class="keyword">const</span> int32_t kInt16Min = std::numeric_limits&lt;int16_t&gt;::min();</div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> batch = 0; batch &lt; n_batch; ++batch)</div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span>  {</div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; n_input; ++i)</div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno">   97</span>    {</div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno">   98</span>      <span class="keyword">const</span> <span class="keywordtype">int</span> index = batch * n_input + i;</div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno">   99</span>      int32_t sum = input_1[index] + input_2[index];</div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno">  100</span>      <span class="keyword">const</span> int32_t sum_clamped = std::min(kInt16Max, std::max(kInt16Min, sum));</div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span>      output[index] = <span class="keyword">static_cast&lt;</span>int16_t<span class="keyword">&gt;</span>(sum_clamped);</div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno">  102</span>    }</div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno">  103</span>  }</div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno">  104</span>}</div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span> </div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#acef25fe5a003e2ff65b2c8ccb2711207">  106</a></span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt; <span class="keywordtype">int</span> <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#acef25fe5a003e2ff65b2c8ccb2711207">count_leading_zeros</a>(T integer_input)</div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span>{</div>
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno">  108</span>  <span class="keyword">static_assert</span>(std::is_unsigned&lt;T&gt;::value, <span class="stringliteral">&quot;Only unsigned integer types handled.&quot;</span>);</div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno">  109</span><span class="preprocessor">#if defined(__GNUC__)</span></div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno">  110</span>  <span class="keywordflow">return</span> integer_input ? __builtin_clz(integer_input) : std::numeric_limits&lt;T&gt;::digits;</div>
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno">  111</span><span class="preprocessor">#else</span></div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno">  112</span>  <span class="keywordflow">if</span> (integer_input == 0)</div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span>  {</div>
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno">  114</span>    <span class="keywordflow">return</span> std::numeric_limits&lt;T&gt;::digits;</div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span>  }</div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno">  116</span> </div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno">  117</span>  <span class="keyword">const</span> T one_in_leading_positive = <span class="keyword">static_cast&lt;</span>T<span class="keyword">&gt;</span>(1) &lt;&lt; (std::numeric_limits&lt;T&gt;::digits - 1);</div>
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno">  118</span>  <span class="keywordtype">int</span> leading_zeros = 0;</div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span>  <span class="keywordflow">while</span> (integer_input &lt; one_in_leading_positive)</div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno">  120</span>  {</div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span>    integer_input &lt;&lt;= 1;</div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno">  122</span>    ++leading_zeros;</div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno">  123</span>  }</div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno">  124</span>  <span class="keywordflow">return</span> leading_zeros;</div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno">  126</span>}</div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span> </div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#a4a2d78fd09384fe6419222fac94e71b3">  128</a></span><span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#a4a2d78fd09384fe6419222fac94e71b3">get_inv_sqrt_quantized_multiplier_exp</a>(int32_t input, <span class="keywordtype">int</span> reverse_shift,</div>
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno">  129</span>                                                  int32_t *output_inv_sqrt, <span class="keywordtype">int</span> *output_shift)</div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno">  130</span>{</div>
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno">  131</span>  <span class="keywordflow">if</span> (input &lt;= 1)</div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span>  {</div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span>    <span class="comment">// Handle the input value 1 separately to avoid overflow in that case</span></div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span>    <span class="comment">// in the general computation below (b/143972021). Also handle 0 as if it</span></div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span>    <span class="comment">// were a 1. 0 is an invalid input here (divide by zero) and 1 is a valid</span></div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span>    <span class="comment">// but rare/unrealistic input value. We can expect both to occur in some</span></div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span>    <span class="comment">// incompletely trained models, but probably not in fully trained models.</span></div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span>    *output_inv_sqrt = std::numeric_limits&lt;std::int32_t&gt;::max();</div>
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno">  139</span>    *output_shift = 0;</div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span>    <span class="keywordflow">return</span>;</div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span>  }</div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno">  142</span>  *output_shift = 11;</div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno">  143</span>  <span class="keywordflow">while</span> (input &gt;= (1 &lt;&lt; 29))</div>
<div class="line"><a id="l00144" name="l00144"></a><span class="lineno">  144</span>  {</div>
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno">  145</span>    input /= 4;</div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span>    ++*output_shift;</div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span>  }</div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span>  <span class="keyword">const</span> <span class="keywordtype">unsigned</span> max_left_shift_bits = <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#acef25fe5a003e2ff65b2c8ccb2711207">count_leading_zeros</a>(<span class="keyword">static_cast&lt;</span>uint32_t<span class="keyword">&gt;</span>(input)) - 1;</div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span>  <span class="keyword">const</span> <span class="keywordtype">unsigned</span> max_left_shift_bit_pairs = max_left_shift_bits / 2;</div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno">  150</span>  <span class="keyword">const</span> <span class="keywordtype">unsigned</span> left_shift_bit_pairs = max_left_shift_bit_pairs - 1;</div>
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno">  151</span>  *output_shift -= left_shift_bit_pairs;</div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno">  152</span>  input &lt;&lt;= 2 * left_shift_bit_pairs;</div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno">  153</span>  <span class="keyword">using </span>gemmlowp::FixedPoint;</div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno">  154</span>  <span class="keyword">using </span>gemmlowp::Rescale;</div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span>  <span class="keyword">using </span>gemmlowp::SaturatingRoundingMultiplyByPOT;</div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span>  <span class="comment">// Using 3 integer bits gives us enough room for the internal arithmetic in</span></div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span>  <span class="comment">// this Newton-Raphson iteration.</span></div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno">  158</span>  <span class="keyword">using </span>F3 = FixedPoint&lt;int32_t, 3&gt;;</div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span>  <span class="keyword">using </span>F0 = FixedPoint&lt;int32_t, 0&gt;;</div>
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno">  160</span>  <span class="keyword">const</span> F3 fixedpoint_input = F3::FromRaw(input &gt;&gt; 1);</div>
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno">  161</span>  <span class="keyword">const</span> F3 fixedpoint_half_input = SaturatingRoundingMultiplyByPOT&lt;-1&gt;(fixedpoint_input);</div>
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno">  162</span>  <span class="keyword">const</span> F3 fixedpoint_half_three =</div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno">  163</span>    GEMMLOWP_CHECKED_FIXEDPOINT_CONSTANT(F3, (1 &lt;&lt; 28) + (1 &lt;&lt; 27), 1.5);</div>
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno">  164</span>  <span class="comment">// Newton-Raphson iteration</span></div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno">  165</span>  <span class="comment">// Naive unoptimized starting guess: x = 1</span></div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno">  166</span>  F3 x = F3::One();</div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno">  167</span>  <span class="comment">// Naive unoptimized number of iterations: 5</span></div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; 5; i++)</div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno">  169</span>  {</div>
<div class="line"><a id="l00170" name="l00170"></a><span class="lineno">  170</span>    <span class="keyword">const</span> F3 x3 = Rescale&lt;3&gt;(x * x * x);</div>
<div class="line"><a id="l00171" name="l00171"></a><span class="lineno">  171</span>    x = Rescale&lt;3&gt;(fixedpoint_half_three * x - fixedpoint_half_input * x3);</div>
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno">  172</span>  }</div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno">  173</span>  <span class="keyword">const</span> F0 fixedpoint_half_sqrt_2 =</div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno">  174</span>    GEMMLOWP_CHECKED_FIXEDPOINT_CONSTANT(F0, 1518500250, std::sqrt(2.) / 2.);</div>
<div class="line"><a id="l00175" name="l00175"></a><span class="lineno">  175</span>  x = x * fixedpoint_half_sqrt_2;</div>
<div class="line"><a id="l00176" name="l00176"></a><span class="lineno">  176</span>  *output_inv_sqrt = x.raw();</div>
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno">  177</span>  <span class="keywordflow">if</span> (*output_shift &lt; 0)</div>
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno">  178</span>  {</div>
<div class="line"><a id="l00179" name="l00179"></a><span class="lineno">  179</span>    *output_inv_sqrt &lt;&lt;= -*output_shift;</div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span>    *output_shift = 0;</div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span>  }</div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span>  <span class="comment">// Convert right shift (right is positive) to left shift.</span></div>
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno">  183</span>  *output_shift *= reverse_shift;</div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span>}</div>
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno">  185</span> </div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#a9c34168ef2084dd14025705bf93271ed">  186</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#a9c34168ef2084dd14025705bf93271ed">apply_layer_norm</a>(<span class="keyword">const</span> int16_t *input, <span class="keyword">const</span> int16_t *layer_norm_weights, <span class="keyword">const</span> int32_t *bias,</div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno">  187</span>                      int32_t layer_norm_scale_a, int32_t layer_norm_scale_b,</div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno">  188</span>                      int32_t variance_limit, <span class="keywordtype">int</span> n_batch, <span class="keywordtype">int</span> n_input, int16_t *output)</div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno">  189</span>{</div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span>  <span class="comment">// The square of std::pow(2, 10), which is the extra factor that makes sure</span></div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span>  <span class="comment">// normalized values has enough resolution.</span></div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span>  <span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">int</span> kTwoToPower20 = 1 &lt;&lt; 20;</div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span>  <span class="keyword">const</span> int32_t kInt16Max = std::numeric_limits&lt;int16_t&gt;::max();</div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span>  <span class="keyword">const</span> int32_t kInt16Min = std::numeric_limits&lt;int16_t&gt;::min();</div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; n_batch; ++i)</div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span>  {</div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span>    int64_t sum = 0;</div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span>    int64_t sum_sq = 0;</div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> j = 0; j &lt; n_input; ++j)</div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span>    {</div>
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno">  201</span>      <span class="keyword">const</span> int32_t index = i * n_input + j;</div>
<div class="line"><a id="l00202" name="l00202"></a><span class="lineno">  202</span>      int32_t val = <span class="keyword">static_cast&lt;</span>int32_t<span class="keyword">&gt;</span>(input[index]);</div>
<div class="line"><a id="l00203" name="l00203"></a><span class="lineno">  203</span>      sum += val;</div>
<div class="line"><a id="l00204" name="l00204"></a><span class="lineno">  204</span>      sum_sq += val * val;</div>
<div class="line"><a id="l00205" name="l00205"></a><span class="lineno">  205</span>    }</div>
<div class="line"><a id="l00206" name="l00206"></a><span class="lineno">  206</span>    int32_t mean = <span class="keyword">static_cast&lt;</span>int32_t<span class="keyword">&gt;</span>(<span class="keyword">static_cast&lt;</span>int64_t<span class="keyword">&gt;</span>(sum) * 1024 / n_input);</div>
<div class="line"><a id="l00207" name="l00207"></a><span class="lineno">  207</span>    <span class="comment">// TODO Avoids overflow but only works for POT n_input.</span></div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span>    int32_t temp = kTwoToPower20 / n_input;</div>
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno">  209</span>    int64_t variance = sum_sq * temp - <span class="keyword">static_cast&lt;</span>int64_t<span class="keyword">&gt;</span>(mean) * <span class="keyword">static_cast&lt;</span>int64_t<span class="keyword">&gt;</span>(mean);</div>
<div class="line"><a id="l00210" name="l00210"></a><span class="lineno">  210</span>    int32_t variance2 = <span class="keyword">static_cast&lt;</span>int32_t<span class="keyword">&gt;</span>(variance / kTwoToPower20);</div>
<div class="line"><a id="l00211" name="l00211"></a><span class="lineno">  211</span>    <span class="keywordflow">if</span> (variance2 &lt; 1)</div>
<div class="line"><a id="l00212" name="l00212"></a><span class="lineno">  212</span>    {</div>
<div class="line"><a id="l00213" name="l00213"></a><span class="lineno">  213</span>      variance2 = variance_limit;</div>
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno">  214</span>    }</div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno">  215</span>    int32_t stddev_inverse_a;</div>
<div class="line"><a id="l00216" name="l00216"></a><span class="lineno">  216</span>    <span class="keywordtype">int</span> stddev_inverse_b;</div>
<div class="line"><a id="l00217" name="l00217"></a><span class="lineno">  217</span>    <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#a4a2d78fd09384fe6419222fac94e71b3">get_inv_sqrt_quantized_multiplier_exp</a>(variance2, <span class="comment">/*reverse_shift*/</span> -1, &amp;stddev_inverse_a,</div>
<div class="line"><a id="l00218" name="l00218"></a><span class="lineno">  218</span>                                          &amp;stddev_inverse_b);</div>
<div class="line"><a id="l00219" name="l00219"></a><span class="lineno">  219</span> </div>
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno">  220</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> j = 0; j &lt; n_input; ++j)</div>
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno">  221</span>    {</div>
<div class="line"><a id="l00222" name="l00222"></a><span class="lineno">  222</span>      <span class="keyword">const</span> int32_t index = i * n_input + j;</div>
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno">  223</span>      int32_t val = <span class="keyword">static_cast&lt;</span>int32_t<span class="keyword">&gt;</span>(input[index]);</div>
<div class="line"><a id="l00224" name="l00224"></a><span class="lineno">  224</span>      int32_t shifted = 1024 * val - mean;</div>
<div class="line"><a id="l00225" name="l00225"></a><span class="lineno">  225</span>      int32_t rescaled =</div>
<div class="line"><a id="l00226" name="l00226"></a><span class="lineno">  226</span>        <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#acbe525077503e0d3f37d59b7fc8276e2">multiply_by_quantized_multiplier</a>(shifted, stddev_inverse_a, stddev_inverse_b);</div>
<div class="line"><a id="l00227" name="l00227"></a><span class="lineno">  227</span>      <span class="comment">// TODO: Saturate this.</span></div>
<div class="line"><a id="l00228" name="l00228"></a><span class="lineno">  228</span>      int64_t val3 = rescaled * layer_norm_weights[j] + bias[j];</div>
<div class="line"><a id="l00229" name="l00229"></a><span class="lineno">  229</span>      int32_t val4 = <span class="keyword">static_cast&lt;</span>int32_t<span class="keyword">&gt;</span>((val3 &gt; 0 ? val3 + 512 : val3 - 512) / 1024);</div>
<div class="line"><a id="l00230" name="l00230"></a><span class="lineno">  230</span>      int32_t val5 =</div>
<div class="line"><a id="l00231" name="l00231"></a><span class="lineno">  231</span>        <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#acbe525077503e0d3f37d59b7fc8276e2">multiply_by_quantized_multiplier</a>(val4, layer_norm_scale_a, layer_norm_scale_b + 12);</div>
<div class="line"><a id="l00232" name="l00232"></a><span class="lineno">  232</span>      val5 = std::min(std::max(kInt16Min, val5), kInt16Max);</div>
<div class="line"><a id="l00233" name="l00233"></a><span class="lineno">  233</span>      output[index] = <span class="keyword">static_cast&lt;</span>int16_t<span class="keyword">&gt;</span>(val5);</div>
<div class="line"><a id="l00234" name="l00234"></a><span class="lineno">  234</span>    }</div>
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno">  235</span>  }</div>
<div class="line"><a id="l00236" name="l00236"></a><span class="lineno">  236</span>}</div>
<div class="line"><a id="l00237" name="l00237"></a><span class="lineno">  237</span> </div>
<div class="line"><a id="l00238" name="l00238"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#a7361af5bb813813c50859760c4cc8f8a">  238</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#a7361af5bb813813c50859760c4cc8f8a">vector_batch_vector_cwise_product_accumulate</a>(<span class="keyword">const</span> int16_t *vector, <span class="keywordtype">int</span> v_size,</div>
<div class="line"><a id="l00239" name="l00239"></a><span class="lineno">  239</span>                                                  <span class="keyword">const</span> int16_t *batch_vector, <span class="keywordtype">int</span> n_batch,</div>
<div class="line"><a id="l00240" name="l00240"></a><span class="lineno">  240</span>                                                  int32_t multiplier, <span class="keywordtype">int</span> shift, int16_t *result)</div>
<div class="line"><a id="l00241" name="l00241"></a><span class="lineno">  241</span>{</div>
<div class="line"><a id="l00242" name="l00242"></a><span class="lineno">  242</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> b = 0; b &lt; n_batch; b++)</div>
<div class="line"><a id="l00243" name="l00243"></a><span class="lineno">  243</span>  {</div>
<div class="line"><a id="l00244" name="l00244"></a><span class="lineno">  244</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> v = 0; v &lt; v_size; v++)</div>
<div class="line"><a id="l00245" name="l00245"></a><span class="lineno">  245</span>    {</div>
<div class="line"><a id="l00246" name="l00246"></a><span class="lineno">  246</span>      int32_t prod = vector[v] * *batch_vector++;</div>
<div class="line"><a id="l00247" name="l00247"></a><span class="lineno">  247</span>      prod = <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#acbe525077503e0d3f37d59b7fc8276e2">multiply_by_quantized_multiplier</a>(prod, multiplier, shift);</div>
<div class="line"><a id="l00248" name="l00248"></a><span class="lineno">  248</span>      int32_t output = prod + *result;</div>
<div class="line"><a id="l00249" name="l00249"></a><span class="lineno">  249</span>      output =</div>
<div class="line"><a id="l00250" name="l00250"></a><span class="lineno">  250</span>        std::max(std::min(<span class="keyword">static_cast&lt;</span>int32_t<span class="keyword">&gt;</span>(32767), output), <span class="keyword">static_cast&lt;</span>int32_t<span class="keyword">&gt;</span>(-32768));</div>
<div class="line"><a id="l00251" name="l00251"></a><span class="lineno">  251</span>      *result++ = output;</div>
<div class="line"><a id="l00252" name="l00252"></a><span class="lineno">  252</span>    }</div>
<div class="line"><a id="l00253" name="l00253"></a><span class="lineno">  253</span>  }</div>
<div class="line"><a id="l00254" name="l00254"></a><span class="lineno">  254</span>}</div>
<div class="line"><a id="l00255" name="l00255"></a><span class="lineno">  255</span> </div>
<div class="line"><a id="l00256" name="l00256"></a><span class="lineno">  256</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="line"><a id="l00257" name="l00257"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#ad9970c643958b6d2c26dcd2506bac62b">  257</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#ad9970c643958b6d2c26dcd2506bac62b">matrix_batch_vector_multiply_accumulate</a>(<span class="keyword">const</span> int8_t *input, <span class="keyword">const</span> int32_t *bias,</div>
<div class="line"><a id="l00258" name="l00258"></a><span class="lineno">  258</span>                                             <span class="keyword">const</span> int8_t *input_to_gate_weights,</div>
<div class="line"><a id="l00259" name="l00259"></a><span class="lineno">  259</span>                                             int32_t multiplier, int32_t shift, int32_t n_batch,</div>
<div class="line"><a id="l00260" name="l00260"></a><span class="lineno">  260</span>                                             int32_t n_input, int32_t n_output, int32_t output_zp,</div>
<div class="line"><a id="l00261" name="l00261"></a><span class="lineno">  261</span>                                             T *output)</div>
<div class="line"><a id="l00262" name="l00262"></a><span class="lineno">  262</span>{</div>
<div class="line"><a id="l00263" name="l00263"></a><span class="lineno">  263</span>  <span class="keyword">const</span> int16_t output_max = std::numeric_limits&lt;T&gt;::max();</div>
<div class="line"><a id="l00264" name="l00264"></a><span class="lineno">  264</span>  <span class="keyword">const</span> int16_t output_min = std::numeric_limits&lt;T&gt;::min();</div>
<div class="line"><a id="l00265" name="l00265"></a><span class="lineno">  265</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> batch = 0; batch &lt; n_batch; ++batch)</div>
<div class="line"><a id="l00266" name="l00266"></a><span class="lineno">  266</span>  {</div>
<div class="line"><a id="l00267" name="l00267"></a><span class="lineno">  267</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> row = 0; row &lt; n_output; ++row)</div>
<div class="line"><a id="l00268" name="l00268"></a><span class="lineno">  268</span>    {</div>
<div class="line"><a id="l00269" name="l00269"></a><span class="lineno">  269</span>      int32_t acc = bias[row];</div>
<div class="line"><a id="l00270" name="l00270"></a><span class="lineno">  270</span>      <span class="keywordflow">for</span> (<span class="keywordtype">int</span> col = 0; col &lt; n_input; ++col)</div>
<div class="line"><a id="l00271" name="l00271"></a><span class="lineno">  271</span>      {</div>
<div class="line"><a id="l00272" name="l00272"></a><span class="lineno">  272</span>        int8_t input_val = input[batch * n_input + col];</div>
<div class="line"><a id="l00273" name="l00273"></a><span class="lineno">  273</span>        int8_t weights_val = input_to_gate_weights[row * n_input + col];</div>
<div class="line"><a id="l00274" name="l00274"></a><span class="lineno">  274</span>        acc += input_val * weights_val;</div>
<div class="line"><a id="l00275" name="l00275"></a><span class="lineno">  275</span>      }</div>
<div class="line"><a id="l00276" name="l00276"></a><span class="lineno">  276</span>      acc = <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#acbe525077503e0d3f37d59b7fc8276e2">multiply_by_quantized_multiplier</a>(acc, multiplier, shift);</div>
<div class="line"><a id="l00277" name="l00277"></a><span class="lineno">  277</span>      acc += output_zp;</div>
<div class="line"><a id="l00278" name="l00278"></a><span class="lineno">  278</span>      acc += output[batch * n_output + row];</div>
<div class="line"><a id="l00279" name="l00279"></a><span class="lineno">  279</span>      <span class="keywordflow">if</span> (acc &gt; output_max)</div>
<div class="line"><a id="l00280" name="l00280"></a><span class="lineno">  280</span>      {</div>
<div class="line"><a id="l00281" name="l00281"></a><span class="lineno">  281</span>        acc = output_max;</div>
<div class="line"><a id="l00282" name="l00282"></a><span class="lineno">  282</span>      }</div>
<div class="line"><a id="l00283" name="l00283"></a><span class="lineno">  283</span>      <span class="keywordflow">if</span> (acc &lt; output_min)</div>
<div class="line"><a id="l00284" name="l00284"></a><span class="lineno">  284</span>      {</div>
<div class="line"><a id="l00285" name="l00285"></a><span class="lineno">  285</span>        acc = output_min;</div>
<div class="line"><a id="l00286" name="l00286"></a><span class="lineno">  286</span>      }</div>
<div class="line"><a id="l00287" name="l00287"></a><span class="lineno">  287</span>      output[batch * n_output + row] = <span class="keyword">static_cast&lt;</span>T<span class="keyword">&gt;</span>(acc);</div>
<div class="line"><a id="l00288" name="l00288"></a><span class="lineno">  288</span>    }</div>
<div class="line"><a id="l00289" name="l00289"></a><span class="lineno">  289</span>  }</div>
<div class="line"><a id="l00290" name="l00290"></a><span class="lineno">  290</span>}</div>
<div class="line"><a id="l00291" name="l00291"></a><span class="lineno">  291</span> </div>
<div class="line"><a id="l00292" name="l00292"></a><span class="lineno">  292</span><span class="keyword">template</span> &lt;<span class="keywordtype">int</span> IntegerBits&gt;</div>
<div class="line"><a id="l00293" name="l00293"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#af16a4f8e96b58833ba85f9b5ef120b6c">  293</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#af16a4f8e96b58833ba85f9b5ef120b6c">apply_tanh_impl</a>(<span class="keyword">const</span> int16_t *input, int32_t n_batch, int32_t n_input, int16_t *output)</div>
<div class="line"><a id="l00294" name="l00294"></a><span class="lineno">  294</span>{</div>
<div class="line"><a id="l00295" name="l00295"></a><span class="lineno">  295</span>  <span class="keyword">using </span>FX = gemmlowp::FixedPoint&lt;std::int16_t, IntegerBits&gt;;</div>
<div class="line"><a id="l00296" name="l00296"></a><span class="lineno">  296</span>  <span class="keyword">using </span>F0 = gemmlowp::FixedPoint&lt;std::int16_t, 0&gt;;</div>
<div class="line"><a id="l00297" name="l00297"></a><span class="lineno">  297</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> batch = 0; batch &lt; n_batch; ++batch)</div>
<div class="line"><a id="l00298" name="l00298"></a><span class="lineno">  298</span>  {</div>
<div class="line"><a id="l00299" name="l00299"></a><span class="lineno">  299</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; n_input; ++i)</div>
<div class="line"><a id="l00300" name="l00300"></a><span class="lineno">  300</span>    {</div>
<div class="line"><a id="l00301" name="l00301"></a><span class="lineno">  301</span>      <span class="keyword">const</span> <span class="keywordtype">int</span> index = batch * n_input + i;</div>
<div class="line"><a id="l00302" name="l00302"></a><span class="lineno">  302</span>      FX tanh_input = FX::FromRaw(input[index]);</div>
<div class="line"><a id="l00303" name="l00303"></a><span class="lineno">  303</span>      F0 tanh_output = gemmlowp::tanh(tanh_input);</div>
<div class="line"><a id="l00304" name="l00304"></a><span class="lineno">  304</span>      output[index] = tanh_output.raw();</div>
<div class="line"><a id="l00305" name="l00305"></a><span class="lineno">  305</span>    }</div>
<div class="line"><a id="l00306" name="l00306"></a><span class="lineno">  306</span>  }</div>
<div class="line"><a id="l00307" name="l00307"></a><span class="lineno">  307</span>}</div>
<div class="line"><a id="l00308" name="l00308"></a><span class="lineno">  308</span> </div>
<div class="line"><a id="l00309" name="l00309"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#ae5995c2f4e037e3d18ef8f0462079564">  309</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#ae5995c2f4e037e3d18ef8f0462079564">apply_tanh</a>(int32_t integer_bits, <span class="keyword">const</span> int16_t *input, int32_t n_batch, int32_t n_input,</div>
<div class="line"><a id="l00310" name="l00310"></a><span class="lineno">  310</span>                int16_t *output)</div>
<div class="line"><a id="l00311" name="l00311"></a><span class="lineno">  311</span>{</div>
<div class="line"><a id="l00312" name="l00312"></a><span class="lineno">  312</span>  assert(integer_bits &lt;= 6);</div>
<div class="line"><a id="l00313" name="l00313"></a><span class="lineno">  313</span><span class="preprocessor">#define DISPATCH_TANH(i)                                 \</span></div>
<div class="line"><a id="l00314" name="l00314"></a><span class="lineno">  314</span><span class="preprocessor">  case i:                                                \</span></div>
<div class="line"><a id="l00315" name="l00315"></a><span class="lineno">  315</span><span class="preprocessor">    apply_tanh_impl&lt;i&gt;(input, n_batch, n_input, output); \</span></div>
<div class="line"><a id="l00316" name="l00316"></a><span class="lineno">  316</span><span class="preprocessor">    break;</span></div>
<div class="line"><a id="l00317" name="l00317"></a><span class="lineno">  317</span>  <span class="keywordflow">switch</span> (integer_bits)</div>
<div class="line"><a id="l00318" name="l00318"></a><span class="lineno">  318</span>  {</div>
<div class="line"><a id="l00319" name="l00319"></a><span class="lineno">  319</span>    <a class="code hl_define" href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h.html#a740521307802d978b1a8134e3eb4acf9">DISPATCH_TANH</a>(0);</div>
<div class="line"><a id="l00320" name="l00320"></a><span class="lineno">  320</span>    <a class="code hl_define" href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h.html#a740521307802d978b1a8134e3eb4acf9">DISPATCH_TANH</a>(1);</div>
<div class="line"><a id="l00321" name="l00321"></a><span class="lineno">  321</span>    <a class="code hl_define" href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h.html#a740521307802d978b1a8134e3eb4acf9">DISPATCH_TANH</a>(2);</div>
<div class="line"><a id="l00322" name="l00322"></a><span class="lineno">  322</span>    <a class="code hl_define" href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h.html#a740521307802d978b1a8134e3eb4acf9">DISPATCH_TANH</a>(3);</div>
<div class="line"><a id="l00323" name="l00323"></a><span class="lineno">  323</span>    <a class="code hl_define" href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h.html#a740521307802d978b1a8134e3eb4acf9">DISPATCH_TANH</a>(4);</div>
<div class="line"><a id="l00324" name="l00324"></a><span class="lineno">  324</span>    <a class="code hl_define" href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h.html#a740521307802d978b1a8134e3eb4acf9">DISPATCH_TANH</a>(5);</div>
<div class="line"><a id="l00325" name="l00325"></a><span class="lineno">  325</span>    <a class="code hl_define" href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h.html#a740521307802d978b1a8134e3eb4acf9">DISPATCH_TANH</a>(6);</div>
<div class="line"><a id="l00326" name="l00326"></a><span class="lineno">  326</span>    <span class="keywordflow">default</span>:</div>
<div class="line"><a id="l00327" name="l00327"></a><span class="lineno">  327</span>      <span class="keywordflow">return</span>;</div>
<div class="line"><a id="l00328" name="l00328"></a><span class="lineno">  328</span>  }</div>
<div class="line"><a id="l00329" name="l00329"></a><span class="lineno">  329</span><span class="preprocessor">#undef DISPATCH_TANH</span></div>
<div class="line"><a id="l00330" name="l00330"></a><span class="lineno">  330</span>}</div>
<div class="line"><a id="l00331" name="l00331"></a><span class="lineno">  331</span> </div>
<div class="line"><a id="l00332" name="l00332"></a><span class="lineno">  332</span><span class="comment">// Calculates the output state tensor of an LSTM step. See Float and hybrid</span></div>
<div class="line"><a id="l00333" name="l00333"></a><span class="lineno">  333</span><span class="comment">// versions as well.</span></div>
<div class="line"><a id="l00334" name="l00334"></a><span class="lineno">  334</span><span class="comment">//</span></div>
<div class="line"><a id="l00335" name="l00335"></a><span class="lineno">  335</span><span class="comment">// Parameters:</span></div>
<div class="line"><a id="l00336" name="l00336"></a><span class="lineno">  336</span><span class="comment">//  - n_batch: batches: the number of distinct vectors in each array.</span></div>
<div class="line"><a id="l00337" name="l00337"></a><span class="lineno">  337</span><span class="comment">//  - n_cell, n_output: sizes of vectors.</span></div>
<div class="line"><a id="l00338" name="l00338"></a><span class="lineno">  338</span><span class="comment">//  - cell_state, output_gate: input vectors, size n_batch*n_cell.</span></div>
<div class="line"><a id="l00339" name="l00339"></a><span class="lineno">  339</span><span class="comment">//  - cell_state_scale: scaling of cell_state.</span></div>
<div class="line"><a id="l00340" name="l00340"></a><span class="lineno">  340</span><span class="comment">//  - hidden_scale_[a|b]: effective scale of cell_state.*output_gate</span></div>
<div class="line"><a id="l00341" name="l00341"></a><span class="lineno">  341</span><span class="comment">//  - hidden_zp: zero_point for cell_state.*output_gate</span></div>
<div class="line"><a id="l00342" name="l00342"></a><span class="lineno">  342</span><span class="comment">//  - projection_weights, proj_scale_[a|b], projection_bias:</span></div>
<div class="line"><a id="l00343" name="l00343"></a><span class="lineno">  343</span><span class="comment">//      constant inputs, describing projection matrix and bias.</span></div>
<div class="line"><a id="l00344" name="l00344"></a><span class="lineno">  344</span><span class="comment">//  - output_state_zp: zero point of output_state. (Input, calibrated value.)</span></div>
<div class="line"><a id="l00345" name="l00345"></a><span class="lineno">  345</span><span class="comment">//  - quantized_proj_clip: if &gt; 0, clip the output of the projection.</span></div>
<div class="line"><a id="l00346" name="l00346"></a><span class="lineno">  346</span><span class="comment">//  - output_state: output vector, size n_batch*n_output. Must be contigous.</span></div>
<div class="line"><a id="l00347" name="l00347"></a><span class="lineno">  347</span><span class="comment">//  - scratch0: scratch area of size n_batch*n_cell</span></div>
<div class="line"><a id="l00348" name="l00348"></a><span class="lineno">  348</span><span class="comment">//  - scratch1: scratch area of size n_batch*n_cell</span></div>
<div class="line"><a id="l00349" name="l00349"></a><span class="lineno">  349</span><span class="comment">//  - scratch2: scratch area used by MatrixBatchVectorMultiplyAccumulate</span></div>
<div class="line"><a id="l00350" name="l00350"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#ad07afcc83af092c475787d8184538098">  350</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#ad07afcc83af092c475787d8184538098">calculate_lstm_output_integer8x8_16</a>(<span class="keywordtype">int</span> n_batch, <span class="keywordtype">int</span> n_cell, <span class="keywordtype">int</span> n_output, int16_t *cell_state,</div>
<div class="line"><a id="l00351" name="l00351"></a><span class="lineno">  351</span>                                         int32_t cell_state_scale, <span class="keyword">const</span> int16_t *output_gate,</div>
<div class="line"><a id="l00352" name="l00352"></a><span class="lineno">  352</span>                                         int32_t hidden_scale_a, int32_t hidden_scale_b,</div>
<div class="line"><a id="l00353" name="l00353"></a><span class="lineno">  353</span>                                         int32_t hidden_zp, <span class="keyword">const</span> int8_t *projection_weights,</div>
<div class="line"><a id="l00354" name="l00354"></a><span class="lineno">  354</span>                                         int32_t proj_scale_a, int32_t proj_scale_b,</div>
<div class="line"><a id="l00355" name="l00355"></a><span class="lineno">  355</span>                                         <span class="keyword">const</span> int32_t *projection_bias, int32_t output_state_zp,</div>
<div class="line"><a id="l00356" name="l00356"></a><span class="lineno">  356</span>                                         int8_t quantized_proj_clip, int8_t *output_state,</div>
<div class="line"><a id="l00357" name="l00357"></a><span class="lineno">  357</span>                                         int16_t *scratch0, int8_t *scratch1, int32_t *scratch2)</div>
<div class="line"><a id="l00358" name="l00358"></a><span class="lineno">  358</span>{</div>
<div class="line"><a id="l00359" name="l00359"></a><span class="lineno">  359</span>  <span class="comment">// Note: unlike float/hybrid, the activation is always Tanh.</span></div>
<div class="line"><a id="l00360" name="l00360"></a><span class="lineno">  360</span>  <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#ae5995c2f4e037e3d18ef8f0462079564">apply_tanh</a>(15 + cell_state_scale, cell_state, n_batch, n_cell, scratch0);</div>
<div class="line"><a id="l00361" name="l00361"></a><span class="lineno">  361</span>  <span class="keyword">const</span> <span class="keywordtype">bool</span> use_projection = (projection_weights != <span class="keyword">nullptr</span>);</div>
<div class="line"><a id="l00362" name="l00362"></a><span class="lineno">  362</span> </div>
<div class="line"><a id="l00363" name="l00363"></a><span class="lineno">  363</span>  <span class="keywordflow">if</span> (use_projection)</div>
<div class="line"><a id="l00364" name="l00364"></a><span class="lineno">  364</span>  {</div>
<div class="line"><a id="l00365" name="l00365"></a><span class="lineno">  365</span>    <span class="comment">// b/246629213 the projection operation assumes -hidden_zp in CwiseMul</span></div>
<div class="line"><a id="l00366" name="l00366"></a><span class="lineno">  366</span>    <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#a13269908e5cbb4827f974e782b98f6b2">cwise_mul</a>(output_gate, scratch0, hidden_scale_a, hidden_scale_b, n_batch, n_cell, -hidden_zp,</div>
<div class="line"><a id="l00367" name="l00367"></a><span class="lineno">  367</span>              scratch1);</div>
<div class="line"><a id="l00368" name="l00368"></a><span class="lineno">  368</span>    <span class="comment">// Note: no bias like in float/hybrid</span></div>
<div class="line"><a id="l00369" name="l00369"></a><span class="lineno">  369</span>    std::fill_n(output_state, n_batch * n_output, 0);</div>
<div class="line"><a id="l00370" name="l00370"></a><span class="lineno">  370</span>    <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#ad9970c643958b6d2c26dcd2506bac62b">matrix_batch_vector_multiply_accumulate</a>(scratch1, projection_bias, projection_weights,</div>
<div class="line"><a id="l00371" name="l00371"></a><span class="lineno">  371</span>                                            proj_scale_a, proj_scale_b, n_batch, n_cell, n_output,</div>
<div class="line"><a id="l00372" name="l00372"></a><span class="lineno">  372</span>                                            output_state_zp, output_state);</div>
<div class="line"><a id="l00373" name="l00373"></a><span class="lineno">  373</span>    <span class="keywordflow">if</span> (quantized_proj_clip &gt; 0)</div>
<div class="line"><a id="l00374" name="l00374"></a><span class="lineno">  374</span>    {</div>
<div class="line"><a id="l00375" name="l00375"></a><span class="lineno">  375</span>      <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#a4e414d74814834c72b789c80e68e843b">cwise_clipping</a>(output_state, n_batch * n_output, quantized_proj_clip);</div>
<div class="line"><a id="l00376" name="l00376"></a><span class="lineno">  376</span>    }</div>
<div class="line"><a id="l00377" name="l00377"></a><span class="lineno">  377</span>  }</div>
<div class="line"><a id="l00378" name="l00378"></a><span class="lineno">  378</span>  <span class="keywordflow">else</span></div>
<div class="line"><a id="l00379" name="l00379"></a><span class="lineno">  379</span>  {</div>
<div class="line"><a id="l00380" name="l00380"></a><span class="lineno">  380</span>    <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#a13269908e5cbb4827f974e782b98f6b2">cwise_mul</a>(output_gate, scratch0, hidden_scale_a, hidden_scale_b, n_batch, n_cell, hidden_zp,</div>
<div class="line"><a id="l00381" name="l00381"></a><span class="lineno">  381</span>              output_state);</div>
<div class="line"><a id="l00382" name="l00382"></a><span class="lineno">  382</span>  }</div>
<div class="line"><a id="l00383" name="l00383"></a><span class="lineno">  383</span>}</div>
<div class="line"><a id="l00384" name="l00384"></a><span class="lineno">  384</span> </div>
<div class="line"><a id="l00385" name="l00385"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#ad0b6a487395ebcaaef58516ae80581a7">  385</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#a13269908e5cbb4827f974e782b98f6b2">cwise_mul</a>(<span class="keyword">const</span> int16_t *input_1, <span class="keyword">const</span> int16_t *input_2, <span class="keywordtype">int</span> n_batch, <span class="keywordtype">int</span> n_input, <span class="keywordtype">int</span> shift,</div>
<div class="line"><a id="l00386" name="l00386"></a><span class="lineno">  386</span>               int16_t *output)</div>
<div class="line"><a id="l00387" name="l00387"></a><span class="lineno">  387</span>{</div>
<div class="line"><a id="l00388" name="l00388"></a><span class="lineno">  388</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> batch = 0; batch &lt; n_batch; ++batch)</div>
<div class="line"><a id="l00389" name="l00389"></a><span class="lineno">  389</span>  {</div>
<div class="line"><a id="l00390" name="l00390"></a><span class="lineno">  390</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; n_input; ++i)</div>
<div class="line"><a id="l00391" name="l00391"></a><span class="lineno">  391</span>    {</div>
<div class="line"><a id="l00392" name="l00392"></a><span class="lineno">  392</span>      <span class="keyword">const</span> <span class="keywordtype">int</span> index = batch * n_input + i;</div>
<div class="line"><a id="l00393" name="l00393"></a><span class="lineno">  393</span>      <span class="keyword">const</span> int16_t a = input_1[index];</div>
<div class="line"><a id="l00394" name="l00394"></a><span class="lineno">  394</span>      <span class="keyword">const</span> int16_t b = input_2[index];</div>
<div class="line"><a id="l00395" name="l00395"></a><span class="lineno">  395</span>      <span class="keyword">const</span> int32_t value = <span class="keyword">static_cast&lt;</span>int32_t<span class="keyword">&gt;</span>(a) * <span class="keyword">static_cast&lt;</span>int32_t<span class="keyword">&gt;</span>(b);</div>
<div class="line"><a id="l00396" name="l00396"></a><span class="lineno">  396</span>      output[index] = <span class="keyword">static_cast&lt;</span>int16_t<span class="keyword">&gt;</span>(gemmlowp::RoundingDivideByPOT(value, shift));</div>
<div class="line"><a id="l00397" name="l00397"></a><span class="lineno">  397</span>    }</div>
<div class="line"><a id="l00398" name="l00398"></a><span class="lineno">  398</span>  }</div>
<div class="line"><a id="l00399" name="l00399"></a><span class="lineno">  399</span>}</div>
<div class="line"><a id="l00400" name="l00400"></a><span class="lineno">  400</span> </div>
<div class="line"><a id="l00401" name="l00401"></a><span class="lineno">  401</span><span class="comment">// Updates the LSTM cell state, used by both integer LSTM versions.</span></div>
<div class="line"><a id="l00402" name="l00402"></a><span class="lineno">  402</span><span class="comment">// Also see UpdateLstmCellFloat.</span></div>
<div class="line"><a id="l00403" name="l00403"></a><span class="lineno">  403</span><span class="comment">//</span></div>
<div class="line"><a id="l00404" name="l00404"></a><span class="lineno">  404</span><span class="comment">// Parameters:</span></div>
<div class="line"><a id="l00405" name="l00405"></a><span class="lineno">  405</span><span class="comment">//  - n_batch, n_cell: sizes of vectors</span></div>
<div class="line"><a id="l00406" name="l00406"></a><span class="lineno">  406</span><span class="comment">//  - cell_state: input/output vector, size n_batch*n_cell</span></div>
<div class="line"><a id="l00407" name="l00407"></a><span class="lineno">  407</span><span class="comment">//  - cell_state_scale: scaling factor of cell state.</span></div>
<div class="line"><a id="l00408" name="l00408"></a><span class="lineno">  408</span><span class="comment">//  - input_gate: input vector, size n_batch*n_cell.</span></div>
<div class="line"><a id="l00409" name="l00409"></a><span class="lineno">  409</span><span class="comment">//  - forget_gate: input/scratch vector, size n_batch*n_cell, always modified.</span></div>
<div class="line"><a id="l00410" name="l00410"></a><span class="lineno">  410</span><span class="comment">//  - cell_gate: input vector, size n_batch*n_cell.</span></div>
<div class="line"><a id="l00411" name="l00411"></a><span class="lineno">  411</span><span class="comment">//  - use_cifg: use 1-forget_gate instead of input_gate.</span></div>
<div class="line"><a id="l00412" name="l00412"></a><span class="lineno">  412</span><span class="comment">//  - clip: if &gt; 0, clip the resulting cell state to [-clip, +clip].</span></div>
<div class="line"><a id="l00413" name="l00413"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#ab554f067a0e70af0121424c774ad3880">  413</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#ab554f067a0e70af0121424c774ad3880">update_lstm_cell_integer</a>(<span class="keywordtype">int</span> n_batch, <span class="keywordtype">int</span> n_cell, int16_t *cell_state,</div>
<div class="line"><a id="l00414" name="l00414"></a><span class="lineno">  414</span>                              int32_t cell_state_scale, <span class="keyword">const</span> int16_t *input_gate,</div>
<div class="line"><a id="l00415" name="l00415"></a><span class="lineno">  415</span>                              int16_t *forget_gate, <span class="keyword">const</span> int16_t *cell_gate, <span class="keywordtype">bool</span> use_cifg,</div>
<div class="line"><a id="l00416" name="l00416"></a><span class="lineno">  416</span>                              int16_t clip)</div>
<div class="line"><a id="l00417" name="l00417"></a><span class="lineno">  417</span>{</div>
<div class="line"><a id="l00418" name="l00418"></a><span class="lineno">  418</span>  <span class="comment">// Use the forget_gate array as scratch, as input_gate array is not allocated</span></div>
<div class="line"><a id="l00419" name="l00419"></a><span class="lineno">  419</span>  <span class="comment">// in CIFG case. (Be careful not to write to the scratch before reading the</span></div>
<div class="line"><a id="l00420" name="l00420"></a><span class="lineno">  420</span>  <span class="comment">// forget gate data.)</span></div>
<div class="line"><a id="l00421" name="l00421"></a><span class="lineno">  421</span>  int16_t *scratch = forget_gate;</div>
<div class="line"><a id="l00422" name="l00422"></a><span class="lineno">  422</span> </div>
<div class="line"><a id="l00423" name="l00423"></a><span class="lineno">  423</span>  <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#a13269908e5cbb4827f974e782b98f6b2">cwise_mul</a>(forget_gate, cell_state, n_batch, n_cell, 15, cell_state);</div>
<div class="line"><a id="l00424" name="l00424"></a><span class="lineno">  424</span>  <span class="keywordflow">if</span> (use_cifg)</div>
<div class="line"><a id="l00425" name="l00425"></a><span class="lineno">  425</span>  {</div>
<div class="line"><a id="l00426" name="l00426"></a><span class="lineno">  426</span>    <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#a7b3a8ce5736307c9146154fd4639e0cb">sub1_vector</a>(forget_gate, n_batch * n_cell, scratch);</div>
<div class="line"><a id="l00427" name="l00427"></a><span class="lineno">  427</span>    <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#a13269908e5cbb4827f974e782b98f6b2">cwise_mul</a>(scratch, cell_gate, n_batch, n_cell, 30 + cell_state_scale, scratch);</div>
<div class="line"><a id="l00428" name="l00428"></a><span class="lineno">  428</span>  }</div>
<div class="line"><a id="l00429" name="l00429"></a><span class="lineno">  429</span>  <span class="keywordflow">else</span></div>
<div class="line"><a id="l00430" name="l00430"></a><span class="lineno">  430</span>  {</div>
<div class="line"><a id="l00431" name="l00431"></a><span class="lineno">  431</span>    <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#a13269908e5cbb4827f974e782b98f6b2">cwise_mul</a>(input_gate, cell_gate, n_batch, n_cell, 30 + cell_state_scale, scratch);</div>
<div class="line"><a id="l00432" name="l00432"></a><span class="lineno">  432</span>  }</div>
<div class="line"><a id="l00433" name="l00433"></a><span class="lineno">  433</span>  <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#af4923cae88d2f75c29b49c78c9a00f99">cwise_add</a>(cell_state, scratch, n_batch, n_cell, cell_state);</div>
<div class="line"><a id="l00434" name="l00434"></a><span class="lineno">  434</span> </div>
<div class="line"><a id="l00435" name="l00435"></a><span class="lineno">  435</span>  <span class="keywordflow">if</span> (clip &gt; 0)</div>
<div class="line"><a id="l00436" name="l00436"></a><span class="lineno">  436</span>  {</div>
<div class="line"><a id="l00437" name="l00437"></a><span class="lineno">  437</span>    <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#a4e414d74814834c72b789c80e68e843b">cwise_clipping</a>(cell_state, n_batch * n_cell, clip);</div>
<div class="line"><a id="l00438" name="l00438"></a><span class="lineno">  438</span>  }</div>
<div class="line"><a id="l00439" name="l00439"></a><span class="lineno">  439</span>}</div>
<div class="line"><a id="l00440" name="l00440"></a><span class="lineno">  440</span> </div>
<div class="line"><a id="l00441" name="l00441"></a><span class="lineno">  441</span><span class="comment">// Calculates a single LSTM gate, int8x8_16 version.</span></div>
<div class="line"><a id="l00442" name="l00442"></a><span class="lineno">  442</span><span class="comment">// Implements the same functionality as CalculateLstmGateFloat.</span></div>
<div class="line"><a id="l00443" name="l00443"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#adaa95dd338f0bbd9be680fd7dfc6d1aa">  443</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#adaa95dd338f0bbd9be680fd7dfc6d1aa">calculate_lstm_gate_integer_8x8_16</a>(</div>
<div class="line"><a id="l00444" name="l00444"></a><span class="lineno">  444</span>  <span class="comment">// Input and weights</span></div>
<div class="line"><a id="l00445" name="l00445"></a><span class="lineno">  445</span>  <span class="keyword">const</span> int8_t *input, <span class="keyword">const</span> int8_t *input_to_gate_weights, <span class="keyword">const</span> int32_t *input_to_gate_bias,</div>
<div class="line"><a id="l00446" name="l00446"></a><span class="lineno">  446</span>  <span class="keyword">const</span> int32_t input_to_gate_scale_a, <span class="keyword">const</span> int32_t input_to_gate_scale_b,</div>
<div class="line"><a id="l00447" name="l00447"></a><span class="lineno">  447</span>  <span class="comment">// Output state and weights</span></div>
<div class="line"><a id="l00448" name="l00448"></a><span class="lineno">  448</span>  <span class="keyword">const</span> int8_t *output_state, <span class="keyword">const</span> int8_t *recurrent_to_gate_weights,</div>
<div class="line"><a id="l00449" name="l00449"></a><span class="lineno">  449</span>  <span class="keyword">const</span> int32_t *recurrent_to_gate_bias, <span class="keyword">const</span> int32_t recurrent_to_gate_scale_a,</div>
<div class="line"><a id="l00450" name="l00450"></a><span class="lineno">  450</span>  <span class="keyword">const</span> int32_t recurrent_to_gate_scale_b,</div>
<div class="line"><a id="l00451" name="l00451"></a><span class="lineno">  451</span>  <span class="comment">// Cell state and weights</span></div>
<div class="line"><a id="l00452" name="l00452"></a><span class="lineno">  452</span>  <span class="keyword">const</span> int16_t *cell_state, <span class="keyword">const</span> int16_t *cell_to_gate_weights,</div>
<div class="line"><a id="l00453" name="l00453"></a><span class="lineno">  453</span>  <span class="keyword">const</span> int32_t cell_to_gate_scale_a, <span class="keyword">const</span> int32_t cell_to_gate_scale_b,</div>
<div class="line"><a id="l00454" name="l00454"></a><span class="lineno">  454</span>  <span class="comment">// Layer normalization parameters (layer norm LSTM)</span></div>
<div class="line"><a id="l00455" name="l00455"></a><span class="lineno">  455</span>  <span class="keyword">const</span> int16_t *layer_norm_coefficients, <span class="keyword">const</span> int32_t *layer_norm_bias,</div>
<div class="line"><a id="l00456" name="l00456"></a><span class="lineno">  456</span>  <span class="keyword">const</span> int32_t layer_norm_input_scale_a, <span class="keyword">const</span> int32_t layer_norm_input_scale_b,</div>
<div class="line"><a id="l00457" name="l00457"></a><span class="lineno">  457</span>  <span class="keyword">const</span> int32_t layer_norm_variance_guard,</div>
<div class="line"><a id="l00458" name="l00458"></a><span class="lineno">  458</span>  <span class="comment">// Array sizes</span></div>
<div class="line"><a id="l00459" name="l00459"></a><span class="lineno">  459</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> n_batch, <span class="keyword">const</span> <span class="keywordtype">int</span> n_input, <span class="keyword">const</span> <span class="keywordtype">int</span> n_output, <span class="keyword">const</span> <span class="keywordtype">int</span> n_cell,</div>
<div class="line"><a id="l00460" name="l00460"></a><span class="lineno">  460</span>  <span class="keyword">const</span> <a class="code hl_enumeration" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63">TfLiteFusedActivation</a> activation,</div>
<div class="line"><a id="l00461" name="l00461"></a><span class="lineno">  461</span>  <span class="comment">// Output</span></div>
<div class="line"><a id="l00462" name="l00462"></a><span class="lineno">  462</span>  int16_t *gate,</div>
<div class="line"><a id="l00463" name="l00463"></a><span class="lineno">  463</span>  <span class="comment">// Parameters for performance optimizations</span></div>
<div class="line"><a id="l00464" name="l00464"></a><span class="lineno">  464</span>  <span class="comment">// Scratch arrays</span></div>
<div class="line"><a id="l00465" name="l00465"></a><span class="lineno">  465</span>  int32_t *scratch5)</div>
<div class="line"><a id="l00466" name="l00466"></a><span class="lineno">  466</span>{</div>
<div class="line"><a id="l00467" name="l00467"></a><span class="lineno">  467</span>  <span class="keyword">const</span> <span class="keywordtype">bool</span> use_peephole = (cell_to_gate_weights != <span class="keyword">nullptr</span>);</div>
<div class="line"><a id="l00468" name="l00468"></a><span class="lineno">  468</span>  <span class="keyword">const</span> <span class="keywordtype">bool</span> use_layer_norm = (layer_norm_coefficients != <span class="keyword">nullptr</span>);</div>
<div class="line"><a id="l00469" name="l00469"></a><span class="lineno">  469</span> </div>
<div class="line"><a id="l00470" name="l00470"></a><span class="lineno">  470</span>  <span class="comment">// Initialize scratch buffers with zeros. Note that unlike float and hybrid</span></div>
<div class="line"><a id="l00471" name="l00471"></a><span class="lineno">  471</span>  <span class="comment">// versions, bias is only used in layer normalization.</span></div>
<div class="line"><a id="l00472" name="l00472"></a><span class="lineno">  472</span>  memset(gate, 0, n_batch * n_cell * <span class="keyword">sizeof</span>(int16_t));</div>
<div class="line"><a id="l00473" name="l00473"></a><span class="lineno">  473</span>  <span class="comment">// For each batch and cell: compute input_weight * input.</span></div>
<div class="line"><a id="l00474" name="l00474"></a><span class="lineno">  474</span>  <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#ad9970c643958b6d2c26dcd2506bac62b">matrix_batch_vector_multiply_accumulate</a>(input, input_to_gate_bias, input_to_gate_weights,</div>
<div class="line"><a id="l00475" name="l00475"></a><span class="lineno">  475</span>                                          input_to_gate_scale_a, input_to_gate_scale_b, n_batch,</div>
<div class="line"><a id="l00476" name="l00476"></a><span class="lineno">  476</span>                                          n_input, n_cell, 0, gate);</div>
<div class="line"><a id="l00477" name="l00477"></a><span class="lineno">  477</span>  <span class="comment">// Note: no aux_input.</span></div>
<div class="line"><a id="l00478" name="l00478"></a><span class="lineno">  478</span>  <span class="comment">// For each batch and cell: compute recurrent_weight * output_state.</span></div>
<div class="line"><a id="l00479" name="l00479"></a><span class="lineno">  479</span>  <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#ad9970c643958b6d2c26dcd2506bac62b">matrix_batch_vector_multiply_accumulate</a>(</div>
<div class="line"><a id="l00480" name="l00480"></a><span class="lineno">  480</span>    output_state, recurrent_to_gate_bias, recurrent_to_gate_weights, recurrent_to_gate_scale_a,</div>
<div class="line"><a id="l00481" name="l00481"></a><span class="lineno">  481</span>    recurrent_to_gate_scale_b, n_batch, n_output, n_cell, 0, gate);</div>
<div class="line"><a id="l00482" name="l00482"></a><span class="lineno">  482</span>  <span class="comment">// For each batch and cell: compute cell_weight * cell_state (peephole LSTM)</span></div>
<div class="line"><a id="l00483" name="l00483"></a><span class="lineno">  483</span>  <span class="keywordflow">if</span> (use_peephole)</div>
<div class="line"><a id="l00484" name="l00484"></a><span class="lineno">  484</span>  {</div>
<div class="line"><a id="l00485" name="l00485"></a><span class="lineno">  485</span>    <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#a7361af5bb813813c50859760c4cc8f8a">vector_batch_vector_cwise_product_accumulate</a>(cell_to_gate_weights, n_output, cell_state,</div>
<div class="line"><a id="l00486" name="l00486"></a><span class="lineno">  486</span>                                                 n_batch, cell_to_gate_scale_a,</div>
<div class="line"><a id="l00487" name="l00487"></a><span class="lineno">  487</span>                                                 cell_to_gate_scale_b, gate);</div>
<div class="line"><a id="l00488" name="l00488"></a><span class="lineno">  488</span>  }</div>
<div class="line"><a id="l00489" name="l00489"></a><span class="lineno">  489</span>  <span class="comment">// Do layer normalization (if layer norm LSTM)</span></div>
<div class="line"><a id="l00490" name="l00490"></a><span class="lineno">  490</span>  <span class="keywordflow">if</span> (use_layer_norm)</div>
<div class="line"><a id="l00491" name="l00491"></a><span class="lineno">  491</span>  {</div>
<div class="line"><a id="l00492" name="l00492"></a><span class="lineno">  492</span>    <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#a9c34168ef2084dd14025705bf93271ed">apply_layer_norm</a>(gate, layer_norm_coefficients, layer_norm_bias, layer_norm_input_scale_a,</div>
<div class="line"><a id="l00493" name="l00493"></a><span class="lineno">  493</span>                     layer_norm_input_scale_b, layer_norm_variance_guard, n_batch, n_cell, gate);</div>
<div class="line"><a id="l00494" name="l00494"></a><span class="lineno">  494</span>  }</div>
<div class="line"><a id="l00495" name="l00495"></a><span class="lineno">  495</span> </div>
<div class="line"><a id="l00496" name="l00496"></a><span class="lineno">  496</span>  <span class="comment">// Apply activation</span></div>
<div class="line"><a id="l00497" name="l00497"></a><span class="lineno">  497</span>  <span class="keywordflow">switch</span> (activation)</div>
<div class="line"><a id="l00498" name="l00498"></a><span class="lineno">  498</span>  {</div>
<div class="line"><a id="l00499" name="l00499"></a><span class="lineno">  499</span>    <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63ab211c831f880a63ebc80994bb0cf2dc2">kTfLiteActSigmoid</a>:</div>
<div class="line"><a id="l00500" name="l00500"></a><span class="lineno">  500</span>      tflite::reference_integer_ops::Logistic(</div>
<div class="line"><a id="l00501" name="l00501"></a><span class="lineno">  501</span>        0 <span class="comment">/*data-&gt;input_multiplier*/</span>, 0 <span class="comment">/*data-&gt;input_left_shift */</span>,</div>
<div class="line"><a id="l00502" name="l00502"></a><span class="lineno">  502</span>        n_batch * n_cell <span class="comment">/*NumElements(input-&gt;dims)*/</span>,</div>
<div class="line"><a id="l00503" name="l00503"></a><span class="lineno">  503</span>        gate <span class="comment">/* tflite::micro::GetTensorData&lt;int16_t&gt;(input) */</span>,</div>
<div class="line"><a id="l00504" name="l00504"></a><span class="lineno">  504</span>        gate <span class="comment">/*tflite::micro::GetTensorData&lt;int16_t&gt;(output) */</span>);</div>
<div class="line"><a id="l00505" name="l00505"></a><span class="lineno">  505</span> </div>
<div class="line"><a id="l00506" name="l00506"></a><span class="lineno">  506</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l00507" name="l00507"></a><span class="lineno">  507</span>    <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63a60bdd9a337a5f1f2866fd65c7d8ffdce">kTfLiteActTanh</a>:</div>
<div class="line"><a id="l00508" name="l00508"></a><span class="lineno">  508</span>    {</div>
<div class="line"><a id="l00509" name="l00509"></a><span class="lineno">  509</span>      int32_t dims_data = n_batch * n_cell;</div>
<div class="line"><a id="l00510" name="l00510"></a><span class="lineno">  510</span>      tflite::RuntimeShape tanh_inp_shape = tflite::RuntimeShape(1, &amp;dims_data);</div>
<div class="line"><a id="l00511" name="l00511"></a><span class="lineno">  511</span>      tflite::reference_integer_ops::Tanh(0, 0, tanh_inp_shape, gate, tanh_inp_shape, gate);</div>
<div class="line"><a id="l00512" name="l00512"></a><span class="lineno">  512</span>    }</div>
<div class="line"><a id="l00513" name="l00513"></a><span class="lineno">  513</span>    <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l00514" name="l00514"></a><span class="lineno">  514</span>    <span class="keywordflow">default</span>:</div>
<div class="line"><a id="l00515" name="l00515"></a><span class="lineno">  515</span>      <span class="comment">// Only Sigmoid or Tanh is used.</span></div>
<div class="line"><a id="l00516" name="l00516"></a><span class="lineno">  516</span>      TFLITE_ASSERT_FALSE;</div>
<div class="line"><a id="l00517" name="l00517"></a><span class="lineno">  517</span>  }</div>
<div class="line"><a id="l00518" name="l00518"></a><span class="lineno">  518</span>}</div>
<div class="line"><a id="l00519" name="l00519"></a><span class="lineno">  519</span> </div>
<div class="line"><a id="l00520" name="l00520"></a><span class="lineno">  520</span><span class="comment">// Fully quantized lstm kernel for 16 bit gate matmul output.</span></div>
<div class="line"><a id="l00521" name="l00521"></a><span class="lineno">  521</span><span class="comment">//</span></div>
<div class="line"><a id="l00522" name="l00522"></a><span class="lineno">  522</span><span class="comment">// Input tensor of size n_batch * n_input:</span></div>
<div class="line"><a id="l00523" name="l00523"></a><span class="lineno">  523</span><span class="comment">//   input_ptr</span></div>
<div class="line"><a id="l00524" name="l00524"></a><span class="lineno">  524</span><span class="comment">//</span></div>
<div class="line"><a id="l00525" name="l00525"></a><span class="lineno">  525</span><span class="comment">// LSTM weights:</span></div>
<div class="line"><a id="l00526" name="l00526"></a><span class="lineno">  526</span><span class="comment">// Quantized input weights of size &#39;n_cell * n_input&#39;:</span></div>
<div class="line"><a id="l00527" name="l00527"></a><span class="lineno">  527</span><span class="comment">//   input_to_input_weight_ptr            - optional</span></div>
<div class="line"><a id="l00528" name="l00528"></a><span class="lineno">  528</span><span class="comment">//   input_to_forget_weight_ptr           - optional</span></div>
<div class="line"><a id="l00529" name="l00529"></a><span class="lineno">  529</span><span class="comment">//   input_to_cell_weight_ptr             - optional</span></div>
<div class="line"><a id="l00530" name="l00530"></a><span class="lineno">  530</span><span class="comment">//   input_to_output_weight_ptr           - optional</span></div>
<div class="line"><a id="l00531" name="l00531"></a><span class="lineno">  531</span><span class="comment">//</span></div>
<div class="line"><a id="l00532" name="l00532"></a><span class="lineno">  532</span><span class="comment">// Quantized recurrent weights of size &#39;n_cell * n_output&#39;:</span></div>
<div class="line"><a id="l00533" name="l00533"></a><span class="lineno">  533</span><span class="comment">//   recurrent_to_input_weight_ptr        - optional</span></div>
<div class="line"><a id="l00534" name="l00534"></a><span class="lineno">  534</span><span class="comment">//   recurrent_to_forget_weights_ptr</span></div>
<div class="line"><a id="l00535" name="l00535"></a><span class="lineno">  535</span><span class="comment">//   recurrent_to_cell_weights_ptr</span></div>
<div class="line"><a id="l00536" name="l00536"></a><span class="lineno">  536</span><span class="comment">//   recurrent_to_input_weights_ptr</span></div>
<div class="line"><a id="l00537" name="l00537"></a><span class="lineno">  537</span><span class="comment">//</span></div>
<div class="line"><a id="l00538" name="l00538"></a><span class="lineno">  538</span><span class="comment">// Quantized peephole weights of size &#39;n_cell&#39;, representing diagonal matrices.</span></div>
<div class="line"><a id="l00539" name="l00539"></a><span class="lineno">  539</span><span class="comment">//   cell_to_input_weights               - optional</span></div>
<div class="line"><a id="l00540" name="l00540"></a><span class="lineno">  540</span><span class="comment">//   cell_to_cell_weights                - optional</span></div>
<div class="line"><a id="l00541" name="l00541"></a><span class="lineno">  541</span><span class="comment">//   cell_to_output_weights              - optional</span></div>
<div class="line"><a id="l00542" name="l00542"></a><span class="lineno">  542</span><span class="comment">//</span></div>
<div class="line"><a id="l00543" name="l00543"></a><span class="lineno">  543</span><span class="comment">// Quantized projection weights of size &#39;n_output * n_cell&#39;</span></div>
<div class="line"><a id="l00544" name="l00544"></a><span class="lineno">  544</span><span class="comment">//   projection_weight_ptr                     - optional</span></div>
<div class="line"><a id="l00545" name="l00545"></a><span class="lineno">  545</span><span class="comment">//</span></div>
<div class="line"><a id="l00546" name="l00546"></a><span class="lineno">  546</span><span class="comment">// Weight scales (scalars) for each of the weights above.</span></div>
<div class="line"><a id="l00547" name="l00547"></a><span class="lineno">  547</span><span class="comment">//   effective_input_to_input_scale_a    - optional</span></div>
<div class="line"><a id="l00548" name="l00548"></a><span class="lineno">  548</span><span class="comment">//   effective_input_to_input_scale_b    - optional</span></div>
<div class="line"><a id="l00549" name="l00549"></a><span class="lineno">  549</span><span class="comment">//   effective_input_to_forget_scale_a</span></div>
<div class="line"><a id="l00550" name="l00550"></a><span class="lineno">  550</span><span class="comment">//   effective_input_to_forget_scale_b</span></div>
<div class="line"><a id="l00551" name="l00551"></a><span class="lineno">  551</span><span class="comment">//   effective_input_to_cell_scale_a</span></div>
<div class="line"><a id="l00552" name="l00552"></a><span class="lineno">  552</span><span class="comment">//   effective_input_to_cell_scale_b</span></div>
<div class="line"><a id="l00553" name="l00553"></a><span class="lineno">  553</span><span class="comment">//   effective_input_to_output_scale_a</span></div>
<div class="line"><a id="l00554" name="l00554"></a><span class="lineno">  554</span><span class="comment">//   effective_input_to_output_scale_b</span></div>
<div class="line"><a id="l00555" name="l00555"></a><span class="lineno">  555</span><span class="comment">//   effective_recurrent_to_input_scale_a    - optional</span></div>
<div class="line"><a id="l00556" name="l00556"></a><span class="lineno">  556</span><span class="comment">//   effective_recurrent_to_input_scale_b    - optional</span></div>
<div class="line"><a id="l00557" name="l00557"></a><span class="lineno">  557</span><span class="comment">//   effective_recurrent_to_forget_scale_a</span></div>
<div class="line"><a id="l00558" name="l00558"></a><span class="lineno">  558</span><span class="comment">//   effective_recurrent_to_forget_scale_b</span></div>
<div class="line"><a id="l00559" name="l00559"></a><span class="lineno">  559</span><span class="comment">//   effective_recurrent_to_cell_scale_a</span></div>
<div class="line"><a id="l00560" name="l00560"></a><span class="lineno">  560</span><span class="comment">//   effective_recurrent_to_cell_scale_b</span></div>
<div class="line"><a id="l00561" name="l00561"></a><span class="lineno">  561</span><span class="comment">//   effective_recurrent_to_output_scale_a</span></div>
<div class="line"><a id="l00562" name="l00562"></a><span class="lineno">  562</span><span class="comment">//   effective_recurrent_to_output_scale_b</span></div>
<div class="line"><a id="l00563" name="l00563"></a><span class="lineno">  563</span><span class="comment">//   effective_proj_scale_a                  - optional</span></div>
<div class="line"><a id="l00564" name="l00564"></a><span class="lineno">  564</span><span class="comment">//   effective_proj_scale_b                  - optional</span></div>
<div class="line"><a id="l00565" name="l00565"></a><span class="lineno">  565</span><span class="comment">//</span></div>
<div class="line"><a id="l00566" name="l00566"></a><span class="lineno">  566</span><span class="comment">// Gate biases of size &#39;n_cell&#39;:</span></div>
<div class="line"><a id="l00567" name="l00567"></a><span class="lineno">  567</span><span class="comment">//   input_gate_bias_ptr                 - optional</span></div>
<div class="line"><a id="l00568" name="l00568"></a><span class="lineno">  568</span><span class="comment">//   forget_gate_bias_ptr</span></div>
<div class="line"><a id="l00569" name="l00569"></a><span class="lineno">  569</span><span class="comment">//   cell_gate_bias_ptr</span></div>
<div class="line"><a id="l00570" name="l00570"></a><span class="lineno">  570</span><span class="comment">//   output_gate_bias_ptr</span></div>
<div class="line"><a id="l00571" name="l00571"></a><span class="lineno">  571</span><span class="comment">//</span></div>
<div class="line"><a id="l00572" name="l00572"></a><span class="lineno">  572</span><span class="comment">// Layer norm coefficients of size &#39;n_cell&#39;, representing diagonal matrices.</span></div>
<div class="line"><a id="l00573" name="l00573"></a><span class="lineno">  573</span><span class="comment">//   layer_norm_input_weight_ptr    - optional</span></div>
<div class="line"><a id="l00574" name="l00574"></a><span class="lineno">  574</span><span class="comment">//   layer_norm_forget_weight_ptr   - optional</span></div>
<div class="line"><a id="l00575" name="l00575"></a><span class="lineno">  575</span><span class="comment">//   layer_norm_cell_weight_ptr     - optional</span></div>
<div class="line"><a id="l00576" name="l00576"></a><span class="lineno">  576</span><span class="comment">//   layer_norm_output_weight_ptr   - optional</span></div>
<div class="line"><a id="l00577" name="l00577"></a><span class="lineno">  577</span><span class="comment">//</span></div>
<div class="line"><a id="l00578" name="l00578"></a><span class="lineno">  578</span><span class="comment">// Layer norm scales of size &#39;n_cell&#39;.</span></div>
<div class="line"><a id="l00579" name="l00579"></a><span class="lineno">  579</span><span class="comment">//   layer_norm_input_scale_a     - optional</span></div>
<div class="line"><a id="l00580" name="l00580"></a><span class="lineno">  580</span><span class="comment">//   layer_norm_input_scale_b     - optional</span></div>
<div class="line"><a id="l00581" name="l00581"></a><span class="lineno">  581</span><span class="comment">//   layer_norm_forget_scale_a    - optional</span></div>
<div class="line"><a id="l00582" name="l00582"></a><span class="lineno">  582</span><span class="comment">//   layer_norm_forget_scale_b    - optional</span></div>
<div class="line"><a id="l00583" name="l00583"></a><span class="lineno">  583</span><span class="comment">//   layer_norm_cell_scale_a      - optional</span></div>
<div class="line"><a id="l00584" name="l00584"></a><span class="lineno">  584</span><span class="comment">//   layer_norm_cell_scale_b      - optional</span></div>
<div class="line"><a id="l00585" name="l00585"></a><span class="lineno">  585</span><span class="comment">//   layer_norm_output_scale_a    - optional</span></div>
<div class="line"><a id="l00586" name="l00586"></a><span class="lineno">  586</span><span class="comment">//   layer_norm_output_scale_b    - optional</span></div>
<div class="line"><a id="l00587" name="l00587"></a><span class="lineno">  587</span><span class="comment">//</span></div>
<div class="line"><a id="l00588" name="l00588"></a><span class="lineno">  588</span><span class="comment">// Scalar values:</span></div>
<div class="line"><a id="l00589" name="l00589"></a><span class="lineno">  589</span><span class="comment">//   quantized_cell_clip: quantized clip value for cell.</span></div>
<div class="line"><a id="l00590" name="l00590"></a><span class="lineno">  590</span><span class="comment">//   quantized_proj_clip: quantized clip value for projection.</span></div>
<div class="line"><a id="l00591" name="l00591"></a><span class="lineno">  591</span><span class="comment">//   cell_state_scale: the power of two scale for cell state.</span></div>
<div class="line"><a id="l00592" name="l00592"></a><span class="lineno">  592</span><span class="comment">//</span></div>
<div class="line"><a id="l00593" name="l00593"></a><span class="lineno">  593</span><span class="comment">// Zero points:</span></div>
<div class="line"><a id="l00594" name="l00594"></a><span class="lineno">  594</span><span class="comment">//   output_state_zp: zero point of output state</span></div>
<div class="line"><a id="l00595" name="l00595"></a><span class="lineno">  595</span><span class="comment">//   hidden_zp: zero point for hidden state.</span></div>
<div class="line"><a id="l00596" name="l00596"></a><span class="lineno">  596</span><span class="comment">//</span></div>
<div class="line"><a id="l00597" name="l00597"></a><span class="lineno">  597</span><span class="comment">// Temporary pre-allocated storage for the calculation. Each is of size n_cell *</span></div>
<div class="line"><a id="l00598" name="l00598"></a><span class="lineno">  598</span><span class="comment">// n_batch.</span></div>
<div class="line"><a id="l00599" name="l00599"></a><span class="lineno">  599</span><span class="comment">//   scratch0</span></div>
<div class="line"><a id="l00600" name="l00600"></a><span class="lineno">  600</span><span class="comment">//   scratch1</span></div>
<div class="line"><a id="l00601" name="l00601"></a><span class="lineno">  601</span><span class="comment">//   scratch2</span></div>
<div class="line"><a id="l00602" name="l00602"></a><span class="lineno">  602</span><span class="comment">//   scratch3</span></div>
<div class="line"><a id="l00603" name="l00603"></a><span class="lineno">  603</span><span class="comment">//   scratch4</span></div>
<div class="line"><a id="l00604" name="l00604"></a><span class="lineno">  604</span><span class="comment">//   scratch5: this scratch buffer is created purely for optimizing the</span></div>
<div class="line"><a id="l00605" name="l00605"></a><span class="lineno">  605</span><span class="comment">//              MatrixBatchVectorMultiplyAccumulate.</span></div>
<div class="line"><a id="l00606" name="l00606"></a><span class="lineno">  606</span><span class="comment">//</span></div>
<div class="line"><a id="l00607" name="l00607"></a><span class="lineno">  607</span><span class="comment">// Outputs:</span></div>
<div class="line"><a id="l00608" name="l00608"></a><span class="lineno">  608</span><span class="comment">//   output_state_ptr - size &#39;n_batch * n_output&#39;</span></div>
<div class="line"><a id="l00609" name="l00609"></a><span class="lineno">  609</span><span class="comment">//   cell_state_ptr   - size &#39;n_batch * n_cell&#39;</span></div>
<div class="line"><a id="l00610" name="l00610"></a><span class="lineno">  610</span><span class="comment">//   output_ptr       - size &#39;n_batch * n_output&#39;</span></div>
<div class="line"><a id="l00611" name="l00611"></a><span class="lineno">  611</span><span class="comment">// TODO(b/159947023): scratch0 is not used if (!cifg). Don&#39;t allocate then.</span></div>
<div class="line"><a id="l00612" name="l00612"></a><span class="lineno"><a class="line" href="namespaceluci__interpreter__pal_1_1lstm.html#aff32234d5392b0c7fdbccc7cad115c0e">  612</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#aff32234d5392b0c7fdbccc7cad115c0e">lstm_step_integer_8x8_16</a>(</div>
<div class="line"><a id="l00613" name="l00613"></a><span class="lineno">  613</span>  <span class="keyword">const</span> int8_t *input_ptr, <span class="keyword">const</span> int8_t *input_to_input_weight_ptr,</div>
<div class="line"><a id="l00614" name="l00614"></a><span class="lineno">  614</span>  int32_t effective_input_to_input_scale_a, int32_t effective_input_to_input_scale_b,</div>
<div class="line"><a id="l00615" name="l00615"></a><span class="lineno">  615</span>  <span class="keyword">const</span> int8_t *input_to_forget_weight_ptr, int32_t effective_input_to_forget_scale_a,</div>
<div class="line"><a id="l00616" name="l00616"></a><span class="lineno">  616</span>  int32_t effective_input_to_forget_scale_b, <span class="keyword">const</span> int8_t *input_to_cell_weight_ptr,</div>
<div class="line"><a id="l00617" name="l00617"></a><span class="lineno">  617</span>  int32_t effective_input_to_cell_scale_a, int32_t effective_input_to_cell_scale_b,</div>
<div class="line"><a id="l00618" name="l00618"></a><span class="lineno">  618</span>  <span class="keyword">const</span> int8_t *input_to_output_weight_ptr, int32_t effective_input_to_output_scale_a,</div>
<div class="line"><a id="l00619" name="l00619"></a><span class="lineno">  619</span>  int32_t effective_input_to_output_scale_b, <span class="keyword">const</span> int8_t *recurrent_to_input_weight_ptr,</div>
<div class="line"><a id="l00620" name="l00620"></a><span class="lineno">  620</span>  int32_t effective_recurrent_to_input_scale_a, int32_t effective_recurrent_to_input_scale_b,</div>
<div class="line"><a id="l00621" name="l00621"></a><span class="lineno">  621</span>  <span class="keyword">const</span> int8_t *recurrent_to_forget_weight_ptr, int32_t effective_recurrent_to_forget_scale_a,</div>
<div class="line"><a id="l00622" name="l00622"></a><span class="lineno">  622</span>  int32_t effective_recurrent_to_forget_scale_b, <span class="keyword">const</span> int8_t *recurrent_to_cell_weight_ptr,</div>
<div class="line"><a id="l00623" name="l00623"></a><span class="lineno">  623</span>  int32_t effective_recurrent_to_cell_scale_a, int32_t effective_recurrent_to_cell_scale_b,</div>
<div class="line"><a id="l00624" name="l00624"></a><span class="lineno">  624</span>  <span class="keyword">const</span> int8_t *recurrent_to_output_weight_ptr, int32_t effective_recurrent_to_output_scale_a,</div>
<div class="line"><a id="l00625" name="l00625"></a><span class="lineno">  625</span>  int32_t effective_recurrent_to_output_scale_b, <span class="keyword">const</span> int16_t *cell_to_input_weight_ptr,</div>
<div class="line"><a id="l00626" name="l00626"></a><span class="lineno">  626</span>  int32_t effective_cell_to_input_scale_a, int32_t effective_cell_to_input_scale_b,</div>
<div class="line"><a id="l00627" name="l00627"></a><span class="lineno">  627</span>  <span class="keyword">const</span> int16_t *cell_to_forget_weight_ptr, int32_t effective_cell_to_forget_scale_a,</div>
<div class="line"><a id="l00628" name="l00628"></a><span class="lineno">  628</span>  int32_t effective_cell_to_forget_scale_b, <span class="keyword">const</span> int16_t *cell_to_output_weight_ptr,</div>
<div class="line"><a id="l00629" name="l00629"></a><span class="lineno">  629</span>  int32_t effective_cell_to_output_scale_a, int32_t effective_cell_to_output_scale_b,</div>
<div class="line"><a id="l00630" name="l00630"></a><span class="lineno">  630</span>  <span class="keyword">const</span> int8_t *projection_weight_ptr, int32_t effective_proj_scale_a,</div>
<div class="line"><a id="l00631" name="l00631"></a><span class="lineno">  631</span>  int32_t effective_proj_scale_b, int32_t hidden_zp, int32_t effective_hidden_scale_a,</div>
<div class="line"><a id="l00632" name="l00632"></a><span class="lineno">  632</span>  int32_t effective_hidden_scale_b, <span class="keyword">const</span> int16_t *layer_norm_input_weight_ptr,</div>
<div class="line"><a id="l00633" name="l00633"></a><span class="lineno">  633</span>  int32_t layer_norm_input_scale_a, int32_t layer_norm_input_scale_b,</div>
<div class="line"><a id="l00634" name="l00634"></a><span class="lineno">  634</span>  <span class="keyword">const</span> int16_t *layer_norm_forget_weight_ptr, int32_t layer_norm_forget_scale_a,</div>
<div class="line"><a id="l00635" name="l00635"></a><span class="lineno">  635</span>  int32_t layer_norm_forget_scale_b, <span class="keyword">const</span> int16_t *layer_norm_cell_weight_ptr,</div>
<div class="line"><a id="l00636" name="l00636"></a><span class="lineno">  636</span>  int32_t layer_norm_cell_scale_a, int32_t layer_norm_cell_scale_b,</div>
<div class="line"><a id="l00637" name="l00637"></a><span class="lineno">  637</span>  <span class="keyword">const</span> int16_t *layer_norm_output_weight_ptr, int32_t layer_norm_output_scale_a,</div>
<div class="line"><a id="l00638" name="l00638"></a><span class="lineno">  638</span>  int32_t layer_norm_output_scale_b, <span class="keyword">const</span> int32_t *input_gate_bias_ptr,</div>
<div class="line"><a id="l00639" name="l00639"></a><span class="lineno">  639</span>  <span class="keyword">const</span> int32_t *forget_gate_bias_ptr, <span class="keyword">const</span> int32_t *cell_gate_bias_ptr,</div>
<div class="line"><a id="l00640" name="l00640"></a><span class="lineno">  640</span>  <span class="keyword">const</span> int32_t *output_gate_bias_ptr, int16_t quantized_cell_clip, int8_t quantized_proj_clip,</div>
<div class="line"><a id="l00641" name="l00641"></a><span class="lineno">  641</span>  int32_t cell_state_scale, int32_t input_variance_guard, int32_t forget_variance_guard,</div>
<div class="line"><a id="l00642" name="l00642"></a><span class="lineno">  642</span>  int32_t cell_variance_guard, int32_t output_variance_guard,</div>
<div class="line"><a id="l00643" name="l00643"></a><span class="lineno">  643</span>  <span class="keyword">const</span> int32_t *input_to_forget_effective_bias, <span class="keyword">const</span> int32_t *recurrent_to_forget_effective_bias,</div>
<div class="line"><a id="l00644" name="l00644"></a><span class="lineno">  644</span>  <span class="keyword">const</span> int32_t *input_to_cell_effective_bias, <span class="keyword">const</span> int32_t *recurrent_to_cell_effective_bias,</div>
<div class="line"><a id="l00645" name="l00645"></a><span class="lineno">  645</span>  <span class="keyword">const</span> int32_t *input_to_output_effective_bias, <span class="keyword">const</span> int32_t *recurrent_to_output_effective_bias,</div>
<div class="line"><a id="l00646" name="l00646"></a><span class="lineno">  646</span>  <span class="keyword">const</span> int32_t *input_to_input_effective_bias, <span class="keyword">const</span> int32_t *recurrent_to_input_effective_bias,</div>
<div class="line"><a id="l00647" name="l00647"></a><span class="lineno">  647</span>  <span class="keyword">const</span> int32_t *projection_effective_bias, <span class="keywordtype">int</span> n_batch, <span class="keywordtype">int</span> n_cell, <span class="keywordtype">int</span> n_input, <span class="keywordtype">int</span> n_output,</div>
<div class="line"><a id="l00648" name="l00648"></a><span class="lineno">  648</span>  int8_t *output_state_ptr, int32_t output_state_zp, int16_t *cell_state_ptr, int8_t *output_ptr,</div>
<div class="line"><a id="l00649" name="l00649"></a><span class="lineno">  649</span>  int16_t *scratch0, int16_t *scratch1, int16_t *scratch2, int16_t *scratch3, int8_t *scratch4,</div>
<div class="line"><a id="l00650" name="l00650"></a><span class="lineno">  650</span>  int32_t *scratch5)</div>
<div class="line"><a id="l00651" name="l00651"></a><span class="lineno">  651</span>{</div>
<div class="line"><a id="l00652" name="l00652"></a><span class="lineno">  652</span>  <span class="comment">// Make named scratch buffers for the different gates.</span></div>
<div class="line"><a id="l00653" name="l00653"></a><span class="lineno">  653</span>  int16_t *input_gate_scratch = scratch0;</div>
<div class="line"><a id="l00654" name="l00654"></a><span class="lineno">  654</span>  int16_t *forget_gate_scratch = scratch1;</div>
<div class="line"><a id="l00655" name="l00655"></a><span class="lineno">  655</span>  int16_t *cell_gate_scratch = scratch2;</div>
<div class="line"><a id="l00656" name="l00656"></a><span class="lineno">  656</span>  int16_t *output_gate_scratch = scratch3;</div>
<div class="line"><a id="l00657" name="l00657"></a><span class="lineno">  657</span> </div>
<div class="line"><a id="l00658" name="l00658"></a><span class="lineno">  658</span>  <span class="comment">// Since we have already checked that weights are all there or none, we</span></div>
<div class="line"><a id="l00659" name="l00659"></a><span class="lineno">  659</span>  <span class="comment">// can check the existence of only one to the get the condition.</span></div>
<div class="line"><a id="l00660" name="l00660"></a><span class="lineno">  660</span>  <span class="keyword">const</span> <span class="keywordtype">bool</span> use_cifg = (input_to_input_weight_ptr == <span class="keyword">nullptr</span>);</div>
<div class="line"><a id="l00661" name="l00661"></a><span class="lineno">  661</span> </div>
<div class="line"><a id="l00662" name="l00662"></a><span class="lineno">  662</span>  <a class="code hl_define" href="compiler_2luci-interpreter_2src_2kernels_2_utils_8h.html#a231f5fa1ff2a3f19222b42cc9bbd1f2d">LUCI_INTERPRETER_CHECK</a>(input_to_forget_effective_bias);</div>
<div class="line"><a id="l00663" name="l00663"></a><span class="lineno">  663</span>  <a class="code hl_define" href="compiler_2luci-interpreter_2src_2kernels_2_utils_8h.html#a231f5fa1ff2a3f19222b42cc9bbd1f2d">LUCI_INTERPRETER_CHECK</a>(recurrent_to_forget_effective_bias);</div>
<div class="line"><a id="l00664" name="l00664"></a><span class="lineno">  664</span>  <a class="code hl_define" href="compiler_2luci-interpreter_2src_2kernels_2_utils_8h.html#a231f5fa1ff2a3f19222b42cc9bbd1f2d">LUCI_INTERPRETER_CHECK</a>(input_to_cell_effective_bias);</div>
<div class="line"><a id="l00665" name="l00665"></a><span class="lineno">  665</span>  <a class="code hl_define" href="compiler_2luci-interpreter_2src_2kernels_2_utils_8h.html#a231f5fa1ff2a3f19222b42cc9bbd1f2d">LUCI_INTERPRETER_CHECK</a>(recurrent_to_cell_effective_bias);</div>
<div class="line"><a id="l00666" name="l00666"></a><span class="lineno">  666</span>  <a class="code hl_define" href="compiler_2luci-interpreter_2src_2kernels_2_utils_8h.html#a231f5fa1ff2a3f19222b42cc9bbd1f2d">LUCI_INTERPRETER_CHECK</a>(input_to_output_effective_bias);</div>
<div class="line"><a id="l00667" name="l00667"></a><span class="lineno">  667</span>  <a class="code hl_define" href="compiler_2luci-interpreter_2src_2kernels_2_utils_8h.html#a231f5fa1ff2a3f19222b42cc9bbd1f2d">LUCI_INTERPRETER_CHECK</a>(recurrent_to_output_effective_bias);</div>
<div class="line"><a id="l00668" name="l00668"></a><span class="lineno">  668</span> </div>
<div class="line"><a id="l00669" name="l00669"></a><span class="lineno">  669</span>  <span class="keywordflow">if</span> (!use_cifg)</div>
<div class="line"><a id="l00670" name="l00670"></a><span class="lineno">  670</span>  {</div>
<div class="line"><a id="l00671" name="l00671"></a><span class="lineno">  671</span>    <a class="code hl_define" href="compiler_2luci-interpreter_2src_2kernels_2_utils_8h.html#a231f5fa1ff2a3f19222b42cc9bbd1f2d">LUCI_INTERPRETER_CHECK</a>(input_to_input_effective_bias);</div>
<div class="line"><a id="l00672" name="l00672"></a><span class="lineno">  672</span>    <a class="code hl_define" href="compiler_2luci-interpreter_2src_2kernels_2_utils_8h.html#a231f5fa1ff2a3f19222b42cc9bbd1f2d">LUCI_INTERPRETER_CHECK</a>(recurrent_to_input_effective_bias);</div>
<div class="line"><a id="l00673" name="l00673"></a><span class="lineno">  673</span>  }</div>
<div class="line"><a id="l00674" name="l00674"></a><span class="lineno">  674</span> </div>
<div class="line"><a id="l00675" name="l00675"></a><span class="lineno">  675</span>  <span class="keyword">const</span> <span class="keywordtype">bool</span> use_projection = (projection_weight_ptr != <span class="keyword">nullptr</span>);</div>
<div class="line"><a id="l00676" name="l00676"></a><span class="lineno">  676</span>  <span class="keywordflow">if</span> (use_projection)</div>
<div class="line"><a id="l00677" name="l00677"></a><span class="lineno">  677</span>  {</div>
<div class="line"><a id="l00678" name="l00678"></a><span class="lineno">  678</span>    <a class="code hl_define" href="compiler_2luci-interpreter_2src_2kernels_2_utils_8h.html#a231f5fa1ff2a3f19222b42cc9bbd1f2d">LUCI_INTERPRETER_CHECK</a>(projection_effective_bias);</div>
<div class="line"><a id="l00679" name="l00679"></a><span class="lineno">  679</span>  }</div>
<div class="line"><a id="l00680" name="l00680"></a><span class="lineno">  680</span> </div>
<div class="line"><a id="l00681" name="l00681"></a><span class="lineno">  681</span>  <span class="keywordflow">if</span> (!use_cifg)</div>
<div class="line"><a id="l00682" name="l00682"></a><span class="lineno">  682</span>  {</div>
<div class="line"><a id="l00683" name="l00683"></a><span class="lineno">  683</span>    <span class="comment">// Calculate the input gate. (If not CIFG.)</span></div>
<div class="line"><a id="l00684" name="l00684"></a><span class="lineno">  684</span>    <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#adaa95dd338f0bbd9be680fd7dfc6d1aa">calculate_lstm_gate_integer_8x8_16</a>(</div>
<div class="line"><a id="l00685" name="l00685"></a><span class="lineno">  685</span>      input_ptr, input_to_input_weight_ptr, input_to_input_effective_bias,</div>
<div class="line"><a id="l00686" name="l00686"></a><span class="lineno">  686</span>      effective_input_to_input_scale_a, effective_input_to_input_scale_b, output_state_ptr,</div>
<div class="line"><a id="l00687" name="l00687"></a><span class="lineno">  687</span>      recurrent_to_input_weight_ptr, recurrent_to_input_effective_bias,</div>
<div class="line"><a id="l00688" name="l00688"></a><span class="lineno">  688</span>      effective_recurrent_to_input_scale_a, effective_recurrent_to_input_scale_b, cell_state_ptr,</div>
<div class="line"><a id="l00689" name="l00689"></a><span class="lineno">  689</span>      cell_to_input_weight_ptr, effective_cell_to_input_scale_a, effective_cell_to_input_scale_b,</div>
<div class="line"><a id="l00690" name="l00690"></a><span class="lineno">  690</span>      layer_norm_input_weight_ptr, input_gate_bias_ptr, layer_norm_input_scale_a,</div>
<div class="line"><a id="l00691" name="l00691"></a><span class="lineno">  691</span>      layer_norm_input_scale_b, input_variance_guard, n_batch, n_input, n_output, n_cell,</div>
<div class="line"><a id="l00692" name="l00692"></a><span class="lineno">  692</span>      <a class="code hl_enumvalue" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63ab211c831f880a63ebc80994bb0cf2dc2">kTfLiteActSigmoid</a>, input_gate_scratch, scratch5);</div>
<div class="line"><a id="l00693" name="l00693"></a><span class="lineno">  693</span>  }</div>
<div class="line"><a id="l00694" name="l00694"></a><span class="lineno">  694</span> </div>
<div class="line"><a id="l00695" name="l00695"></a><span class="lineno">  695</span>  <span class="comment">// Calculate the forget gate.</span></div>
<div class="line"><a id="l00696" name="l00696"></a><span class="lineno">  696</span>  <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#adaa95dd338f0bbd9be680fd7dfc6d1aa">calculate_lstm_gate_integer_8x8_16</a>(</div>
<div class="line"><a id="l00697" name="l00697"></a><span class="lineno">  697</span>    input_ptr, input_to_forget_weight_ptr, input_to_forget_effective_bias,</div>
<div class="line"><a id="l00698" name="l00698"></a><span class="lineno">  698</span>    effective_input_to_forget_scale_a, effective_input_to_forget_scale_b, output_state_ptr,</div>
<div class="line"><a id="l00699" name="l00699"></a><span class="lineno">  699</span>    recurrent_to_forget_weight_ptr, recurrent_to_forget_effective_bias,</div>
<div class="line"><a id="l00700" name="l00700"></a><span class="lineno">  700</span>    effective_recurrent_to_forget_scale_a, effective_recurrent_to_forget_scale_b, cell_state_ptr,</div>
<div class="line"><a id="l00701" name="l00701"></a><span class="lineno">  701</span>    cell_to_forget_weight_ptr, effective_cell_to_forget_scale_a, effective_cell_to_forget_scale_b,</div>
<div class="line"><a id="l00702" name="l00702"></a><span class="lineno">  702</span>    layer_norm_forget_weight_ptr, forget_gate_bias_ptr, layer_norm_forget_scale_a,</div>
<div class="line"><a id="l00703" name="l00703"></a><span class="lineno">  703</span>    layer_norm_forget_scale_b, forget_variance_guard, n_batch, n_input, n_output, n_cell,</div>
<div class="line"><a id="l00704" name="l00704"></a><span class="lineno">  704</span>    <a class="code hl_enumvalue" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63ab211c831f880a63ebc80994bb0cf2dc2">kTfLiteActSigmoid</a>, forget_gate_scratch, scratch5);</div>
<div class="line"><a id="l00705" name="l00705"></a><span class="lineno">  705</span> </div>
<div class="line"><a id="l00706" name="l00706"></a><span class="lineno">  706</span>  <span class="comment">// Calculate the cell update gate.</span></div>
<div class="line"><a id="l00707" name="l00707"></a><span class="lineno">  707</span>  <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#adaa95dd338f0bbd9be680fd7dfc6d1aa">calculate_lstm_gate_integer_8x8_16</a>(</div>
<div class="line"><a id="l00708" name="l00708"></a><span class="lineno">  708</span>    input_ptr, input_to_cell_weight_ptr, input_to_cell_effective_bias,</div>
<div class="line"><a id="l00709" name="l00709"></a><span class="lineno">  709</span>    effective_input_to_cell_scale_a, effective_input_to_cell_scale_b, output_state_ptr,</div>
<div class="line"><a id="l00710" name="l00710"></a><span class="lineno">  710</span>    recurrent_to_cell_weight_ptr, recurrent_to_cell_effective_bias,</div>
<div class="line"><a id="l00711" name="l00711"></a><span class="lineno">  711</span>    effective_recurrent_to_cell_scale_a, effective_recurrent_to_cell_scale_b, cell_state_ptr,</div>
<div class="line"><a id="l00712" name="l00712"></a><span class="lineno">  712</span>    <span class="comment">/*cell_to_gate_weights=*/</span><span class="keyword">nullptr</span>, <span class="comment">/*cell_to_gate_scale_a=*/</span>0,</div>
<div class="line"><a id="l00713" name="l00713"></a><span class="lineno">  713</span>    <span class="comment">/*cell_to_gate_scale_b=*/</span>0, layer_norm_cell_weight_ptr, cell_gate_bias_ptr,</div>
<div class="line"><a id="l00714" name="l00714"></a><span class="lineno">  714</span>    layer_norm_cell_scale_a, layer_norm_cell_scale_b, cell_variance_guard, n_batch, n_input,</div>
<div class="line"><a id="l00715" name="l00715"></a><span class="lineno">  715</span>    n_output, n_cell, <a class="code hl_enumvalue" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63a60bdd9a337a5f1f2866fd65c7d8ffdce">kTfLiteActTanh</a>, cell_gate_scratch, scratch5);</div>
<div class="line"><a id="l00716" name="l00716"></a><span class="lineno">  716</span> </div>
<div class="line"><a id="l00717" name="l00717"></a><span class="lineno">  717</span>  <span class="comment">// Update the cell state.</span></div>
<div class="line"><a id="l00718" name="l00718"></a><span class="lineno">  718</span>  <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#ab554f067a0e70af0121424c774ad3880">update_lstm_cell_integer</a>(n_batch, n_cell, cell_state_ptr, cell_state_scale, input_gate_scratch,</div>
<div class="line"><a id="l00719" name="l00719"></a><span class="lineno">  719</span>                           forget_gate_scratch, cell_gate_scratch, use_cifg, quantized_cell_clip);</div>
<div class="line"><a id="l00720" name="l00720"></a><span class="lineno">  720</span> </div>
<div class="line"><a id="l00721" name="l00721"></a><span class="lineno">  721</span>  <span class="comment">// Calculate the output gate.</span></div>
<div class="line"><a id="l00722" name="l00722"></a><span class="lineno">  722</span>  <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#adaa95dd338f0bbd9be680fd7dfc6d1aa">calculate_lstm_gate_integer_8x8_16</a>(</div>
<div class="line"><a id="l00723" name="l00723"></a><span class="lineno">  723</span>    input_ptr, input_to_output_weight_ptr, input_to_output_effective_bias,</div>
<div class="line"><a id="l00724" name="l00724"></a><span class="lineno">  724</span>    effective_input_to_output_scale_a, effective_input_to_output_scale_b, output_state_ptr,</div>
<div class="line"><a id="l00725" name="l00725"></a><span class="lineno">  725</span>    recurrent_to_output_weight_ptr, recurrent_to_output_effective_bias,</div>
<div class="line"><a id="l00726" name="l00726"></a><span class="lineno">  726</span>    effective_recurrent_to_output_scale_a, effective_recurrent_to_output_scale_b, cell_state_ptr,</div>
<div class="line"><a id="l00727" name="l00727"></a><span class="lineno">  727</span>    cell_to_output_weight_ptr, effective_cell_to_output_scale_a, effective_cell_to_output_scale_b,</div>
<div class="line"><a id="l00728" name="l00728"></a><span class="lineno">  728</span>    layer_norm_output_weight_ptr, output_gate_bias_ptr, layer_norm_output_scale_a,</div>
<div class="line"><a id="l00729" name="l00729"></a><span class="lineno">  729</span>    layer_norm_output_scale_b, output_variance_guard, n_batch, n_input, n_output, n_cell,</div>
<div class="line"><a id="l00730" name="l00730"></a><span class="lineno">  730</span>    <a class="code hl_enumvalue" href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63ab211c831f880a63ebc80994bb0cf2dc2">kTfLiteActSigmoid</a>, output_gate_scratch, scratch5);</div>
<div class="line"><a id="l00731" name="l00731"></a><span class="lineno">  731</span> </div>
<div class="line"><a id="l00732" name="l00732"></a><span class="lineno">  732</span>  <span class="comment">// Update the output state.</span></div>
<div class="line"><a id="l00733" name="l00733"></a><span class="lineno">  733</span>  <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#ad07afcc83af092c475787d8184538098">calculate_lstm_output_integer8x8_16</a>(</div>
<div class="line"><a id="l00734" name="l00734"></a><span class="lineno">  734</span>    n_batch, n_cell, n_output, cell_state_ptr, cell_state_scale, output_gate_scratch,</div>
<div class="line"><a id="l00735" name="l00735"></a><span class="lineno">  735</span>    effective_hidden_scale_a, effective_hidden_scale_b, hidden_zp, projection_weight_ptr,</div>
<div class="line"><a id="l00736" name="l00736"></a><span class="lineno">  736</span>    effective_proj_scale_a, effective_proj_scale_b, projection_effective_bias, output_state_zp,</div>
<div class="line"><a id="l00737" name="l00737"></a><span class="lineno">  737</span>    quantized_proj_clip, output_state_ptr, scratch0, scratch4, scratch5);</div>
<div class="line"><a id="l00738" name="l00738"></a><span class="lineno">  738</span>  <span class="comment">// Copy output state to the output. Note that unlike float or hybrid, output</span></div>
<div class="line"><a id="l00739" name="l00739"></a><span class="lineno">  739</span>  <span class="comment">// is always contiguous.</span></div>
<div class="line"><a id="l00740" name="l00740"></a><span class="lineno">  740</span>  std::copy_n(output_state_ptr, n_batch * n_output, output_ptr);</div>
<div class="line"><a id="l00741" name="l00741"></a><span class="lineno">  741</span>}</div>
<div class="line"><a id="l00742" name="l00742"></a><span class="lineno">  742</span> </div>
<div class="line"><a id="l00743" name="l00743"></a><span class="lineno">  743</span>} <span class="comment">// namespace lstm</span></div>
<div class="line"><a id="l00744" name="l00744"></a><span class="lineno">  744</span> </div>
<div class="line"><a id="l00745" name="l00745"></a><span class="lineno">  745</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespaceluci__interpreter__pal.html#a6a0b2d1d970f94be53e13b87b4bffa13">eval_integer_8x8_16_lstm</a>(</div>
<div class="line"><a id="l00746" name="l00746"></a><span class="lineno">  746</span>  <span class="keyword">const</span> <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *input, <span class="keyword">const</span> <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *input_to_input_weights,</div>
<div class="line"><a id="l00747" name="l00747"></a><span class="lineno">  747</span>  <span class="keyword">const</span> <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *input_to_forget_weights,</div>
<div class="line"><a id="l00748" name="l00748"></a><span class="lineno">  748</span>  <span class="keyword">const</span> <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *input_to_cell_weights,</div>
<div class="line"><a id="l00749" name="l00749"></a><span class="lineno">  749</span>  <span class="keyword">const</span> <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *input_to_output_weights,</div>
<div class="line"><a id="l00750" name="l00750"></a><span class="lineno">  750</span>  <span class="keyword">const</span> <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *recurrent_to_input_weights,</div>
<div class="line"><a id="l00751" name="l00751"></a><span class="lineno">  751</span>  <span class="keyword">const</span> <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *recurrent_to_forget_weights,</div>
<div class="line"><a id="l00752" name="l00752"></a><span class="lineno">  752</span>  <span class="keyword">const</span> <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *recurrent_to_cell_weights,</div>
<div class="line"><a id="l00753" name="l00753"></a><span class="lineno">  753</span>  <span class="keyword">const</span> <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *recurrent_to_output_weights,</div>
<div class="line"><a id="l00754" name="l00754"></a><span class="lineno">  754</span>  <span class="keyword">const</span> <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *cell_to_input_weights,</div>
<div class="line"><a id="l00755" name="l00755"></a><span class="lineno">  755</span>  <span class="keyword">const</span> <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *cell_to_forget_weights,</div>
<div class="line"><a id="l00756" name="l00756"></a><span class="lineno">  756</span>  <span class="keyword">const</span> <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *cell_to_output_weights,</div>
<div class="line"><a id="l00757" name="l00757"></a><span class="lineno">  757</span>  <span class="keyword">const</span> <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *input_layer_norm_coefficients,</div>
<div class="line"><a id="l00758" name="l00758"></a><span class="lineno">  758</span>  <span class="keyword">const</span> <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *forget_layer_norm_coefficients,</div>
<div class="line"><a id="l00759" name="l00759"></a><span class="lineno">  759</span>  <span class="keyword">const</span> <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *cell_layer_norm_coefficients,</div>
<div class="line"><a id="l00760" name="l00760"></a><span class="lineno">  760</span>  <span class="keyword">const</span> <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *output_layer_norm_coefficients,</div>
<div class="line"><a id="l00761" name="l00761"></a><span class="lineno">  761</span>  <span class="keyword">const</span> <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *input_gate_bias, <span class="keyword">const</span> <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *forget_gate_bias,</div>
<div class="line"><a id="l00762" name="l00762"></a><span class="lineno">  762</span>  <span class="keyword">const</span> <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *cell_gate_bias, <span class="keyword">const</span> <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *output_gate_bias,</div>
<div class="line"><a id="l00763" name="l00763"></a><span class="lineno">  763</span>  <span class="keyword">const</span> <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *projection_weights,</div>
<div class="line"><a id="l00764" name="l00764"></a><span class="lineno">  764</span>  <span class="keyword">const</span> <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *projection_bias,</div>
<div class="line"><a id="l00765" name="l00765"></a><span class="lineno">  765</span>  <span class="keyword">const</span> <a class="code hl_struct" href="structluci__interpreter_1_1_unidirectional_sequence_l_s_t_m_params.html">luci_interpreter::UnidirectionalSequenceLSTMParams</a> &amp;params, <span class="keywordtype">bool</span> forward_sequence,</div>
<div class="line"><a id="l00766" name="l00766"></a><span class="lineno">  766</span>  <span class="keywordtype">bool</span> time_major, <span class="keyword">const</span> <a class="code hl_struct" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html">luci_interpreter::IntegerLSTMParams</a> &amp;integer_lstm_param,</div>
<div class="line"><a id="l00767" name="l00767"></a><span class="lineno">  767</span>  int32_t output_state_zp, <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *output_state,</div>
<div class="line"><a id="l00768" name="l00768"></a><span class="lineno">  768</span>  <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *cell_state, <a class="code hl_class" href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a> *output, int16_t *scratch0,</div>
<div class="line"><a id="l00769" name="l00769"></a><span class="lineno">  769</span>  int16_t *scratch1, int16_t *scratch2, int16_t *scratch3, int8_t *scratch4, int32_t *scratch5)</div>
<div class="line"><a id="l00770" name="l00770"></a><span class="lineno">  770</span>{</div>
<div class="line"><a id="l00771" name="l00771"></a><span class="lineno">  771</span>  <span class="keyword">const</span> <span class="keyword">auto</span> input_shape = input-&gt;shape();</div>
<div class="line"><a id="l00772" name="l00772"></a><span class="lineno">  772</span>  <a class="code hl_define" href="compiler_2luci-interpreter_2src_2kernels_2_utils_8h.html#a231f5fa1ff2a3f19222b42cc9bbd1f2d">LUCI_INTERPRETER_CHECK</a>(input_shape.num_dims() &gt;= 2 &amp;&amp; input_shape.num_dims() &lt;= 3);</div>
<div class="line"><a id="l00773" name="l00773"></a><span class="lineno">  773</span> </div>
<div class="line"><a id="l00774" name="l00774"></a><span class="lineno">  774</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> n_input = input_shape.dim(input_shape.num_dims() - 1);</div>
<div class="line"><a id="l00775" name="l00775"></a><span class="lineno">  775</span>  <span class="keywordtype">int</span> max_time, n_batch;</div>
<div class="line"><a id="l00776" name="l00776"></a><span class="lineno">  776</span>  <span class="keywordflow">if</span> (input_shape.num_dims() == 2)</div>
<div class="line"><a id="l00777" name="l00777"></a><span class="lineno">  777</span>  {</div>
<div class="line"><a id="l00778" name="l00778"></a><span class="lineno">  778</span>    max_time = 1;</div>
<div class="line"><a id="l00779" name="l00779"></a><span class="lineno">  779</span>    n_batch = input_shape.dim(0);</div>
<div class="line"><a id="l00780" name="l00780"></a><span class="lineno">  780</span>  }</div>
<div class="line"><a id="l00781" name="l00781"></a><span class="lineno">  781</span>  <span class="keywordflow">else</span></div>
<div class="line"><a id="l00782" name="l00782"></a><span class="lineno">  782</span>  {</div>
<div class="line"><a id="l00783" name="l00783"></a><span class="lineno">  783</span>    max_time = (time_major) ? input_shape.dim(0) : input_shape.dim(1);</div>
<div class="line"><a id="l00784" name="l00784"></a><span class="lineno">  784</span>    n_batch = (time_major) ? input_shape.dim(1) : input_shape.dim(0);</div>
<div class="line"><a id="l00785" name="l00785"></a><span class="lineno">  785</span>  }</div>
<div class="line"><a id="l00786" name="l00786"></a><span class="lineno">  786</span> </div>
<div class="line"><a id="l00787" name="l00787"></a><span class="lineno">  787</span>  <span class="comment">// n_cell and n_output will be the same size when there is no projection.</span></div>
<div class="line"><a id="l00788" name="l00788"></a><span class="lineno">  788</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> n_cell = input_to_output_weights-&gt;<a class="code hl_function" href="classluci__interpreter_1_1_tensor.html#a5ea62328ce6d801a3aef30b903b95d69">shape</a>().<a class="code hl_function" href="classluci__interpreter_1_1_shape.html#a83aee8788dd50f2ea66c48697c7c0a34">dim</a>(0);</div>
<div class="line"><a id="l00789" name="l00789"></a><span class="lineno">  789</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> n_output = recurrent_to_output_weights-&gt;<a class="code hl_function" href="classluci__interpreter_1_1_tensor.html#a5ea62328ce6d801a3aef30b903b95d69">shape</a>().<a class="code hl_function" href="classluci__interpreter_1_1_shape.html#a83aee8788dd50f2ea66c48697c7c0a34">dim</a>(1);</div>
<div class="line"><a id="l00790" name="l00790"></a><span class="lineno">  790</span> </div>
<div class="line"><a id="l00791" name="l00791"></a><span class="lineno">  791</span>  <span class="comment">// Get params for time/batch/sequence.</span></div>
<div class="line"><a id="l00792" name="l00792"></a><span class="lineno">  792</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> output_batch_leading_dim = <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">output</a>-&gt;shape().dim(<a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">output</a>-&gt;shape().num_dims() - 1);</div>
<div class="line"><a id="l00793" name="l00793"></a><span class="lineno">  793</span> </div>
<div class="line"><a id="l00794" name="l00794"></a><span class="lineno">  794</span>  <span class="keywordflow">if</span> (time_major)</div>
<div class="line"><a id="l00795" name="l00795"></a><span class="lineno">  795</span>  {</div>
<div class="line"><a id="l00796" name="l00796"></a><span class="lineno">  796</span>    <span class="keyword">const</span> <span class="keywordtype">int</span> input_step = n_batch * n_input;</div>
<div class="line"><a id="l00797" name="l00797"></a><span class="lineno">  797</span>    <span class="keyword">const</span> <span class="keywordtype">int</span> output_step = n_batch * output_batch_leading_dim;</div>
<div class="line"><a id="l00798" name="l00798"></a><span class="lineno">  798</span> </div>
<div class="line"><a id="l00799" name="l00799"></a><span class="lineno">  799</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> t = 0; t &lt; max_time; t++)</div>
<div class="line"><a id="l00800" name="l00800"></a><span class="lineno">  800</span>    {</div>
<div class="line"><a id="l00801" name="l00801"></a><span class="lineno">  801</span>      <span class="keyword">const</span> <span class="keywordtype">int</span> t_rel = t;</div>
<div class="line"><a id="l00802" name="l00802"></a><span class="lineno">  802</span>      int8_t *output_ptr =</div>
<div class="line"><a id="l00803" name="l00803"></a><span class="lineno">  803</span>        luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(output) + t_rel * output_step;</div>
<div class="line"><a id="l00804" name="l00804"></a><span class="lineno">  804</span>      <span class="keyword">const</span> int8_t *input_ptr =</div>
<div class="line"><a id="l00805" name="l00805"></a><span class="lineno">  805</span>        luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(input) + t_rel * input_step;</div>
<div class="line"><a id="l00806" name="l00806"></a><span class="lineno">  806</span> </div>
<div class="line"><a id="l00807" name="l00807"></a><span class="lineno">  807</span>      <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#aff32234d5392b0c7fdbccc7cad115c0e">lstm::lstm_step_integer_8x8_16</a>(</div>
<div class="line"><a id="l00808" name="l00808"></a><span class="lineno">  808</span>        input_ptr,</div>
<div class="line"><a id="l00809" name="l00809"></a><span class="lineno">  809</span>        input_to_input_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00810" name="l00810"></a><span class="lineno">  810</span>          ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00811" name="l00811"></a><span class="lineno">  811</span>          : luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(input_to_input_weights),</div>
<div class="line"><a id="l00812" name="l00812"></a><span class="lineno">  812</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a1815b45d4e9979eaf81cb89f299c8f79">effective_input_to_input_scale_a</a>,</div>
<div class="line"><a id="l00813" name="l00813"></a><span class="lineno">  813</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#aab48dc57abe245d257c35cc1c6ad7354">effective_input_to_input_scale_b</a>,</div>
<div class="line"><a id="l00814" name="l00814"></a><span class="lineno">  814</span>        input_to_forget_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00815" name="l00815"></a><span class="lineno">  815</span>          ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00816" name="l00816"></a><span class="lineno">  816</span>          : luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(input_to_forget_weights),</div>
<div class="line"><a id="l00817" name="l00817"></a><span class="lineno">  817</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#aad3a135d4309854e3ca3ffcf375aa07a">effective_input_to_forget_scale_a</a>,</div>
<div class="line"><a id="l00818" name="l00818"></a><span class="lineno">  818</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#adc38a56e44f8a3e6550bc80bfaca363e">effective_input_to_forget_scale_b</a>,</div>
<div class="line"><a id="l00819" name="l00819"></a><span class="lineno">  819</span>        input_to_cell_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00820" name="l00820"></a><span class="lineno">  820</span>          ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00821" name="l00821"></a><span class="lineno">  821</span>          : luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(input_to_cell_weights),</div>
<div class="line"><a id="l00822" name="l00822"></a><span class="lineno">  822</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a17aa2b0f550808acc80edf483d9aefc0">effective_input_to_cell_scale_a</a>,</div>
<div class="line"><a id="l00823" name="l00823"></a><span class="lineno">  823</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a88ce1ec27fc97e74415f066b281bcb71">effective_input_to_cell_scale_b</a>,</div>
<div class="line"><a id="l00824" name="l00824"></a><span class="lineno">  824</span>        input_to_output_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00825" name="l00825"></a><span class="lineno">  825</span>          ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00826" name="l00826"></a><span class="lineno">  826</span>          : luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(input_to_output_weights),</div>
<div class="line"><a id="l00827" name="l00827"></a><span class="lineno">  827</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a436a706c17cf37479593607220ff0aab">effective_input_to_output_scale_a</a>,</div>
<div class="line"><a id="l00828" name="l00828"></a><span class="lineno">  828</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a8f050cf3537363681b3aff86395f7813">effective_input_to_output_scale_b</a>,</div>
<div class="line"><a id="l00829" name="l00829"></a><span class="lineno">  829</span>        recurrent_to_input_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00830" name="l00830"></a><span class="lineno">  830</span>          ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00831" name="l00831"></a><span class="lineno">  831</span>          : luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(recurrent_to_input_weights),</div>
<div class="line"><a id="l00832" name="l00832"></a><span class="lineno">  832</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a38de4e598127e2fb764fce6a21c2fc9e">effective_recurrent_to_input_scale_a</a>,</div>
<div class="line"><a id="l00833" name="l00833"></a><span class="lineno">  833</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a9686553df691e2b1b8c716615f13753e">effective_recurrent_to_input_scale_b</a>,</div>
<div class="line"><a id="l00834" name="l00834"></a><span class="lineno">  834</span>        recurrent_to_forget_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00835" name="l00835"></a><span class="lineno">  835</span>          ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00836" name="l00836"></a><span class="lineno">  836</span>          : luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(recurrent_to_forget_weights),</div>
<div class="line"><a id="l00837" name="l00837"></a><span class="lineno">  837</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a786a7d187a322aab6e8d07bfb157c834">effective_recurrent_to_forget_scale_a</a>,</div>
<div class="line"><a id="l00838" name="l00838"></a><span class="lineno">  838</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a0f2e283966be688baf8353cb83d6cabe">effective_recurrent_to_forget_scale_b</a>,</div>
<div class="line"><a id="l00839" name="l00839"></a><span class="lineno">  839</span>        recurrent_to_cell_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00840" name="l00840"></a><span class="lineno">  840</span>          ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00841" name="l00841"></a><span class="lineno">  841</span>          : luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(recurrent_to_cell_weights),</div>
<div class="line"><a id="l00842" name="l00842"></a><span class="lineno">  842</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#ae8b58fbab6226ddb2b3d5b972ca47a3d">effective_recurrent_to_cell_scale_a</a>,</div>
<div class="line"><a id="l00843" name="l00843"></a><span class="lineno">  843</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a7429f0edf41d6c2ffce4987830d31235">effective_recurrent_to_cell_scale_b</a>,</div>
<div class="line"><a id="l00844" name="l00844"></a><span class="lineno">  844</span>        recurrent_to_output_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00845" name="l00845"></a><span class="lineno">  845</span>          ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00846" name="l00846"></a><span class="lineno">  846</span>          : luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(recurrent_to_output_weights),</div>
<div class="line"><a id="l00847" name="l00847"></a><span class="lineno">  847</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a1ef00ac5637652bc42302b668595c14f">effective_recurrent_to_output_scale_a</a>,</div>
<div class="line"><a id="l00848" name="l00848"></a><span class="lineno">  848</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a397af438d6a1e7051cd78da4dbb743ba">effective_recurrent_to_output_scale_b</a>,</div>
<div class="line"><a id="l00849" name="l00849"></a><span class="lineno">  849</span>        cell_to_input_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00850" name="l00850"></a><span class="lineno">  850</span>          ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00851" name="l00851"></a><span class="lineno">  851</span>          : luci_interpreter::kernels::getTensorData&lt;int16_t&gt;(cell_to_input_weights),</div>
<div class="line"><a id="l00852" name="l00852"></a><span class="lineno">  852</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#abe40c57692043111c35301789a9218e6">effective_cell_to_input_scale_a</a>,</div>
<div class="line"><a id="l00853" name="l00853"></a><span class="lineno">  853</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#aacc97958d62163e8f69f44703bd2b411">effective_cell_to_input_scale_b</a>,</div>
<div class="line"><a id="l00854" name="l00854"></a><span class="lineno">  854</span>        cell_to_forget_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00855" name="l00855"></a><span class="lineno">  855</span>          ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00856" name="l00856"></a><span class="lineno">  856</span>          : luci_interpreter::kernels::getTensorData&lt;int16_t&gt;(cell_to_forget_weights),</div>
<div class="line"><a id="l00857" name="l00857"></a><span class="lineno">  857</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a6e524defb86176d1c87074f90d30b6fc">effective_cell_to_forget_scale_a</a>,</div>
<div class="line"><a id="l00858" name="l00858"></a><span class="lineno">  858</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#aab68f6adb9ab9fbdcb02b1561939f623">effective_cell_to_forget_scale_b</a>,</div>
<div class="line"><a id="l00859" name="l00859"></a><span class="lineno">  859</span>        cell_to_output_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00860" name="l00860"></a><span class="lineno">  860</span>          ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00861" name="l00861"></a><span class="lineno">  861</span>          : luci_interpreter::kernels::getTensorData&lt;int16_t&gt;(cell_to_output_weights),</div>
<div class="line"><a id="l00862" name="l00862"></a><span class="lineno">  862</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#affdebdc0521280db0be1bec0434c04e4">effective_cell_to_output_scale_a</a>,</div>
<div class="line"><a id="l00863" name="l00863"></a><span class="lineno">  863</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a760916e38abee7495fa35d198ba96008">effective_cell_to_output_scale_b</a>,</div>
<div class="line"><a id="l00864" name="l00864"></a><span class="lineno">  864</span>        projection_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00865" name="l00865"></a><span class="lineno">  865</span>          ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00866" name="l00866"></a><span class="lineno">  866</span>          : luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(projection_weights),</div>
<div class="line"><a id="l00867" name="l00867"></a><span class="lineno">  867</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a27867e3ab1cbefb506f3d384587b5a32">effective_proj_scale_a</a>, integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a78b06d907d35a460555947d9ce6b6192">effective_proj_scale_b</a>,</div>
<div class="line"><a id="l00868" name="l00868"></a><span class="lineno">  868</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a9179415a87f49b1efd429c501c20432c">hidden_zp</a>, integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#abb27a971ebf03b639b8c9206fdaa392f">effective_hidden_scale_a</a>,</div>
<div class="line"><a id="l00869" name="l00869"></a><span class="lineno">  869</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a3fed6619c9e6f648f17f00aa5af6aacd">effective_hidden_scale_b</a>,</div>
<div class="line"><a id="l00870" name="l00870"></a><span class="lineno">  870</span>        input_layer_norm_coefficients == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00871" name="l00871"></a><span class="lineno">  871</span>          ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00872" name="l00872"></a><span class="lineno">  872</span>          : luci_interpreter::kernels::getTensorData&lt;int16_t&gt;(input_layer_norm_coefficients),</div>
<div class="line"><a id="l00873" name="l00873"></a><span class="lineno">  873</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#ac0c85d53bd0a78802d42a9493616fa9e">layer_norm_input_scale_a</a>, integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#afde0dc24fcf4a78b859be82f28632b61">layer_norm_input_scale_b</a>,</div>
<div class="line"><a id="l00874" name="l00874"></a><span class="lineno">  874</span>        forget_layer_norm_coefficients == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00875" name="l00875"></a><span class="lineno">  875</span>          ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00876" name="l00876"></a><span class="lineno">  876</span>          : luci_interpreter::kernels::getTensorData&lt;int16_t&gt;(forget_layer_norm_coefficients),</div>
<div class="line"><a id="l00877" name="l00877"></a><span class="lineno">  877</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a4f17d869e9a7e018549d323949d507e8">layer_norm_forget_scale_a</a>, integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#aff505a21fe1205ce8de8d6349274d1be">layer_norm_forget_scale_b</a>,</div>
<div class="line"><a id="l00878" name="l00878"></a><span class="lineno">  878</span>        cell_layer_norm_coefficients == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00879" name="l00879"></a><span class="lineno">  879</span>          ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00880" name="l00880"></a><span class="lineno">  880</span>          : luci_interpreter::kernels::getTensorData&lt;int16_t&gt;(cell_layer_norm_coefficients),</div>
<div class="line"><a id="l00881" name="l00881"></a><span class="lineno">  881</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#aa121ea209ac56e9b152ea2b7a8818715">layer_norm_cell_scale_a</a>, integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a63778507ff2e28c090b2937fba31cbf2">layer_norm_cell_scale_b</a>,</div>
<div class="line"><a id="l00882" name="l00882"></a><span class="lineno">  882</span>        output_layer_norm_coefficients == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00883" name="l00883"></a><span class="lineno">  883</span>          ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00884" name="l00884"></a><span class="lineno">  884</span>          : luci_interpreter::kernels::getTensorData&lt;int16_t&gt;(output_layer_norm_coefficients),</div>
<div class="line"><a id="l00885" name="l00885"></a><span class="lineno">  885</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a05119ca8a00dfb53b66ca3cc187c5b05">layer_norm_output_scale_a</a>, integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#ac3690c9c36794675982ba9ec3607f8b7">layer_norm_output_scale_b</a>,</div>
<div class="line"><a id="l00886" name="l00886"></a><span class="lineno">  886</span>        input_gate_bias == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00887" name="l00887"></a><span class="lineno">  887</span>          ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00888" name="l00888"></a><span class="lineno">  888</span>          : luci_interpreter::kernels::getTensorData&lt;int32_t&gt;(input_gate_bias),</div>
<div class="line"><a id="l00889" name="l00889"></a><span class="lineno">  889</span>        forget_gate_bias == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00890" name="l00890"></a><span class="lineno">  890</span>          ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00891" name="l00891"></a><span class="lineno">  891</span>          : luci_interpreter::kernels::getTensorData&lt;int32_t&gt;(forget_gate_bias),</div>
<div class="line"><a id="l00892" name="l00892"></a><span class="lineno">  892</span>        cell_gate_bias == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00893" name="l00893"></a><span class="lineno">  893</span>          ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00894" name="l00894"></a><span class="lineno">  894</span>          : luci_interpreter::kernels::getTensorData&lt;int32_t&gt;(cell_gate_bias),</div>
<div class="line"><a id="l00895" name="l00895"></a><span class="lineno">  895</span>        output_gate_bias == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00896" name="l00896"></a><span class="lineno">  896</span>          ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00897" name="l00897"></a><span class="lineno">  897</span>          : luci_interpreter::kernels::getTensorData&lt;int32_t&gt;(output_gate_bias),</div>
<div class="line"><a id="l00898" name="l00898"></a><span class="lineno">  898</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a8462a1a6cced18ac3a6b82306bfcc780">quantized_cell_clip</a>, integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#ac8ddd6f032f01eaefa39a8a1259e900d">quantized_proj_clip</a>,</div>
<div class="line"><a id="l00899" name="l00899"></a><span class="lineno">  899</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#ab7664e69aed93448fcc3bae80cff7b57">cell_scale</a>, integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#af9a05c5052c25714265807ee320bc966">input_variance_guard</a>,</div>
<div class="line"><a id="l00900" name="l00900"></a><span class="lineno">  900</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#ad4ee84a5a78c2c9dfe7fabe78b9388d1">forget_variance_guard</a>, integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#ae922b35a1ae080073fce915fb42eb4c7">cell_variance_guard</a>,</div>
<div class="line"><a id="l00901" name="l00901"></a><span class="lineno">  901</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a34cb17f71c767ce6ad0b60daeec89c18">output_variance_guard</a>,</div>
<div class="line"><a id="l00902" name="l00902"></a><span class="lineno">  902</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a5230bd10273c2df881d2992ca89d764d">input_to_forget_effective_bias</a>.data(),</div>
<div class="line"><a id="l00903" name="l00903"></a><span class="lineno">  903</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a08150d9662d4b9e4471a0fb28298a5c2">recurrent_to_forget_effective_bias</a>.data(),</div>
<div class="line"><a id="l00904" name="l00904"></a><span class="lineno">  904</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#add6e3338ffe810eff38750897882d35c">input_to_cell_effective_bias</a>.data(),</div>
<div class="line"><a id="l00905" name="l00905"></a><span class="lineno">  905</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#af8e50735cb0b964413f1c273220131d6">recurrent_to_cell_effective_bias</a>.data(),</div>
<div class="line"><a id="l00906" name="l00906"></a><span class="lineno">  906</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a66f2874ced3aa8934bf0ee93ae61cec0">input_to_output_effective_bias</a>.data(),</div>
<div class="line"><a id="l00907" name="l00907"></a><span class="lineno">  907</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a7a79444954718b6ec2b01bb61afcd40b">recurrent_to_output_effective_bias</a>.data(),</div>
<div class="line"><a id="l00908" name="l00908"></a><span class="lineno">  908</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a3a42233043f3d11e76ff7e5a48b98609">input_to_input_effective_bias</a>.data(),</div>
<div class="line"><a id="l00909" name="l00909"></a><span class="lineno">  909</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a88d966314f5bce1f3dab6a948436f409">recurrent_to_input_effective_bias</a>.data(),</div>
<div class="line"><a id="l00910" name="l00910"></a><span class="lineno">  910</span>        integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a72134384372348fba20502cd12af5fe9">projection_effective_bias</a>.data(), n_batch, n_cell, n_input, n_output,</div>
<div class="line"><a id="l00911" name="l00911"></a><span class="lineno">  911</span>        luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(output_state), output_state_zp,</div>
<div class="line"><a id="l00912" name="l00912"></a><span class="lineno">  912</span>        luci_interpreter::kernels::getTensorData&lt;int16_t&gt;(cell_state), output_ptr, scratch0,</div>
<div class="line"><a id="l00913" name="l00913"></a><span class="lineno">  913</span>        scratch1, scratch2, scratch3, scratch4, scratch5);</div>
<div class="line"><a id="l00914" name="l00914"></a><span class="lineno">  914</span>    }</div>
<div class="line"><a id="l00915" name="l00915"></a><span class="lineno">  915</span>  }</div>
<div class="line"><a id="l00916" name="l00916"></a><span class="lineno">  916</span>  <span class="keywordflow">else</span></div>
<div class="line"><a id="l00917" name="l00917"></a><span class="lineno">  917</span>  {</div>
<div class="line"><a id="l00918" name="l00918"></a><span class="lineno">  918</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> b = 0; <a class="code hl_variable" href="namespacejpeg2hdf5.html#a1a0fe2ec4c2bc8757bcf4f0fcd4f74c1">b</a> &lt; n_batch; <a class="code hl_variable" href="namespacejpeg2hdf5.html#a1a0fe2ec4c2bc8757bcf4f0fcd4f74c1">b</a>++)</div>
<div class="line"><a id="l00919" name="l00919"></a><span class="lineno">  919</span>    {</div>
<div class="line"><a id="l00920" name="l00920"></a><span class="lineno">  920</span>      <span class="keyword">const</span> <span class="keywordtype">int</span> input_step = n_input;</div>
<div class="line"><a id="l00921" name="l00921"></a><span class="lineno">  921</span>      <span class="keyword">const</span> <span class="keywordtype">int</span> output_step = output_batch_leading_dim;</div>
<div class="line"><a id="l00922" name="l00922"></a><span class="lineno">  922</span> </div>
<div class="line"><a id="l00923" name="l00923"></a><span class="lineno">  923</span>      <span class="keywordflow">for</span> (<span class="keywordtype">int</span> t = 0; t &lt; max_time; t++)</div>
<div class="line"><a id="l00924" name="l00924"></a><span class="lineno">  924</span>      {</div>
<div class="line"><a id="l00925" name="l00925"></a><span class="lineno">  925</span>        <span class="comment">// If this is the forward_sequence, step forward, otherwise step</span></div>
<div class="line"><a id="l00926" name="l00926"></a><span class="lineno">  926</span>        <span class="comment">// backwards.</span></div>
<div class="line"><a id="l00927" name="l00927"></a><span class="lineno">  927</span>        <span class="keyword">const</span> <span class="keywordtype">int</span> t_rel = forward_sequence ? t : max_time - t - 1;</div>
<div class="line"><a id="l00928" name="l00928"></a><span class="lineno">  928</span>        <span class="keyword">const</span> <span class="keywordtype">int</span> time_offset = <a class="code hl_variable" href="namespacejpeg2hdf5.html#a1a0fe2ec4c2bc8757bcf4f0fcd4f74c1">b</a> * max_time + t_rel;</div>
<div class="line"><a id="l00929" name="l00929"></a><span class="lineno">  929</span>        <span class="keyword">const</span> int8_t *input_ptr =</div>
<div class="line"><a id="l00930" name="l00930"></a><span class="lineno">  930</span>          luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(input) + time_offset * input_step;</div>
<div class="line"><a id="l00931" name="l00931"></a><span class="lineno">  931</span>        int8_t *output_ptr =</div>
<div class="line"><a id="l00932" name="l00932"></a><span class="lineno">  932</span>          luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(output) + time_offset * output_step;</div>
<div class="line"><a id="l00933" name="l00933"></a><span class="lineno">  933</span> </div>
<div class="line"><a id="l00934" name="l00934"></a><span class="lineno">  934</span>        <span class="comment">// Offset the {output,cell}_state pointers to the right batch.</span></div>
<div class="line"><a id="l00935" name="l00935"></a><span class="lineno">  935</span>        int8_t *output_state_ptr = luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(output_state) +</div>
<div class="line"><a id="l00936" name="l00936"></a><span class="lineno">  936</span>                                   <a class="code hl_variable" href="namespacejpeg2hdf5.html#a1a0fe2ec4c2bc8757bcf4f0fcd4f74c1">b</a> * output_batch_leading_dim;</div>
<div class="line"><a id="l00937" name="l00937"></a><span class="lineno">  937</span>        int16_t *cell_state_ptr =</div>
<div class="line"><a id="l00938" name="l00938"></a><span class="lineno">  938</span>          luci_interpreter::kernels::getTensorData&lt;int16_t&gt;(cell_state) + <a class="code hl_variable" href="namespacejpeg2hdf5.html#a1a0fe2ec4c2bc8757bcf4f0fcd4f74c1">b</a> * n_cell;</div>
<div class="line"><a id="l00939" name="l00939"></a><span class="lineno">  939</span> </div>
<div class="line"><a id="l00940" name="l00940"></a><span class="lineno">  940</span>        <a class="code hl_function" href="namespaceluci__interpreter__pal_1_1lstm.html#aff32234d5392b0c7fdbccc7cad115c0e">lstm::lstm_step_integer_8x8_16</a>(</div>
<div class="line"><a id="l00941" name="l00941"></a><span class="lineno">  941</span>          input_ptr,</div>
<div class="line"><a id="l00942" name="l00942"></a><span class="lineno">  942</span>          input_to_input_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00943" name="l00943"></a><span class="lineno">  943</span>            ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00944" name="l00944"></a><span class="lineno">  944</span>            : luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(input_to_input_weights),</div>
<div class="line"><a id="l00945" name="l00945"></a><span class="lineno">  945</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a1815b45d4e9979eaf81cb89f299c8f79">effective_input_to_input_scale_a</a>,</div>
<div class="line"><a id="l00946" name="l00946"></a><span class="lineno">  946</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#aab48dc57abe245d257c35cc1c6ad7354">effective_input_to_input_scale_b</a>,</div>
<div class="line"><a id="l00947" name="l00947"></a><span class="lineno">  947</span>          input_to_forget_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00948" name="l00948"></a><span class="lineno">  948</span>            ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00949" name="l00949"></a><span class="lineno">  949</span>            : luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(input_to_forget_weights),</div>
<div class="line"><a id="l00950" name="l00950"></a><span class="lineno">  950</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#aad3a135d4309854e3ca3ffcf375aa07a">effective_input_to_forget_scale_a</a>,</div>
<div class="line"><a id="l00951" name="l00951"></a><span class="lineno">  951</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#adc38a56e44f8a3e6550bc80bfaca363e">effective_input_to_forget_scale_b</a>,</div>
<div class="line"><a id="l00952" name="l00952"></a><span class="lineno">  952</span>          input_to_cell_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00953" name="l00953"></a><span class="lineno">  953</span>            ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00954" name="l00954"></a><span class="lineno">  954</span>            : luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(input_to_cell_weights),</div>
<div class="line"><a id="l00955" name="l00955"></a><span class="lineno">  955</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a17aa2b0f550808acc80edf483d9aefc0">effective_input_to_cell_scale_a</a>,</div>
<div class="line"><a id="l00956" name="l00956"></a><span class="lineno">  956</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a88ce1ec27fc97e74415f066b281bcb71">effective_input_to_cell_scale_b</a>,</div>
<div class="line"><a id="l00957" name="l00957"></a><span class="lineno">  957</span>          input_to_output_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00958" name="l00958"></a><span class="lineno">  958</span>            ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00959" name="l00959"></a><span class="lineno">  959</span>            : luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(input_to_output_weights),</div>
<div class="line"><a id="l00960" name="l00960"></a><span class="lineno">  960</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a436a706c17cf37479593607220ff0aab">effective_input_to_output_scale_a</a>,</div>
<div class="line"><a id="l00961" name="l00961"></a><span class="lineno">  961</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a8f050cf3537363681b3aff86395f7813">effective_input_to_output_scale_b</a>,</div>
<div class="line"><a id="l00962" name="l00962"></a><span class="lineno">  962</span>          recurrent_to_input_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00963" name="l00963"></a><span class="lineno">  963</span>            ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00964" name="l00964"></a><span class="lineno">  964</span>            : luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(recurrent_to_input_weights),</div>
<div class="line"><a id="l00965" name="l00965"></a><span class="lineno">  965</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a38de4e598127e2fb764fce6a21c2fc9e">effective_recurrent_to_input_scale_a</a>,</div>
<div class="line"><a id="l00966" name="l00966"></a><span class="lineno">  966</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a9686553df691e2b1b8c716615f13753e">effective_recurrent_to_input_scale_b</a>,</div>
<div class="line"><a id="l00967" name="l00967"></a><span class="lineno">  967</span>          recurrent_to_forget_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00968" name="l00968"></a><span class="lineno">  968</span>            ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00969" name="l00969"></a><span class="lineno">  969</span>            : luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(recurrent_to_forget_weights),</div>
<div class="line"><a id="l00970" name="l00970"></a><span class="lineno">  970</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a786a7d187a322aab6e8d07bfb157c834">effective_recurrent_to_forget_scale_a</a>,</div>
<div class="line"><a id="l00971" name="l00971"></a><span class="lineno">  971</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a0f2e283966be688baf8353cb83d6cabe">effective_recurrent_to_forget_scale_b</a>,</div>
<div class="line"><a id="l00972" name="l00972"></a><span class="lineno">  972</span>          recurrent_to_cell_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00973" name="l00973"></a><span class="lineno">  973</span>            ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00974" name="l00974"></a><span class="lineno">  974</span>            : luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(recurrent_to_cell_weights),</div>
<div class="line"><a id="l00975" name="l00975"></a><span class="lineno">  975</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#ae8b58fbab6226ddb2b3d5b972ca47a3d">effective_recurrent_to_cell_scale_a</a>,</div>
<div class="line"><a id="l00976" name="l00976"></a><span class="lineno">  976</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a7429f0edf41d6c2ffce4987830d31235">effective_recurrent_to_cell_scale_b</a>,</div>
<div class="line"><a id="l00977" name="l00977"></a><span class="lineno">  977</span>          recurrent_to_output_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00978" name="l00978"></a><span class="lineno">  978</span>            ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00979" name="l00979"></a><span class="lineno">  979</span>            : luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(recurrent_to_output_weights),</div>
<div class="line"><a id="l00980" name="l00980"></a><span class="lineno">  980</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a1ef00ac5637652bc42302b668595c14f">effective_recurrent_to_output_scale_a</a>,</div>
<div class="line"><a id="l00981" name="l00981"></a><span class="lineno">  981</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a397af438d6a1e7051cd78da4dbb743ba">effective_recurrent_to_output_scale_b</a>,</div>
<div class="line"><a id="l00982" name="l00982"></a><span class="lineno">  982</span>          cell_to_input_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00983" name="l00983"></a><span class="lineno">  983</span>            ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00984" name="l00984"></a><span class="lineno">  984</span>            : luci_interpreter::kernels::getTensorData&lt;int16_t&gt;(cell_to_input_weights),</div>
<div class="line"><a id="l00985" name="l00985"></a><span class="lineno">  985</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#abe40c57692043111c35301789a9218e6">effective_cell_to_input_scale_a</a>,</div>
<div class="line"><a id="l00986" name="l00986"></a><span class="lineno">  986</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#aacc97958d62163e8f69f44703bd2b411">effective_cell_to_input_scale_b</a>,</div>
<div class="line"><a id="l00987" name="l00987"></a><span class="lineno">  987</span>          cell_to_forget_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00988" name="l00988"></a><span class="lineno">  988</span>            ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00989" name="l00989"></a><span class="lineno">  989</span>            : luci_interpreter::kernels::getTensorData&lt;int16_t&gt;(cell_to_forget_weights),</div>
<div class="line"><a id="l00990" name="l00990"></a><span class="lineno">  990</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a6e524defb86176d1c87074f90d30b6fc">effective_cell_to_forget_scale_a</a>,</div>
<div class="line"><a id="l00991" name="l00991"></a><span class="lineno">  991</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#aab68f6adb9ab9fbdcb02b1561939f623">effective_cell_to_forget_scale_b</a>,</div>
<div class="line"><a id="l00992" name="l00992"></a><span class="lineno">  992</span>          cell_to_output_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00993" name="l00993"></a><span class="lineno">  993</span>            ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00994" name="l00994"></a><span class="lineno">  994</span>            : luci_interpreter::kernels::getTensorData&lt;int16_t&gt;(cell_to_output_weights),</div>
<div class="line"><a id="l00995" name="l00995"></a><span class="lineno">  995</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#affdebdc0521280db0be1bec0434c04e4">effective_cell_to_output_scale_a</a>,</div>
<div class="line"><a id="l00996" name="l00996"></a><span class="lineno">  996</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a760916e38abee7495fa35d198ba96008">effective_cell_to_output_scale_b</a>,</div>
<div class="line"><a id="l00997" name="l00997"></a><span class="lineno">  997</span>          projection_weights == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00998" name="l00998"></a><span class="lineno">  998</span>            ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l00999" name="l00999"></a><span class="lineno">  999</span>            : luci_interpreter::kernels::getTensorData&lt;int8_t&gt;(projection_weights),</div>
<div class="line"><a id="l01000" name="l01000"></a><span class="lineno"> 1000</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a27867e3ab1cbefb506f3d384587b5a32">effective_proj_scale_a</a>, integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a78b06d907d35a460555947d9ce6b6192">effective_proj_scale_b</a>,</div>
<div class="line"><a id="l01001" name="l01001"></a><span class="lineno"> 1001</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a9179415a87f49b1efd429c501c20432c">hidden_zp</a>, integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#abb27a971ebf03b639b8c9206fdaa392f">effective_hidden_scale_a</a>,</div>
<div class="line"><a id="l01002" name="l01002"></a><span class="lineno"> 1002</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a3fed6619c9e6f648f17f00aa5af6aacd">effective_hidden_scale_b</a>,</div>
<div class="line"><a id="l01003" name="l01003"></a><span class="lineno"> 1003</span>          input_layer_norm_coefficients == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l01004" name="l01004"></a><span class="lineno"> 1004</span>            ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l01005" name="l01005"></a><span class="lineno"> 1005</span>            : luci_interpreter::kernels::getTensorData&lt;int16_t&gt;(input_layer_norm_coefficients),</div>
<div class="line"><a id="l01006" name="l01006"></a><span class="lineno"> 1006</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#ac0c85d53bd0a78802d42a9493616fa9e">layer_norm_input_scale_a</a>, integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#afde0dc24fcf4a78b859be82f28632b61">layer_norm_input_scale_b</a>,</div>
<div class="line"><a id="l01007" name="l01007"></a><span class="lineno"> 1007</span>          forget_layer_norm_coefficients == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l01008" name="l01008"></a><span class="lineno"> 1008</span>            ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l01009" name="l01009"></a><span class="lineno"> 1009</span>            : luci_interpreter::kernels::getTensorData&lt;int16_t&gt;(forget_layer_norm_coefficients),</div>
<div class="line"><a id="l01010" name="l01010"></a><span class="lineno"> 1010</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a4f17d869e9a7e018549d323949d507e8">layer_norm_forget_scale_a</a>,</div>
<div class="line"><a id="l01011" name="l01011"></a><span class="lineno"> 1011</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#aff505a21fe1205ce8de8d6349274d1be">layer_norm_forget_scale_b</a>,</div>
<div class="line"><a id="l01012" name="l01012"></a><span class="lineno"> 1012</span>          cell_layer_norm_coefficients == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l01013" name="l01013"></a><span class="lineno"> 1013</span>            ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l01014" name="l01014"></a><span class="lineno"> 1014</span>            : luci_interpreter::kernels::getTensorData&lt;int16_t&gt;(cell_layer_norm_coefficients),</div>
<div class="line"><a id="l01015" name="l01015"></a><span class="lineno"> 1015</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#aa121ea209ac56e9b152ea2b7a8818715">layer_norm_cell_scale_a</a>, integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a63778507ff2e28c090b2937fba31cbf2">layer_norm_cell_scale_b</a>,</div>
<div class="line"><a id="l01016" name="l01016"></a><span class="lineno"> 1016</span>          output_layer_norm_coefficients == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l01017" name="l01017"></a><span class="lineno"> 1017</span>            ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l01018" name="l01018"></a><span class="lineno"> 1018</span>            : luci_interpreter::kernels::getTensorData&lt;int16_t&gt;(output_layer_norm_coefficients),</div>
<div class="line"><a id="l01019" name="l01019"></a><span class="lineno"> 1019</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a05119ca8a00dfb53b66ca3cc187c5b05">layer_norm_output_scale_a</a>,</div>
<div class="line"><a id="l01020" name="l01020"></a><span class="lineno"> 1020</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#ac3690c9c36794675982ba9ec3607f8b7">layer_norm_output_scale_b</a>,</div>
<div class="line"><a id="l01021" name="l01021"></a><span class="lineno"> 1021</span>          input_gate_bias == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l01022" name="l01022"></a><span class="lineno"> 1022</span>            ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l01023" name="l01023"></a><span class="lineno"> 1023</span>            : luci_interpreter::kernels::getTensorData&lt;int32_t&gt;(input_gate_bias),</div>
<div class="line"><a id="l01024" name="l01024"></a><span class="lineno"> 1024</span>          forget_gate_bias == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l01025" name="l01025"></a><span class="lineno"> 1025</span>            ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l01026" name="l01026"></a><span class="lineno"> 1026</span>            : luci_interpreter::kernels::getTensorData&lt;int32_t&gt;(forget_gate_bias),</div>
<div class="line"><a id="l01027" name="l01027"></a><span class="lineno"> 1027</span>          cell_gate_bias == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l01028" name="l01028"></a><span class="lineno"> 1028</span>            ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l01029" name="l01029"></a><span class="lineno"> 1029</span>            : luci_interpreter::kernels::getTensorData&lt;int32_t&gt;(cell_gate_bias),</div>
<div class="line"><a id="l01030" name="l01030"></a><span class="lineno"> 1030</span>          output_gate_bias == <span class="keyword">nullptr</span></div>
<div class="line"><a id="l01031" name="l01031"></a><span class="lineno"> 1031</span>            ? <span class="keyword">nullptr</span></div>
<div class="line"><a id="l01032" name="l01032"></a><span class="lineno"> 1032</span>            : luci_interpreter::kernels::getTensorData&lt;int32_t&gt;(output_gate_bias),</div>
<div class="line"><a id="l01033" name="l01033"></a><span class="lineno"> 1033</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a8462a1a6cced18ac3a6b82306bfcc780">quantized_cell_clip</a>, integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#ac8ddd6f032f01eaefa39a8a1259e900d">quantized_proj_clip</a>,</div>
<div class="line"><a id="l01034" name="l01034"></a><span class="lineno"> 1034</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#ab7664e69aed93448fcc3bae80cff7b57">cell_scale</a>, integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#af9a05c5052c25714265807ee320bc966">input_variance_guard</a>,</div>
<div class="line"><a id="l01035" name="l01035"></a><span class="lineno"> 1035</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#ad4ee84a5a78c2c9dfe7fabe78b9388d1">forget_variance_guard</a>, integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#ae922b35a1ae080073fce915fb42eb4c7">cell_variance_guard</a>,</div>
<div class="line"><a id="l01036" name="l01036"></a><span class="lineno"> 1036</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a34cb17f71c767ce6ad0b60daeec89c18">output_variance_guard</a>,</div>
<div class="line"><a id="l01037" name="l01037"></a><span class="lineno"> 1037</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a5230bd10273c2df881d2992ca89d764d">input_to_forget_effective_bias</a>.data(),</div>
<div class="line"><a id="l01038" name="l01038"></a><span class="lineno"> 1038</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a08150d9662d4b9e4471a0fb28298a5c2">recurrent_to_forget_effective_bias</a>.data(),</div>
<div class="line"><a id="l01039" name="l01039"></a><span class="lineno"> 1039</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#add6e3338ffe810eff38750897882d35c">input_to_cell_effective_bias</a>.data(),</div>
<div class="line"><a id="l01040" name="l01040"></a><span class="lineno"> 1040</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#af8e50735cb0b964413f1c273220131d6">recurrent_to_cell_effective_bias</a>.data(),</div>
<div class="line"><a id="l01041" name="l01041"></a><span class="lineno"> 1041</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a66f2874ced3aa8934bf0ee93ae61cec0">input_to_output_effective_bias</a>.data(),</div>
<div class="line"><a id="l01042" name="l01042"></a><span class="lineno"> 1042</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a7a79444954718b6ec2b01bb61afcd40b">recurrent_to_output_effective_bias</a>.data(),</div>
<div class="line"><a id="l01043" name="l01043"></a><span class="lineno"> 1043</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a3a42233043f3d11e76ff7e5a48b98609">input_to_input_effective_bias</a>.data(),</div>
<div class="line"><a id="l01044" name="l01044"></a><span class="lineno"> 1044</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a88d966314f5bce1f3dab6a948436f409">recurrent_to_input_effective_bias</a>.data(),</div>
<div class="line"><a id="l01045" name="l01045"></a><span class="lineno"> 1045</span>          integer_lstm_param.<a class="code hl_variable" href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a72134384372348fba20502cd12af5fe9">projection_effective_bias</a>.data(), <span class="comment">/*n_batch=*/</span>1, n_cell, n_input,</div>
<div class="line"><a id="l01046" name="l01046"></a><span class="lineno"> 1046</span>          n_output, output_state_ptr, output_state_zp, cell_state_ptr, output_ptr, scratch0,</div>
<div class="line"><a id="l01047" name="l01047"></a><span class="lineno"> 1047</span>          scratch1, scratch2, scratch3, scratch4, scratch5);</div>
<div class="line"><a id="l01048" name="l01048"></a><span class="lineno"> 1048</span>      }</div>
<div class="line"><a id="l01049" name="l01049"></a><span class="lineno"> 1049</span>    }</div>
<div class="line"><a id="l01050" name="l01050"></a><span class="lineno"> 1050</span>  }</div>
<div class="line"><a id="l01051" name="l01051"></a><span class="lineno"> 1051</span>}</div>
<div class="line"><a id="l01052" name="l01052"></a><span class="lineno"> 1052</span> </div>
<div class="line"><a id="l01053" name="l01053"></a><span class="lineno"> 1053</span>} <span class="comment">// namespace luci_interpreter_pal</span></div>
<div class="line"><a id="l01054" name="l01054"></a><span class="lineno"> 1054</span> </div>
<div class="line"><a id="l01055" name="l01055"></a><span class="lineno"> 1055</span><span class="preprocessor">#endif </span><span class="comment">// LUCI_INTERPRETER_PAL_UNIDIRECTIONAL_SEQUENCE_LSTM_H</span></div>
<div class="ttc" id="aclassluci__interpreter_1_1_shape_html_a83aee8788dd50f2ea66c48697c7c0a34"><div class="ttname"><a href="classluci__interpreter_1_1_shape.html#a83aee8788dd50f2ea66c48697c7c0a34">luci_interpreter::Shape::dim</a></div><div class="ttdeci">int32_t dim(int i) const</div><div class="ttdef"><b>Definition:</b> <a href="compiler_2luci-interpreter_2include_2luci__interpreter_2core_2_tensor_8h_source.html#l00041">Tensor.h:41</a></div></div>
<div class="ttc" id="aclassluci__interpreter_1_1_tensor_html"><div class="ttname"><a href="classluci__interpreter_1_1_tensor.html">luci_interpreter::Tensor</a></div><div class="ttdef"><b>Definition:</b> <a href="compiler_2luci-interpreter_2include_2luci__interpreter_2core_2_tensor_8h_source.html#l00089">Tensor.h:90</a></div></div>
<div class="ttc" id="aclassluci__interpreter_1_1_tensor_html_a5ea62328ce6d801a3aef30b903b95d69"><div class="ttname"><a href="classluci__interpreter_1_1_tensor.html#a5ea62328ce6d801a3aef30b903b95d69">luci_interpreter::Tensor::shape</a></div><div class="ttdeci">const Shape &amp; shape() const</div><div class="ttdef"><b>Definition:</b> <a href="compiler_2luci-interpreter_2include_2luci__interpreter_2core_2_tensor_8h_source.html#l00096">Tensor.h:96</a></div></div>
<div class="ttc" id="acompiler_2luci-interpreter_2src_2kernels_2_utils_8h_html_a231f5fa1ff2a3f19222b42cc9bbd1f2d"><div class="ttname"><a href="compiler_2luci-interpreter_2src_2kernels_2_utils_8h.html#a231f5fa1ff2a3f19222b42cc9bbd1f2d">LUCI_INTERPRETER_CHECK</a></div><div class="ttdeci">#define LUCI_INTERPRETER_CHECK(cond)</div><div class="ttdef"><b>Definition:</b> <a href="compiler_2luci-interpreter_2src_2kernels_2_utils_8h_source.html#l00036">Utils.h:36</a></div></div>
<div class="ttc" id="amcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_html_a740521307802d978b1a8134e3eb4acf9"><div class="ttname"><a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h.html#a740521307802d978b1a8134e3eb4acf9">DISPATCH_TANH</a></div><div class="ttdeci">#define DISPATCH_TANH(i)</div></div>
<div class="ttc" id="anamespacegen__h5__explicit__inputs_html_acd1aa9ba45d45c6b619b723e6e34c576"><div class="ttname"><a href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">gen_h5_explicit_inputs.output</a></div><div class="ttdeci">output</div><div class="ttdef"><b>Definition:</b> <a href="gen__h5__explicit__inputs_8py_source.html#l00035">gen_h5_explicit_inputs.py:35</a></div></div>
<div class="ttc" id="anamespacejpeg2hdf5_html_a1a0fe2ec4c2bc8757bcf4f0fcd4f74c1"><div class="ttname"><a href="namespacejpeg2hdf5.html#a1a0fe2ec4c2bc8757bcf4f0fcd4f74c1">jpeg2hdf5.b</a></div><div class="ttdeci">b</div><div class="ttdef"><b>Definition:</b> <a href="jpeg2hdf5_8py_source.html#l00105">jpeg2hdf5.py:105</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_a13269908e5cbb4827f974e782b98f6b2"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#a13269908e5cbb4827f974e782b98f6b2">luci_interpreter_pal::lstm::cwise_mul</a></div><div class="ttdeci">void cwise_mul(const int16_t *input_1, const int16_t *input_2, int32_t multiplier, int32_t shift, int32_t n_batch, int32_t n_input, int32_t output_zp, int8_t *output)</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00052">PALUnidirectionalSequenceLSTM.h:52</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_a4a2d78fd09384fe6419222fac94e71b3"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#a4a2d78fd09384fe6419222fac94e71b3">luci_interpreter_pal::lstm::get_inv_sqrt_quantized_multiplier_exp</a></div><div class="ttdeci">void get_inv_sqrt_quantized_multiplier_exp(int32_t input, int reverse_shift, int32_t *output_inv_sqrt, int *output_shift)</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00128">PALUnidirectionalSequenceLSTM.h:128</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_a4e414d74814834c72b789c80e68e843b"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#a4e414d74814834c72b789c80e68e843b">luci_interpreter_pal::lstm::cwise_clipping</a></div><div class="ttdeci">void cwise_clipping(T *vector, const int v_size, const T &amp;clipping_value)</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00081">PALUnidirectionalSequenceLSTM.h:81</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_a7361af5bb813813c50859760c4cc8f8a"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#a7361af5bb813813c50859760c4cc8f8a">luci_interpreter_pal::lstm::vector_batch_vector_cwise_product_accumulate</a></div><div class="ttdeci">void vector_batch_vector_cwise_product_accumulate(const int16_t *vector, int v_size, const int16_t *batch_vector, int n_batch, int32_t multiplier, int shift, int16_t *result)</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00238">PALUnidirectionalSequenceLSTM.h:238</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_a7b3a8ce5736307c9146154fd4639e0cb"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#a7b3a8ce5736307c9146154fd4639e0cb">luci_interpreter_pal::lstm::sub1_vector</a></div><div class="ttdeci">void sub1_vector(const int16_t *vector, int v_size, int16_t *result)</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00072">PALUnidirectionalSequenceLSTM.h:72</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_a9c34168ef2084dd14025705bf93271ed"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#a9c34168ef2084dd14025705bf93271ed">luci_interpreter_pal::lstm::apply_layer_norm</a></div><div class="ttdeci">void apply_layer_norm(const int16_t *input, const int16_t *layer_norm_weights, const int32_t *bias, int32_t layer_norm_scale_a, int32_t layer_norm_scale_b, int32_t variance_limit, int n_batch, int n_input, int16_t *output)</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00186">PALUnidirectionalSequenceLSTM.h:186</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_ab554f067a0e70af0121424c774ad3880"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#ab554f067a0e70af0121424c774ad3880">luci_interpreter_pal::lstm::update_lstm_cell_integer</a></div><div class="ttdeci">void update_lstm_cell_integer(int n_batch, int n_cell, int16_t *cell_state, int32_t cell_state_scale, const int16_t *input_gate, int16_t *forget_gate, const int16_t *cell_gate, bool use_cifg, int16_t clip)</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00413">PALUnidirectionalSequenceLSTM.h:413</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_acbe525077503e0d3f37d59b7fc8276e2"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#acbe525077503e0d3f37d59b7fc8276e2">luci_interpreter_pal::lstm::multiply_by_quantized_multiplier</a></div><div class="ttdeci">int32_t multiply_by_quantized_multiplier(int32_t x, int32_t quantized_multiplier, int shift)</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00042">PALUnidirectionalSequenceLSTM.h:42</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_acef25fe5a003e2ff65b2c8ccb2711207"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#acef25fe5a003e2ff65b2c8ccb2711207">luci_interpreter_pal::lstm::count_leading_zeros</a></div><div class="ttdeci">int count_leading_zeros(T integer_input)</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00106">PALUnidirectionalSequenceLSTM.h:106</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_ad07afcc83af092c475787d8184538098"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#ad07afcc83af092c475787d8184538098">luci_interpreter_pal::lstm::calculate_lstm_output_integer8x8_16</a></div><div class="ttdeci">void calculate_lstm_output_integer8x8_16(int n_batch, int n_cell, int n_output, int16_t *cell_state, int32_t cell_state_scale, const int16_t *output_gate, int32_t hidden_scale_a, int32_t hidden_scale_b, int32_t hidden_zp, const int8_t *projection_weights, int32_t proj_scale_a, int32_t proj_scale_b, const int32_t *projection_bias, int32_t output_state_zp, int8_t quantized_proj_clip, int8_t *output_state, int16_t *scratch0, int8_t *scratch1, int32_t *scratch2)</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00350">PALUnidirectionalSequenceLSTM.h:350</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_ad9970c643958b6d2c26dcd2506bac62b"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#ad9970c643958b6d2c26dcd2506bac62b">luci_interpreter_pal::lstm::matrix_batch_vector_multiply_accumulate</a></div><div class="ttdeci">void matrix_batch_vector_multiply_accumulate(const int8_t *input, const int32_t *bias, const int8_t *input_to_gate_weights, int32_t multiplier, int32_t shift, int32_t n_batch, int32_t n_input, int32_t n_output, int32_t output_zp, T *output)</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00257">PALUnidirectionalSequenceLSTM.h:257</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_adaa95dd338f0bbd9be680fd7dfc6d1aa"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#adaa95dd338f0bbd9be680fd7dfc6d1aa">luci_interpreter_pal::lstm::calculate_lstm_gate_integer_8x8_16</a></div><div class="ttdeci">void calculate_lstm_gate_integer_8x8_16(const int8_t *input, const int8_t *input_to_gate_weights, const int32_t *input_to_gate_bias, const int32_t input_to_gate_scale_a, const int32_t input_to_gate_scale_b, const int8_t *output_state, const int8_t *recurrent_to_gate_weights, const int32_t *recurrent_to_gate_bias, const int32_t recurrent_to_gate_scale_a, const int32_t recurrent_to_gate_scale_b, const int16_t *cell_state, const int16_t *cell_to_gate_weights, const int32_t cell_to_gate_scale_a, const int32_t cell_to_gate_scale_b, const int16_t *layer_norm_coefficients, const int32_t *layer_norm_bias, const int32_t layer_norm_input_scale_a, const int32_t layer_norm_input_scale_b, const int32_t layer_norm_variance_guard, const int n_batch, const int n_input, const int n_output, const int n_cell, const TfLiteFusedActivation activation, int16_t *gate, int32_t *scratch5)</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00443">PALUnidirectionalSequenceLSTM.h:443</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_ae5995c2f4e037e3d18ef8f0462079564"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#ae5995c2f4e037e3d18ef8f0462079564">luci_interpreter_pal::lstm::apply_tanh</a></div><div class="ttdeci">void apply_tanh(int32_t integer_bits, const int16_t *input, int32_t n_batch, int32_t n_input, int16_t *output)</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00309">PALUnidirectionalSequenceLSTM.h:309</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_ae73bbfa7d9e0192734d7e01e5c05df63"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63">luci_interpreter_pal::lstm::TfLiteFusedActivation</a></div><div class="ttdeci">TfLiteFusedActivation</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00031">PALUnidirectionalSequenceLSTM.h:32</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_ae73bbfa7d9e0192734d7e01e5c05df63a06a35e36dd2f10a2e82095f663eb7cb7"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63a06a35e36dd2f10a2e82095f663eb7cb7">luci_interpreter_pal::lstm::kTfLiteActRelu</a></div><div class="ttdeci">@ kTfLiteActRelu</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00034">PALUnidirectionalSequenceLSTM.h:34</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_ae73bbfa7d9e0192734d7e01e5c05df63a60bdd9a337a5f1f2866fd65c7d8ffdce"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63a60bdd9a337a5f1f2866fd65c7d8ffdce">luci_interpreter_pal::lstm::kTfLiteActTanh</a></div><div class="ttdeci">@ kTfLiteActTanh</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00037">PALUnidirectionalSequenceLSTM.h:37</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_ae73bbfa7d9e0192734d7e01e5c05df63a611f6492ff91826833d1b9e42f7f9a5e"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63a611f6492ff91826833d1b9e42f7f9a5e">luci_interpreter_pal::lstm::kTfLiteActNone</a></div><div class="ttdeci">@ kTfLiteActNone</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00033">PALUnidirectionalSequenceLSTM.h:33</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_ae73bbfa7d9e0192734d7e01e5c05df63a9f385b0941a619677310da5deb8c0751"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63a9f385b0941a619677310da5deb8c0751">luci_interpreter_pal::lstm::kTfLiteActReluN1To1</a></div><div class="ttdeci">@ kTfLiteActReluN1To1</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00035">PALUnidirectionalSequenceLSTM.h:35</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_ae73bbfa7d9e0192734d7e01e5c05df63ab211c831f880a63ebc80994bb0cf2dc2"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63ab211c831f880a63ebc80994bb0cf2dc2">luci_interpreter_pal::lstm::kTfLiteActSigmoid</a></div><div class="ttdeci">@ kTfLiteActSigmoid</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00039">PALUnidirectionalSequenceLSTM.h:39</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_ae73bbfa7d9e0192734d7e01e5c05df63ad5ee29be46ddc348e9865b96129a533a"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63ad5ee29be46ddc348e9865b96129a533a">luci_interpreter_pal::lstm::kTfLiteActSignBit</a></div><div class="ttdeci">@ kTfLiteActSignBit</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00038">PALUnidirectionalSequenceLSTM.h:38</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_ae73bbfa7d9e0192734d7e01e5c05df63adcc6c589b6ffe8ff89fd701c70b38342"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#ae73bbfa7d9e0192734d7e01e5c05df63adcc6c589b6ffe8ff89fd701c70b38342">luci_interpreter_pal::lstm::kTfLiteActRelu6</a></div><div class="ttdeci">@ kTfLiteActRelu6</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00036">PALUnidirectionalSequenceLSTM.h:36</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_af16a4f8e96b58833ba85f9b5ef120b6c"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#af16a4f8e96b58833ba85f9b5ef120b6c">luci_interpreter_pal::lstm::apply_tanh_impl</a></div><div class="ttdeci">void apply_tanh_impl(const int16_t *input, int32_t n_batch, int32_t n_input, int16_t *output)</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00293">PALUnidirectionalSequenceLSTM.h:293</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_af4923cae88d2f75c29b49c78c9a00f99"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#af4923cae88d2f75c29b49c78c9a00f99">luci_interpreter_pal::lstm::cwise_add</a></div><div class="ttdeci">void cwise_add(const int16_t *input_1, const int16_t *input_2, int n_batch, int n_input, int16_t *output)</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00089">PALUnidirectionalSequenceLSTM.h:89</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_1_1lstm_html_aff32234d5392b0c7fdbccc7cad115c0e"><div class="ttname"><a href="namespaceluci__interpreter__pal_1_1lstm.html#aff32234d5392b0c7fdbccc7cad115c0e">luci_interpreter_pal::lstm::lstm_step_integer_8x8_16</a></div><div class="ttdeci">void lstm_step_integer_8x8_16(const int8_t *input_ptr, const int8_t *input_to_input_weight_ptr, int32_t effective_input_to_input_scale_a, int32_t effective_input_to_input_scale_b, const int8_t *input_to_forget_weight_ptr, int32_t effective_input_to_forget_scale_a, int32_t effective_input_to_forget_scale_b, const int8_t *input_to_cell_weight_ptr, int32_t effective_input_to_cell_scale_a, int32_t effective_input_to_cell_scale_b, const int8_t *input_to_output_weight_ptr, int32_t effective_input_to_output_scale_a, int32_t effective_input_to_output_scale_b, const int8_t *recurrent_to_input_weight_ptr, int32_t effective_recurrent_to_input_scale_a, int32_t effective_recurrent_to_input_scale_b, const int8_t *recurrent_to_forget_weight_ptr, int32_t effective_recurrent_to_forget_scale_a, int32_t effective_recurrent_to_forget_scale_b, const int8_t *recurrent_to_cell_weight_ptr, int32_t effective_recurrent_to_cell_scale_a, int32_t effective_recurrent_to_cell_scale_b, const int8_t *recurrent_to_output_weight_ptr, int32_t effective_recurrent_to_output_scale_a, int32_t effective_recurrent_to_output_scale_b, const int16_t *cell_to_input_weight_ptr, int32_t effective_cell_to_input_scale_a, int32_t effective_cell_to_input_scale_b, const int16_t *cell_to_forget_weight_ptr, int32_t effective_cell_to_forget_scale_a, int32_t effective_cell_to_forget_scale_b, const int16_t *cell_to_output_weight_ptr, int32_t effective_cell_to_output_scale_a, int32_t effective_cell_to_output_scale_b, const int8_t *projection_weight_ptr, int32_t effective_proj_scale_a, int32_t effective_proj_scale_b, int32_t hidden_zp, int32_t effective_hidden_scale_a, int32_t effective_hidden_scale_b, const int16_t *layer_norm_input_weight_ptr, int32_t layer_norm_input_scale_a, int32_t layer_norm_input_scale_b, const int16_t *layer_norm_forget_weight_ptr, int32_t layer_norm_forget_scale_a, int32_t layer_norm_forget_scale_b, const int16_t *layer_norm_cell_weight_ptr, int32_t layer_norm_cell_scale_a, int32_t layer_norm_cell_scale_b, const int16_t *layer_norm_output_weight_ptr, int32_t layer_norm_output_scale_a, int32_t layer_norm_output_scale_b, const int32_t *input_gate_bias_ptr, const int32_t *forget_gate_bias_ptr, const int32_t *cell_gate_bias_ptr, const int32_t *output_gate_bias_ptr, int16_t quantized_cell_clip, int8_t quantized_proj_clip, int32_t cell_state_scale, int32_t input_variance_guard, int32_t forget_variance_guard, int32_t cell_variance_guard, int32_t output_variance_guard, const int32_t *input_to_forget_effective_bias, const int32_t *recurrent_to_forget_effective_bias, const int32_t *input_to_cell_effective_bias, const int32_t *recurrent_to_cell_effective_bias, const int32_t *input_to_output_effective_bias, const int32_t *recurrent_to_output_effective_bias, const int32_t *input_to_input_effective_bias, const int32_t *recurrent_to_input_effective_bias, const int32_t *projection_effective_bias, int n_batch, int n_cell, int n_input, int n_output, int8_t *output_state_ptr, int32_t output_state_zp, int16_t *cell_state_ptr, int8_t *output_ptr, int16_t *scratch0, int16_t *scratch1, int16_t *scratch2, int16_t *scratch3, int8_t *scratch4, int32_t *scratch5)</div><div class="ttdef"><b>Definition:</b> <a href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00612">PALUnidirectionalSequenceLSTM.h:612</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_html"><div class="ttname"><a href="namespaceluci__interpreter__pal.html">luci_interpreter_pal</a></div><div class="ttdef"><b>Definition:</b> <a href="compiler_2luci-interpreter_2pal_2cmsisnn_2_p_a_l_arg_max_8h_source.html#l00022">PALArgMax.h:23</a></div></div>
<div class="ttc" id="anamespaceluci__interpreter__pal_html_a6a0b2d1d970f94be53e13b87b4bffa13"><div class="ttname"><a href="namespaceluci__interpreter__pal.html#a6a0b2d1d970f94be53e13b87b4bffa13">luci_interpreter_pal::eval_integer_8x8_16_lstm</a></div><div class="ttdeci">void eval_integer_8x8_16_lstm(const luci_interpreter::Tensor *input, const luci_interpreter::Tensor *input_to_input_weights, const luci_interpreter::Tensor *input_to_forget_weights, const luci_interpreter::Tensor *input_to_cell_weights, const luci_interpreter::Tensor *input_to_output_weights, const luci_interpreter::Tensor *recurrent_to_input_weights, const luci_interpreter::Tensor *recurrent_to_forget_weights, const luci_interpreter::Tensor *recurrent_to_cell_weights, const luci_interpreter::Tensor *recurrent_to_output_weights, const luci_interpreter::Tensor *cell_to_input_weights, const luci_interpreter::Tensor *cell_to_forget_weights, const luci_interpreter::Tensor *cell_to_output_weights, const luci_interpreter::Tensor *input_layer_norm_coefficients, const luci_interpreter::Tensor *forget_layer_norm_coefficients, const luci_interpreter::Tensor *cell_layer_norm_coefficients, const luci_interpreter::Tensor *output_layer_norm_coefficients, const luci_interpreter::Tensor *input_gate_bias, const luci_interpreter::Tensor *forget_gate_bias, const luci_interpreter::Tensor *cell_gate_bias, const luci_interpreter::Tensor *output_gate_bias, const luci_interpreter::Tensor *projection_weights, const luci_interpreter::Tensor *projection_bias, const luci_interpreter::UnidirectionalSequenceLSTMParams &amp;params, bool forward_sequence, bool time_major, const luci_interpreter::IntegerLSTMParams &amp;integer_lstm_param, int32_t output_state_zp, luci_interpreter::Tensor *output_state, luci_interpreter::Tensor *cell_state, luci_interpreter::Tensor *output, int16_t *scratch0, int16_t *scratch1, int16_t *scratch2, int16_t *scratch3, int8_t *scratch4, int32_t *scratch5)</div><div class="ttdef"><b>Definition:</b> <a href="cmsisnn_2_p_a_l_unidirectional_sequence_l_s_t_m_8h_source.html#l00126">PALUnidirectionalSequenceLSTM.h:126</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html">luci_interpreter::IntegerLSTMParams</a></div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00229">KernelParams.h:230</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a05119ca8a00dfb53b66ca3cc187c5b05"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a05119ca8a00dfb53b66ca3cc187c5b05">luci_interpreter::IntegerLSTMParams::layer_norm_output_scale_a</a></div><div class="ttdeci">int32_t layer_norm_output_scale_a</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00283">KernelParams.h:283</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a08150d9662d4b9e4471a0fb28298a5c2"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a08150d9662d4b9e4471a0fb28298a5c2">luci_interpreter::IntegerLSTMParams::recurrent_to_forget_effective_bias</a></div><div class="ttdeci">std::vector&lt; int32_t &gt; recurrent_to_forget_effective_bias</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00294">KernelParams.h:294</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a0f2e283966be688baf8353cb83d6cabe"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a0f2e283966be688baf8353cb83d6cabe">luci_interpreter::IntegerLSTMParams::effective_recurrent_to_forget_scale_b</a></div><div class="ttdeci">int32_t effective_recurrent_to_forget_scale_b</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00248">KernelParams.h:248</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a17aa2b0f550808acc80edf483d9aefc0"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a17aa2b0f550808acc80edf483d9aefc0">luci_interpreter::IntegerLSTMParams::effective_input_to_cell_scale_a</a></div><div class="ttdeci">int32_t effective_input_to_cell_scale_a</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00253">KernelParams.h:253</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a1815b45d4e9979eaf81cb89f299c8f79"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a1815b45d4e9979eaf81cb89f299c8f79">luci_interpreter::IntegerLSTMParams::effective_input_to_input_scale_a</a></div><div class="ttdeci">int32_t effective_input_to_input_scale_a</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00235">KernelParams.h:235</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a1ef00ac5637652bc42302b668595c14f"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a1ef00ac5637652bc42302b668595c14f">luci_interpreter::IntegerLSTMParams::effective_recurrent_to_output_scale_a</a></div><div class="ttdeci">int32_t effective_recurrent_to_output_scale_a</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00262">KernelParams.h:262</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a27867e3ab1cbefb506f3d384587b5a32"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a27867e3ab1cbefb506f3d384587b5a32">luci_interpreter::IntegerLSTMParams::effective_proj_scale_a</a></div><div class="ttdeci">int32_t effective_proj_scale_a</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00268">KernelParams.h:268</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a34cb17f71c767ce6ad0b60daeec89c18"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a34cb17f71c767ce6ad0b60daeec89c18">luci_interpreter::IntegerLSTMParams::output_variance_guard</a></div><div class="ttdeci">int32_t output_variance_guard</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00291">KernelParams.h:291</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a38de4e598127e2fb764fce6a21c2fc9e"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a38de4e598127e2fb764fce6a21c2fc9e">luci_interpreter::IntegerLSTMParams::effective_recurrent_to_input_scale_a</a></div><div class="ttdeci">int32_t effective_recurrent_to_input_scale_a</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00238">KernelParams.h:238</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a397af438d6a1e7051cd78da4dbb743ba"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a397af438d6a1e7051cd78da4dbb743ba">luci_interpreter::IntegerLSTMParams::effective_recurrent_to_output_scale_b</a></div><div class="ttdeci">int32_t effective_recurrent_to_output_scale_b</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00263">KernelParams.h:263</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a3a42233043f3d11e76ff7e5a48b98609"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a3a42233043f3d11e76ff7e5a48b98609">luci_interpreter::IntegerLSTMParams::input_to_input_effective_bias</a></div><div class="ttdeci">std::vector&lt; int32_t &gt; input_to_input_effective_bias</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00299">KernelParams.h:299</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a3fed6619c9e6f648f17f00aa5af6aacd"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a3fed6619c9e6f648f17f00aa5af6aacd">luci_interpreter::IntegerLSTMParams::effective_hidden_scale_b</a></div><div class="ttdeci">int32_t effective_hidden_scale_b</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00272">KernelParams.h:272</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a436a706c17cf37479593607220ff0aab"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a436a706c17cf37479593607220ff0aab">luci_interpreter::IntegerLSTMParams::effective_input_to_output_scale_a</a></div><div class="ttdeci">int32_t effective_input_to_output_scale_a</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00259">KernelParams.h:259</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a4f17d869e9a7e018549d323949d507e8"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a4f17d869e9a7e018549d323949d507e8">luci_interpreter::IntegerLSTMParams::layer_norm_forget_scale_a</a></div><div class="ttdeci">int32_t layer_norm_forget_scale_a</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00277">KernelParams.h:277</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a5230bd10273c2df881d2992ca89d764d"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a5230bd10273c2df881d2992ca89d764d">luci_interpreter::IntegerLSTMParams::input_to_forget_effective_bias</a></div><div class="ttdeci">std::vector&lt; int32_t &gt; input_to_forget_effective_bias</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00293">KernelParams.h:293</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a63778507ff2e28c090b2937fba31cbf2"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a63778507ff2e28c090b2937fba31cbf2">luci_interpreter::IntegerLSTMParams::layer_norm_cell_scale_b</a></div><div class="ttdeci">int32_t layer_norm_cell_scale_b</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00281">KernelParams.h:281</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a66f2874ced3aa8934bf0ee93ae61cec0"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a66f2874ced3aa8934bf0ee93ae61cec0">luci_interpreter::IntegerLSTMParams::input_to_output_effective_bias</a></div><div class="ttdeci">std::vector&lt; int32_t &gt; input_to_output_effective_bias</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00297">KernelParams.h:297</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a6e524defb86176d1c87074f90d30b6fc"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a6e524defb86176d1c87074f90d30b6fc">luci_interpreter::IntegerLSTMParams::effective_cell_to_forget_scale_a</a></div><div class="ttdeci">int32_t effective_cell_to_forget_scale_a</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00250">KernelParams.h:250</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a72134384372348fba20502cd12af5fe9"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a72134384372348fba20502cd12af5fe9">luci_interpreter::IntegerLSTMParams::projection_effective_bias</a></div><div class="ttdeci">std::vector&lt; int32_t &gt; projection_effective_bias</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00301">KernelParams.h:301</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a7429f0edf41d6c2ffce4987830d31235"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a7429f0edf41d6c2ffce4987830d31235">luci_interpreter::IntegerLSTMParams::effective_recurrent_to_cell_scale_b</a></div><div class="ttdeci">int32_t effective_recurrent_to_cell_scale_b</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00257">KernelParams.h:257</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a760916e38abee7495fa35d198ba96008"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a760916e38abee7495fa35d198ba96008">luci_interpreter::IntegerLSTMParams::effective_cell_to_output_scale_b</a></div><div class="ttdeci">int32_t effective_cell_to_output_scale_b</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00266">KernelParams.h:266</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a786a7d187a322aab6e8d07bfb157c834"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a786a7d187a322aab6e8d07bfb157c834">luci_interpreter::IntegerLSTMParams::effective_recurrent_to_forget_scale_a</a></div><div class="ttdeci">int32_t effective_recurrent_to_forget_scale_a</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00247">KernelParams.h:247</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a78b06d907d35a460555947d9ce6b6192"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a78b06d907d35a460555947d9ce6b6192">luci_interpreter::IntegerLSTMParams::effective_proj_scale_b</a></div><div class="ttdeci">int32_t effective_proj_scale_b</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00269">KernelParams.h:269</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a7a79444954718b6ec2b01bb61afcd40b"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a7a79444954718b6ec2b01bb61afcd40b">luci_interpreter::IntegerLSTMParams::recurrent_to_output_effective_bias</a></div><div class="ttdeci">std::vector&lt; int32_t &gt; recurrent_to_output_effective_bias</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00298">KernelParams.h:298</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a8462a1a6cced18ac3a6b82306bfcc780"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a8462a1a6cced18ac3a6b82306bfcc780">luci_interpreter::IntegerLSTMParams::quantized_cell_clip</a></div><div class="ttdeci">int16_t quantized_cell_clip</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00231">KernelParams.h:231</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a88ce1ec27fc97e74415f066b281bcb71"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a88ce1ec27fc97e74415f066b281bcb71">luci_interpreter::IntegerLSTMParams::effective_input_to_cell_scale_b</a></div><div class="ttdeci">int32_t effective_input_to_cell_scale_b</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00254">KernelParams.h:254</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a88d966314f5bce1f3dab6a948436f409"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a88d966314f5bce1f3dab6a948436f409">luci_interpreter::IntegerLSTMParams::recurrent_to_input_effective_bias</a></div><div class="ttdeci">std::vector&lt; int32_t &gt; recurrent_to_input_effective_bias</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00300">KernelParams.h:300</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a8f050cf3537363681b3aff86395f7813"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a8f050cf3537363681b3aff86395f7813">luci_interpreter::IntegerLSTMParams::effective_input_to_output_scale_b</a></div><div class="ttdeci">int32_t effective_input_to_output_scale_b</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00260">KernelParams.h:260</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a9179415a87f49b1efd429c501c20432c"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a9179415a87f49b1efd429c501c20432c">luci_interpreter::IntegerLSTMParams::hidden_zp</a></div><div class="ttdeci">int32_t hidden_zp</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00286">KernelParams.h:286</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_a9686553df691e2b1b8c716615f13753e"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#a9686553df691e2b1b8c716615f13753e">luci_interpreter::IntegerLSTMParams::effective_recurrent_to_input_scale_b</a></div><div class="ttdeci">int32_t effective_recurrent_to_input_scale_b</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00239">KernelParams.h:239</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_aa121ea209ac56e9b152ea2b7a8818715"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#aa121ea209ac56e9b152ea2b7a8818715">luci_interpreter::IntegerLSTMParams::layer_norm_cell_scale_a</a></div><div class="ttdeci">int32_t layer_norm_cell_scale_a</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00280">KernelParams.h:280</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_aab48dc57abe245d257c35cc1c6ad7354"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#aab48dc57abe245d257c35cc1c6ad7354">luci_interpreter::IntegerLSTMParams::effective_input_to_input_scale_b</a></div><div class="ttdeci">int32_t effective_input_to_input_scale_b</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00236">KernelParams.h:236</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_aab68f6adb9ab9fbdcb02b1561939f623"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#aab68f6adb9ab9fbdcb02b1561939f623">luci_interpreter::IntegerLSTMParams::effective_cell_to_forget_scale_b</a></div><div class="ttdeci">int32_t effective_cell_to_forget_scale_b</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00251">KernelParams.h:251</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_aacc97958d62163e8f69f44703bd2b411"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#aacc97958d62163e8f69f44703bd2b411">luci_interpreter::IntegerLSTMParams::effective_cell_to_input_scale_b</a></div><div class="ttdeci">int32_t effective_cell_to_input_scale_b</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00242">KernelParams.h:242</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_aad3a135d4309854e3ca3ffcf375aa07a"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#aad3a135d4309854e3ca3ffcf375aa07a">luci_interpreter::IntegerLSTMParams::effective_input_to_forget_scale_a</a></div><div class="ttdeci">int32_t effective_input_to_forget_scale_a</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00244">KernelParams.h:244</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_ab7664e69aed93448fcc3bae80cff7b57"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#ab7664e69aed93448fcc3bae80cff7b57">luci_interpreter::IntegerLSTMParams::cell_scale</a></div><div class="ttdeci">int cell_scale</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00233">KernelParams.h:233</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_abb27a971ebf03b639b8c9206fdaa392f"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#abb27a971ebf03b639b8c9206fdaa392f">luci_interpreter::IntegerLSTMParams::effective_hidden_scale_a</a></div><div class="ttdeci">int32_t effective_hidden_scale_a</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00271">KernelParams.h:271</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_abe40c57692043111c35301789a9218e6"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#abe40c57692043111c35301789a9218e6">luci_interpreter::IntegerLSTMParams::effective_cell_to_input_scale_a</a></div><div class="ttdeci">int32_t effective_cell_to_input_scale_a</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00241">KernelParams.h:241</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_ac0c85d53bd0a78802d42a9493616fa9e"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#ac0c85d53bd0a78802d42a9493616fa9e">luci_interpreter::IntegerLSTMParams::layer_norm_input_scale_a</a></div><div class="ttdeci">int32_t layer_norm_input_scale_a</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00274">KernelParams.h:274</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_ac3690c9c36794675982ba9ec3607f8b7"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#ac3690c9c36794675982ba9ec3607f8b7">luci_interpreter::IntegerLSTMParams::layer_norm_output_scale_b</a></div><div class="ttdeci">int32_t layer_norm_output_scale_b</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00284">KernelParams.h:284</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_ac8ddd6f032f01eaefa39a8a1259e900d"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#ac8ddd6f032f01eaefa39a8a1259e900d">luci_interpreter::IntegerLSTMParams::quantized_proj_clip</a></div><div class="ttdeci">int8_t quantized_proj_clip</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00232">KernelParams.h:232</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_ad4ee84a5a78c2c9dfe7fabe78b9388d1"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#ad4ee84a5a78c2c9dfe7fabe78b9388d1">luci_interpreter::IntegerLSTMParams::forget_variance_guard</a></div><div class="ttdeci">int32_t forget_variance_guard</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00289">KernelParams.h:289</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_adc38a56e44f8a3e6550bc80bfaca363e"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#adc38a56e44f8a3e6550bc80bfaca363e">luci_interpreter::IntegerLSTMParams::effective_input_to_forget_scale_b</a></div><div class="ttdeci">int32_t effective_input_to_forget_scale_b</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00245">KernelParams.h:245</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_add6e3338ffe810eff38750897882d35c"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#add6e3338ffe810eff38750897882d35c">luci_interpreter::IntegerLSTMParams::input_to_cell_effective_bias</a></div><div class="ttdeci">std::vector&lt; int32_t &gt; input_to_cell_effective_bias</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00295">KernelParams.h:295</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_ae8b58fbab6226ddb2b3d5b972ca47a3d"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#ae8b58fbab6226ddb2b3d5b972ca47a3d">luci_interpreter::IntegerLSTMParams::effective_recurrent_to_cell_scale_a</a></div><div class="ttdeci">int32_t effective_recurrent_to_cell_scale_a</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00256">KernelParams.h:256</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_ae922b35a1ae080073fce915fb42eb4c7"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#ae922b35a1ae080073fce915fb42eb4c7">luci_interpreter::IntegerLSTMParams::cell_variance_guard</a></div><div class="ttdeci">int32_t cell_variance_guard</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00290">KernelParams.h:290</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_af8e50735cb0b964413f1c273220131d6"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#af8e50735cb0b964413f1c273220131d6">luci_interpreter::IntegerLSTMParams::recurrent_to_cell_effective_bias</a></div><div class="ttdeci">std::vector&lt; int32_t &gt; recurrent_to_cell_effective_bias</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00296">KernelParams.h:296</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_af9a05c5052c25714265807ee320bc966"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#af9a05c5052c25714265807ee320bc966">luci_interpreter::IntegerLSTMParams::input_variance_guard</a></div><div class="ttdeci">int32_t input_variance_guard</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00288">KernelParams.h:288</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_afde0dc24fcf4a78b859be82f28632b61"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#afde0dc24fcf4a78b859be82f28632b61">luci_interpreter::IntegerLSTMParams::layer_norm_input_scale_b</a></div><div class="ttdeci">int32_t layer_norm_input_scale_b</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00275">KernelParams.h:275</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_aff505a21fe1205ce8de8d6349274d1be"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#aff505a21fe1205ce8de8d6349274d1be">luci_interpreter::IntegerLSTMParams::layer_norm_forget_scale_b</a></div><div class="ttdeci">int32_t layer_norm_forget_scale_b</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00278">KernelParams.h:278</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_integer_l_s_t_m_params_html_affdebdc0521280db0be1bec0434c04e4"><div class="ttname"><a href="structluci__interpreter_1_1_integer_l_s_t_m_params.html#affdebdc0521280db0be1bec0434c04e4">luci_interpreter::IntegerLSTMParams::effective_cell_to_output_scale_a</a></div><div class="ttdeci">int32_t effective_cell_to_output_scale_a</div><div class="ttdef"><b>Definition:</b> <a href="onert-micro_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00265">KernelParams.h:265</a></div></div>
<div class="ttc" id="astructluci__interpreter_1_1_unidirectional_sequence_l_s_t_m_params_html"><div class="ttname"><a href="structluci__interpreter_1_1_unidirectional_sequence_l_s_t_m_params.html">luci_interpreter::UnidirectionalSequenceLSTMParams</a></div><div class="ttdef"><b>Definition:</b> <a href="compiler_2luci-interpreter_2src_2core_2_kernel_params_8h_source.html#l00221">KernelParams.h:222</a></div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_2f1d0fa04477eba32645101cc39c87e0.html">onert-micro</a></li><li class="navelem"><a class="el" href="dir_ce4f6825df8839c6a8b44d3d97c3a322.html">luci-interpreter</a></li><li class="navelem"><a class="el" href="dir_b1874143933efc2bfd7e96bdea4da454.html">pal</a></li><li class="navelem"><a class="el" href="dir_132de01d1c06e6c7d9be57d5e7d50eec.html">mcu</a></li><li class="navelem"><a class="el" href="mcu_2_p_a_l_unidirectional_sequence_l_s_t_m_8h.html">PALUnidirectionalSequenceLSTM.h</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.5 </li>
  </ul>
</div>
</body>
</html>
