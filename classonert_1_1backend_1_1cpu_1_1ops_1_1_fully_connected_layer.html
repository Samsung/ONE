<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ONE - On-device Neural Engine: onert::backend::cpu::ops::FullyConnectedLayer Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">ONE - On-device Neural Engine
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pro-attribs">Protected Attributes</a>  </div>
  <div class="headertitle"><div class="title">onert::backend::cpu::ops::FullyConnectedLayer Class Reference</div></div>
</div><!--header-->
<div class="contents">

<p><code>#include &lt;<a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html">FullyConnectedLayer.h</a>&gt;</code></p>
<div class="dynheader">
Collaboration diagram for onert::backend::cpu::ops::FullyConnectedLayer:</div>
<div class="dyncontent">
<div class="center"><img src="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer__coll__graph.png" border="0" usemap="#aonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_coll__map" alt="Collaboration graph"/></div>
<map name="aonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_coll__map" id="aonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_coll__map">
<area shape="rect" title=" " alt="" coords="11,243,186,283"/>
<area shape="rect" href="classonert_1_1exec_1_1_i_function.html" title=" " alt="" coords="5,102,149,127"/>
<area shape="poly" title=" " alt="" coords="84,142,98,242,93,243,78,143"/>
<area shape="rect" href="classonert_1_1backend_1_1_i_portable_tensor.html" title="A tensor class that is portable for other backends." alt="" coords="173,94,336,135"/>
<area shape="poly" title=" " alt="" coords="225,147,121,244,117,240,221,143"/>
<area shape="rect" href="classonert_1_1backend_1_1_i_tensor.html" title=" " alt="" coords="91,5,247,31"/>
<area shape="poly" title=" " alt="" coords="192,41,238,92,235,95,188,44"/>
<area shape="rect" href="classonert_1_1ir_1_1_operand_info.html" title="Class to save tensor&#39;s shape and type." alt="" coords="271,5,411,31"/>
<area shape="poly" title=" " alt="" coords="322,44,274,95,271,92,318,40"/>
</map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ab9659326558b505132635a729eb7dc26" id="r_ab9659326558b505132635a729eb7dc26"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ab9659326558b505132635a729eb7dc26">FullyConnectedLayer</a> ()</td></tr>
<tr class="separator:ab9659326558b505132635a729eb7dc26"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a822066c1d1450094011067542f0b9a0d" id="r_a822066c1d1450094011067542f0b9a0d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a822066c1d1450094011067542f0b9a0d">~FullyConnectedLayer</a> ()</td></tr>
<tr class="separator:a822066c1d1450094011067542f0b9a0d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a648618c630985a3d90aeae23ec2cdc4e" id="r_a648618c630985a3d90aeae23ec2cdc4e"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a648618c630985a3d90aeae23ec2cdc4e">fullyConnectedFloat32</a> ()</td></tr>
<tr class="separator:a648618c630985a3d90aeae23ec2cdc4e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af90252c9fc392b5b8bb7f8c0fa203741" id="r_af90252c9fc392b5b8bb7f8c0fa203741"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#af90252c9fc392b5b8bb7f8c0fa203741">fullyConnectedQuant8</a> ()</td></tr>
<tr class="separator:af90252c9fc392b5b8bb7f8c0fa203741"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea2f03e86f6d110ff8a1eaae0caa8d82" id="r_aea2f03e86f6d110ff8a1eaae0caa8d82"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aea2f03e86f6d110ff8a1eaae0caa8d82">fullyConnectedHybrid</a> ()</td></tr>
<tr class="separator:aea2f03e86f6d110ff8a1eaae0caa8d82"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a27ebc09cfe60bf438b6ac2b831d0a8b5" id="r_a27ebc09cfe60bf438b6ac2b831d0a8b5"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a27ebc09cfe60bf438b6ac2b831d0a8b5">fullyConnectedSparseWeight</a> ()</td></tr>
<tr class="separator:a27ebc09cfe60bf438b6ac2b831d0a8b5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2006db79e45053eb357f55af95471524" id="r_a2006db79e45053eb357f55af95471524"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2006db79e45053eb357f55af95471524">fullyConnected16x1Float32</a> ()</td></tr>
<tr class="separator:a2006db79e45053eb357f55af95471524"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aee0f4ff5a4e1d31c65f4346494499e82" id="r_aee0f4ff5a4e1d31c65f4346494499e82"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aee0f4ff5a4e1d31c65f4346494499e82">configure</a> (const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *input, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *weights, const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *bias, <a class="el" href="namespaceonert_1_1ir.html#a8ce6c92ea138aca1332e4be9531bd5d4">ir::Activation</a> activation, <a class="el" href="namespaceonert_1_1ir.html#a4dc82d1ced0dff0fcabe7e74d6c76c19">ir::FullyConnectedWeightsFormat</a> weights_format, <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *output, const std::shared_ptr&lt; <a class="el" href="classonert_1_1backend_1_1cpu_1_1_external_context.html">ExternalContext</a> &gt; &amp;external_context)</td></tr>
<tr class="separator:aee0f4ff5a4e1d31c65f4346494499e82"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff0e02437f1e864effa060ca8ea19bc1" id="r_aff0e02437f1e864effa060ca8ea19bc1"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aff0e02437f1e864effa060ca8ea19bc1">run</a> () override</td></tr>
<tr class="separator:aff0e02437f1e864effa060ca8ea19bc1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab5fc53c26dd7f5863daed38d58cd7c18" id="r_ab5fc53c26dd7f5863daed38d58cd7c18"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ab5fc53c26dd7f5863daed38d58cd7c18">prepare</a> () override</td></tr>
<tr class="separator:ab5fc53c26dd7f5863daed38d58cd7c18"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classonert_1_1exec_1_1_i_function"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classonert_1_1exec_1_1_i_function')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classonert_1_1exec_1_1_i_function.html">onert::exec::IFunction</a></td></tr>
<tr class="memitem:ae05c7341d5ee2cac795f17d4b735cbfd inherit pub_methods_classonert_1_1exec_1_1_i_function" id="r_ae05c7341d5ee2cac795f17d4b735cbfd"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1exec_1_1_i_function.html#ae05c7341d5ee2cac795f17d4b735cbfd">~IFunction</a> ()=default</td></tr>
<tr class="separator:ae05c7341d5ee2cac795f17d4b735cbfd inherit pub_methods_classonert_1_1exec_1_1_i_function"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pro-attribs" name="pro-attribs"></a>
Protected Attributes</h2></td></tr>
<tr class="memitem:ad20b91c5fd9f048ca2b7b650b4e9d95e" id="r_ad20b91c5fd9f048ca2b7b650b4e9d95e"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a></td></tr>
<tr class="separator:ad20b91c5fd9f048ca2b7b650b4e9d95e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2b1775533510102ae7787082bc588439" id="r_a2b1775533510102ae7787082bc588439"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a></td></tr>
<tr class="separator:a2b1775533510102ae7787082bc588439"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a351b6a5cfcc2725297d58b5ee21fd938" id="r_a351b6a5cfcc2725297d58b5ee21fd938"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a></td></tr>
<tr class="separator:a351b6a5cfcc2725297d58b5ee21fd938"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a77947469291a9e32a6daa860cc1de1de" id="r_a77947469291a9e32a6daa860cc1de1de"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">_output</a></td></tr>
<tr class="separator:a77947469291a9e32a6daa860cc1de1de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0c9bd8a18a3685d051e1b1a0d1f287f6" id="r_a0c9bd8a18a3685d051e1b1a0d1f287f6"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespaceonert_1_1ir.html#a8ce6c92ea138aca1332e4be9531bd5d4">ir::Activation</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a0c9bd8a18a3685d051e1b1a0d1f287f6">_activation</a></td></tr>
<tr class="separator:a0c9bd8a18a3685d051e1b1a0d1f287f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e0cacbbb55a70e80c8ec2b635d9956d" id="r_a8e0cacbbb55a70e80c8ec2b635d9956d"><td class="memItemLeft" align="right" valign="top">std::unique_ptr&lt; <a class="el" href="classnnfw_1_1cker_1_1_f_c_temp_arena.html">nnfw::cker::FCTempArena</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a8e0cacbbb55a70e80c8ec2b635d9956d">_temp_arena</a></td></tr>
<tr class="separator:a8e0cacbbb55a70e80c8ec2b635d9956d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa7430715d3e0ce6f565e0907b4b07732" id="r_aa7430715d3e0ce6f565e0907b4b07732"><td class="memItemLeft" align="right" valign="top">std::shared_ptr&lt; <a class="el" href="classonert_1_1backend_1_1cpu_1_1_external_context.html">ExternalContext</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aa7430715d3e0ce6f565e0907b4b07732">_external_context</a></td></tr>
<tr class="separator:aa7430715d3e0ce6f565e0907b4b07732"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9396777fe8ae35b050ace67e923f15e7" id="r_a9396777fe8ae35b050ace67e923f15e7"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a9396777fe8ae35b050ace67e923f15e7">_is_hybrid</a>: 1</td></tr>
<tr class="separator:a9396777fe8ae35b050ace67e923f15e7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a576d08d56b68f41f9347fa0dca4f0078" id="r_a576d08d56b68f41f9347fa0dca4f0078"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a576d08d56b68f41f9347fa0dca4f0078">_is_shuffled16x1float32</a>: 1</td></tr>
<tr class="separator:a576d08d56b68f41f9347fa0dca4f0078"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock">
<p class="definition">Definition at line <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00043">43</a> of file <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html">FullyConnectedLayer.h</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="ab9659326558b505132635a729eb7dc26" name="ab9659326558b505132635a729eb7dc26"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab9659326558b505132635a729eb7dc26">&#9670;&#160;</a></span>FullyConnectedLayer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">onert::backend::cpu::ops::FullyConnectedLayer::FullyConnectedLayer </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00033">33</a> of file <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html">FullyConnectedLayer.cc</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   34</span>  : <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>(<span class="keyword">nullptr</span>), <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>(<span class="keyword">nullptr</span>), <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a>(<span class="keyword">nullptr</span>), <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">_output</a>(<span class="keyword">nullptr</span>),</div>
<div class="line"><span class="lineno">   35</span>    <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a0c9bd8a18a3685d051e1b1a0d1f287f6">_activation</a>(<a class="code hl_enumvalue" href="namespaceonert_1_1ir.html#a8ce6c92ea138aca1332e4be9531bd5d4ab50339a10e1de285ac99d4c3990b8693">ir::Activation::NONE</a>), <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a8e0cacbbb55a70e80c8ec2b635d9956d">_temp_arena</a>(<span class="keyword">new</span> <a class="code hl_class" href="classnnfw_1_1cker_1_1_f_c_temp_arena.html">nnfw::cker::FCTempArena</a>()),</div>
<div class="line"><span class="lineno">   36</span>    <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aa7430715d3e0ce6f565e0907b4b07732">_external_context</a>(<span class="keyword">nullptr</span>), <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a9396777fe8ae35b050ace67e923f15e7">_is_hybrid</a>(<span class="keyword">false</span>), <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a576d08d56b68f41f9347fa0dca4f0078">_is_shuffled16x1float32</a>(<span class="keyword">false</span>)</div>
<div class="line"><span class="lineno">   37</span>{</div>
<div class="line"><span class="lineno">   38</span>  <span class="comment">// DO NOTHING</span></div>
<div class="line"><span class="lineno">   39</span>}</div>
<div class="ttc" id="aclassnnfw_1_1cker_1_1_f_c_temp_arena_html"><div class="ttname"><a href="classnnfw_1_1cker_1_1_f_c_temp_arena.html">nnfw::cker::FCTempArena</a></div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h_source.html#l00036">FullyConnected.h:37</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_a0c9bd8a18a3685d051e1b1a0d1f287f6"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a0c9bd8a18a3685d051e1b1a0d1f287f6">onert::backend::cpu::ops::FullyConnectedLayer::_activation</a></div><div class="ttdeci">ir::Activation _activation</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00075">FullyConnectedLayer.h:75</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_a2b1775533510102ae7787082bc588439"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">onert::backend::cpu::ops::FullyConnectedLayer::_weights</a></div><div class="ttdeci">const IPortableTensor * _weights</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00071">FullyConnectedLayer.h:71</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_a351b6a5cfcc2725297d58b5ee21fd938"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">onert::backend::cpu::ops::FullyConnectedLayer::_bias</a></div><div class="ttdeci">const IPortableTensor * _bias</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00072">FullyConnectedLayer.h:72</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_a576d08d56b68f41f9347fa0dca4f0078"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a576d08d56b68f41f9347fa0dca4f0078">onert::backend::cpu::ops::FullyConnectedLayer::_is_shuffled16x1float32</a></div><div class="ttdeci">bool _is_shuffled16x1float32</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00081">FullyConnectedLayer.h:81</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_a77947469291a9e32a6daa860cc1de1de"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">onert::backend::cpu::ops::FullyConnectedLayer::_output</a></div><div class="ttdeci">IPortableTensor * _output</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00073">FullyConnectedLayer.h:73</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_a8e0cacbbb55a70e80c8ec2b635d9956d"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a8e0cacbbb55a70e80c8ec2b635d9956d">onert::backend::cpu::ops::FullyConnectedLayer::_temp_arena</a></div><div class="ttdeci">std::unique_ptr&lt; nnfw::cker::FCTempArena &gt; _temp_arena</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00076">FullyConnectedLayer.h:76</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_a9396777fe8ae35b050ace67e923f15e7"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a9396777fe8ae35b050ace67e923f15e7">onert::backend::cpu::ops::FullyConnectedLayer::_is_hybrid</a></div><div class="ttdeci">bool _is_hybrid</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00080">FullyConnectedLayer.h:80</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_aa7430715d3e0ce6f565e0907b4b07732"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aa7430715d3e0ce6f565e0907b4b07732">onert::backend::cpu::ops::FullyConnectedLayer::_external_context</a></div><div class="ttdeci">std::shared_ptr&lt; ExternalContext &gt; _external_context</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00078">FullyConnectedLayer.h:78</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_ad20b91c5fd9f048ca2b7b650b4e9d95e"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">onert::backend::cpu::ops::FullyConnectedLayer::_input</a></div><div class="ttdeci">const IPortableTensor * _input</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00070">FullyConnectedLayer.h:70</a></div></div>
<div class="ttc" id="anamespaceonert_1_1ir_html_a8ce6c92ea138aca1332e4be9531bd5d4ab50339a10e1de285ac99d4c3990b8693"><div class="ttname"><a href="namespaceonert_1_1ir.html#a8ce6c92ea138aca1332e4be9531bd5d4ab50339a10e1de285ac99d4c3990b8693">onert::ir::Activation::NONE</a></div><div class="ttdeci">@ NONE</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a822066c1d1450094011067542f0b9a0d" name="a822066c1d1450094011067542f0b9a0d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a822066c1d1450094011067542f0b9a0d">&#9670;&#160;</a></span>~FullyConnectedLayer()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">onert::backend::cpu::ops::FullyConnectedLayer::~FullyConnectedLayer </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">default</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="aee0f4ff5a4e1d31c65f4346494499e82" name="aee0f4ff5a4e1d31c65f4346494499e82"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aee0f4ff5a4e1d31c65f4346494499e82">&#9670;&#160;</a></span>configure()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void onert::backend::cpu::ops::FullyConnectedLayer::configure </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespaceonert_1_1ir.html#a8ce6c92ea138aca1332e4be9531bd5d4">ir::Activation</a>&#160;</td>
          <td class="paramname"><em>activation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespaceonert_1_1ir.html#a4dc82d1ced0dff0fcabe7e74d6c76c19">ir::FullyConnectedWeightsFormat</a>&#160;</td>
          <td class="paramname"><em>weights_format</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::shared_ptr&lt; <a class="el" href="classonert_1_1backend_1_1cpu_1_1_external_context.html">ExternalContext</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>external_context</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00198">198</a> of file <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html">FullyConnectedLayer.cc</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  203</span>{</div>
<div class="line"><span class="lineno">  204</span>  <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a> = <a class="code hl_enumvalue" href="namespacemir__caffe.html#a80d91a921af9e0cb352bf83b19ed18c8aa43c1b0aa53a0c908810c06ab1ff3967">input</a>;</div>
<div class="line"><span class="lineno">  205</span>  <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a> = weights;</div>
<div class="line"><span class="lineno">  206</span>  <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a> = <a class="code hl_enumvalue" href="namespacemir__caffe.html#a80d91a921af9e0cb352bf83b19ed18c8a1603f79f250bd05d84dcb190bee408bc">bias</a>;</div>
<div class="line"><span class="lineno">  207</span>  <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a0c9bd8a18a3685d051e1b1a0d1f287f6">_activation</a> = activation;</div>
<div class="line"><span class="lineno">  208</span>  <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">_output</a> = <a class="code hl_variable" href="namespacegen__h5__explicit__inputs__all.html#a16463a18a337afa452ad5ea77ff25c71">output</a>;</div>
<div class="line"><span class="lineno">  209</span>  <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a9396777fe8ae35b050ace67e923f15e7">_is_hybrid</a> = <a class="code hl_enumvalue" href="namespacemir__caffe.html#a80d91a921af9e0cb352bf83b19ed18c8aa43c1b0aa53a0c908810c06ab1ff3967">input</a>-&gt;data_type() == OperandType::FLOAT32 &amp;&amp;</div>
<div class="line"><span class="lineno">  210</span>               weights-&gt;data_type() == OperandType::QUANT_INT8_SYMM;</div>
<div class="line"><span class="lineno">  211</span>  <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a576d08d56b68f41f9347fa0dca4f0078">_is_shuffled16x1float32</a> = weights_format == <a class="code hl_enumvalue" href="namespaceonert_1_1ir.html#a4dc82d1ced0dff0fcabe7e74d6c76c19a00d4e131097ee909d6bcf8f8e05ac93b">ir::FullyConnectedWeightsFormat::Shuffled16x1Float32</a>;</div>
<div class="line"><span class="lineno">  212</span><span class="preprocessor">#if !defined(__aarch64__) || !defined(USE_NEON)</span></div>
<div class="line"><span class="lineno">  213</span>  <span class="keywordflow">if</span> (<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a576d08d56b68f41f9347fa0dca4f0078">_is_shuffled16x1float32</a>)</div>
<div class="line"><span class="lineno">  214</span>  {</div>
<div class="line"><span class="lineno">  215</span>    <span class="keywordflow">throw</span> std::runtime_error{</div>
<div class="line"><span class="lineno">  216</span>      <span class="stringliteral">&quot;FullyConnected: Shuffled16x1Float32 weights_format is not supported.&quot;</span>};</div>
<div class="line"><span class="lineno">  217</span>  }</div>
<div class="line"><span class="lineno">  218</span><span class="preprocessor">#endif</span></div>
<div class="line"><span class="lineno">  219</span>  <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aa7430715d3e0ce6f565e0907b4b07732">_external_context</a> = external_context;</div>
<div class="line"><span class="lineno">  220</span>}</div>
<div class="ttc" id="anamespacegen__h5__explicit__inputs__all_html_a16463a18a337afa452ad5ea77ff25c71"><div class="ttname"><a href="namespacegen__h5__explicit__inputs__all.html#a16463a18a337afa452ad5ea77ff25c71">gen_h5_explicit_inputs_all.output</a></div><div class="ttdeci">output</div><div class="ttdef"><b>Definition</b> <a href="gen__h5__explicit__inputs__all_8py_source.html#l00099">gen_h5_explicit_inputs_all.py:99</a></div></div>
<div class="ttc" id="anamespacemir__caffe_html_a80d91a921af9e0cb352bf83b19ed18c8a1603f79f250bd05d84dcb190bee408bc"><div class="ttname"><a href="namespacemir__caffe.html#a80d91a921af9e0cb352bf83b19ed18c8a1603f79f250bd05d84dcb190bee408bc">mir_caffe::CaffeOpType::bias</a></div><div class="ttdeci">@ bias</div></div>
<div class="ttc" id="anamespacemir__caffe_html_a80d91a921af9e0cb352bf83b19ed18c8aa43c1b0aa53a0c908810c06ab1ff3967"><div class="ttname"><a href="namespacemir__caffe.html#a80d91a921af9e0cb352bf83b19ed18c8aa43c1b0aa53a0c908810c06ab1ff3967">mir_caffe::CaffeOpType::input</a></div><div class="ttdeci">@ input</div></div>
<div class="ttc" id="anamespaceonert_1_1ir_html_a4dc82d1ced0dff0fcabe7e74d6c76c19a00d4e131097ee909d6bcf8f8e05ac93b"><div class="ttname"><a href="namespaceonert_1_1ir.html#a4dc82d1ced0dff0fcabe7e74d6c76c19a00d4e131097ee909d6bcf8f8e05ac93b">onert::ir::FullyConnectedWeightsFormat::Shuffled16x1Float32</a></div><div class="ttdeci">@ Shuffled16x1Float32</div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00075">_activation</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00072">_bias</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00078">_external_context</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00070">_input</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00080">_is_hybrid</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00081">_is_shuffled16x1float32</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00073">_output</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00071">_weights</a>, <a class="el" href="classonert_1_1backend_1_1_i_tensor.html#a6d57b178316225a9e08f1191ce489ad9">onert::backend::ITensor::data_type()</a>, and <a class="el" href="namespaceonert_1_1ir.html#a4dc82d1ced0dff0fcabe7e74d6c76c19a00d4e131097ee909d6bcf8f8e05ac93b">onert::ir::Shuffled16x1Float32</a>.</p>

</div>
</div>
<a id="a2006db79e45053eb357f55af95471524" name="a2006db79e45053eb357f55af95471524"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2006db79e45053eb357f55af95471524">&#9670;&#160;</a></span>fullyConnected16x1Float32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void onert::backend::cpu::ops::FullyConnectedLayer::fullyConnected16x1Float32 </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00180">180</a> of file <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html">FullyConnectedLayer.cc</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  181</span>{</div>
<div class="line"><span class="lineno">  182</span><span class="preprocessor">#if defined(__aarch64__) &amp;&amp; defined(USE_NEON)</span></div>
<div class="line"><span class="lineno">  183</span>  <span class="keywordtype">float</span> output_activation_min = 0, output_activation_max = 0;</div>
<div class="line"><span class="lineno">  184</span>  <a class="code hl_function" href="namespaceonert_1_1util.html#a9aac61f35b6d507552fea7bd8ac070ab">CalculateActivationRange</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a0c9bd8a18a3685d051e1b1a0d1f287f6">_activation</a>, &amp;output_activation_min, &amp;output_activation_max);</div>
<div class="line"><span class="lineno">  185</span> </div>
<div class="line"><span class="lineno">  186</span>  <a class="code hl_struct" href="structnnfw_1_1cker_1_1_fully_connected_params.html">nnfw::cker::FullyConnectedParams</a> op_params;</div>
<div class="line"><span class="lineno">  187</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a15410fd240c7d16cdeaca54856b712c8">activation</a> = <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a0e7672ebf55bbaa7e1d86a46cfd53c5e">convertActivationType</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a0c9bd8a18a3685d051e1b1a0d1f287f6">_activation</a>);</div>
<div class="line"><span class="lineno">  188</span> </div>
<div class="line"><span class="lineno">  189</span>  nnfw::cker::FullyConnected16x1Float32(op_params, <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>), getBuffer&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>),</div>
<div class="line"><span class="lineno">  190</span>                                        <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>), getBuffer&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>),</div>
<div class="line"><span class="lineno">  191</span>                                        <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a>), <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a> ? getBuffer&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a>) : nullptr,</div>
<div class="line"><span class="lineno">  192</span>                                        <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">_output</a>), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a0054916d6bc97916914b4b69c1a398e8">getBuffer</a>&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">_output</a>));</div>
<div class="line"><span class="lineno">  193</span><span class="preprocessor">#else</span></div>
<div class="line"><span class="lineno">  194</span>  <span class="keywordflow">throw</span> std::runtime_error{<span class="stringliteral">&quot;FullyConnected: Shuffled16x1Float32 weights_format is not supported.&quot;</span>};</div>
<div class="line"><span class="lineno">  195</span><span class="preprocessor">#endif</span></div>
<div class="line"><span class="lineno">  196</span>}</div>
<div class="ttc" id="anamespaceonert_1_1backend_1_1cpu_1_1ops_html_a0054916d6bc97916914b4b69c1a398e8"><div class="ttname"><a href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a0054916d6bc97916914b4b69c1a398e8">onert::backend::cpu::ops::getBuffer</a></div><div class="ttdeci">const T * getBuffer(const IPortableTensor *tensor)</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_operation_utils_8h_source.html#l00182">OperationUtils.h:182</a></div></div>
<div class="ttc" id="anamespaceonert_1_1backend_1_1cpu_1_1ops_html_a0e7672ebf55bbaa7e1d86a46cfd53c5e"><div class="ttname"><a href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a0e7672ebf55bbaa7e1d86a46cfd53c5e">onert::backend::cpu::ops::convertActivationType</a></div><div class="ttdeci">nnfw::cker::FusedActivationFunctionType convertActivationType(const ir::Activation activation)</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_operation_utils_8h_source.html#l00114">OperationUtils.h:114</a></div></div>
<div class="ttc" id="anamespaceonert_1_1backend_1_1cpu_1_1ops_html_a1cfb53087f7fc161b9162d65aa5520d9"><div class="ttname"><a href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">onert::backend::cpu::ops::getShape</a></div><div class="ttdeci">nnfw::cker::Shape getShape(const IPortableTensor *tensor)</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_operation_utils_8h_source.html#l00094">OperationUtils.h:94</a></div></div>
<div class="ttc" id="anamespaceonert_1_1util_html_a9aac61f35b6d507552fea7bd8ac070ab"><div class="ttname"><a href="namespaceonert_1_1util.html#a9aac61f35b6d507552fea7bd8ac070ab">onert::util::CalculateActivationRange</a></div><div class="ttdeci">void CalculateActivationRange(ir::Activation activation, T *activation_min, T *activation_max)</div><div class="ttdef"><b>Definition</b> <a href="_calculate_activation_range_8h_source.html#l00030">CalculateActivationRange.h:30</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html">nnfw::cker::FullyConnectedParams</a></div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00247">Types.h:248</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_a15410fd240c7d16cdeaca54856b712c8"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#a15410fd240c7d16cdeaca54856b712c8">nnfw::cker::FullyConnectedParams::activation</a></div><div class="ttdeci">FusedActivationFunctionType activation</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00249">Types.h:249</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00075">_activation</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00072">_bias</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00070">_input</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00073">_output</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00071">_weights</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00249">nnfw::cker::FullyConnectedParams::activation</a>, <a class="el" href="_calculate_activation_range_8h_source.html#l00030">onert::util::CalculateActivationRange()</a>, <a class="el" href="cpu_2ops_2_operation_utils_8h_source.html#l00114">onert::backend::cpu::ops::convertActivationType()</a>, and <a class="el" href="cpu_2ops_2_operation_utils_8h_source.html#l00094">onert::backend::cpu::ops::getShape()</a>.</p>

<p class="reference">Referenced by <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00222">run()</a>.</p>

</div>
</div>
<a id="a648618c630985a3d90aeae23ec2cdc4e" name="a648618c630985a3d90aeae23ec2cdc4e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a648618c630985a3d90aeae23ec2cdc4e">&#9670;&#160;</a></span>fullyConnectedFloat32()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void onert::backend::cpu::ops::FullyConnectedLayer::fullyConnectedFloat32 </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00043">43</a> of file <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html">FullyConnectedLayer.cc</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   44</span>{</div>
<div class="line"><span class="lineno">   45</span>  <a class="code hl_struct" href="structnnfw_1_1cker_1_1_fully_connected_params.html">nnfw::cker::FullyConnectedParams</a> op_params;</div>
<div class="line"><span class="lineno">   46</span>  <span class="keywordtype">float</span> output_activation_min = 0;</div>
<div class="line"><span class="lineno">   47</span>  <span class="keywordtype">float</span> output_activation_max = 0;</div>
<div class="line"><span class="lineno">   48</span>  <a class="code hl_function" href="namespaceonert_1_1util.html#a9aac61f35b6d507552fea7bd8ac070ab">CalculateActivationRange</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a0c9bd8a18a3685d051e1b1a0d1f287f6">_activation</a>, &amp;output_activation_min, &amp;output_activation_max);</div>
<div class="line"><span class="lineno">   49</span> </div>
<div class="line"><span class="lineno">   50</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a15410fd240c7d16cdeaca54856b712c8">activation</a> = <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a0e7672ebf55bbaa7e1d86a46cfd53c5e">convertActivationType</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a0c9bd8a18a3685d051e1b1a0d1f287f6">_activation</a>);</div>
<div class="line"><span class="lineno">   51</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a54122b18164d003566b614b051ec6682">float_activation_min</a> = output_activation_min;</div>
<div class="line"><span class="lineno">   52</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a18880d1a910e57f9bc486ff6aa9bd43b">float_activation_max</a> = output_activation_max;</div>
<div class="line"><span class="lineno">   53</span>  <span class="comment">// TODO Set both cachables as false when training</span></div>
<div class="line"><span class="lineno">   54</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a0be6785579faac1ca4e009d2943e65d9">lhs_cacheable</a> = <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#a0aa4408d72f1ea3643c386520d9eb4e3">is_constant</a>();</div>
<div class="line"><span class="lineno">   55</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a0b3e0916c736a1eca2b85ed046d6433f">rhs_cacheable</a> = <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#a0aa4408d72f1ea3643c386520d9eb4e3">is_constant</a>();</div>
<div class="line"><span class="lineno">   56</span> </div>
<div class="line"><span class="lineno">   57</span>  <a class="code hl_function" href="namespacennfw_1_1cker.html#a893434782a43556a99989be14e599d63">nnfw::cker::FullyConnected</a>(op_params, <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>), getBuffer&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>),</div>
<div class="line"><span class="lineno">   58</span>                             <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>), getBuffer&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a>),</div>
<div class="line"><span class="lineno">   59</span>                             <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a> ? getBuffer&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a>) : nullptr, <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">_output</a>),</div>
<div class="line"><span class="lineno">   60</span>                             <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a0054916d6bc97916914b4b69c1a398e8">getBuffer</a>&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">_output</a>));</div>
<div class="line"><span class="lineno">   61</span>}</div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_tensor_html_a0aa4408d72f1ea3643c386520d9eb4e3"><div class="ttname"><a href="classonert_1_1backend_1_1_i_tensor.html#a0aa4408d72f1ea3643c386520d9eb4e3">onert::backend::ITensor::is_constant</a></div><div class="ttdeci">virtual bool is_constant() const</div><div class="ttdoc">Return true if the tensor is constant.</div><div class="ttdef"><b>Definition</b> <a href="_i_tensor_8h_source.html#l00072">ITensor.h:72</a></div></div>
<div class="ttc" id="anamespacennfw_1_1cker_html_a893434782a43556a99989be14e599d63"><div class="ttname"><a href="namespacennfw_1_1cker.html#a893434782a43556a99989be14e599d63">nnfw::cker::FullyConnected</a></div><div class="ttdeci">void FullyConnected(const FullyConnectedParams &amp;params, const Shape &amp;input_shape, const float *input_data, const Shape &amp;weights_shape, const float *weights_data, const Shape &amp;, const float *bias_data, const Shape &amp;, float *output_data)</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h_source.html#l00098">FullyConnected.h:98</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_a0b3e0916c736a1eca2b85ed046d6433f"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#a0b3e0916c736a1eca2b85ed046d6433f">nnfw::cker::FullyConnectedParams::rhs_cacheable</a></div><div class="ttdeci">bool rhs_cacheable</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00266">Types.h:266</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_a0be6785579faac1ca4e009d2943e65d9"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#a0be6785579faac1ca4e009d2943e65d9">nnfw::cker::FullyConnectedParams::lhs_cacheable</a></div><div class="ttdeci">bool lhs_cacheable</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00265">Types.h:265</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_a18880d1a910e57f9bc486ff6aa9bd43b"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#a18880d1a910e57f9bc486ff6aa9bd43b">nnfw::cker::FullyConnectedParams::float_activation_max</a></div><div class="ttdeci">float float_activation_max</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00263">Types.h:263</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_a54122b18164d003566b614b051ec6682"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#a54122b18164d003566b614b051ec6682">nnfw::cker::FullyConnectedParams::float_activation_min</a></div><div class="ttdeci">float float_activation_min</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00262">Types.h:262</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00075">_activation</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00072">_bias</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00070">_input</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00073">_output</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00071">_weights</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00249">nnfw::cker::FullyConnectedParams::activation</a>, <a class="el" href="_calculate_activation_range_8h_source.html#l00030">onert::util::CalculateActivationRange()</a>, <a class="el" href="cpu_2ops_2_operation_utils_8h_source.html#l00114">onert::backend::cpu::ops::convertActivationType()</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00263">nnfw::cker::FullyConnectedParams::float_activation_max</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00262">nnfw::cker::FullyConnectedParams::float_activation_min</a>, <a class="el" href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h_source.html#l00098">nnfw::cker::FullyConnected()</a>, <a class="el" href="cpu_2ops_2_operation_utils_8h_source.html#l00094">onert::backend::cpu::ops::getShape()</a>, <a class="el" href="_i_tensor_8h_source.html#l00072">onert::backend::ITensor::is_constant()</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00265">nnfw::cker::FullyConnectedParams::lhs_cacheable</a>, and <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00266">nnfw::cker::FullyConnectedParams::rhs_cacheable</a>.</p>

<p class="reference">Referenced by <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00222">run()</a>.</p>

</div>
</div>
<a id="aea2f03e86f6d110ff8a1eaae0caa8d82" name="aea2f03e86f6d110ff8a1eaae0caa8d82"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aea2f03e86f6d110ff8a1eaae0caa8d82">&#9670;&#160;</a></span>fullyConnectedHybrid()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void onert::backend::cpu::ops::FullyConnectedLayer::fullyConnectedHybrid </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00092">92</a> of file <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html">FullyConnectedLayer.cc</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   93</span>{</div>
<div class="line"><span class="lineno">   94</span>  <a class="code hl_class" href="classnnfw_1_1cker_1_1_f_c_temp_arena.html">nnfw::cker::FCTempArena</a> &amp;temp_arena = *<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a8e0cacbbb55a70e80c8ec2b635d9956d">_temp_arena</a>;</div>
<div class="line"><span class="lineno">   95</span>  <span class="keywordflow">if</span> (!temp_arena.<a class="code hl_variable" href="classnnfw_1_1cker_1_1_f_c_temp_arena.html#a6743d412a028cb7a7021bf255274345f">prepared</a>)</div>
<div class="line"><span class="lineno">   96</span>  {</div>
<div class="line"><span class="lineno">   97</span>    temp_arena.<a class="code hl_function" href="classnnfw_1_1cker_1_1_f_c_temp_arena.html#acafeac459e58e656d39398433953b0d0">prepare</a>(<a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>));</div>
<div class="line"><span class="lineno">   98</span>  }</div>
<div class="line"><span class="lineno">   99</span> </div>
<div class="line"><span class="lineno">  100</span>  <a class="code hl_struct" href="structnnfw_1_1cker_1_1_fully_connected_params.html">nnfw::cker::FullyConnectedParams</a> op_params;</div>
<div class="line"><span class="lineno">  101</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a15410fd240c7d16cdeaca54856b712c8">activation</a> = <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a0e7672ebf55bbaa7e1d86a46cfd53c5e">convertActivationType</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a0c9bd8a18a3685d051e1b1a0d1f287f6">_activation</a>);</div>
<div class="line"><span class="lineno">  102</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#ad7a6c95463633a349e7551dad13f8dba">weights_scale</a> = <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#aedf4a030ba4e787ec06eb0c86b261539">data_scale</a>();</div>
<div class="line"><span class="lineno">  103</span> </div>
<div class="line"><span class="lineno">  104</span><span class="preprocessor">#ifndef USE_RUY_GEMV</span></div>
<div class="line"><span class="lineno">  105</span>  <a class="code hl_function" href="namespacennfw_1_1cker.html#a86c3c8cb5e011dd68e4e3eaaa99d5800">nnfw::cker::FullyConnectedHybrid</a>(</div>
<div class="line"><span class="lineno">  106</span>    op_params, <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>), getBuffer&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>),</div>
<div class="line"><span class="lineno">  107</span>    getBuffer&lt;int8_t&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a>), <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a> ? getBuffer&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a>) : nullptr,</div>
<div class="line"><span class="lineno">  108</span>    <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">_output</a>), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a0054916d6bc97916914b4b69c1a398e8">getBuffer</a>&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">_output</a>), temp_arena, <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aa7430715d3e0ce6f565e0907b4b07732">_external_context</a>-&gt;ruy_context());</div>
<div class="line"><span class="lineno">  109</span><span class="preprocessor">#else</span></div>
<div class="line"><span class="lineno">  110</span>  <a class="code hl_function" href="namespacennfw_1_1cker.html#a86c3c8cb5e011dd68e4e3eaaa99d5800">nnfw::cker::FullyConnectedHybrid</a>(</div>
<div class="line"><span class="lineno">  111</span>    op_params, <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>), getBuffer&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>),</div>
<div class="line"><span class="lineno">  112</span>    (_cached_weights) ? <span class="keyword">reinterpret_cast&lt;</span><span class="keyword">const </span>int8_t *<span class="keyword">&gt;</span>(_cached_weights)</div>
<div class="line"><span class="lineno">  113</span>                      : <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a0054916d6bc97916914b4b69c1a398e8">getBuffer</a>&lt;int8_t&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>),</div>
<div class="line"><span class="lineno">  114</span>    <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a>), <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a> ? <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a0054916d6bc97916914b4b69c1a398e8">getBuffer</a>&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a>) : nullptr, <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">_output</a>),</div>
<div class="line"><span class="lineno">  115</span>    <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a0054916d6bc97916914b4b69c1a398e8">getBuffer</a>&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">_output</a>), temp_arena, <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aa7430715d3e0ce6f565e0907b4b07732">_external_context</a>-&gt;ruy_context());</div>
<div class="line"><span class="lineno">  116</span> </div>
<div class="line"><span class="lineno">  117</span>  <span class="keywordflow">if</span> (_cached_weights == <span class="keyword">nullptr</span> || _is_weights_freed)</div>
<div class="line"><span class="lineno">  118</span>    <span class="keywordflow">return</span>;</div>
<div class="line"><span class="lineno">  119</span> </div>
<div class="line"><span class="lineno">  120</span>  <span class="comment">// &#39;_cached_weights is not nullptr and _is_weights_freed is false&#39; means</span></div>
<div class="line"><span class="lineno">  121</span>  <span class="comment">// this weight shape is satisfied with the ruy kernel&#39;s prepack cache&#39;s condition.</span></div>
<div class="line"><span class="lineno">  122</span>  <span class="comment">// After entering here, it will not enter again except below the case - input is zero-vector</span></div>
<div class="line"><span class="lineno">  123</span> </div>
<div class="line"><span class="lineno">  124</span>  <span class="comment">// if input&#39;s elements are filled with zero, it by-passes(does not enter ruy-kernel path)</span></div>
<div class="line"><span class="lineno">  125</span>  <span class="comment">// so that handle this case</span></div>
<div class="line"><span class="lineno">  126</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> input_size = <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>).<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#ac7e29fd510111992fbd44906e2080f12">FlatSize</a>();</div>
<div class="line"><span class="lineno">  127</span>  <span class="keywordflow">if</span> (<a class="code hl_function" href="namespacennfw_1_1cker.html#af82fa9f0cdbd15fed59567999835cebf">nnfw::cker::IsZeroVector</a>(getBuffer&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>), input_size))</div>
<div class="line"><span class="lineno">  128</span>    <span class="keywordflow">return</span>;</div>
<div class="line"><span class="lineno">  129</span> </div>
<div class="line"><span class="lineno">  130</span>  <span class="keyword">auto</span> weight_tensor = nnfw::misc::polymorphic_downcast&lt;const Tensor *&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>);</div>
<div class="line"><span class="lineno">  131</span> </div>
<div class="line"><span class="lineno">  132</span>  <span class="comment">// This weight tensor could be other ops&#39; const tensor.</span></div>
<div class="line"><span class="lineno">  133</span>  <span class="comment">// Therefore, below reference should be checked like following</span></div>
<div class="line"><span class="lineno">  134</span>  <span class="keyword">auto</span> <a class="code hl_variable" href="namespace_gen_h5_random_inputs.html#a8ccc67c6dabd22b5465400b73929c0fc">tensor</a> = <span class="keyword">const_cast&lt;</span><a class="code hl_class" href="class_tensor.html">Tensor</a> *<span class="keyword">&gt;</span>(weight_tensor);</div>
<div class="line"><span class="lineno">  135</span>  <span class="keywordflow">if</span> (<a class="code hl_variable" href="namespace_gen_h5_random_inputs.html#a8ccc67c6dabd22b5465400b73929c0fc">tensor</a>-&gt;buffer() == <span class="keyword">nullptr</span>) <span class="comment">// ref is already 0?</span></div>
<div class="line"><span class="lineno">  136</span>  {</div>
<div class="line"><span class="lineno">  137</span>    _is_weights_freed = <span class="keyword">true</span>;</div>
<div class="line"><span class="lineno">  138</span>    <span class="keywordflow">return</span>;</div>
<div class="line"><span class="lineno">  139</span>  }</div>
<div class="line"><span class="lineno">  140</span> </div>
<div class="line"><span class="lineno">  141</span>  <a class="code hl_variable" href="namespace_gen_h5_random_inputs.html#a8ccc67c6dabd22b5465400b73929c0fc">tensor</a>-&gt;decrease_ref();</div>
<div class="line"><span class="lineno">  142</span>  <span class="keywordflow">if</span> (<a class="code hl_variable" href="namespace_gen_h5_random_inputs.html#a8ccc67c6dabd22b5465400b73929c0fc">tensor</a>-&gt;buffer() == <span class="keyword">nullptr</span>) <span class="comment">// ref == 0?</span></div>
<div class="line"><span class="lineno">  143</span>  {</div>
<div class="line"><span class="lineno">  144</span><span class="preprocessor">#if defined(__ANDROID__) &amp;&amp; (__ANDROID_API__ &gt;= 26)</span></div>
<div class="line"><span class="lineno">  145</span>    <span class="comment">// NOTE This line forces OS to release any unused memory immediately</span></div>
<div class="line"><span class="lineno">  146</span>    mallopt(M_PURGE, 0);</div>
<div class="line"><span class="lineno">  147</span><span class="preprocessor">#endif</span></div>
<div class="line"><span class="lineno">  148</span>    _is_weights_freed = <span class="keyword">true</span>;</div>
<div class="line"><span class="lineno">  149</span>  }</div>
<div class="line"><span class="lineno">  150</span><span class="preprocessor">#endif</span></div>
<div class="line"><span class="lineno">  151</span>}</div>
<div class="ttc" id="aclass_tensor_html"><div class="ttname"><a href="class_tensor.html">Tensor</a></div><div class="ttdef"><b>Definition</b> <a href="tensor__gen_8cpp_source.html#l00031">tensor_gen.cpp:32</a></div></div>
<div class="ttc" id="aclassnnfw_1_1cker_1_1_f_c_temp_arena_html_a6743d412a028cb7a7021bf255274345f"><div class="ttname"><a href="classnnfw_1_1cker_1_1_f_c_temp_arena.html#a6743d412a028cb7a7021bf255274345f">nnfw::cker::FCTempArena::prepared</a></div><div class="ttdeci">bool prepared</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h_source.html#l00056">FullyConnected.h:56</a></div></div>
<div class="ttc" id="aclassnnfw_1_1cker_1_1_f_c_temp_arena_html_acafeac459e58e656d39398433953b0d0"><div class="ttname"><a href="classnnfw_1_1cker_1_1_f_c_temp_arena.html#acafeac459e58e656d39398433953b0d0">nnfw::cker::FCTempArena::prepare</a></div><div class="ttdeci">void prepare(const Shape &amp;input_shape, const Shape &amp;weights_shape)</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h_source.html#l00044">FullyConnected.h:44</a></div></div>
<div class="ttc" id="aclassnnfw_1_1cker_1_1_shape_html_ac7e29fd510111992fbd44906e2080f12"><div class="ttname"><a href="classnnfw_1_1cker_1_1_shape.html#ac7e29fd510111992fbd44906e2080f12">nnfw::cker::Shape::FlatSize</a></div><div class="ttdeci">int FlatSize() const</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00183">Shape.h:183</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_portable_tensor_html_aedf4a030ba4e787ec06eb0c86b261539"><div class="ttname"><a href="classonert_1_1backend_1_1_i_portable_tensor.html#aedf4a030ba4e787ec06eb0c86b261539">onert::backend::IPortableTensor::data_scale</a></div><div class="ttdeci">float data_scale() const override</div><div class="ttdef"><b>Definition</b> <a href="_i_portable_tensor_8h_source.html#l00046">IPortableTensor.h:46</a></div></div>
<div class="ttc" id="anamespace_gen_h5_random_inputs_html_a8ccc67c6dabd22b5465400b73929c0fc"><div class="ttname"><a href="namespace_gen_h5_random_inputs.html#a8ccc67c6dabd22b5465400b73929c0fc">GenH5RandomInputs.tensor</a></div><div class="ttdeci">tensor</div><div class="ttdef"><b>Definition</b> <a href="_gen_h5_random_inputs_8py_source.html#l00061">GenH5RandomInputs.py:61</a></div></div>
<div class="ttc" id="anamespacennfw_1_1cker_html_a86c3c8cb5e011dd68e4e3eaaa99d5800"><div class="ttname"><a href="namespacennfw_1_1cker.html#a86c3c8cb5e011dd68e4e3eaaa99d5800">nnfw::cker::FullyConnectedHybrid</a></div><div class="ttdeci">void FullyConnectedHybrid(const FullyConnectedParams &amp;params, const Shape &amp;input_shape, const float *input_data, const Shape &amp;filter_shape, const int8_t *filter_data, const Shape &amp;, const float *bias_data, const Shape &amp;output_shape, float *output_data, FCTempArena &amp;temp_arena, ruy::Context *ruy_context)</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h_source.html#l00185">FullyConnected.h:185</a></div></div>
<div class="ttc" id="anamespacennfw_1_1cker_html_af82fa9f0cdbd15fed59567999835cebf"><div class="ttname"><a href="namespacennfw_1_1cker.html#af82fa9f0cdbd15fed59567999835cebf">nnfw::cker::IsZeroVector</a></div><div class="ttdeci">bool IsZeroVector(const float *vector, int v_size)</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_tensor_utils_8h_source.html#l00104">TensorUtils.h:104</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_ad7a6c95463633a349e7551dad13f8dba"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#ad7a6c95463633a349e7551dad13f8dba">nnfw::cker::FullyConnectedParams::weights_scale</a></div><div class="ttdeci">float weights_scale</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00254">Types.h:254</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00075">_activation</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00072">_bias</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00078">_external_context</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00070">_input</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00073">_output</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00076">_temp_arena</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00071">_weights</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00249">nnfw::cker::FullyConnectedParams::activation</a>, <a class="el" href="cpu_2ops_2_operation_utils_8h_source.html#l00114">onert::backend::cpu::ops::convertActivationType()</a>, <a class="el" href="_i_portable_tensor_8h_source.html#l00046">onert::backend::IPortableTensor::data_scale()</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00183">nnfw::cker::Shape::FlatSize()</a>, <a class="el" href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h_source.html#l00185">nnfw::cker::FullyConnectedHybrid()</a>, <a class="el" href="cpu_2ops_2_operation_utils_8h_source.html#l00094">onert::backend::cpu::ops::getShape()</a>, <a class="el" href="compute_2cker_2include_2cker_2_tensor_utils_8h_source.html#l00104">nnfw::cker::IsZeroVector()</a>, <a class="el" href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h_source.html#l00044">nnfw::cker::FCTempArena::prepare()</a>, <a class="el" href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h_source.html#l00056">nnfw::cker::FCTempArena::prepared</a>, and <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00254">nnfw::cker::FullyConnectedParams::weights_scale</a>.</p>

<p class="reference">Referenced by <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00222">run()</a>.</p>

</div>
</div>
<a id="af90252c9fc392b5b8bb7f8c0fa203741" name="af90252c9fc392b5b8bb7f8c0fa203741"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af90252c9fc392b5b8bb7f8c0fa203741">&#9670;&#160;</a></span>fullyConnectedQuant8()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void onert::backend::cpu::ops::FullyConnectedLayer::fullyConnectedQuant8 </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00065">65</a> of file <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html">FullyConnectedLayer.cc</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   66</span>{</div>
<div class="line"><span class="lineno">   67</span>  <span class="keywordtype">double</span> real_multiplier = 0.0;</div>
<div class="line"><span class="lineno">   68</span>  int32_t output_multiplier = 0;</div>
<div class="line"><span class="lineno">   69</span>  int32_t output_shift = 0;</div>
<div class="line"><span class="lineno">   70</span>  int32_t output_activation_min = 0;</div>
<div class="line"><span class="lineno">   71</span>  int32_t output_activation_max = 0;</div>
<div class="line"><span class="lineno">   72</span>  <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#ae4d438d3d3062bfd95a6e0caed125457">GetQuantizedConvolutionMultiplier</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>, <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>, <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a>, <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">_output</a>, &amp;real_multiplier);</div>
<div class="line"><span class="lineno">   73</span>  <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a3be5fe32ffdf0573dd36b64172dbaa3a">QuantizeMultiplier</a>(real_multiplier, &amp;output_multiplier, &amp;output_shift);</div>
<div class="line"><span class="lineno">   74</span>  <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#aa3ed894d41e9c8473df0db171af23d7d">CalculateActivationRangeQuantized</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a0c9bd8a18a3685d051e1b1a0d1f287f6">_activation</a>, <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">_output</a>, &amp;output_activation_min,</div>
<div class="line"><span class="lineno">   75</span>                                    &amp;output_activation_max);</div>
<div class="line"><span class="lineno">   76</span> </div>
<div class="line"><span class="lineno">   77</span>  <a class="code hl_struct" href="structnnfw_1_1cker_1_1_fully_connected_params.html">nnfw::cker::FullyConnectedParams</a> op_params;</div>
<div class="line"><span class="lineno">   78</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a88a4ccb4fb1a3a1fc0b5066ca98b1fef">input_offset</a> = -<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#a0c2877a5e6e7d5ac7416baf7d3315644">data_zero_point</a>();</div>
<div class="line"><span class="lineno">   79</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a386f74239ea2059f97fadb7b3c407f37">weights_offset</a> = -<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#a0c2877a5e6e7d5ac7416baf7d3315644">data_zero_point</a>();</div>
<div class="line"><span class="lineno">   80</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#aba4be915f48ac33044094e092fe04c38">output_offset</a> = <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">_output</a>-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#a0c2877a5e6e7d5ac7416baf7d3315644">data_zero_point</a>();</div>
<div class="line"><span class="lineno">   81</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a092f1b0d178bedcbec27ae01bdb35295">output_multiplier</a> = output_multiplier;</div>
<div class="line"><span class="lineno">   82</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#aad53016de4b3709a2c0691bc5cab3c12">output_shift</a> = output_shift;</div>
<div class="line"><span class="lineno">   83</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a5268ff3c0cf7eed73da16324a82f3e39">quantized_activation_min</a> = output_activation_min;</div>
<div class="line"><span class="lineno">   84</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a7e955d0d5d1022cd53da9c32ebf48ae0">quantized_activation_max</a> = output_activation_max;</div>
<div class="line"><span class="lineno">   85</span> </div>
<div class="line"><span class="lineno">   86</span>  <a class="code hl_function" href="namespacennfw_1_1cker.html#a893434782a43556a99989be14e599d63">nnfw::cker::FullyConnected</a>(op_params, <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>), getBuffer&lt;uint8_t&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>),</div>
<div class="line"><span class="lineno">   87</span>                             <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>), getBuffer&lt;uint8_t&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a>),</div>
<div class="line"><span class="lineno">   88</span>                             <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a> ? getBuffer&lt;int32_t&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a>) : nullptr, <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">_output</a>),</div>
<div class="line"><span class="lineno">   89</span>                             <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a0054916d6bc97916914b4b69c1a398e8">getBuffer</a>&lt;uint8_t&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">_output</a>));</div>
<div class="line"><span class="lineno">   90</span>}</div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_portable_tensor_html_a0c2877a5e6e7d5ac7416baf7d3315644"><div class="ttname"><a href="classonert_1_1backend_1_1_i_portable_tensor.html#a0c2877a5e6e7d5ac7416baf7d3315644">onert::backend::IPortableTensor::data_zero_point</a></div><div class="ttdeci">int32_t data_zero_point() const override</div><div class="ttdef"><b>Definition</b> <a href="_i_portable_tensor_8h_source.html#l00047">IPortableTensor.h:47</a></div></div>
<div class="ttc" id="anamespaceonert_1_1backend_1_1cpu_1_1ops_html_a3be5fe32ffdf0573dd36b64172dbaa3a"><div class="ttname"><a href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a3be5fe32ffdf0573dd36b64172dbaa3a">onert::backend::cpu::ops::QuantizeMultiplier</a></div><div class="ttdeci">void QuantizeMultiplier(double double_multiplier, int32_t *quantized_multiplier, int *shift)</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_operation_utils_8cc_source.html#l00062">OperationUtils.cc:62</a></div></div>
<div class="ttc" id="anamespaceonert_1_1backend_1_1cpu_1_1ops_html_aa3ed894d41e9c8473df0db171af23d7d"><div class="ttname"><a href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#aa3ed894d41e9c8473df0db171af23d7d">onert::backend::cpu::ops::CalculateActivationRangeQuantized</a></div><div class="ttdeci">void CalculateActivationRangeQuantized(ir::Activation activation, const IPortableTensor *output, int32_t *act_min, int32_t *act_max)</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_operation_utils_8cc_source.html#l00144">OperationUtils.cc:144</a></div></div>
<div class="ttc" id="anamespaceonert_1_1backend_1_1cpu_1_1ops_html_ae4d438d3d3062bfd95a6e0caed125457"><div class="ttname"><a href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#ae4d438d3d3062bfd95a6e0caed125457">onert::backend::cpu::ops::GetQuantizedConvolutionMultiplier</a></div><div class="ttdeci">void GetQuantizedConvolutionMultiplier(const IPortableTensor *input, const IPortableTensor *filter, const IPortableTensor *bias, const IPortableTensor *output, double *multiplier)</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_operation_utils_8cc_source.html#l00083">OperationUtils.cc:83</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_a092f1b0d178bedcbec27ae01bdb35295"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#a092f1b0d178bedcbec27ae01bdb35295">nnfw::cker::FullyConnectedParams::output_multiplier</a></div><div class="ttdeci">int32_t output_multiplier</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00256">Types.h:256</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_a386f74239ea2059f97fadb7b3c407f37"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#a386f74239ea2059f97fadb7b3c407f37">nnfw::cker::FullyConnectedParams::weights_offset</a></div><div class="ttdeci">int32_t weights_offset</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00253">Types.h:253</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_a5268ff3c0cf7eed73da16324a82f3e39"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#a5268ff3c0cf7eed73da16324a82f3e39">nnfw::cker::FullyConnectedParams::quantized_activation_min</a></div><div class="ttdeci">int32_t quantized_activation_min</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00259">Types.h:259</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_a7e955d0d5d1022cd53da9c32ebf48ae0"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#a7e955d0d5d1022cd53da9c32ebf48ae0">nnfw::cker::FullyConnectedParams::quantized_activation_max</a></div><div class="ttdeci">int32_t quantized_activation_max</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00260">Types.h:260</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_a88a4ccb4fb1a3a1fc0b5066ca98b1fef"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#a88a4ccb4fb1a3a1fc0b5066ca98b1fef">nnfw::cker::FullyConnectedParams::input_offset</a></div><div class="ttdeci">int32_t input_offset</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00252">Types.h:252</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_aad53016de4b3709a2c0691bc5cab3c12"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#aad53016de4b3709a2c0691bc5cab3c12">nnfw::cker::FullyConnectedParams::output_shift</a></div><div class="ttdeci">int output_shift</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00257">Types.h:257</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_aba4be915f48ac33044094e092fe04c38"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#aba4be915f48ac33044094e092fe04c38">nnfw::cker::FullyConnectedParams::output_offset</a></div><div class="ttdeci">int32_t output_offset</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00255">Types.h:255</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00075">_activation</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00072">_bias</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00070">_input</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00073">_output</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00071">_weights</a>, <a class="el" href="cpu_2ops_2_operation_utils_8cc_source.html#l00144">onert::backend::cpu::ops::CalculateActivationRangeQuantized()</a>, <a class="el" href="_i_portable_tensor_8h_source.html#l00047">onert::backend::IPortableTensor::data_zero_point()</a>, <a class="el" href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h_source.html#l00098">nnfw::cker::FullyConnected()</a>, <a class="el" href="cpu_2ops_2_operation_utils_8cc_source.html#l00083">onert::backend::cpu::ops::GetQuantizedConvolutionMultiplier()</a>, <a class="el" href="cpu_2ops_2_operation_utils_8h_source.html#l00094">onert::backend::cpu::ops::getShape()</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00252">nnfw::cker::FullyConnectedParams::input_offset</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00256">nnfw::cker::FullyConnectedParams::output_multiplier</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00255">nnfw::cker::FullyConnectedParams::output_offset</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00257">nnfw::cker::FullyConnectedParams::output_shift</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00260">nnfw::cker::FullyConnectedParams::quantized_activation_max</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00259">nnfw::cker::FullyConnectedParams::quantized_activation_min</a>, <a class="el" href="cpu_2ops_2_operation_utils_8cc_source.html#l00062">onert::backend::cpu::ops::QuantizeMultiplier()</a>, and <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00253">nnfw::cker::FullyConnectedParams::weights_offset</a>.</p>

<p class="reference">Referenced by <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00222">run()</a>.</p>

</div>
</div>
<a id="a27ebc09cfe60bf438b6ac2b831d0a8b5" name="a27ebc09cfe60bf438b6ac2b831d0a8b5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a27ebc09cfe60bf438b6ac2b831d0a8b5">&#9670;&#160;</a></span>fullyConnectedSparseWeight()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void onert::backend::cpu::ops::FullyConnectedLayer::fullyConnectedSparseWeight </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00153">153</a> of file <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html">FullyConnectedLayer.cc</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  154</span>{</div>
<div class="line"><span class="lineno">  155</span>  <a class="code hl_struct" href="structnnfw_1_1cker_1_1_fully_connected_params.html">nnfw::cker::FullyConnectedParams</a> op_params;</div>
<div class="line"><span class="lineno">  156</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a15410fd240c7d16cdeaca54856b712c8">activation</a> = <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a0e7672ebf55bbaa7e1d86a46cfd53c5e">convertActivationType</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a0c9bd8a18a3685d051e1b1a0d1f287f6">_activation</a>);</div>
<div class="line"><span class="lineno">  157</span> </div>
<div class="line"><span class="lineno">  158</span>  <span class="keyword">const</span> uint16_t *w1_segments = <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#aee0afc215e2f87867c419da5425528eb">sparsity</a>()-&gt;<a class="code hl_function" href="structonert_1_1ir_1_1_sparsity.html#a46532d90a469c48114b12ab3ba16c76b">w1_segments</a>();</div>
<div class="line"><span class="lineno">  159</span>  <span class="keyword">const</span> uint16_t *w1_indices = <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#aee0afc215e2f87867c419da5425528eb">sparsity</a>()-&gt;<a class="code hl_function" href="structonert_1_1ir_1_1_sparsity.html#a76b05fe5094e56d48d87652f553e038c">w1_indices</a>();</div>
<div class="line"><span class="lineno">  160</span> </div>
<div class="line"><span class="lineno">  161</span>  <span class="keyword">auto</span> block_size = <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#aee0afc215e2f87867c419da5425528eb">sparsity</a>()-&gt;<a class="code hl_function" href="structonert_1_1ir_1_1_sparsity.html#a27434d14d1c2593592a6b9e043e308dc">block_size</a>();</div>
<div class="line"><span class="lineno">  162</span>  <span class="keywordflow">if</span> (block_size.size() == 0)</div>
<div class="line"><span class="lineno">  163</span>  {</div>
<div class="line"><span class="lineno">  164</span>    <a class="code hl_function" href="namespacennfw_1_1cker.html#a0da6b0f998eacd17836e7f7265cd1605">nnfw::cker::FullyConnectedSparseWeightRandom</a>(</div>
<div class="line"><span class="lineno">  165</span>      op_params, <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>), getBuffer&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>),</div>
<div class="line"><span class="lineno">  166</span>      getBuffer&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a>), <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a> ? getBuffer&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a>) : nullptr,</div>
<div class="line"><span class="lineno">  167</span>      <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">_output</a>), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a0054916d6bc97916914b4b69c1a398e8">getBuffer</a>&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">_output</a>), w1_segments, w1_indices);</div>
<div class="line"><span class="lineno">  168</span>  }</div>
<div class="line"><span class="lineno">  169</span>  <span class="keywordflow">else</span> <span class="keywordflow">if</span> (block_size.size() == 2 &amp;&amp; block_size[0] == 16 &amp;&amp; block_size[1] == 1)</div>
<div class="line"><span class="lineno">  170</span>  {</div>
<div class="line"><span class="lineno">  171</span>    <a class="code hl_function" href="namespacennfw_1_1cker.html#a38ce7e8df68ce5c6527f23b008a422b3">nnfw::cker::FullyConnectedSparseWeight16x1</a>(</div>
<div class="line"><span class="lineno">  172</span>      op_params, <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>), getBuffer&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>),</div>
<div class="line"><span class="lineno">  173</span>      getBuffer&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a>), <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a> ? getBuffer&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a>) : nullptr,</div>
<div class="line"><span class="lineno">  174</span>      <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">_output</a>), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a0054916d6bc97916914b4b69c1a398e8">getBuffer</a>&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a77947469291a9e32a6daa860cc1de1de">_output</a>), w1_segments, w1_indices);</div>
<div class="line"><span class="lineno">  175</span>  }</div>
<div class="line"><span class="lineno">  176</span>  <span class="keywordflow">else</span></div>
<div class="line"><span class="lineno">  177</span>    <span class="keywordflow">throw</span> std::runtime_error{<span class="stringliteral">&quot;FullyConnected: unsupported sparsity&quot;</span>};</div>
<div class="line"><span class="lineno">  178</span>}</div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_portable_tensor_html_aee0afc215e2f87867c419da5425528eb"><div class="ttname"><a href="classonert_1_1backend_1_1_i_portable_tensor.html#aee0afc215e2f87867c419da5425528eb">onert::backend::IPortableTensor::sparsity</a></div><div class="ttdeci">virtual const ir::Sparsity * sparsity() const</div><div class="ttdef"><b>Definition</b> <a href="_i_portable_tensor_8h_source.html#l00044">IPortableTensor.h:44</a></div></div>
<div class="ttc" id="anamespacennfw_1_1cker_html_a0da6b0f998eacd17836e7f7265cd1605"><div class="ttname"><a href="namespacennfw_1_1cker.html#a0da6b0f998eacd17836e7f7265cd1605">nnfw::cker::FullyConnectedSparseWeightRandom</a></div><div class="ttdeci">void FullyConnectedSparseWeightRandom(const FullyConnectedParams &amp;params, const Shape &amp;input_shape, const float *input_data, const Shape &amp;weights_shape, const float *weights_data, const Shape &amp;bias_shape, const float *bias_data, const Shape &amp;output_shape, float *output_data, const uint16_t *w1_segments, const uint16_t *w1_indices)</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h_source.html#l00253">FullyConnected.h:253</a></div></div>
<div class="ttc" id="anamespacennfw_1_1cker_html_a38ce7e8df68ce5c6527f23b008a422b3"><div class="ttname"><a href="namespacennfw_1_1cker.html#a38ce7e8df68ce5c6527f23b008a422b3">nnfw::cker::FullyConnectedSparseWeight16x1</a></div><div class="ttdeci">void FullyConnectedSparseWeight16x1(const FullyConnectedParams &amp;params, const Shape &amp;input_shape, const float *input_data, const Shape &amp;weights_shape, const float *weights_data, const Shape &amp;bias_shape, const float *bias_data, const Shape &amp;output_shape, float *output_data, const uint16_t *w1_segments, const uint16_t *w1_indices)</div><div class="ttdef"><b>Definition</b> <a href="_fully_connected_sparse16x1_8h_source.html#l00057">FullyConnectedSparse16x1.h:57</a></div></div>
<div class="ttc" id="astructonert_1_1ir_1_1_sparsity_html_a27434d14d1c2593592a6b9e043e308dc"><div class="ttname"><a href="structonert_1_1ir_1_1_sparsity.html#a27434d14d1c2593592a6b9e043e308dc">onert::ir::Sparsity::block_size</a></div><div class="ttdeci">const std::vector&lt; int32_t &gt; &amp; block_size() const</div><div class="ttdoc">Returns block size which is used for block sparsity.</div><div class="ttdef"><b>Definition</b> <a href="_sparsity_8h_source.html#l00053">Sparsity.h:53</a></div></div>
<div class="ttc" id="astructonert_1_1ir_1_1_sparsity_html_a46532d90a469c48114b12ab3ba16c76b"><div class="ttname"><a href="structonert_1_1ir_1_1_sparsity.html#a46532d90a469c48114b12ab3ba16c76b">onert::ir::Sparsity::w1_segments</a></div><div class="ttdeci">const uint16_t * w1_segments() const</div><div class="ttdoc">Returns segments array. See compressed sparse row format.</div><div class="ttdef"><b>Definition</b> <a href="_sparsity_8h_source.html#l00045">Sparsity.h:45</a></div></div>
<div class="ttc" id="astructonert_1_1ir_1_1_sparsity_html_a76b05fe5094e56d48d87652f553e038c"><div class="ttname"><a href="structonert_1_1ir_1_1_sparsity.html#a76b05fe5094e56d48d87652f553e038c">onert::ir::Sparsity::w1_indices</a></div><div class="ttdeci">const uint16_t * w1_indices() const</div><div class="ttdoc">Returns indices array. See compressed sparse row format.</div><div class="ttdef"><b>Definition</b> <a href="_sparsity_8h_source.html#l00049">Sparsity.h:49</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00075">_activation</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00072">_bias</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00070">_input</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00073">_output</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00071">_weights</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00249">nnfw::cker::FullyConnectedParams::activation</a>, <a class="el" href="_sparsity_8h_source.html#l00053">onert::ir::Sparsity::block_size()</a>, <a class="el" href="cpu_2ops_2_operation_utils_8h_source.html#l00114">onert::backend::cpu::ops::convertActivationType()</a>, <a class="el" href="_fully_connected_sparse16x1_8h_source.html#l00057">nnfw::cker::FullyConnectedSparseWeight16x1()</a>, <a class="el" href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h_source.html#l00253">nnfw::cker::FullyConnectedSparseWeightRandom()</a>, <a class="el" href="cpu_2ops_2_operation_utils_8h_source.html#l00094">onert::backend::cpu::ops::getShape()</a>, <a class="el" href="_i_portable_tensor_8h_source.html#l00044">onert::backend::IPortableTensor::sparsity()</a>, <a class="el" href="_sparsity_8h_source.html#l00049">onert::ir::Sparsity::w1_indices()</a>, and <a class="el" href="_sparsity_8h_source.html#l00045">onert::ir::Sparsity::w1_segments()</a>.</p>

<p class="reference">Referenced by <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00222">run()</a>.</p>

</div>
</div>
<a id="ab5fc53c26dd7f5863daed38d58cd7c18" name="ab5fc53c26dd7f5863daed38d58cd7c18"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab5fc53c26dd7f5863daed38d58cd7c18">&#9670;&#160;</a></span>prepare()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void onert::backend::cpu::ops::FullyConnectedLayer::prepare </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Reimplemented from <a class="el" href="classonert_1_1exec_1_1_i_function.html#a901ae0973ef08a6ca59f6a00bd3bac4c">onert::exec::IFunction</a>.</p>

<p class="definition">Definition at line <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00246">246</a> of file <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html">FullyConnectedLayer.cc</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  247</span>{</div>
<div class="line"><span class="lineno">  248</span>  <span class="keywordflow">if</span> (<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a> &amp;&amp; <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a>-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#a0aa4408d72f1ea3643c386520d9eb4e3">is_constant</a>())</div>
<div class="line"><span class="lineno">  249</span>  {</div>
<div class="line"><span class="lineno">  250</span>    <span class="keyword">const</span> <span class="keywordtype">int</span> bias_size = <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a>).<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#ac7e29fd510111992fbd44906e2080f12">FlatSize</a>();</div>
<div class="line"><span class="lineno">  251</span>    <span class="keywordflow">if</span> (<a class="code hl_function" href="namespacennfw_1_1cker.html#af82fa9f0cdbd15fed59567999835cebf">nnfw::cker::IsZeroVector</a>(getBuffer&lt;float&gt;(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a>), bias_size))</div>
<div class="line"><span class="lineno">  252</span>    {</div>
<div class="line"><span class="lineno">  253</span>      <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a351b6a5cfcc2725297d58b5ee21fd938">_bias</a> = <span class="keyword">nullptr</span>;</div>
<div class="line"><span class="lineno">  254</span>    }</div>
<div class="line"><span class="lineno">  255</span>  }</div>
<div class="line"><span class="lineno">  256</span> </div>
<div class="line"><span class="lineno">  257</span><span class="preprocessor">#if (defined(__ARM_NEON__) || defined(__ARM_NEON)) &amp;&amp; defined(USE_RUY_GEMV)</span></div>
<div class="line"><span class="lineno">  258</span>  <span class="comment">// TODO This is workaround</span></div>
<div class="line"><span class="lineno">  259</span>  <span class="comment">// The only fc hybrid will use ruy kernel</span></div>
<div class="line"><span class="lineno">  260</span>  <span class="keywordflow">if</span> (<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#a6d57b178316225a9e08f1191ce489ad9">data_type</a>() != OperandType::FLOAT32 ||</div>
<div class="line"><span class="lineno">  261</span>      <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#a6d57b178316225a9e08f1191ce489ad9">data_type</a>() != OperandType::QUANT_INT8_SYMM)</div>
<div class="line"><span class="lineno">  262</span>  {</div>
<div class="line"><span class="lineno">  263</span>    <span class="keywordflow">return</span>;</div>
<div class="line"><span class="lineno">  264</span>  }</div>
<div class="line"><span class="lineno">  265</span> </div>
<div class="line"><span class="lineno">  266</span>  <span class="comment">// NOTE. The condition to enable caching on ruy kernel can be changed according to ruy&#39;s version</span></div>
<div class="line"><span class="lineno">  267</span> </div>
<div class="line"><span class="lineno">  268</span>  <span class="comment">// If input is dynamic, it changes total size of input</span></div>
<div class="line"><span class="lineno">  269</span>  <span class="comment">// If weights is not constant, weights cannot be cached</span></div>
<div class="line"><span class="lineno">  270</span>  <span class="keywordflow">if</span> (<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#a4202633be970298f135e2c00d217c0b0">is_dynamic</a>() || !<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#a0aa4408d72f1ea3643c386520d9eb4e3">is_constant</a>())</div>
<div class="line"><span class="lineno">  271</span>    <span class="keywordflow">return</span>;</div>
<div class="line"><span class="lineno">  272</span> </div>
<div class="line"><span class="lineno">  273</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> rows = <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>).<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(0);</div>
<div class="line"><span class="lineno">  274</span>  <span class="keywordflow">if</span> (rows % 4 == 0)</div>
<div class="line"><span class="lineno">  275</span>  {</div>
<div class="line"><span class="lineno">  276</span>    <span class="comment">// TODO If it&#39;s possible to extract precaching from ruy kernel,</span></div>
<div class="line"><span class="lineno">  277</span>    <span class="comment">// place this instead of below code</span></div>
<div class="line"><span class="lineno">  278</span> </div>
<div class="line"><span class="lineno">  279</span>    <span class="comment">// buffer will be used by ruy kernel as a cache key</span></div>
<div class="line"><span class="lineno">  280</span>    _cached_weights = <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#ac42a9739e80a0e11be18c0e0a61ccf85">buffer</a>();</div>
<div class="line"><span class="lineno">  281</span>  }</div>
<div class="line"><span class="lineno">  282</span><span class="preprocessor">#endif</span></div>
<div class="line"><span class="lineno">  283</span>}</div>
<div class="ttc" id="aclassnnfw_1_1cker_1_1_shape_html_a497180ee7844bbef51b36bd58e61fa31"><div class="ttname"><a href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">nnfw::cker::Shape::Dims</a></div><div class="ttdeci">int32_t Dims(int i) const</div><div class="ttdef"><b>Definition</b> <a href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00094">Shape.h:94</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_tensor_html_a4202633be970298f135e2c00d217c0b0"><div class="ttname"><a href="classonert_1_1backend_1_1_i_tensor.html#a4202633be970298f135e2c00d217c0b0">onert::backend::ITensor::is_dynamic</a></div><div class="ttdeci">virtual bool is_dynamic() const =0</div><div class="ttdoc">Return true if the tensor needs dynamic allocation, meaning that during compile-time the outpus shape...</div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_tensor_html_a6d57b178316225a9e08f1191ce489ad9"><div class="ttname"><a href="classonert_1_1backend_1_1_i_tensor.html#a6d57b178316225a9e08f1191ce489ad9">onert::backend::ITensor::data_type</a></div><div class="ttdeci">virtual ir::DataType data_type() const =0</div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_tensor_html_ac42a9739e80a0e11be18c0e0a61ccf85"><div class="ttname"><a href="classonert_1_1backend_1_1_i_tensor.html#ac42a9739e80a0e11be18c0e0a61ccf85">onert::backend::ITensor::buffer</a></div><div class="ttdeci">virtual uint8_t * buffer() const =0</div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00072">_bias</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00070">_input</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00071">_weights</a>, <a class="el" href="classonert_1_1backend_1_1_i_tensor.html#ac42a9739e80a0e11be18c0e0a61ccf85">onert::backend::ITensor::buffer()</a>, <a class="el" href="classonert_1_1backend_1_1_i_tensor.html#a6d57b178316225a9e08f1191ce489ad9">onert::backend::ITensor::data_type()</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00094">nnfw::cker::Shape::Dims()</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00183">nnfw::cker::Shape::FlatSize()</a>, <a class="el" href="cpu_2ops_2_operation_utils_8h_source.html#l00094">onert::backend::cpu::ops::getShape()</a>, <a class="el" href="_i_tensor_8h_source.html#l00072">onert::backend::ITensor::is_constant()</a>, <a class="el" href="classonert_1_1backend_1_1_i_tensor.html#a4202633be970298f135e2c00d217c0b0">onert::backend::ITensor::is_dynamic()</a>, and <a class="el" href="compute_2cker_2include_2cker_2_tensor_utils_8h_source.html#l00104">nnfw::cker::IsZeroVector()</a>.</p>

</div>
</div>
<a id="aff0e02437f1e864effa060ca8ea19bc1" name="aff0e02437f1e864effa060ca8ea19bc1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aff0e02437f1e864effa060ca8ea19bc1">&#9670;&#160;</a></span>run()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void onert::backend::cpu::ops::FullyConnectedLayer::run </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Implements <a class="el" href="classonert_1_1exec_1_1_i_function.html#aedd6f5e12852d808abb97327b9d229e2">onert::exec::IFunction</a>.</p>

<p class="definition">Definition at line <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00222">222</a> of file <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html">FullyConnectedLayer.cc</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  223</span>{</div>
<div class="line"><span class="lineno">  224</span>  <span class="keywordflow">if</span> (<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a9396777fe8ae35b050ace67e923f15e7">_is_hybrid</a>)</div>
<div class="line"><span class="lineno">  225</span>  {</div>
<div class="line"><span class="lineno">  226</span>    <a class="code hl_function" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aea2f03e86f6d110ff8a1eaae0caa8d82">fullyConnectedHybrid</a>();</div>
<div class="line"><span class="lineno">  227</span>  }</div>
<div class="line"><span class="lineno">  228</span>  <span class="keywordflow">else</span> <span class="keywordflow">if</span> (<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2b1775533510102ae7787082bc588439">_weights</a>-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#aee0afc215e2f87867c419da5425528eb">sparsity</a>())</div>
<div class="line"><span class="lineno">  229</span>  {</div>
<div class="line"><span class="lineno">  230</span>    <a class="code hl_function" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a27ebc09cfe60bf438b6ac2b831d0a8b5">fullyConnectedSparseWeight</a>();</div>
<div class="line"><span class="lineno">  231</span>  }</div>
<div class="line"><span class="lineno">  232</span>  <span class="keywordflow">else</span> <span class="keywordflow">if</span> (<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#a6d57b178316225a9e08f1191ce489ad9">data_type</a>() == OperandType::FLOAT32)</div>
<div class="line"><span class="lineno">  233</span>  {</div>
<div class="line"><span class="lineno">  234</span>    <a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a576d08d56b68f41f9347fa0dca4f0078">_is_shuffled16x1float32</a> ? <a class="code hl_function" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2006db79e45053eb357f55af95471524">fullyConnected16x1Float32</a>() : <a class="code hl_function" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a648618c630985a3d90aeae23ec2cdc4e">fullyConnectedFloat32</a>();</div>
<div class="line"><span class="lineno">  235</span>  }</div>
<div class="line"><span class="lineno">  236</span>  <span class="keywordflow">else</span> <span class="keywordflow">if</span> (<a class="code hl_variable" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ad20b91c5fd9f048ca2b7b650b4e9d95e">_input</a>-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#a6d57b178316225a9e08f1191ce489ad9">data_type</a>() == OperandType::QUANT_UINT8_ASYMM)</div>
<div class="line"><span class="lineno">  237</span>  {</div>
<div class="line"><span class="lineno">  238</span>    <a class="code hl_function" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#af90252c9fc392b5b8bb7f8c0fa203741">fullyConnectedQuant8</a>();</div>
<div class="line"><span class="lineno">  239</span>  }</div>
<div class="line"><span class="lineno">  240</span>  <span class="keywordflow">else</span></div>
<div class="line"><span class="lineno">  241</span>  {</div>
<div class="line"><span class="lineno">  242</span>    <span class="keywordflow">throw</span> std::runtime_error{<span class="stringliteral">&quot;FullyConnected: unsupported data type&quot;</span>};</div>
<div class="line"><span class="lineno">  243</span>  }</div>
<div class="line"><span class="lineno">  244</span>}</div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_a2006db79e45053eb357f55af95471524"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2006db79e45053eb357f55af95471524">onert::backend::cpu::ops::FullyConnectedLayer::fullyConnected16x1Float32</a></div><div class="ttdeci">void fullyConnected16x1Float32()</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00180">FullyConnectedLayer.cc:180</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_a27ebc09cfe60bf438b6ac2b831d0a8b5"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a27ebc09cfe60bf438b6ac2b831d0a8b5">onert::backend::cpu::ops::FullyConnectedLayer::fullyConnectedSparseWeight</a></div><div class="ttdeci">void fullyConnectedSparseWeight()</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00153">FullyConnectedLayer.cc:153</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_a648618c630985a3d90aeae23ec2cdc4e"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a648618c630985a3d90aeae23ec2cdc4e">onert::backend::cpu::ops::FullyConnectedLayer::fullyConnectedFloat32</a></div><div class="ttdeci">void fullyConnectedFloat32()</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00043">FullyConnectedLayer.cc:43</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_aea2f03e86f6d110ff8a1eaae0caa8d82"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aea2f03e86f6d110ff8a1eaae0caa8d82">onert::backend::cpu::ops::FullyConnectedLayer::fullyConnectedHybrid</a></div><div class="ttdeci">void fullyConnectedHybrid()</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00092">FullyConnectedLayer.cc:92</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_af90252c9fc392b5b8bb7f8c0fa203741"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#af90252c9fc392b5b8bb7f8c0fa203741">onert::backend::cpu::ops::FullyConnectedLayer::fullyConnectedQuant8</a></div><div class="ttdeci">void fullyConnectedQuant8()</div><div class="ttdef"><b>Definition</b> <a href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00065">FullyConnectedLayer.cc:65</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00070">_input</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00080">_is_hybrid</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00081">_is_shuffled16x1float32</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00071">_weights</a>, <a class="el" href="classonert_1_1backend_1_1_i_tensor.html#a6d57b178316225a9e08f1191ce489ad9">onert::backend::ITensor::data_type()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00180">fullyConnected16x1Float32()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00043">fullyConnectedFloat32()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00092">fullyConnectedHybrid()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00065">fullyConnectedQuant8()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00153">fullyConnectedSparseWeight()</a>, and <a class="el" href="_i_portable_tensor_8h_source.html#l00044">onert::backend::IPortableTensor::sparsity()</a>.</p>

<p class="reference">Referenced by <a class="el" href="train_2ops_2_fully_connected_layer_8cc_source.html#l00107">onert::backend::train::ops::FullyConnectedLayer::forward()</a>, and <a class="el" href="libnnfw__api__pybind_8py_source.html#l00060">package.libnnfw_api_pybind.nnfw_session_wrapper::inference()</a>.</p>

</div>
</div>
<h2 class="groupheader">Field Documentation</h2>
<a id="a0c9bd8a18a3685d051e1b1a0d1f287f6" name="a0c9bd8a18a3685d051e1b1a0d1f287f6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0c9bd8a18a3685d051e1b1a0d1f287f6">&#9670;&#160;</a></span>_activation</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespaceonert_1_1ir.html#a8ce6c92ea138aca1332e4be9531bd5d4">ir::Activation</a> onert::backend::cpu::ops::FullyConnectedLayer::_activation</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00075">75</a> of file <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html">FullyConnectedLayer.h</a>.</p>

<p class="reference">Referenced by <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00198">configure()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00180">fullyConnected16x1Float32()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00043">fullyConnectedFloat32()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00092">fullyConnectedHybrid()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00065">fullyConnectedQuant8()</a>, and <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00153">fullyConnectedSparseWeight()</a>.</p>

</div>
</div>
<a id="a351b6a5cfcc2725297d58b5ee21fd938" name="a351b6a5cfcc2725297d58b5ee21fd938"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a351b6a5cfcc2725297d58b5ee21fd938">&#9670;&#160;</a></span>_bias</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a>* onert::backend::cpu::ops::FullyConnectedLayer::_bias</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00072">72</a> of file <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html">FullyConnectedLayer.h</a>.</p>

<p class="reference">Referenced by <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00198">configure()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00180">fullyConnected16x1Float32()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00043">fullyConnectedFloat32()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00092">fullyConnectedHybrid()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00065">fullyConnectedQuant8()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00153">fullyConnectedSparseWeight()</a>, and <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00246">prepare()</a>.</p>

</div>
</div>
<a id="aa7430715d3e0ce6f565e0907b4b07732" name="aa7430715d3e0ce6f565e0907b4b07732"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa7430715d3e0ce6f565e0907b4b07732">&#9670;&#160;</a></span>_external_context</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt;<a class="el" href="classonert_1_1backend_1_1cpu_1_1_external_context.html">ExternalContext</a>&gt; onert::backend::cpu::ops::FullyConnectedLayer::_external_context</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00078">78</a> of file <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html">FullyConnectedLayer.h</a>.</p>

<p class="reference">Referenced by <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00198">configure()</a>, and <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00092">fullyConnectedHybrid()</a>.</p>

</div>
</div>
<a id="ad20b91c5fd9f048ca2b7b650b4e9d95e" name="ad20b91c5fd9f048ca2b7b650b4e9d95e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad20b91c5fd9f048ca2b7b650b4e9d95e">&#9670;&#160;</a></span>_input</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a>* onert::backend::cpu::ops::FullyConnectedLayer::_input</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00070">70</a> of file <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html">FullyConnectedLayer.h</a>.</p>

<p class="reference">Referenced by <a class="el" href="train_2ops_2_fully_connected_layer_8cc_source.html#l00109">onert::backend::train::ops::FullyConnectedLayer::backward()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00198">configure()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00180">fullyConnected16x1Float32()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00043">fullyConnectedFloat32()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00092">fullyConnectedHybrid()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00065">fullyConnectedQuant8()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00153">fullyConnectedSparseWeight()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00246">prepare()</a>, and <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00222">run()</a>.</p>

</div>
</div>
<a id="a9396777fe8ae35b050ace67e923f15e7" name="a9396777fe8ae35b050ace67e923f15e7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9396777fe8ae35b050ace67e923f15e7">&#9670;&#160;</a></span>_is_hybrid</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool onert::backend::cpu::ops::FullyConnectedLayer::_is_hybrid</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00080">80</a> of file <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html">FullyConnectedLayer.h</a>.</p>

<p class="reference">Referenced by <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00198">configure()</a>, and <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00222">run()</a>.</p>

</div>
</div>
<a id="a576d08d56b68f41f9347fa0dca4f0078" name="a576d08d56b68f41f9347fa0dca4f0078"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a576d08d56b68f41f9347fa0dca4f0078">&#9670;&#160;</a></span>_is_shuffled16x1float32</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool onert::backend::cpu::ops::FullyConnectedLayer::_is_shuffled16x1float32</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00081">81</a> of file <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html">FullyConnectedLayer.h</a>.</p>

<p class="reference">Referenced by <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00198">configure()</a>, and <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00222">run()</a>.</p>

</div>
</div>
<a id="a77947469291a9e32a6daa860cc1de1de" name="a77947469291a9e32a6daa860cc1de1de"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a77947469291a9e32a6daa860cc1de1de">&#9670;&#160;</a></span>_output</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a>* onert::backend::cpu::ops::FullyConnectedLayer::_output</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00073">73</a> of file <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html">FullyConnectedLayer.h</a>.</p>

<p class="reference">Referenced by <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00198">configure()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00180">fullyConnected16x1Float32()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00043">fullyConnectedFloat32()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00092">fullyConnectedHybrid()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00065">fullyConnectedQuant8()</a>, and <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00153">fullyConnectedSparseWeight()</a>.</p>

</div>
</div>
<a id="a8e0cacbbb55a70e80c8ec2b635d9956d" name="a8e0cacbbb55a70e80c8ec2b635d9956d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8e0cacbbb55a70e80c8ec2b635d9956d">&#9670;&#160;</a></span>_temp_arena</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::unique_ptr&lt;<a class="el" href="classnnfw_1_1cker_1_1_f_c_temp_arena.html">nnfw::cker::FCTempArena</a>&gt; onert::backend::cpu::ops::FullyConnectedLayer::_temp_arena</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00076">76</a> of file <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html">FullyConnectedLayer.h</a>.</p>

<p class="reference">Referenced by <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00092">fullyConnectedHybrid()</a>.</p>

</div>
</div>
<a id="a2b1775533510102ae7787082bc588439" name="a2b1775533510102ae7787082bc588439"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2b1775533510102ae7787082bc588439">&#9670;&#160;</a></span>_weights</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a>* onert::backend::cpu::ops::FullyConnectedLayer::_weights</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html#l00071">71</a> of file <a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html">FullyConnectedLayer.h</a>.</p>

<p class="reference">Referenced by <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00198">configure()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00180">fullyConnected16x1Float32()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00043">fullyConnectedFloat32()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00092">fullyConnectedHybrid()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00065">fullyConnectedQuant8()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00153">fullyConnectedSparseWeight()</a>, <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00246">prepare()</a>, and <a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00222">run()</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>runtime/onert/backend/cpu/ops/<a class="el" href="cpu_2ops_2_fully_connected_layer_8h_source.html">FullyConnectedLayer.h</a></li>
<li>runtime/onert/backend/cpu/ops/<a class="el" href="cpu_2ops_2_fully_connected_layer_8cc_source.html">FullyConnectedLayer.cc</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespaceonert.html">onert</a></li><li class="navelem"><a class="el" href="namespaceonert_1_1backend.html">backend</a></li><li class="navelem"><a class="el" href="namespaceonert_1_1backend_1_1cpu.html">cpu</a></li><li class="navelem"><a class="el" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html">ops</a></li><li class="navelem"><a class="el" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html">FullyConnectedLayer</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
