one (1.26.0) bionic; urgency=medium

  * Support more Op(s): HardSwish, CumSum, BroadcastTo
  * Support more optimization option(s): `decompose_softmax`, `decompose_hardswish`, `fuse_slice_with_tconv`,
    `fuse_mul_with_conv`, `remove_unnecessary_add`, `fuse_horizontal_fc_layers`, `common_subexpression_elimination`,
    `remove_unnecessary_transpose`
  * _one-quantize_ supports more option
    - Requantization option to convert TF2-quantized int8 model to uint8 model (--requantize)
    - A new option to automatically find mixed-precision configuration (--ampq)
    - A new option to save calibrated min/max values (--save_min_max)
    - Add new parameters for moving average calibration (--moving_avg_batch, --moving_avg_const)
  * Introduce _q-implant_ that writes quantization parameters and weights into the circle model
  * Introduce _minmax-embedder_ that embeds min/max values into the circle model

 -- seongwoo <mhs4670go@naver.com>  Thu, 21 Dec 2023 08:20:28 +0900

one (1.24.0) bionic; urgency=medium

  * Introduce _one-import-onnx_ extension interface
  * _onecc_ supports profiling of multiple backends with a single cfg file
  * Enable more Quantize operator: FloorMod, Squeeze
  * _visq_ supports multi-out nodes
  * _onecc_ introduces `dynamic_batch_to_single_batch option` option.

 -- seongwoo <seongwoo@sw>  Thu, 18 Jul 2023 14:10:22 +0900

one (1.23.0) bionic; urgency=medium

  * Support more Op(s): GeLU
  * Support more option(s): `--fuse-gelu`
  * Support multiple backends compilation with a single configuration file
  * Upgrade Circle schema to 0.5

 -- seongwoo <seongwoo@sw>  Thu, 18 May 2023 19:10:21 +0900

one (1.22.0) bionic; urgency=medium

  * Introduce new optimization options: `unroll_unidirseqlstm`, `forward_transpose_op`, `fold_fully_connected`, `fuse_prelu`
  * Support more Ops for fake quantization: `Depth2Space`, `Space2Depth`, `Pack`, `Unpack`, `Abs`
  * Support more Ops for quantization: `Abs`, `ReduceProd`
  * Introduce _visq_ tool for quantization error visualization
  * Introduce _Environment_ section into configuration file
  * Improve speed of `convert_nchw_to_nhwc` option
  * Support `Add`, `Mul` of index-type (int32, int64) tensors in _one-quantize_
  * Support ubuntu 20.04

 -- seongwoo <mhs4670go@naver.com>  Fri, 24 Mar 2023 13:58:16 +0900

one (1.21.0) bionic; urgency=medium

  * Support unrolling of LSTM and RNN Ops in `one-import-onnx` tool
  * Introduced new tools `one-infer`, `circle-operator`, `circle-interpreter`
  * Introduced `Workflow`(WIP) in `one-cmds`
  * New option `quant_config` in `one-quantize`
  * New option `fake_quantize` in `one-quantize`
  * More Ops supported: Densify
  * More Ops for quantization: ReduceMax
  * More Ops for mixed-precision quantization (MPQ): LeakyRelu, Neg, Relu6, Squeeze
  * More Ops for `convert_nchw_to_nhwc` option: LogSoftmax, ReduceMax, SplitV, Softmax
  * New optimization options in `one-optimize`: `replace_non_const_fc_with_bmm`, `resolve_customop_splitv`, `fold_densify`
  * Improved reshape elimination in `convert_nchw_to_nhwc` option.
  * Support fusion of Channel-wise Add + Relu with TConv
  * Support negative axis in ArgMin/Max
  * Show errors for unrecognized options in `one-optimize`
  * Fix shape inference for `StridedSlice`
  * Fix FuseBatchNormWithTConvPass to support TConv with bias
  * Deprecate `--O1` option in `circle2circle`
  * Support gcc-11
  * Support limited Float16 for kernels constants with dequantization to Float32

 -- seongwoo <mhs4670go@naver.com>  Wed, 06 Sep 2022 12:00:00 +0900

one (1.20.0) bionic; urgency=medium

  * luci-interpreter supports multiple kernels with PAL layer including Cortext-M
  * luci-interpreter supports integer tensor for partly kernels
  * luci import support constant without coping to reduce memory for luci-interpreter
  * Reduce duplicate codes to package released modules
  * Limited support for ONNX LSTM/RNN unrolling while importing
  * Limited support for ARM32 cross build
  * Support new operator: SVDF
  * New virtual CircleVariable to support tensor with variable
  * Support quantization of BatchMatMul Op
  * Support mixed(UINT8 + INT16) quantization
  * Support backward propagation of quantization parameters
  * Upgrade default python to version 3.8
  * Support TensorFlow 2.8.0, ONNX-TF 1.10.0, ONNX 1.11.0
  * Upgrade circle schema to follow tflite schema v3b
  * Refactor to mio-tflite280, mio-circle04 with version and helpers methods
  * Use one flatbuffers 2.0 version
  * Drop support for TensorFlow 1.x
  * Fix for several bugs, performance enhancements, and typos

 -- seongwoo <mhs4670go@naver.com>  Tue, 26 Apr 2022 12:00:00 +0900

one (1.19.0) bionic; urgency=medium

  * `circle-quantizer` supports input/output type option
  * Introduce configuration file for optimization options

 -- seongwoo <mhs4670go@naver.com>  Wed, 10 Nov 2021 15:53:39 +0900

one (1.18.0) bionic; urgency=medium

  * More optimization pass

 -- seongwoo <mhs4670go@naver.com>  Fri, 15 Oct 2021 15:23:20 +0900

one (1.17.0) bionic; urgency=medium

  * More optimization pass
  * Add new InstanceNorm pattern in `FuseInstanceNormPass`
  * Add verbose option
  * Introduce `onecc` driver to `one-cmds`
  * Introduce `one-profile` driver to `one-cmds`

 -- seongwoo <mhs4670go@naver.com>  Fri, 20 Aug 2021 17:50:20 +0900

one (1.16.1) bionic; urgency=medium

  * Extends the point where `one-codegen` finds backends.

 -- seongwoo chae <mhs4670go@naver.com>  Wed, 26 May 2021 18:06:53 +0900

one (1.16.0) bionic; urgency=low

  * Initial release.

 -- seongwoo chae <mhs4670go@naver.com>  Mon, 26 Apr 2021 14:34:57 +0900
