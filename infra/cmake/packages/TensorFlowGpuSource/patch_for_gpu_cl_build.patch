diff --git a/tensorflow/lite/delegates/gpu/api.h b/tensorflow/lite/delegates/gpu/api.h
index 7892d0ce..fae4fb69 100644
--- a/tensorflow/lite/delegates/gpu/api.h
+++ b/tensorflow/lite/delegates/gpu/api.h
@@ -43,11 +43,18 @@ limitations under the License.
 #include "tensorflow/lite/delegates/gpu/common/data_type.h"
 #include "tensorflow/lite/delegates/gpu/common/status.h"
 #include "tensorflow/lite/delegates/gpu/common/util.h"
+
+#ifdef TFLITE_GPU_LIB_FIX
 #include <vulkan/vulkan.h>
+#endif
 
 #define GL_NO_PROTOTYPES
 #define EGL_NO_PROTOTYPES
+
+#ifdef TFLITE_GPU_LIB_FIX
 #include "tensorflow/lite/delegates/gpu/gl/portable_gl31.h"
+#endif
+
 #undef GL_NO_PROTOTYPES
 #undef EGL_NO_PROTOTYPES
 
@@ -80,6 +87,7 @@ enum class ObjectType {
   VULKAN_TEXTURE
 };
 
+#ifdef TFLITE_GPU_LIB_FIX
 struct OpenGlBuffer {
   OpenGlBuffer() = default;
   explicit OpenGlBuffer(GLuint new_id) : id(new_id) {}
@@ -95,6 +103,7 @@ struct OpenGlTexture {
   GLuint id = GL_INVALID_INDEX;
   GLenum format = GL_INVALID_ENUM;
 };
+#endif
 
 struct OpenClBuffer {
   OpenClBuffer() = default;
@@ -111,6 +120,7 @@ struct OpenClTexture {
   // TODO(akulik): should it specify texture format?
 };
 
+#ifdef TFLITE_GPU_LIB_FIX
 struct VulkanBuffer {
   VulkanBuffer() = default;
   explicit VulkanBuffer(VkBuffer buffer_, VkDeviceSize size_,
@@ -143,6 +153,7 @@ struct VulkanMemory {
   VkDeviceSize size;
   VkDeviceSize offset;
 };
+#endif
 
 struct CpuMemory {
   CpuMemory() = default;
@@ -228,10 +239,15 @@ bool IsValid(const TensorObjectDef& def);
 // @return the number of elements in a tensor object.
 uint32_t NumElements(const TensorObjectDef& def);
 
+#ifdef TFLITE_GPU_LIB_FIX
 using TensorObject =
     absl::variant<absl::monostate, OpenGlBuffer, OpenGlTexture, CpuMemory,
                   OpenClBuffer, OpenClTexture, VulkanBuffer, VulkanTexture>;
-
+#else
+using TensorObject =
+    absl::variant<absl::monostate, CpuMemory,
+                  OpenClBuffer, OpenClTexture>;
+#endif
 // @return true if object is set and corresponding values are defined.
 bool IsValid(const TensorObjectDef& def, const TensorObject& object);
 
diff --git a/tensorflow/lite/delegates/gpu/cl/api.h b/tensorflow/lite/delegates/gpu/cl/api.h
index 65671117..c339f3f0 100644
--- a/tensorflow/lite/delegates/gpu/cl/api.h
+++ b/tensorflow/lite/delegates/gpu/cl/api.h
@@ -20,7 +20,9 @@ limitations under the License.
 #define EGL_NO_PROTOTYPES
 #endif
 
+#ifdef TFLITE_GPU_LIB_FIX
 #include <EGL/egl.h>
+#endif
 
 #include <cstdint>
 #include <memory>
@@ -115,9 +117,10 @@ struct InferenceEnvironmentOptions {
   // It is the error to set egl_display, egl_context AND context at the same
   // time. If egl_display and egl_context are set, they will be used to create
   // GL-aware CL context.
+#ifdef TFLITE_GPU_LIB_FIX
   EGLDisplay egl_display = EGL_NO_DISPLAY;
   EGLContext egl_context = EGL_NO_CONTEXT;
-
+#endif //TFLITE_GPU_LIB_FIX
   // Should contain data returned from
   // InferenceEnvironment::GetSerializedBinaryCache method.
   // Invalid or incompatible data will be discarded. Compiled binary may become
@@ -125,7 +128,11 @@ struct InferenceEnvironmentOptions {
   absl::Span<const uint8_t> serialized_binary_cache;
 
   bool IsGlAware() const {
+#ifdef TFLITE_GPU_LIB_FIX
     return egl_context != EGL_NO_CONTEXT && egl_display != EGL_NO_DISPLAY;
+#else //TFLITE_GPU_LIB_FIX
+    return false;
+#endif //TFLITE_GPU_LIB_FIX
   }
 };
 
diff --git a/tensorflow/lite/delegates/gpu/cl/arguments.h b/tensorflow/lite/delegates/gpu/cl/arguments.h
index a5435c4f..e088355b 100644
--- a/tensorflow/lite/delegates/gpu/cl/arguments.h
+++ b/tensorflow/lite/delegates/gpu/cl/arguments.h
@@ -23,7 +23,9 @@ limitations under the License.
 #include "tensorflow/lite/delegates/gpu/cl/cl_device.h"
 #include "tensorflow/lite/delegates/gpu/cl/gpu_object.h"
 #include "tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h"
+#ifdef TFLITE_GPU_LIB_FIX
 #include "tensorflow/lite/delegates/gpu/cl/serialization_generated.h"
+#endif
 #include "tensorflow/lite/delegates/gpu/cl/util.h"
 #include "tensorflow/lite/delegates/gpu/common/access_type.h"
 #include "tensorflow/lite/delegates/gpu/common/status.h"
@@ -78,11 +80,12 @@ class Arguments : public ArgumentsBinder {
   ~Arguments() override = default;
 
  private:
+#ifdef TFLITE_GPU_LIB_FIX
   friend flatbuffers::Offset<data::Arguments> Encode(
       const Arguments& args, flatbuffers::FlatBufferBuilder* builder);
   friend absl::Status Decode(CLContext* context, const data::Arguments* fb_args,
                              Arguments* args);
-
+#endif
   void AddBuffer(const std::string& name, const GPUBufferDescriptor& desc);
   void AddImage2D(const std::string& name, const GPUImage2DDescriptor& desc);
   void AddImage2DArray(const std::string& name,
diff --git a/tensorflow/lite/delegates/gpu/cl/gpu_object.h b/tensorflow/lite/delegates/gpu/cl/gpu_object.h
index abd77a44..ac1b7f00 100644
--- a/tensorflow/lite/delegates/gpu/cl/gpu_object.h
+++ b/tensorflow/lite/delegates/gpu/cl/gpu_object.h
@@ -23,7 +23,9 @@ limitations under the License.
 
 #include "tensorflow/lite/delegates/gpu/cl/cl_context.h"
 #include "tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h"
+#ifdef TFLITE_GPU_LIB_FIX
 #include "tensorflow/lite/delegates/gpu/cl/serialization_generated.h"
+#endif
 #include "tensorflow/lite/delegates/gpu/common/access_type.h"
 #include "tensorflow/lite/delegates/gpu/common/data_type.h"
 #include "tensorflow/lite/delegates/gpu/common/status.h"
@@ -165,10 +167,12 @@ class GPUObjectDescriptor {
   AccessType GetAccess() const { return access_type_; }
 
  protected:
+#ifdef TFLITE_GPU_LIB_FIX
   friend flatbuffers::Offset<data::GPUObjectDescriptor> Encode(
       const GPUObjectDescriptor& desc, flatbuffers::FlatBufferBuilder* builder);
   friend void Decode(const data::GPUObjectDescriptor* fb_obj,
                      GPUObjectDescriptor* obj);
+#endif
   mutable std::map<std::string, std::string> state_vars_;
   AccessType access_type_;
 };
diff --git a/tensorflow/lite/delegates/gpu/cl/inference_context.cc b/tensorflow/lite/delegates/gpu/cl/inference_context.cc
index ca0c0319..f3cbc863 100644
--- a/tensorflow/lite/delegates/gpu/cl/inference_context.cc
+++ b/tensorflow/lite/delegates/gpu/cl/inference_context.cc
@@ -151,6 +151,7 @@ CLNode& CLNode::operator=(CLNode&& node) {
   return *this;
 }
 
+#ifdef TFLITE_GPU_LIB_FIX
 absl::Status InferenceContext::InitFromGraph(
     const CreateInferenceInfo& create_info, const GraphFloat32& graph,
     Environment* env, std::vector<uint8_t>* serialized_model) {
@@ -239,6 +240,7 @@ absl::Status InferenceContext::RestoreDeserialized(
   }
   return absl::OkStatus();
 }
+#endif
 
 absl::Status InferenceContext::InitFromGraphWithTransforms(
     const CreateInferenceInfo& create_info, GraphFloat32* graph,
diff --git a/tensorflow/lite/delegates/gpu/cl/inference_context.h b/tensorflow/lite/delegates/gpu/cl/inference_context.h
index ec8055eb..871af9dd 100644
--- a/tensorflow/lite/delegates/gpu/cl/inference_context.h
+++ b/tensorflow/lite/delegates/gpu/cl/inference_context.h
@@ -31,7 +31,9 @@ limitations under the License.
 #include "tensorflow/lite/delegates/gpu/cl/model_hints.h"
 #include "tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h"
 #include "tensorflow/lite/delegates/gpu/cl/precision.h"
+#ifdef TFLITE_GPU_LIB_FIX
 #include "tensorflow/lite/delegates/gpu/cl/serialization_generated.h"
+#endif
 #include "tensorflow/lite/delegates/gpu/cl/tensor_type.h"
 #include "tensorflow/lite/delegates/gpu/common/model.h"
 #include "tensorflow/lite/delegates/gpu/common/status.h"
@@ -100,12 +102,14 @@ class InferenceContext {
  private:
   enum TensorMemoryType { STRONG_SHAPE = 0, BUFFER = 1, VARIABLE = 2 };
 
+#ifdef TFLITE_GPU_LIB_FIX
   friend flatbuffers::Offset<data::InferenceContext> Encode(
       const InferenceContext& inference,
       flatbuffers::FlatBufferBuilder* builder);
   friend absl::Status Decode(CLContext* context,
                              const data::InferenceContext* fb_inference,
                              InferenceContext* inference);
+#endif
 
   void CopyInAndOutIds(const GraphFloat32& graph);
   absl::Status ConvertOperations(const DeviceInfo& device_info,
diff --git a/tensorflow/lite/delegates/gpu/cl/kernels/gpu_operation.h b/tensorflow/lite/delegates/gpu/cl/kernels/gpu_operation.h
index 57d8690c..8178e2de 100644
--- a/tensorflow/lite/delegates/gpu/cl/kernels/gpu_operation.h
+++ b/tensorflow/lite/delegates/gpu/cl/kernels/gpu_operation.h
@@ -30,7 +30,9 @@ limitations under the License.
 #include "tensorflow/lite/delegates/gpu/cl/kernels/tuning_parameters.h"
 #include "tensorflow/lite/delegates/gpu/cl/precision.h"
 #include "tensorflow/lite/delegates/gpu/cl/program_cache.h"
+#ifdef TFLITE_GPU_LIB_FIX
 #include "tensorflow/lite/delegates/gpu/cl/serialization_generated.h"
+#endif
 #include "tensorflow/lite/delegates/gpu/cl/tensor.h"
 #include "tensorflow/lite/delegates/gpu/cl/tensor_type.h"
 #include "tensorflow/lite/delegates/gpu/common/data_type.h"
@@ -169,11 +171,12 @@ class GPUOperation {
   bool check_src_channels_size_ = false;
 
  protected:
+#ifdef TFLITE_GPU_LIB_FIX
   friend flatbuffers::Offset<data::GPUOperation> Encode(
       const GPUOperation& op, flatbuffers::FlatBufferBuilder* builder);
   friend absl::Status Decode(CLContext* context,
                              const data::GPUOperation* fb_op, GPUOperation* op);
-
+#endif
   virtual absl::Status BindArguments(ArgumentsBinder* args) {
     return absl::OkStatus();
   }
diff --git a/tensorflow/lite/delegates/gpu/cl/program_cache.cc b/tensorflow/lite/delegates/gpu/cl/program_cache.cc
index 285aa06d..f636a909 100644
--- a/tensorflow/lite/delegates/gpu/cl/program_cache.cc
+++ b/tensorflow/lite/delegates/gpu/cl/program_cache.cc
@@ -18,9 +18,13 @@ limitations under the License.
 #include <cstdint>
 #include <string>
 
+#ifdef TFLITE_GPU_LIB_FIX
 #include "flatbuffers/flatbuffers.h"  // from @flatbuffers
+#endif
 #include "tensorflow/lite/delegates/gpu/cl/cl_program.h"
+#ifdef TFLITE_GPU_LIB_FIX
 #include "tensorflow/lite/delegates/gpu/cl/compiled_program_cache_generated.h"
+#endif
 #include "tensorflow/lite/delegates/gpu/cl/util.h"
 #include "tensorflow/lite/delegates/gpu/common/status.h"
 #include <farmhash.h>
@@ -82,6 +86,7 @@ absl::Status ProgramCache::GetOrCreateCLKernel(const std::string& code,
   return GetOrCreateCLKernel(code, function_name, {}, context, device, result);
 }
 
+#ifdef TFLITE_GPU_LIB_FIX
 absl::Status ProgramCache::AddSerializedCache(
     const CLContext& context, const CLDevice& device,
     absl::Span<const uint8_t> serialized_cache) {
@@ -143,6 +148,7 @@ absl::Status ProgramCache::GetSerializedCache(
               builder.GetSize());
   return absl::OkStatus();
 }
+#endif
 
 }  // namespace cl
 }  // namespace gpu
diff --git a/tensorflow/lite/delegates/gpu/common/types.h b/tensorflow/lite/delegates/gpu/common/types.h
index 4ddb46f3..2b692f0b 100644
--- a/tensorflow/lite/delegates/gpu/common/types.h
+++ b/tensorflow/lite/delegates/gpu/common/types.h
@@ -34,9 +34,9 @@ class alignas(2) half {
   HalfBits bits;
 
   half() = default;
-
+#ifdef TFLITE_GPU_LIB_FIX
   half(const half& f) : bits(f.bits) {}
-
+#endif
   explicit half(float other) { bits = fp16_ieee_from_fp32_value(other); }
 
   void operator=(float f) { *this = half(f); }
