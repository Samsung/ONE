<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.5"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ONE - On-device Neural Engine: runtime/onert/backend/cpu/ops/FullyConnectedLayer.cc Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">ONE - On-device Neural Engine
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.5 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('cpu_2ops_2_fully_connected_layer_8cc_source.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">FullyConnectedLayer.cc</div></div>
</div><!--header-->
<div class="contents">
<a href="cpu_2ops_2_fully_connected_layer_8cc.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno">    1</span><span class="comment">/*</span></div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="comment"> * Copyright (c) 2018 Samsung Electronics Co., Ltd. All Rights Reserved</span></div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span><span class="comment"> *</span></div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span><span class="comment"> * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span><span class="comment"> * you may not use this file except in compliance with the License.</span></div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span><span class="comment"> * You may obtain a copy of the License at</span></div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span><span class="comment"> *</span></div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno">    8</span><span class="comment"> *      http://www.apache.org/licenses/LICENSE-2.0</span></div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span><span class="comment"> *</span></div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span><span class="comment"> * Unless required by applicable law or agreed to in writing, software</span></div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span><span class="comment"> * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span><span class="comment"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span><span class="comment"> * See the License for the specific language governing permissions and</span></div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="comment"> * limitations under the License.</span></div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span><span class="comment"> */</span></div>
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno">   16</span> </div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span><span class="preprocessor">#include &quot;<a class="code" href="xnnpack_2ops_2_fully_connected_layer_8h.html">FullyConnectedLayer.h</a>&quot;</span></div>
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno">   18</span> </div>
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno">   19</span><span class="preprocessor">#include &quot;../Tensor.h&quot;</span></div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span><span class="preprocessor">#include &lt;<a class="code" href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h.html">cker/operation/FullyConnected.h</a>&gt;</span></div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno">   21</span><span class="preprocessor">#include &lt;<a class="code" href="compute_2cker_2include_2cker_2_tensor_utils_8h.html">cker/TensorUtils.h</a>&gt;</span></div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span><span class="preprocessor">#include &lt;<a class="code" href="polymorphic__downcast_8h.html">misc/polymorphic_downcast.h</a>&gt;</span></div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno">   23</span> </div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno">   24</span><span class="keyword">namespace </span><a class="code hl_namespace" href="namespaceonert.html">onert</a></div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno">   25</span>{</div>
<div class="line"><a id="l00026" name="l00026"></a><span class="lineno">   26</span><span class="keyword">namespace </span>backend</div>
<div class="line"><a id="l00027" name="l00027"></a><span class="lineno">   27</span>{</div>
<div class="line"><a id="l00028" name="l00028"></a><span class="lineno">   28</span><span class="keyword">namespace </span>cpu</div>
<div class="line"><a id="l00029" name="l00029"></a><span class="lineno">   29</span>{</div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno">   30</span><span class="keyword">namespace </span><a class="code hl_namespace" href="namespacemir_1_1ops.html">ops</a></div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno">   31</span>{</div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno">   32</span> </div>
<div class="line"><a id="l00033" name="l00033"></a><span class="lineno"><a class="line" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ab9659326558b505132635a729eb7dc26">   33</a></span><a class="code hl_function" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ab9659326558b505132635a729eb7dc26">FullyConnectedLayer::FullyConnectedLayer</a>()</div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno">   34</span>  : _input(nullptr), _weights(nullptr), _bias(nullptr), _output(nullptr),</div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno">   35</span>    _activation(ir::Activation::<a class="code hl_enumvalue" href="_fused_8h.html#a4c6c18f14951cbc3aa6e8089b3a24342ab50339a10e1de285ac99d4c3990b8693">NONE</a>), _temp_arena(new <a class="code hl_namespace" href="namespacennfw.html">nnfw</a>::cker::FCTempArena()),</div>
<div class="line"><a id="l00036" name="l00036"></a><span class="lineno">   36</span>    _external_context(nullptr), _is_hybrid(false), _is_shuffled16x1float32(false)</div>
<div class="line"><a id="l00037" name="l00037"></a><span class="lineno">   37</span>{</div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno">   38</span>  <span class="comment">// DO NOTHING</span></div>
<div class="line"><a id="l00039" name="l00039"></a><span class="lineno">   39</span>}</div>
<div class="line"><a id="l00040" name="l00040"></a><span class="lineno">   40</span> </div>
<div class="line"><a id="l00041" name="l00041"></a><span class="lineno">   41</span><a class="code hl_function" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a822066c1d1450094011067542f0b9a0d">FullyConnectedLayer::~FullyConnectedLayer</a>() = <span class="keywordflow">default</span>;</div>
<div class="line"><a id="l00042" name="l00042"></a><span class="lineno">   42</span> </div>
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno"><a class="line" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a648618c630985a3d90aeae23ec2cdc4e">   43</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a648618c630985a3d90aeae23ec2cdc4e">FullyConnectedLayer::fullyConnectedFloat32</a>()</div>
<div class="line"><a id="l00044" name="l00044"></a><span class="lineno">   44</span>{</div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno">   45</span>  <a class="code hl_struct" href="structnnfw_1_1cker_1_1_fully_connected_params.html">nnfw::cker::FullyConnectedParams</a> op_params;</div>
<div class="line"><a id="l00046" name="l00046"></a><span class="lineno">   46</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a15410fd240c7d16cdeaca54856b712c8">activation</a> = <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a0e7672ebf55bbaa7e1d86a46cfd53c5e">convertActivationType</a>(_activation);</div>
<div class="line"><a id="l00047" name="l00047"></a><span class="lineno">   47</span> </div>
<div class="line"><a id="l00048" name="l00048"></a><span class="lineno">   48</span>  <a class="code hl_function" href="namespacennfw_1_1cker.html#a893434782a43556a99989be14e599d63">nnfw::cker::FullyConnected</a>(op_params, <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_input), getBuffer&lt;float&gt;(_input),</div>
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno">   49</span>                             <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_weights), getBuffer&lt;float&gt;(_weights), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_bias),</div>
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno">   50</span>                             _bias ? getBuffer&lt;float&gt;(_bias) : <span class="keyword">nullptr</span>, <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_output),</div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno">   51</span>                             getBuffer&lt;float&gt;(_output));</div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno">   52</span>}</div>
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno">   53</span> </div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno">   54</span><span class="comment">// executionMutex is used to protect concurrent access of non-threadsafe resources</span></div>
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno">   55</span><span class="comment">// like gemmlowp::GemmContext.</span></div>
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno"><a class="line" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#af90252c9fc392b5b8bb7f8c0fa203741">   56</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#af90252c9fc392b5b8bb7f8c0fa203741">FullyConnectedLayer::fullyConnectedQuant8</a>()</div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno">   57</span>{</div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span>  <span class="keywordtype">double</span> real_multiplier = 0.0;</div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno">   59</span>  int32_t output_multiplier = 0;</div>
<div class="line"><a id="l00060" name="l00060"></a><span class="lineno">   60</span>  int32_t output_shift = 0;</div>
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno">   61</span>  int32_t output_activation_min = 0;</div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span>  int32_t output_activation_max = 0;</div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno">   63</span>  <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#ae4d438d3d3062bfd95a6e0caed125457">GetQuantizedConvolutionMultiplier</a>(_input, _weights, _bias, _output, &amp;real_multiplier);</div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span>  <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a3be5fe32ffdf0573dd36b64172dbaa3a">QuantizeMultiplier</a>(real_multiplier, &amp;output_multiplier, &amp;output_shift);</div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span>  <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#aa3ed894d41e9c8473df0db171af23d7d">CalculateActivationRangeQuantized</a>(_activation, _output, &amp;output_activation_min,</div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span>                                    &amp;output_activation_max);</div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span> </div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno">   68</span>  <a class="code hl_struct" href="structnnfw_1_1cker_1_1_fully_connected_params.html">nnfw::cker::FullyConnectedParams</a> op_params;</div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a88a4ccb4fb1a3a1fc0b5066ca98b1fef">input_offset</a> = -_input-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#a0c2877a5e6e7d5ac7416baf7d3315644">data_zero_point</a>();</div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a386f74239ea2059f97fadb7b3c407f37">weights_offset</a> = -_weights-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#a0c2877a5e6e7d5ac7416baf7d3315644">data_zero_point</a>();</div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno">   71</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#aba4be915f48ac33044094e092fe04c38">output_offset</a> = _output-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#a0c2877a5e6e7d5ac7416baf7d3315644">data_zero_point</a>();</div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno">   72</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a092f1b0d178bedcbec27ae01bdb35295">output_multiplier</a> = output_multiplier;</div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#aad53016de4b3709a2c0691bc5cab3c12">output_shift</a> = output_shift;</div>
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a5268ff3c0cf7eed73da16324a82f3e39">quantized_activation_min</a> = output_activation_min;</div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a7e955d0d5d1022cd53da9c32ebf48ae0">quantized_activation_max</a> = output_activation_max;</div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span> </div>
<div class="line"><a id="l00077" name="l00077"></a><span class="lineno">   77</span>  <a class="code hl_function" href="namespacennfw_1_1cker.html#a893434782a43556a99989be14e599d63">nnfw::cker::FullyConnected</a>(op_params, <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_input), getBuffer&lt;uint8_t&gt;(_input),</div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno">   78</span>                             <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_weights), getBuffer&lt;uint8_t&gt;(_weights), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_bias),</div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno">   79</span>                             _bias ? getBuffer&lt;int32_t&gt;(_bias) : <span class="keyword">nullptr</span>, <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_output),</div>
<div class="line"><a id="l00080" name="l00080"></a><span class="lineno">   80</span>                             getBuffer&lt;uint8_t&gt;(_output));</div>
<div class="line"><a id="l00081" name="l00081"></a><span class="lineno">   81</span>}</div>
<div class="line"><a id="l00082" name="l00082"></a><span class="lineno">   82</span> </div>
<div class="line"><a id="l00083" name="l00083"></a><span class="lineno"><a class="line" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aea2f03e86f6d110ff8a1eaae0caa8d82">   83</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aea2f03e86f6d110ff8a1eaae0caa8d82">FullyConnectedLayer::fullyConnectedHybrid</a>()</div>
<div class="line"><a id="l00084" name="l00084"></a><span class="lineno">   84</span>{</div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno">   85</span>  <a class="code hl_class" href="classnnfw_1_1cker_1_1_f_c_temp_arena.html">nnfw::cker::FCTempArena</a> &amp;temp_arena = *_temp_arena;</div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno">   86</span>  <span class="keywordflow">if</span> (!temp_arena.<a class="code hl_variable" href="classnnfw_1_1cker_1_1_f_c_temp_arena.html#a6743d412a028cb7a7021bf255274345f">prepared</a>)</div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span>  {</div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span>    temp_arena.<a class="code hl_function" href="classnnfw_1_1cker_1_1_f_c_temp_arena.html#acafeac459e58e656d39398433953b0d0">prepare</a>(<a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_input), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_weights));</div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span>  }</div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno">   90</span> </div>
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno">   91</span>  <a class="code hl_struct" href="structnnfw_1_1cker_1_1_fully_connected_params.html">nnfw::cker::FullyConnectedParams</a> op_params;</div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno">   92</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a15410fd240c7d16cdeaca54856b712c8">activation</a> = <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a0e7672ebf55bbaa7e1d86a46cfd53c5e">convertActivationType</a>(_activation);</div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno">   93</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#ad7a6c95463633a349e7551dad13f8dba">weights_scale</a> = _weights-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#aedf4a030ba4e787ec06eb0c86b261539">data_scale</a>();</div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span> </div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span><span class="preprocessor">#ifndef USE_RUY_GEMV</span></div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span>  <a class="code hl_function" href="namespacennfw_1_1cker.html#a86c3c8cb5e011dd68e4e3eaaa99d5800">nnfw::cker::FullyConnectedHybrid</a>(</div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno">   97</span>    op_params, <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_input), getBuffer&lt;float&gt;(_input), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_weights),</div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno">   98</span>    getBuffer&lt;int8_t&gt;(_weights), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_bias), _bias ? getBuffer&lt;float&gt;(_bias) : <span class="keyword">nullptr</span>,</div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno">   99</span>    <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_output), getBuffer&lt;float&gt;(_output), temp_arena, _external_context-&gt;ruy_context());</div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno">  100</span><span class="preprocessor">#else</span></div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span>  <a class="code hl_function" href="namespacennfw_1_1cker.html#a86c3c8cb5e011dd68e4e3eaaa99d5800">nnfw::cker::FullyConnectedHybrid</a>(</div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno">  102</span>    op_params, <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_input), getBuffer&lt;float&gt;(_input), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_weights),</div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno">  103</span>    (_cached_weights) ? <span class="keyword">reinterpret_cast&lt;</span><span class="keyword">const </span>int8_t *<span class="keyword">&gt;</span>(_cached_weights)</div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno">  104</span>                      : getBuffer&lt;int8_t&gt;(_weights),</div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span>    <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_bias), _bias ? getBuffer&lt;float&gt;(_bias) : <span class="keyword">nullptr</span>, <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_output),</div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span>    getBuffer&lt;float&gt;(_output), temp_arena, _external_context-&gt;ruy_context());</div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span> </div>
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno">  108</span>  <span class="keywordflow">if</span> (_cached_weights == <span class="keyword">nullptr</span> || _is_weights_freed)</div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno">  109</span>    <span class="keywordflow">return</span>;</div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno">  110</span> </div>
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno">  111</span>  <span class="comment">// &#39;_cached_weights is not nullptr and _is_weights_freed is false&#39; means</span></div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno">  112</span>  <span class="comment">// this weight shape is satisfied with the ruy kernel&#39;s prepack cache&#39;s condition.</span></div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span>  <span class="comment">// After entering here, it will not enter again except below the case - input is zero-vector</span></div>
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno">  114</span> </div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span>  <span class="comment">// if input&#39;s elements are filled with zero, it by-passes(does not enter ruy-kernel path)</span></div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno">  116</span>  <span class="comment">// so that handle this case</span></div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno">  117</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> input_size = <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_input).<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#ac7e29fd510111992fbd44906e2080f12">FlatSize</a>();</div>
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno">  118</span>  <span class="keywordflow">if</span> (<a class="code hl_function" href="namespacennfw_1_1cker.html#af82fa9f0cdbd15fed59567999835cebf">nnfw::cker::IsZeroVector</a>(getBuffer&lt;float&gt;(_input), input_size))</div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span>    <span class="keywordflow">return</span>;</div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno">  120</span> </div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span>  <span class="keyword">auto</span> weight_tensor = nnfw::misc::polymorphic_downcast&lt;const Tensor *&gt;(_weights);</div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno">  122</span> </div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno">  123</span>  <span class="comment">// This weight tensor could be other ops&#39; const tensor.</span></div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno">  124</span>  <span class="comment">// Therefore, below reference should be checked like following</span></div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span>  <span class="keyword">auto</span> tensor = <span class="keyword">const_cast&lt;</span><a class="code hl_class" href="classonert_1_1backend_1_1basic_1_1_tensor.html">Tensor</a> *<span class="keyword">&gt;</span>(weight_tensor);</div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno">  126</span>  <span class="keywordflow">if</span> (tensor-&gt;buffer() == <span class="keyword">nullptr</span>) <span class="comment">// ref is already 0?</span></div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span>  {</div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span>    _is_weights_freed = <span class="keyword">true</span>;</div>
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno">  129</span>    <span class="keywordflow">return</span>;</div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno">  130</span>  }</div>
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno">  131</span> </div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span>  tensor-&gt;decrease_ref();</div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span>  <span class="keywordflow">if</span> (tensor-&gt;buffer() == <span class="keyword">nullptr</span>) <span class="comment">// ref == 0?</span></div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span>  {</div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span><span class="preprocessor">#if defined(__ANDROID__) &amp;&amp; (__ANDROID_API__ &gt;= 26)</span></div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span>    <span class="comment">// NOTE This line forces OS to release any unused memory immediately</span></div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span>    mallopt(M_PURGE, 0);</div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno">  139</span>    _is_weights_freed = <span class="keyword">true</span>;</div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span>  }</div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno">  142</span>}</div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno">  143</span> </div>
<div class="line"><a id="l00144" name="l00144"></a><span class="lineno"><a class="line" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a27ebc09cfe60bf438b6ac2b831d0a8b5">  144</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a27ebc09cfe60bf438b6ac2b831d0a8b5">FullyConnectedLayer::fullyConnectedSparseWeight</a>()</div>
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno">  145</span>{</div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span>  <a class="code hl_struct" href="structnnfw_1_1cker_1_1_fully_connected_params.html">nnfw::cker::FullyConnectedParams</a> op_params;</div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a15410fd240c7d16cdeaca54856b712c8">activation</a> = <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a0e7672ebf55bbaa7e1d86a46cfd53c5e">convertActivationType</a>(_activation);</div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span> </div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span>  <span class="keyword">const</span> uint16_t *w1_segments = _weights-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#aee0afc215e2f87867c419da5425528eb">sparsity</a>()-&gt;<a class="code hl_function" href="structonert_1_1ir_1_1_sparsity.html#a46532d90a469c48114b12ab3ba16c76b">w1_segments</a>();</div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno">  150</span>  <span class="keyword">const</span> uint16_t *w1_indices = _weights-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#aee0afc215e2f87867c419da5425528eb">sparsity</a>()-&gt;<a class="code hl_function" href="structonert_1_1ir_1_1_sparsity.html#a76b05fe5094e56d48d87652f553e038c">w1_indices</a>();</div>
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno">  151</span> </div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno">  152</span>  <span class="keyword">auto</span> block_size = _weights-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#aee0afc215e2f87867c419da5425528eb">sparsity</a>()-&gt;<a class="code hl_function" href="structonert_1_1ir_1_1_sparsity.html#a27434d14d1c2593592a6b9e043e308dc">block_size</a>();</div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno">  153</span>  <span class="keywordflow">if</span> (block_size.size() == 0)</div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno">  154</span>  {</div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span>    <a class="code hl_function" href="namespacennfw_1_1cker.html#a0da6b0f998eacd17836e7f7265cd1605">nnfw::cker::FullyConnectedSparseWeightRandom</a>(</div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span>      op_params, <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_input), getBuffer&lt;float&gt;(_input), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_weights),</div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span>      getBuffer&lt;float&gt;(_weights), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_bias), _bias ? getBuffer&lt;float&gt;(_bias) : <span class="keyword">nullptr</span>,</div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno">  158</span>      <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_output), getBuffer&lt;float&gt;(_output), w1_segments, w1_indices);</div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span>  }</div>
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno">  160</span>  <span class="keywordflow">else</span> <span class="keywordflow">if</span> (block_size.size() == 2 &amp;&amp; block_size[0] == 16 &amp;&amp; block_size[1] == 1)</div>
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno">  161</span>  {</div>
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno">  162</span>    <a class="code hl_function" href="namespacennfw_1_1cker.html#a38ce7e8df68ce5c6527f23b008a422b3">nnfw::cker::FullyConnectedSparseWeight16x1</a>(</div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno">  163</span>      op_params, <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_input), getBuffer&lt;float&gt;(_input), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_weights),</div>
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno">  164</span>      getBuffer&lt;float&gt;(_weights), <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_bias), _bias ? getBuffer&lt;float&gt;(_bias) : <span class="keyword">nullptr</span>,</div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno">  165</span>      <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_output), getBuffer&lt;float&gt;(_output), w1_segments, w1_indices);</div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno">  166</span>  }</div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno">  167</span>  <span class="keywordflow">else</span></div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span>    <span class="keywordflow">throw</span> std::runtime_error{<span class="stringliteral">&quot;FullyConnected: unsupported sparsity&quot;</span>};</div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno">  169</span>}</div>
<div class="line"><a id="l00170" name="l00170"></a><span class="lineno">  170</span> </div>
<div class="line"><a id="l00171" name="l00171"></a><span class="lineno"><a class="line" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2006db79e45053eb357f55af95471524">  171</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2006db79e45053eb357f55af95471524">FullyConnectedLayer::fullyConnected16x1Float32</a>()</div>
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno">  172</span>{</div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno">  173</span><span class="preprocessor">#if defined(__aarch64__) &amp;&amp; defined(USE_NEON)</span></div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno">  174</span>  <span class="keywordtype">float</span> output_activation_min = 0, output_activation_max = 0;</div>
<div class="line"><a id="l00175" name="l00175"></a><span class="lineno">  175</span>  <a class="code hl_function" href="namespaceonert_1_1util.html#a9aac61f35b6d507552fea7bd8ac070ab">CalculateActivationRange</a>(_activation, &amp;output_activation_min, &amp;output_activation_max);</div>
<div class="line"><a id="l00176" name="l00176"></a><span class="lineno">  176</span> </div>
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno">  177</span>  <a class="code hl_struct" href="structnnfw_1_1cker_1_1_fully_connected_params.html">nnfw::cker::FullyConnectedParams</a> op_params;</div>
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno">  178</span>  op_params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_fully_connected_params.html#a15410fd240c7d16cdeaca54856b712c8">activation</a> = <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a0e7672ebf55bbaa7e1d86a46cfd53c5e">convertActivationType</a>(_activation);</div>
<div class="line"><a id="l00179" name="l00179"></a><span class="lineno">  179</span> </div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span>  nnfw::cker::FullyConnected16x1Float32(op_params, <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_input), getBuffer&lt;float&gt;(_input),</div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span>                                        <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_weights), getBuffer&lt;float&gt;(_weights),</div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span>                                        <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_bias), _bias ? getBuffer&lt;float&gt;(_bias) : <span class="keyword">nullptr</span>,</div>
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno">  183</span>                                        <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_output), getBuffer&lt;float&gt;(_output));</div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span><span class="preprocessor">#else</span></div>
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno">  185</span>  <span class="keywordflow">throw</span> std::runtime_error{<span class="stringliteral">&quot;FullyConnected: Shuffled16x1Float32 weights_format is not supported.&quot;</span>};</div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno">  187</span>}</div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno">  188</span> </div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno"><a class="line" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aee0f4ff5a4e1d31c65f4346494499e82">  189</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aee0f4ff5a4e1d31c65f4346494499e82">FullyConnectedLayer::configure</a>(<span class="keyword">const</span> <a class="code hl_class" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *input, <span class="keyword">const</span> <a class="code hl_class" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *weights,</div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span>                                    <span class="keyword">const</span> <a class="code hl_class" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *bias, <a class="code hl_enumeration" href="namespaceonert_1_1ir.html#a8ce6c92ea138aca1332e4be9531bd5d4">ir::Activation</a> activation,</div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span>                                    <a class="code hl_enumeration" href="namespaceonert_1_1ir.html#a4dc82d1ced0dff0fcabe7e74d6c76c19">ir::FullyConnectedWeightsFormat</a> weights_format,</div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span>                                    <a class="code hl_class" href="classonert_1_1backend_1_1_i_portable_tensor.html">IPortableTensor</a> *output,</div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span>                                    <span class="keyword">const</span> std::shared_ptr&lt;ExternalContext&gt; &amp;external_context)</div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span>{</div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span>  _input = input;</div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span>  _weights = weights;</div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span>  _bias = bias;</div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span>  _activation = activation;</div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span>  _output = output;</div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span>  _is_hybrid = input-&gt;data_type() == OperandType::FLOAT32 &amp;&amp;</div>
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno">  201</span>               weights-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#a6d57b178316225a9e08f1191ce489ad9">data_type</a>() == OperandType::QUANT_INT8_SYMM;</div>
<div class="line"><a id="l00202" name="l00202"></a><span class="lineno">  202</span>  _is_shuffled16x1float32 = weights_format == <a class="code hl_enumvalue" href="namespaceonert_1_1ir.html#a4dc82d1ced0dff0fcabe7e74d6c76c19a00d4e131097ee909d6bcf8f8e05ac93b">ir::FullyConnectedWeightsFormat::Shuffled16x1Float32</a>;</div>
<div class="line"><a id="l00203" name="l00203"></a><span class="lineno">  203</span><span class="preprocessor">#if !defined(__aarch64__) || !defined(USE_NEON)</span></div>
<div class="line"><a id="l00204" name="l00204"></a><span class="lineno">  204</span>  <span class="keywordflow">if</span> (_is_shuffled16x1float32)</div>
<div class="line"><a id="l00205" name="l00205"></a><span class="lineno">  205</span>  {</div>
<div class="line"><a id="l00206" name="l00206"></a><span class="lineno">  206</span>    <span class="keywordflow">throw</span> std::runtime_error{</div>
<div class="line"><a id="l00207" name="l00207"></a><span class="lineno">  207</span>      <span class="stringliteral">&quot;FullyConnected: Shuffled16x1Float32 weights_format is not supported.&quot;</span>};</div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span>  }</div>
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno">  209</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00210" name="l00210"></a><span class="lineno">  210</span>  _external_context = external_context;</div>
<div class="line"><a id="l00211" name="l00211"></a><span class="lineno">  211</span>}</div>
<div class="line"><a id="l00212" name="l00212"></a><span class="lineno">  212</span> </div>
<div class="line"><a id="l00213" name="l00213"></a><span class="lineno"><a class="line" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aff0e02437f1e864effa060ca8ea19bc1">  213</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aff0e02437f1e864effa060ca8ea19bc1">FullyConnectedLayer::run</a>()</div>
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno">  214</span>{</div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno">  215</span>  <span class="keywordflow">if</span> (_is_hybrid)</div>
<div class="line"><a id="l00216" name="l00216"></a><span class="lineno">  216</span>  {</div>
<div class="line"><a id="l00217" name="l00217"></a><span class="lineno">  217</span>    <a class="code hl_function" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aea2f03e86f6d110ff8a1eaae0caa8d82">fullyConnectedHybrid</a>();</div>
<div class="line"><a id="l00218" name="l00218"></a><span class="lineno">  218</span>  }</div>
<div class="line"><a id="l00219" name="l00219"></a><span class="lineno">  219</span>  <span class="keywordflow">else</span> <span class="keywordflow">if</span> (_weights-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_portable_tensor.html#aee0afc215e2f87867c419da5425528eb">sparsity</a>())</div>
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno">  220</span>  {</div>
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno">  221</span>    <a class="code hl_function" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a27ebc09cfe60bf438b6ac2b831d0a8b5">fullyConnectedSparseWeight</a>();</div>
<div class="line"><a id="l00222" name="l00222"></a><span class="lineno">  222</span>  }</div>
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno">  223</span>  <span class="keywordflow">else</span> <span class="keywordflow">if</span> (_input-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#a6d57b178316225a9e08f1191ce489ad9">data_type</a>() == OperandType::FLOAT32)</div>
<div class="line"><a id="l00224" name="l00224"></a><span class="lineno">  224</span>  {</div>
<div class="line"><a id="l00225" name="l00225"></a><span class="lineno">  225</span>    _is_shuffled16x1float32 ? <a class="code hl_function" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2006db79e45053eb357f55af95471524">fullyConnected16x1Float32</a>() : <a class="code hl_function" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a648618c630985a3d90aeae23ec2cdc4e">fullyConnectedFloat32</a>();</div>
<div class="line"><a id="l00226" name="l00226"></a><span class="lineno">  226</span>  }</div>
<div class="line"><a id="l00227" name="l00227"></a><span class="lineno">  227</span>  <span class="keywordflow">else</span> <span class="keywordflow">if</span> (_input-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#a6d57b178316225a9e08f1191ce489ad9">data_type</a>() == OperandType::QUANT_UINT8_ASYMM)</div>
<div class="line"><a id="l00228" name="l00228"></a><span class="lineno">  228</span>  {</div>
<div class="line"><a id="l00229" name="l00229"></a><span class="lineno">  229</span>    <a class="code hl_function" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#af90252c9fc392b5b8bb7f8c0fa203741">fullyConnectedQuant8</a>();</div>
<div class="line"><a id="l00230" name="l00230"></a><span class="lineno">  230</span>  }</div>
<div class="line"><a id="l00231" name="l00231"></a><span class="lineno">  231</span>  <span class="keywordflow">else</span></div>
<div class="line"><a id="l00232" name="l00232"></a><span class="lineno">  232</span>  {</div>
<div class="line"><a id="l00233" name="l00233"></a><span class="lineno">  233</span>    <span class="keywordflow">throw</span> std::runtime_error{<span class="stringliteral">&quot;FullyConnected: unsupported data type&quot;</span>};</div>
<div class="line"><a id="l00234" name="l00234"></a><span class="lineno">  234</span>  }</div>
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno">  235</span>}</div>
<div class="line"><a id="l00236" name="l00236"></a><span class="lineno">  236</span> </div>
<div class="line"><a id="l00237" name="l00237"></a><span class="lineno"><a class="line" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ab5fc53c26dd7f5863daed38d58cd7c18">  237</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ab5fc53c26dd7f5863daed38d58cd7c18">FullyConnectedLayer::prepare</a>()</div>
<div class="line"><a id="l00238" name="l00238"></a><span class="lineno">  238</span>{</div>
<div class="line"><a id="l00239" name="l00239"></a><span class="lineno">  239</span>  <span class="keywordflow">if</span> (_bias &amp;&amp; _bias-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#a0aa4408d72f1ea3643c386520d9eb4e3">is_constant</a>())</div>
<div class="line"><a id="l00240" name="l00240"></a><span class="lineno">  240</span>  {</div>
<div class="line"><a id="l00241" name="l00241"></a><span class="lineno">  241</span>    <span class="keyword">const</span> <span class="keywordtype">int</span> bias_size = <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_bias).<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#ac7e29fd510111992fbd44906e2080f12">FlatSize</a>();</div>
<div class="line"><a id="l00242" name="l00242"></a><span class="lineno">  242</span>    <span class="keywordflow">if</span> (<a class="code hl_function" href="namespacennfw_1_1cker.html#af82fa9f0cdbd15fed59567999835cebf">nnfw::cker::IsZeroVector</a>(getBuffer&lt;float&gt;(_bias), bias_size))</div>
<div class="line"><a id="l00243" name="l00243"></a><span class="lineno">  243</span>    {</div>
<div class="line"><a id="l00244" name="l00244"></a><span class="lineno">  244</span>      _bias = <span class="keyword">nullptr</span>;</div>
<div class="line"><a id="l00245" name="l00245"></a><span class="lineno">  245</span>    }</div>
<div class="line"><a id="l00246" name="l00246"></a><span class="lineno">  246</span>  }</div>
<div class="line"><a id="l00247" name="l00247"></a><span class="lineno">  247</span> </div>
<div class="line"><a id="l00248" name="l00248"></a><span class="lineno">  248</span><span class="preprocessor">#if (defined(__ARM_NEON__) || defined(__ARM_NEON)) &amp;&amp; defined(USE_RUY_GEMV)</span></div>
<div class="line"><a id="l00249" name="l00249"></a><span class="lineno">  249</span>  <span class="comment">// TODO This is workaround</span></div>
<div class="line"><a id="l00250" name="l00250"></a><span class="lineno">  250</span>  <span class="comment">// The only fc hybrid will use ruy kernel</span></div>
<div class="line"><a id="l00251" name="l00251"></a><span class="lineno">  251</span>  <span class="keywordflow">if</span> (_input-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#a6d57b178316225a9e08f1191ce489ad9">data_type</a>() != OperandType::FLOAT32 ||</div>
<div class="line"><a id="l00252" name="l00252"></a><span class="lineno">  252</span>      _weights-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#a6d57b178316225a9e08f1191ce489ad9">data_type</a>() != OperandType::QUANT_INT8_SYMM)</div>
<div class="line"><a id="l00253" name="l00253"></a><span class="lineno">  253</span>  {</div>
<div class="line"><a id="l00254" name="l00254"></a><span class="lineno">  254</span>    <span class="keywordflow">return</span>;</div>
<div class="line"><a id="l00255" name="l00255"></a><span class="lineno">  255</span>  }</div>
<div class="line"><a id="l00256" name="l00256"></a><span class="lineno">  256</span> </div>
<div class="line"><a id="l00257" name="l00257"></a><span class="lineno">  257</span>  <span class="comment">// NOTE. The condition to enable caching on ruy kernel can be changed according to ruy&#39;s version</span></div>
<div class="line"><a id="l00258" name="l00258"></a><span class="lineno">  258</span> </div>
<div class="line"><a id="l00259" name="l00259"></a><span class="lineno">  259</span>  <span class="comment">// If input is dynamic, it changes total size of input</span></div>
<div class="line"><a id="l00260" name="l00260"></a><span class="lineno">  260</span>  <span class="comment">// If weights is not constant, weights cannot be cached</span></div>
<div class="line"><a id="l00261" name="l00261"></a><span class="lineno">  261</span>  <span class="keywordflow">if</span> (_input-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#a4202633be970298f135e2c00d217c0b0">is_dynamic</a>() || !_weights-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#a0aa4408d72f1ea3643c386520d9eb4e3">is_constant</a>())</div>
<div class="line"><a id="l00262" name="l00262"></a><span class="lineno">  262</span>    <span class="keywordflow">return</span>;</div>
<div class="line"><a id="l00263" name="l00263"></a><span class="lineno">  263</span> </div>
<div class="line"><a id="l00264" name="l00264"></a><span class="lineno">  264</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> rows = <a class="code hl_function" href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">getShape</a>(_weights).<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(0);</div>
<div class="line"><a id="l00265" name="l00265"></a><span class="lineno">  265</span>  <span class="keywordflow">if</span> (rows % 4 == 0)</div>
<div class="line"><a id="l00266" name="l00266"></a><span class="lineno">  266</span>  {</div>
<div class="line"><a id="l00267" name="l00267"></a><span class="lineno">  267</span>    <span class="comment">// TODO If it&#39;s possible to extract precaching from ruy kernel,</span></div>
<div class="line"><a id="l00268" name="l00268"></a><span class="lineno">  268</span>    <span class="comment">// place this instead of below code</span></div>
<div class="line"><a id="l00269" name="l00269"></a><span class="lineno">  269</span> </div>
<div class="line"><a id="l00270" name="l00270"></a><span class="lineno">  270</span>    <span class="comment">// buffer will be used by ruy kernel as a cache key</span></div>
<div class="line"><a id="l00271" name="l00271"></a><span class="lineno">  271</span>    _cached_weights = _weights-&gt;<a class="code hl_function" href="classonert_1_1backend_1_1_i_tensor.html#ac42a9739e80a0e11be18c0e0a61ccf85">buffer</a>();</div>
<div class="line"><a id="l00272" name="l00272"></a><span class="lineno">  272</span>  }</div>
<div class="line"><a id="l00273" name="l00273"></a><span class="lineno">  273</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00274" name="l00274"></a><span class="lineno">  274</span>}</div>
<div class="line"><a id="l00275" name="l00275"></a><span class="lineno">  275</span> </div>
<div class="line"><a id="l00276" name="l00276"></a><span class="lineno">  276</span>} <span class="comment">// namespace ops</span></div>
<div class="line"><a id="l00277" name="l00277"></a><span class="lineno">  277</span>} <span class="comment">// namespace cpu</span></div>
<div class="line"><a id="l00278" name="l00278"></a><span class="lineno">  278</span>} <span class="comment">// namespace backend</span></div>
<div class="line"><a id="l00279" name="l00279"></a><span class="lineno">  279</span>} <span class="comment">// namespace onert</span></div>
<div class="ttc" id="a_fused_8h_html_a4c6c18f14951cbc3aa6e8089b3a24342ab50339a10e1de285ac99d4c3990b8693"><div class="ttname"><a href="_fused_8h.html#a4c6c18f14951cbc3aa6e8089b3a24342ab50339a10e1de285ac99d4c3990b8693">FusedActivationFunc::NONE</a></div><div class="ttdeci">@ NONE</div></div>
<div class="ttc" id="aclassnnfw_1_1cker_1_1_f_c_temp_arena_html"><div class="ttname"><a href="classnnfw_1_1cker_1_1_f_c_temp_arena.html">nnfw::cker::FCTempArena</a></div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h_source.html#l00035">FullyConnected.h:36</a></div></div>
<div class="ttc" id="aclassnnfw_1_1cker_1_1_f_c_temp_arena_html_a6743d412a028cb7a7021bf255274345f"><div class="ttname"><a href="classnnfw_1_1cker_1_1_f_c_temp_arena.html#a6743d412a028cb7a7021bf255274345f">nnfw::cker::FCTempArena::prepared</a></div><div class="ttdeci">bool prepared</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h_source.html#l00055">FullyConnected.h:55</a></div></div>
<div class="ttc" id="aclassnnfw_1_1cker_1_1_f_c_temp_arena_html_acafeac459e58e656d39398433953b0d0"><div class="ttname"><a href="classnnfw_1_1cker_1_1_f_c_temp_arena.html#acafeac459e58e656d39398433953b0d0">nnfw::cker::FCTempArena::prepare</a></div><div class="ttdeci">void prepare(const Shape &amp;input_shape, const Shape &amp;weights_shape)</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h_source.html#l00043">FullyConnected.h:43</a></div></div>
<div class="ttc" id="aclassnnfw_1_1cker_1_1_shape_html_a497180ee7844bbef51b36bd58e61fa31"><div class="ttname"><a href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">nnfw::cker::Shape::Dims</a></div><div class="ttdeci">int32_t Dims(int i) const</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00094">Shape.h:94</a></div></div>
<div class="ttc" id="aclassnnfw_1_1cker_1_1_shape_html_ac7e29fd510111992fbd44906e2080f12"><div class="ttname"><a href="classnnfw_1_1cker_1_1_shape.html#ac7e29fd510111992fbd44906e2080f12">nnfw::cker::Shape::FlatSize</a></div><div class="ttdeci">int FlatSize() const</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00183">Shape.h:183</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_portable_tensor_html"><div class="ttname"><a href="classonert_1_1backend_1_1_i_portable_tensor.html">onert::backend::IPortableTensor</a></div><div class="ttdoc">A tensor class that is portable for other backends.</div><div class="ttdef"><b>Definition:</b> <a href="_i_portable_tensor_8h_source.html#l00038">IPortableTensor.h:39</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_portable_tensor_html_a0c2877a5e6e7d5ac7416baf7d3315644"><div class="ttname"><a href="classonert_1_1backend_1_1_i_portable_tensor.html#a0c2877a5e6e7d5ac7416baf7d3315644">onert::backend::IPortableTensor::data_zero_point</a></div><div class="ttdeci">int32_t data_zero_point() const override</div><div class="ttdef"><b>Definition:</b> <a href="_i_portable_tensor_8h_source.html#l00047">IPortableTensor.h:47</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_portable_tensor_html_aedf4a030ba4e787ec06eb0c86b261539"><div class="ttname"><a href="classonert_1_1backend_1_1_i_portable_tensor.html#aedf4a030ba4e787ec06eb0c86b261539">onert::backend::IPortableTensor::data_scale</a></div><div class="ttdeci">float data_scale() const override</div><div class="ttdef"><b>Definition:</b> <a href="_i_portable_tensor_8h_source.html#l00046">IPortableTensor.h:46</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_portable_tensor_html_aee0afc215e2f87867c419da5425528eb"><div class="ttname"><a href="classonert_1_1backend_1_1_i_portable_tensor.html#aee0afc215e2f87867c419da5425528eb">onert::backend::IPortableTensor::sparsity</a></div><div class="ttdeci">virtual const ir::Sparsity * sparsity() const</div><div class="ttdef"><b>Definition:</b> <a href="_i_portable_tensor_8h_source.html#l00044">IPortableTensor.h:44</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_tensor_html_a0aa4408d72f1ea3643c386520d9eb4e3"><div class="ttname"><a href="classonert_1_1backend_1_1_i_tensor.html#a0aa4408d72f1ea3643c386520d9eb4e3">onert::backend::ITensor::is_constant</a></div><div class="ttdeci">virtual bool is_constant() const</div><div class="ttdoc">Return true if the tensor is constant.</div><div class="ttdef"><b>Definition:</b> <a href="_i_tensor_8h_source.html#l00072">ITensor.h:72</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_tensor_html_a4202633be970298f135e2c00d217c0b0"><div class="ttname"><a href="classonert_1_1backend_1_1_i_tensor.html#a4202633be970298f135e2c00d217c0b0">onert::backend::ITensor::is_dynamic</a></div><div class="ttdeci">virtual bool is_dynamic() const =0</div><div class="ttdoc">Return true if the tensor needs dynamic allocation, meaning that during compile-time the outpus shape...</div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_tensor_html_a6d57b178316225a9e08f1191ce489ad9"><div class="ttname"><a href="classonert_1_1backend_1_1_i_tensor.html#a6d57b178316225a9e08f1191ce489ad9">onert::backend::ITensor::data_type</a></div><div class="ttdeci">virtual ir::DataType data_type() const =0</div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1_i_tensor_html_ac42a9739e80a0e11be18c0e0a61ccf85"><div class="ttname"><a href="classonert_1_1backend_1_1_i_tensor.html#ac42a9739e80a0e11be18c0e0a61ccf85">onert::backend::ITensor::buffer</a></div><div class="ttdeci">virtual uint8_t * buffer() const =0</div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1basic_1_1_tensor_html"><div class="ttname"><a href="classonert_1_1backend_1_1basic_1_1_tensor.html">onert::backend::basic::Tensor</a></div><div class="ttdef"><b>Definition:</b> <a href="runtime_2onert_2core_2include_2backend_2basic_2_tensor_8h_source.html#l00035">Tensor.h:36</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_a2006db79e45053eb357f55af95471524"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a2006db79e45053eb357f55af95471524">onert::backend::cpu::ops::FullyConnectedLayer::fullyConnected16x1Float32</a></div><div class="ttdeci">void fullyConnected16x1Float32()</div><div class="ttdef"><b>Definition:</b> <a href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00171">FullyConnectedLayer.cc:171</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_a27ebc09cfe60bf438b6ac2b831d0a8b5"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a27ebc09cfe60bf438b6ac2b831d0a8b5">onert::backend::cpu::ops::FullyConnectedLayer::fullyConnectedSparseWeight</a></div><div class="ttdeci">void fullyConnectedSparseWeight()</div><div class="ttdef"><b>Definition:</b> <a href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00144">FullyConnectedLayer.cc:144</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_a648618c630985a3d90aeae23ec2cdc4e"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a648618c630985a3d90aeae23ec2cdc4e">onert::backend::cpu::ops::FullyConnectedLayer::fullyConnectedFloat32</a></div><div class="ttdeci">void fullyConnectedFloat32()</div><div class="ttdef"><b>Definition:</b> <a href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00043">FullyConnectedLayer.cc:43</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_a822066c1d1450094011067542f0b9a0d"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#a822066c1d1450094011067542f0b9a0d">onert::backend::cpu::ops::FullyConnectedLayer::~FullyConnectedLayer</a></div><div class="ttdeci">~FullyConnectedLayer()</div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_ab5fc53c26dd7f5863daed38d58cd7c18"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ab5fc53c26dd7f5863daed38d58cd7c18">onert::backend::cpu::ops::FullyConnectedLayer::prepare</a></div><div class="ttdeci">void prepare() override</div><div class="ttdef"><b>Definition:</b> <a href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00237">FullyConnectedLayer.cc:237</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_ab9659326558b505132635a729eb7dc26"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#ab9659326558b505132635a729eb7dc26">onert::backend::cpu::ops::FullyConnectedLayer::FullyConnectedLayer</a></div><div class="ttdeci">FullyConnectedLayer()</div><div class="ttdef"><b>Definition:</b> <a href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00033">FullyConnectedLayer.cc:33</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_aea2f03e86f6d110ff8a1eaae0caa8d82"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aea2f03e86f6d110ff8a1eaae0caa8d82">onert::backend::cpu::ops::FullyConnectedLayer::fullyConnectedHybrid</a></div><div class="ttdeci">void fullyConnectedHybrid()</div><div class="ttdef"><b>Definition:</b> <a href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00083">FullyConnectedLayer.cc:83</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_aee0f4ff5a4e1d31c65f4346494499e82"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aee0f4ff5a4e1d31c65f4346494499e82">onert::backend::cpu::ops::FullyConnectedLayer::configure</a></div><div class="ttdeci">void configure(const IPortableTensor *input, const IPortableTensor *weights, const IPortableTensor *bias, ir::Activation activation, ir::FullyConnectedWeightsFormat weights_format, IPortableTensor *output, const std::shared_ptr&lt; ExternalContext &gt; &amp;external_context)</div><div class="ttdef"><b>Definition:</b> <a href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00189">FullyConnectedLayer.cc:189</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_af90252c9fc392b5b8bb7f8c0fa203741"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#af90252c9fc392b5b8bb7f8c0fa203741">onert::backend::cpu::ops::FullyConnectedLayer::fullyConnectedQuant8</a></div><div class="ttdeci">void fullyConnectedQuant8()</div><div class="ttdef"><b>Definition:</b> <a href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00056">FullyConnectedLayer.cc:56</a></div></div>
<div class="ttc" id="aclassonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer_html_aff0e02437f1e864effa060ca8ea19bc1"><div class="ttname"><a href="classonert_1_1backend_1_1cpu_1_1ops_1_1_fully_connected_layer.html#aff0e02437f1e864effa060ca8ea19bc1">onert::backend::cpu::ops::FullyConnectedLayer::run</a></div><div class="ttdeci">void run() override</div><div class="ttdef"><b>Definition:</b> <a href="cpu_2ops_2_fully_connected_layer_8cc_source.html#l00213">FullyConnectedLayer.cc:213</a></div></div>
<div class="ttc" id="acompute_2cker_2include_2cker_2_tensor_utils_8h_html"><div class="ttname"><a href="compute_2cker_2include_2cker_2_tensor_utils_8h.html">TensorUtils.h</a></div></div>
<div class="ttc" id="acompute_2cker_2include_2cker_2operation_2_fully_connected_8h_html"><div class="ttname"><a href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h.html">FullyConnected.h</a></div></div>
<div class="ttc" id="anamespacemir_1_1ops_html"><div class="ttname"><a href="namespacemir_1_1ops.html">mir::ops</a></div><div class="ttdef"><b>Definition:</b> <a href="_abs_op_8h_source.html#l00024">AbsOp.h:25</a></div></div>
<div class="ttc" id="anamespacennfw_1_1cker_html_a0da6b0f998eacd17836e7f7265cd1605"><div class="ttname"><a href="namespacennfw_1_1cker.html#a0da6b0f998eacd17836e7f7265cd1605">nnfw::cker::FullyConnectedSparseWeightRandom</a></div><div class="ttdeci">void FullyConnectedSparseWeightRandom(const FullyConnectedParams &amp;params, const Shape &amp;input_shape, const float *input_data, const Shape &amp;weights_shape, const float *weights_data, const Shape &amp;bias_shape, const float *bias_data, const Shape &amp;output_shape, float *output_data, const uint16_t *w1_segments, const uint16_t *w1_indices)</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h_source.html#l00214">FullyConnected.h:214</a></div></div>
<div class="ttc" id="anamespacennfw_1_1cker_html_a38ce7e8df68ce5c6527f23b008a422b3"><div class="ttname"><a href="namespacennfw_1_1cker.html#a38ce7e8df68ce5c6527f23b008a422b3">nnfw::cker::FullyConnectedSparseWeight16x1</a></div><div class="ttdeci">void FullyConnectedSparseWeight16x1(const FullyConnectedParams &amp;params, const Shape &amp;input_shape, const float *input_data, const Shape &amp;weights_shape, const float *weights_data, const Shape &amp;bias_shape, const float *bias_data, const Shape &amp;output_shape, float *output_data, const uint16_t *w1_segments, const uint16_t *w1_indices)</div><div class="ttdef"><b>Definition:</b> <a href="_fully_connected_sparse16x1_8h_source.html#l00057">FullyConnectedSparse16x1.h:57</a></div></div>
<div class="ttc" id="anamespacennfw_1_1cker_html_a86c3c8cb5e011dd68e4e3eaaa99d5800"><div class="ttname"><a href="namespacennfw_1_1cker.html#a86c3c8cb5e011dd68e4e3eaaa99d5800">nnfw::cker::FullyConnectedHybrid</a></div><div class="ttdeci">void FullyConnectedHybrid(const FullyConnectedParams &amp;params, const Shape &amp;input_shape, const float *input_data, const Shape &amp;filter_shape, const int8_t *filter_data, const Shape &amp;, const float *bias_data, const Shape &amp;output_shape, float *output_data, FCTempArena &amp;temp_arena, ruy::Context *ruy_context)</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h_source.html#l00146">FullyConnected.h:146</a></div></div>
<div class="ttc" id="anamespacennfw_1_1cker_html_a893434782a43556a99989be14e599d63"><div class="ttname"><a href="namespacennfw_1_1cker.html#a893434782a43556a99989be14e599d63">nnfw::cker::FullyConnected</a></div><div class="ttdeci">void FullyConnected(const FullyConnectedParams &amp;params, const Shape &amp;input_shape, const float *input_data, const Shape &amp;weights_shape, const float *weights_data, const Shape &amp;, const float *bias_data, const Shape &amp;, float *output_data)</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2operation_2_fully_connected_8h_source.html#l00061">FullyConnected.h:61</a></div></div>
<div class="ttc" id="anamespacennfw_1_1cker_html_af82fa9f0cdbd15fed59567999835cebf"><div class="ttname"><a href="namespacennfw_1_1cker.html#af82fa9f0cdbd15fed59567999835cebf">nnfw::cker::IsZeroVector</a></div><div class="ttdeci">bool IsZeroVector(const float *vector, int v_size)</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_tensor_utils_8h_source.html#l00104">TensorUtils.h:104</a></div></div>
<div class="ttc" id="anamespacennfw_html"><div class="ttname"><a href="namespacennfw.html">nnfw</a></div><div class="ttdef"><b>Definition:</b> <a href="topk__v2_8h_source.html#l00029">topk_v2.h:30</a></div></div>
<div class="ttc" id="anamespaceonert_1_1backend_1_1cpu_1_1ops_html_a0e7672ebf55bbaa7e1d86a46cfd53c5e"><div class="ttname"><a href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a0e7672ebf55bbaa7e1d86a46cfd53c5e">onert::backend::cpu::ops::convertActivationType</a></div><div class="ttdeci">nnfw::cker::FusedActivationFunctionType convertActivationType(const ir::Activation activation)</div><div class="ttdef"><b>Definition:</b> <a href="cpu_2ops_2_operation_utils_8h_source.html#l00114">OperationUtils.h:114</a></div></div>
<div class="ttc" id="anamespaceonert_1_1backend_1_1cpu_1_1ops_html_a1cfb53087f7fc161b9162d65aa5520d9"><div class="ttname"><a href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a1cfb53087f7fc161b9162d65aa5520d9">onert::backend::cpu::ops::getShape</a></div><div class="ttdeci">nnfw::cker::Shape getShape(const IPortableTensor *tensor)</div><div class="ttdef"><b>Definition:</b> <a href="cpu_2ops_2_operation_utils_8h_source.html#l00094">OperationUtils.h:94</a></div></div>
<div class="ttc" id="anamespaceonert_1_1backend_1_1cpu_1_1ops_html_a3be5fe32ffdf0573dd36b64172dbaa3a"><div class="ttname"><a href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#a3be5fe32ffdf0573dd36b64172dbaa3a">onert::backend::cpu::ops::QuantizeMultiplier</a></div><div class="ttdeci">void QuantizeMultiplier(double double_multiplier, int32_t *quantized_multiplier, int *shift)</div><div class="ttdef"><b>Definition:</b> <a href="cpu_2ops_2_operation_utils_8cc_source.html#l00062">OperationUtils.cc:62</a></div></div>
<div class="ttc" id="anamespaceonert_1_1backend_1_1cpu_1_1ops_html_aa3ed894d41e9c8473df0db171af23d7d"><div class="ttname"><a href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#aa3ed894d41e9c8473df0db171af23d7d">onert::backend::cpu::ops::CalculateActivationRangeQuantized</a></div><div class="ttdeci">void CalculateActivationRangeQuantized(ir::Activation activation, const IPortableTensor *output, int32_t *act_min, int32_t *act_max)</div><div class="ttdef"><b>Definition:</b> <a href="cpu_2ops_2_operation_utils_8cc_source.html#l00144">OperationUtils.cc:144</a></div></div>
<div class="ttc" id="anamespaceonert_1_1backend_1_1cpu_1_1ops_html_ae4d438d3d3062bfd95a6e0caed125457"><div class="ttname"><a href="namespaceonert_1_1backend_1_1cpu_1_1ops.html#ae4d438d3d3062bfd95a6e0caed125457">onert::backend::cpu::ops::GetQuantizedConvolutionMultiplier</a></div><div class="ttdeci">void GetQuantizedConvolutionMultiplier(const IPortableTensor *input, const IPortableTensor *filter, const IPortableTensor *bias, const IPortableTensor *output, double *multiplier)</div><div class="ttdef"><b>Definition:</b> <a href="cpu_2ops_2_operation_utils_8cc_source.html#l00083">OperationUtils.cc:83</a></div></div>
<div class="ttc" id="anamespaceonert_1_1ir_html_a4dc82d1ced0dff0fcabe7e74d6c76c19"><div class="ttname"><a href="namespaceonert_1_1ir.html#a4dc82d1ced0dff0fcabe7e74d6c76c19">onert::ir::FullyConnectedWeightsFormat</a></div><div class="ttdeci">FullyConnectedWeightsFormat</div><div class="ttdef"><b>Definition:</b> <a href="_internal_type_8h_source.html#l00049">InternalType.h:50</a></div></div>
<div class="ttc" id="anamespaceonert_1_1ir_html_a4dc82d1ced0dff0fcabe7e74d6c76c19a00d4e131097ee909d6bcf8f8e05ac93b"><div class="ttname"><a href="namespaceonert_1_1ir.html#a4dc82d1ced0dff0fcabe7e74d6c76c19a00d4e131097ee909d6bcf8f8e05ac93b">onert::ir::FullyConnectedWeightsFormat::Shuffled16x1Float32</a></div><div class="ttdeci">@ Shuffled16x1Float32</div></div>
<div class="ttc" id="anamespaceonert_1_1ir_html_a8ce6c92ea138aca1332e4be9531bd5d4"><div class="ttname"><a href="namespaceonert_1_1ir.html#a8ce6c92ea138aca1332e4be9531bd5d4">onert::ir::Activation</a></div><div class="ttdeci">Activation</div><div class="ttdef"><b>Definition:</b> <a href="_internal_type_8h_source.html#l00027">InternalType.h:28</a></div></div>
<div class="ttc" id="anamespaceonert_1_1util_html_a9aac61f35b6d507552fea7bd8ac070ab"><div class="ttname"><a href="namespaceonert_1_1util.html#a9aac61f35b6d507552fea7bd8ac070ab">onert::util::CalculateActivationRange</a></div><div class="ttdeci">void CalculateActivationRange(ir::Activation activation, T *activation_min, T *activation_max)</div><div class="ttdef"><b>Definition:</b> <a href="_calculate_activation_range_8h_source.html#l00030">CalculateActivationRange.h:30</a></div></div>
<div class="ttc" id="anamespaceonert_html"><div class="ttname"><a href="namespaceonert.html">onert</a></div><div class="ttdef"><b>Definition:</b> <a href="_custom_kernel_8cc_source.html#l00019">CustomKernel.cc:20</a></div></div>
<div class="ttc" id="apolymorphic__downcast_8h_html"><div class="ttname"><a href="polymorphic__downcast_8h.html">polymorphic_downcast.h</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html">nnfw::cker::FullyConnectedParams</a></div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00247">Types.h:248</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_a092f1b0d178bedcbec27ae01bdb35295"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#a092f1b0d178bedcbec27ae01bdb35295">nnfw::cker::FullyConnectedParams::output_multiplier</a></div><div class="ttdeci">int32_t output_multiplier</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00256">Types.h:256</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_a15410fd240c7d16cdeaca54856b712c8"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#a15410fd240c7d16cdeaca54856b712c8">nnfw::cker::FullyConnectedParams::activation</a></div><div class="ttdeci">FusedActivationFunctionType activation</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00249">Types.h:249</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_a386f74239ea2059f97fadb7b3c407f37"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#a386f74239ea2059f97fadb7b3c407f37">nnfw::cker::FullyConnectedParams::weights_offset</a></div><div class="ttdeci">int32_t weights_offset</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00253">Types.h:253</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_a5268ff3c0cf7eed73da16324a82f3e39"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#a5268ff3c0cf7eed73da16324a82f3e39">nnfw::cker::FullyConnectedParams::quantized_activation_min</a></div><div class="ttdeci">int32_t quantized_activation_min</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00259">Types.h:259</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_a7e955d0d5d1022cd53da9c32ebf48ae0"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#a7e955d0d5d1022cd53da9c32ebf48ae0">nnfw::cker::FullyConnectedParams::quantized_activation_max</a></div><div class="ttdeci">int32_t quantized_activation_max</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00260">Types.h:260</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_a88a4ccb4fb1a3a1fc0b5066ca98b1fef"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#a88a4ccb4fb1a3a1fc0b5066ca98b1fef">nnfw::cker::FullyConnectedParams::input_offset</a></div><div class="ttdeci">int32_t input_offset</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00252">Types.h:252</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_aad53016de4b3709a2c0691bc5cab3c12"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#aad53016de4b3709a2c0691bc5cab3c12">nnfw::cker::FullyConnectedParams::output_shift</a></div><div class="ttdeci">int output_shift</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00257">Types.h:257</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_aba4be915f48ac33044094e092fe04c38"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#aba4be915f48ac33044094e092fe04c38">nnfw::cker::FullyConnectedParams::output_offset</a></div><div class="ttdeci">int32_t output_offset</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00255">Types.h:255</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_fully_connected_params_html_ad7a6c95463633a349e7551dad13f8dba"><div class="ttname"><a href="structnnfw_1_1cker_1_1_fully_connected_params.html#ad7a6c95463633a349e7551dad13f8dba">nnfw::cker::FullyConnectedParams::weights_scale</a></div><div class="ttdeci">float weights_scale</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00254">Types.h:254</a></div></div>
<div class="ttc" id="astructonert_1_1ir_1_1_sparsity_html_a27434d14d1c2593592a6b9e043e308dc"><div class="ttname"><a href="structonert_1_1ir_1_1_sparsity.html#a27434d14d1c2593592a6b9e043e308dc">onert::ir::Sparsity::block_size</a></div><div class="ttdeci">const std::vector&lt; int32_t &gt; &amp; block_size() const</div><div class="ttdoc">Returns block size which is used for block sparsity.</div><div class="ttdef"><b>Definition:</b> <a href="_sparsity_8h_source.html#l00053">Sparsity.h:53</a></div></div>
<div class="ttc" id="astructonert_1_1ir_1_1_sparsity_html_a46532d90a469c48114b12ab3ba16c76b"><div class="ttname"><a href="structonert_1_1ir_1_1_sparsity.html#a46532d90a469c48114b12ab3ba16c76b">onert::ir::Sparsity::w1_segments</a></div><div class="ttdeci">const uint16_t * w1_segments() const</div><div class="ttdoc">Returns segments array. See compressed sparse row format.</div><div class="ttdef"><b>Definition:</b> <a href="_sparsity_8h_source.html#l00045">Sparsity.h:45</a></div></div>
<div class="ttc" id="astructonert_1_1ir_1_1_sparsity_html_a76b05fe5094e56d48d87652f553e038c"><div class="ttname"><a href="structonert_1_1ir_1_1_sparsity.html#a76b05fe5094e56d48d87652f553e038c">onert::ir::Sparsity::w1_indices</a></div><div class="ttdeci">const uint16_t * w1_indices() const</div><div class="ttdoc">Returns indices array. See compressed sparse row format.</div><div class="ttdef"><b>Definition:</b> <a href="_sparsity_8h_source.html#l00049">Sparsity.h:49</a></div></div>
<div class="ttc" id="axnnpack_2ops_2_fully_connected_layer_8h_html"><div class="ttname"><a href="xnnpack_2ops_2_fully_connected_layer_8h.html">FullyConnectedLayer.h</a></div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_cb031e414f281a658b23dddb30bb9d2c.html">runtime</a></li><li class="navelem"><a class="el" href="dir_e8e2d335b1be314b4aeca39d410c6e2f.html">onert</a></li><li class="navelem"><a class="el" href="dir_e3c1c6f396287f59b9861978effe28d3.html">backend</a></li><li class="navelem"><a class="el" href="dir_cbf6658beac9ccb6c16f8d8eb7b234d2.html">cpu</a></li><li class="navelem"><a class="el" href="dir_41fcf59703ad3e4317a6c52e7bbdc719.html">ops</a></li><li class="navelem"><a class="el" href="cpu_2ops_2_fully_connected_layer_8cc.html">FullyConnectedLayer.cc</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.5 </li>
  </ul>
</div>
</body>
</html>
