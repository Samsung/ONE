<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ONE - On-device Neural Engine: onnx_legalizer Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">ONE - On-device Neural Engine
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('namespaceonnx__legalizer.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#nested-classes">Data Structures</a> &#124;
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">onnx_legalizer Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Data Structures</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnx__legalizer_1_1___model_transformer_helper.html">_ModelTransformerHelper</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnx__legalizer_1_1___tensor_info.html">_TensorInfo</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnx__legalizer_1_1_legalize_options.html">LegalizeOptions</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:acce4e92684340ba22f5db5f9f35b1811" id="r_acce4e92684340ba22f5db5f9f35b1811"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnx__legalizer.html#acce4e92684340ba22f5db5f9f35b1811">_reverse_str</a> (s)</td></tr>
<tr class="separator:acce4e92684340ba22f5db5f9f35b1811"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1bd044e6391a3acdf2722c675408178b" id="r_a1bd044e6391a3acdf2722c675408178b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnx__legalizer.html#a1bd044e6391a3acdf2722c675408178b">_parse_tensor_name</a> (name)</td></tr>
<tr class="separator:a1bd044e6391a3acdf2722c675408178b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0fab3df298da4c943e9ca634f633e434" id="r_a0fab3df298da4c943e9ca634f633e434"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnx__legalizer.html#a0fab3df298da4c943e9ca634f633e434">_get_tensor_infos</a> (<a class="el" href="namespaceonnx__legalizer.html#a8485b6ddcea4daf81ebe90ecaf592971">model</a>)</td></tr>
<tr class="separator:a0fab3df298da4c943e9ca634f633e434"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac269aff495a12f6bd89c45c30dddd277" id="r_ac269aff495a12f6bd89c45c30dddd277"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnx__legalizer.html#ac269aff495a12f6bd89c45c30dddd277">_dtype_to_np</a> (dtype)</td></tr>
<tr class="separator:ac269aff495a12f6bd89c45c30dddd277"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab181deaf1295e11f68feb087108e928a" id="r_ab181deaf1295e11f68feb087108e928a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnx__legalizer.html#ab181deaf1295e11f68feb087108e928a">_generate_one_direction_RNN</a> (transformer, X, W, R, B, initial_h, clip, activation_name)</td></tr>
<tr class="separator:ab181deaf1295e11f68feb087108e928a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a10267e7e63cd609e18c31d5d92f86c53" id="r_a10267e7e63cd609e18c31d5d92f86c53"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnx__legalizer.html#a10267e7e63cd609e18c31d5d92f86c53">_transform_unidirectional_RNN</a> (transformer, original_node, x, tensor_infos, activation, clip, direction, hidden_size, layout)</td></tr>
<tr class="separator:a10267e7e63cd609e18c31d5d92f86c53"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7a40eb31811a44d036ea14c533c5f13a" id="r_a7a40eb31811a44d036ea14c533c5f13a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnx__legalizer.html#a7a40eb31811a44d036ea14c533c5f13a">_transform_bidirectional_RNN</a> (transformer, original_node, x, tensor_infos, activations, clip, hidden_size, layout)</td></tr>
<tr class="separator:a7a40eb31811a44d036ea14c533c5f13a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a46684478851b90ca545921590ddca1aa" id="r_a46684478851b90ca545921590ddca1aa"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnx__legalizer.html#a46684478851b90ca545921590ddca1aa">_legalize_RNN</a> (transformer, tensor_infos, node)</td></tr>
<tr class="separator:a46684478851b90ca545921590ddca1aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac9201e557312c76c1515906e274a7d2b" id="r_ac9201e557312c76c1515906e274a7d2b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnx__legalizer.html#ac9201e557312c76c1515906e274a7d2b">_generate_one_direction_LSTM</a> (transformer, X, W, R, B, initial_h, initial_c, P, clip, act, dtype, hidden_size, batch_size)</td></tr>
<tr class="separator:ac9201e557312c76c1515906e274a7d2b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8053415a9752c3f4d9401091fe7ec921" id="r_a8053415a9752c3f4d9401091fe7ec921"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnx__legalizer.html#a8053415a9752c3f4d9401091fe7ec921">_transform_unidirectional_LSTM</a> (transformer, original_node, x, tensor_infos, activations, clip, direction, hidden_size, layout)</td></tr>
<tr class="separator:a8053415a9752c3f4d9401091fe7ec921"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a37047cc6aeedb2fd12739d9ae259ba97" id="r_a37047cc6aeedb2fd12739d9ae259ba97"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnx__legalizer.html#a37047cc6aeedb2fd12739d9ae259ba97">_transform_bidirectional_LSTM</a> (transformer, original_node, x, tensor_infos, activations, clip, hidden_size, layout)</td></tr>
<tr class="separator:a37047cc6aeedb2fd12739d9ae259ba97"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0e35c1dafe17a08559cb9cb6a263ba4e" id="r_a0e35c1dafe17a08559cb9cb6a263ba4e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnx__legalizer.html#a0e35c1dafe17a08559cb9cb6a263ba4e">_legalize_LSTM</a> (transformer, tensor_infos, node)</td></tr>
<tr class="separator:a0e35c1dafe17a08559cb9cb6a263ba4e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:accc2392dcc041c6c26643e3e408d2402" id="r_accc2392dcc041c6c26643e3e408d2402"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnx__legalizer.html#accc2392dcc041c6c26643e3e408d2402">legalize</a> (<a class="el" href="namespaceonnx__legalizer.html#a8485b6ddcea4daf81ebe90ecaf592971">model</a>, <a class="el" href="namespaceonnx__legalizer.html#a5f63ff6f9c0c3e7103c2b9b88021555e">options</a>)</td></tr>
<tr class="separator:accc2392dcc041c6c26643e3e408d2402"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:a5f63ff6f9c0c3e7103c2b9b88021555e" id="r_a5f63ff6f9c0c3e7103c2b9b88021555e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnx__legalizer.html#a5f63ff6f9c0c3e7103c2b9b88021555e">options</a> = <a class="el" href="classonnx__legalizer_1_1_legalize_options.html">LegalizeOptions</a>()</td></tr>
<tr class="separator:a5f63ff6f9c0c3e7103c2b9b88021555e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f5c3aed8975cb54f164b31f5c2cb319" id="r_a4f5c3aed8975cb54f164b31f5c2cb319"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnx__legalizer.html#a4f5c3aed8975cb54f164b31f5c2cb319">unroll_lstm</a></td></tr>
<tr class="separator:a4f5c3aed8975cb54f164b31f5c2cb319"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5389d22ca037325a27ca9f5afa583d5d" id="r_a5389d22ca037325a27ca9f5afa583d5d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnx__legalizer.html#a5389d22ca037325a27ca9f5afa583d5d">unroll_rnn</a></td></tr>
<tr class="separator:a5389d22ca037325a27ca9f5afa583d5d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8485b6ddcea4daf81ebe90ecaf592971" id="r_a8485b6ddcea4daf81ebe90ecaf592971"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnx__legalizer.html#a8485b6ddcea4daf81ebe90ecaf592971">model</a> = onnx.load(sys.argv[1])</td></tr>
<tr class="separator:a8485b6ddcea4daf81ebe90ecaf592971"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="ac269aff495a12f6bd89c45c30dddd277" name="ac269aff495a12f6bd89c45c30dddd277"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac269aff495a12f6bd89c45c30dddd277">&#9670;&#160;</a></span>_dtype_to_np()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">onnx_legalizer._dtype_to_np </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dtype</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Convert onnx dtype value to numpy dtype class

For more types see:
https://github.com/onnx/onnx/blob/96516aecd4c110b0ac57eba08ac236ebf7205728/onnx/onnx.proto3#L484

Args:
    dtype (int): onnx dtype

Returns:
    numpy data type: numpy dtype, like np.float32
</pre> 
<p class="definition">Definition at line <a class="el" href="onnx__legalizer_8py_source.html#l00325">325</a> of file <a class="el" href="onnx__legalizer_8py_source.html">onnx_legalizer.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  325</span><span class="keyword">def </span>_dtype_to_np(dtype):</div>
<div class="line"><span class="lineno">  326</span>    <span class="stringliteral">&quot;&quot;&quot;Convert onnx dtype value to numpy dtype class</span></div>
<div class="line"><span class="lineno">  327</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  328</span><span class="stringliteral">    For more types see:</span></div>
<div class="line"><span class="lineno">  329</span><span class="stringliteral">    https://github.com/onnx/onnx/blob/96516aecd4c110b0ac57eba08ac236ebf7205728/onnx/onnx.proto3#L484</span></div>
<div class="line"><span class="lineno">  330</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  331</span><span class="stringliteral">    Args:</span></div>
<div class="line"><span class="lineno">  332</span><span class="stringliteral">        dtype (int): onnx dtype</span></div>
<div class="line"><span class="lineno">  333</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  334</span><span class="stringliteral">    Returns:</span></div>
<div class="line"><span class="lineno">  335</span><span class="stringliteral">        numpy data type: numpy dtype, like np.float32</span></div>
<div class="line"><span class="lineno">  336</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  337</span> </div>
<div class="line"><span class="lineno">  338</span>    <span class="keywordflow">if</span> dtype == 1:</div>
<div class="line"><span class="lineno">  339</span>        <span class="keywordflow">return</span> np.float32</div>
<div class="line"><span class="lineno">  340</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  341</span>        <span class="keywordflow">raise</span> NotImplementedError(<span class="stringliteral">&#39;unsupported data type&#39;</span>)</div>
<div class="line"><span class="lineno">  342</span> </div>
<div class="line"><span class="lineno">  343</span> </div>
</div><!-- fragment -->
<p class="reference">Referenced by <a class="el" href="onnx__legalizer_8py_source.html#l00828">_transform_bidirectional_LSTM()</a>, <a class="el" href="onnx__legalizer_8py_source.html#l00455">_transform_bidirectional_RNN()</a>, <a class="el" href="onnx__legalizer_8py_source.html#l00756">_transform_unidirectional_LSTM()</a>, and <a class="el" href="onnx__legalizer_8py_source.html#l00399">_transform_unidirectional_RNN()</a>.</p>

</div>
</div>
<a id="ac9201e557312c76c1515906e274a7d2b" name="ac9201e557312c76c1515906e274a7d2b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac9201e557312c76c1515906e274a7d2b">&#9670;&#160;</a></span>_generate_one_direction_LSTM()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">onnx_legalizer._generate_one_direction_LSTM </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>transformer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>W</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>R</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>B</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>initial_h</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>initial_c</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>P</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>clip</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>act</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dtype</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>hidden_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>batch_size</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Generate subgraph for one direction of unrolled LSTM layer

Args:
    transformer (_ModelTransformerHelper): helper for model generation
    X (list of str): names of tensors in input sequence. Each tensor shape: [batch_size, input_size]
    W (str): name of concatenated weight tensor: [input, output, forget, cell]
    R (str): name of concatenated recurrence weights tensor: [input, output, forget, cell]
    B (str): name of concatenated bias tensor: [input, output, forget, cell]
    initial_h (str or None): name of tensor containing initial hidden state. Shape [batch_size, hidden_size]
    initial_c (str or None): name of tensor containing initial cell state. Shape [batch_size, hidden_size]
    P (str or None): name of concatenated peephole tensor: [input, output, forget]
    clip (float or None): range which clips input of activations
    act (dict of str):  activation functions {'f': 'Sigmoid', 'g': 'Tanh', 'h': 'Tanh'}
    dtype (numpy dtype): data type used in created LSTM operation
    hidden_size (int): hidden dimension
    batch_size (int): batch dimension
</pre> 
<p class="definition">Definition at line <a class="el" href="onnx__legalizer_8py_source.html#l00612">612</a> of file <a class="el" href="onnx__legalizer_8py_source.html">onnx_legalizer.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  613</span>                                 act, dtype, hidden_size, batch_size):</div>
<div class="line"><span class="lineno">  614</span>    <span class="stringliteral">&quot;&quot;&quot;Generate subgraph for one direction of unrolled LSTM layer</span></div>
<div class="line"><span class="lineno">  615</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  616</span><span class="stringliteral">    Args:</span></div>
<div class="line"><span class="lineno">  617</span><span class="stringliteral">        transformer (_ModelTransformerHelper): helper for model generation</span></div>
<div class="line"><span class="lineno">  618</span><span class="stringliteral">        X (list of str): names of tensors in input sequence. Each tensor shape: [batch_size, input_size]</span></div>
<div class="line"><span class="lineno">  619</span><span class="stringliteral">        W (str): name of concatenated weight tensor: [input, output, forget, cell]</span></div>
<div class="line"><span class="lineno">  620</span><span class="stringliteral">        R (str): name of concatenated recurrence weights tensor: [input, output, forget, cell]</span></div>
<div class="line"><span class="lineno">  621</span><span class="stringliteral">        B (str): name of concatenated bias tensor: [input, output, forget, cell]</span></div>
<div class="line"><span class="lineno">  622</span><span class="stringliteral">        initial_h (str or None): name of tensor containing initial hidden state. Shape [batch_size, hidden_size]</span></div>
<div class="line"><span class="lineno">  623</span><span class="stringliteral">        initial_c (str or None): name of tensor containing initial cell state. Shape [batch_size, hidden_size]</span></div>
<div class="line"><span class="lineno">  624</span><span class="stringliteral">        P (str or None): name of concatenated peephole tensor: [input, output, forget]</span></div>
<div class="line"><span class="lineno">  625</span><span class="stringliteral">        clip (float or None): range which clips input of activations</span></div>
<div class="line"><span class="lineno">  626</span><span class="stringliteral">        act (dict of str):  activation functions {&#39;f&#39;: &#39;Sigmoid&#39;, &#39;g&#39;: &#39;Tanh&#39;, &#39;h&#39;: &#39;Tanh&#39;}</span></div>
<div class="line"><span class="lineno">  627</span><span class="stringliteral">        dtype (numpy dtype): data type used in created LSTM operation</span></div>
<div class="line"><span class="lineno">  628</span><span class="stringliteral">        hidden_size (int): hidden dimension</span></div>
<div class="line"><span class="lineno">  629</span><span class="stringliteral">        batch_size (int): batch dimension</span></div>
<div class="line"><span class="lineno">  630</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  631</span>    <span class="comment"># one direction LSTM:</span></div>
<div class="line"><span class="lineno">  632</span>    <span class="comment">#</span></div>
<div class="line"><span class="lineno">  633</span>    <span class="comment"># For details see:</span></div>
<div class="line"><span class="lineno">  634</span>    <span class="comment"># https://github.com/onnx/onnx/blob/5cf5feef5ec3fd5527b2fdb6c29780e3b705059f/docs/Changelog.md#LSTM-7</span></div>
<div class="line"><span class="lineno">  635</span>    <span class="comment">#</span></div>
<div class="line"><span class="lineno">  636</span>    <span class="comment"># it = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Pi (.) Ct-1 + Wbi + Rbi)</span></div>
<div class="line"><span class="lineno">  637</span>    <span class="comment"># ft = f(Xt*(Wf^T) + Ht-1*(Rf^T) + Pf (.) Ct-1 + Wbf + Rbf)</span></div>
<div class="line"><span class="lineno">  638</span>    <span class="comment"># ct = g(Xt*(Wc^T) + Ht-1*(Rc^T) + Wbc + Rbc)</span></div>
<div class="line"><span class="lineno">  639</span>    <span class="comment"># Ct = ft (.) Ct-1 + it (.) ct</span></div>
<div class="line"><span class="lineno">  640</span>    <span class="comment"># ot = f(Xt*(Wo^T) + Ht-1*(Ro^T) + Po (.) Ct + Wbo + Rbo)</span></div>
<div class="line"><span class="lineno">  641</span>    <span class="comment"># Ht = ot (.) h(Ct)</span></div>
<div class="line"><span class="lineno">  642</span>    <span class="comment">#</span></div>
<div class="line"><span class="lineno">  643</span>    <span class="comment"># X - input tensor</span></div>
<div class="line"><span class="lineno">  644</span>    <span class="comment"># i - input gate</span></div>
<div class="line"><span class="lineno">  645</span>    <span class="comment"># o - output gate</span></div>
<div class="line"><span class="lineno">  646</span>    <span class="comment"># f - forget gate</span></div>
<div class="line"><span class="lineno">  647</span>    <span class="comment"># c - cell gate</span></div>
<div class="line"><span class="lineno">  648</span>    <span class="comment"># t - time step (t-1 means previous time step)</span></div>
<div class="line"><span class="lineno">  649</span>    <span class="comment"># W[iofc] - W parameter weight matrix for input, output, forget, and cell gates</span></div>
<div class="line"><span class="lineno">  650</span>    <span class="comment"># R[iofc] - R recurrence weight matrix for input, output, forget, and cell gates</span></div>
<div class="line"><span class="lineno">  651</span>    <span class="comment"># Wb[iofc] - W bias vectors for input, output, forget, and cell gates</span></div>
<div class="line"><span class="lineno">  652</span>    <span class="comment"># Rb[iofc] - R bias vectors for input, output, forget, and cell gates</span></div>
<div class="line"><span class="lineno">  653</span>    <span class="comment"># P[iof] - P peephole weight vector for input, output, and forget gates</span></div>
<div class="line"><span class="lineno">  654</span>    <span class="comment"># WB[iofc] - W parameter weight matrix for backward input, output, forget, and cell gates</span></div>
<div class="line"><span class="lineno">  655</span>    <span class="comment"># RB[iofc] - R recurrence weight matrix for backward input, output, forget, and cell gates</span></div>
<div class="line"><span class="lineno">  656</span>    <span class="comment"># WBb[iofc] - W bias vectors for backward input, output, forget, and cell gates</span></div>
<div class="line"><span class="lineno">  657</span>    <span class="comment"># RBb[iofc] - R bias vectors for backward input, output, forget, and cell gates</span></div>
<div class="line"><span class="lineno">  658</span>    <span class="comment"># PB[iof] - P peephole weight vector for backward input, output, and forget gates</span></div>
<div class="line"><span class="lineno">  659</span>    <span class="comment"># H - Hidden state</span></div>
<div class="line"><span class="lineno">  660</span> </div>
<div class="line"><span class="lineno">  661</span>    seq_length = len(X)</div>
<div class="line"><span class="lineno">  662</span>    state_h_tensors = []</div>
<div class="line"><span class="lineno">  663</span> </div>
<div class="line"><span class="lineno">  664</span>    w_tensors = transformer.make_split(W, split_sizes=[hidden_size] * 4, axis=0)</div>
<div class="line"><span class="lineno">  665</span>    W = {<span class="stringliteral">&#39;i&#39;</span>: w_tensors[0], <span class="stringliteral">&#39;o&#39;</span>: w_tensors[1], <span class="stringliteral">&#39;f&#39;</span>: w_tensors[2], <span class="stringliteral">&#39;c&#39;</span>: w_tensors[3]}</div>
<div class="line"><span class="lineno">  666</span> </div>
<div class="line"><span class="lineno">  667</span>    r_tensors = transformer.make_split(R, split_sizes=[hidden_size] * 4, axis=0)</div>
<div class="line"><span class="lineno">  668</span>    R = {<span class="stringliteral">&#39;i&#39;</span>: r_tensors[0], <span class="stringliteral">&#39;o&#39;</span>: r_tensors[1], <span class="stringliteral">&#39;f&#39;</span>: r_tensors[2], <span class="stringliteral">&#39;c&#39;</span>: r_tensors[3]}</div>
<div class="line"><span class="lineno">  669</span> </div>
<div class="line"><span class="lineno">  670</span>    <span class="keywordflow">if</span> B <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  671</span>        separate_b_tensors = transformer.make_split(</div>
<div class="line"><span class="lineno">  672</span>            B, split_sizes=[hidden_size] * 8, axis=0)</div>
<div class="line"><span class="lineno">  673</span>        b_tensors = []</div>
<div class="line"><span class="lineno">  674</span>        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(4):</div>
<div class="line"><span class="lineno">  675</span>            b_tensors += [</div>
<div class="line"><span class="lineno">  676</span>                transformer.make_add(separate_b_tensors[i], separate_b_tensors[i + 4])</div>
<div class="line"><span class="lineno">  677</span>            ]</div>
<div class="line"><span class="lineno">  678</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  679</span>        b_tensors = [</div>
<div class="line"><span class="lineno">  680</span>            transformer.make_constant_tensor(</div>
<div class="line"><span class="lineno">  681</span>                np.zeros((hidden_size), dtype=dtype), <span class="stringliteral">&#39;zero_b&#39;</span>)</div>
<div class="line"><span class="lineno">  682</span>        ] * 4</div>
<div class="line"><span class="lineno">  683</span>    B = {<span class="stringliteral">&#39;i&#39;</span>: b_tensors[0], <span class="stringliteral">&#39;o&#39;</span>: b_tensors[1], <span class="stringliteral">&#39;f&#39;</span>: b_tensors[2], <span class="stringliteral">&#39;c&#39;</span>: b_tensors[3]}</div>
<div class="line"><span class="lineno">  684</span> </div>
<div class="line"><span class="lineno">  685</span>    <span class="keywordflow">if</span> initial_h <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  686</span>        previous_h_state_tensor = initial_h</div>
<div class="line"><span class="lineno">  687</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  688</span>        previous_h_state_tensor = transformer.make_constant_tensor(</div>
<div class="line"><span class="lineno">  689</span>            np.zeros((batch_size, hidden_size), dtype=dtype), <span class="stringliteral">&#39;initial_h&#39;</span>)</div>
<div class="line"><span class="lineno">  690</span> </div>
<div class="line"><span class="lineno">  691</span>    <span class="keywordflow">if</span> initial_c <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  692</span>        previous_c_state_tensor = initial_c</div>
<div class="line"><span class="lineno">  693</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  694</span>        previous_c_state_tensor = transformer.make_constant_tensor(</div>
<div class="line"><span class="lineno">  695</span>            np.zeros((batch_size, hidden_size), dtype=dtype), <span class="stringliteral">&#39;initial_c&#39;</span>)</div>
<div class="line"><span class="lineno">  696</span> </div>
<div class="line"><span class="lineno">  697</span>    <span class="keywordflow">if</span> P <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  698</span>        p_tensors = transformer.make_split(P, split_sizes=[hidden_size] * 3, axis=0)</div>
<div class="line"><span class="lineno">  699</span>        P = {<span class="stringliteral">&#39;i&#39;</span>: p_tensors[0], <span class="stringliteral">&#39;o&#39;</span>: p_tensors[1], <span class="stringliteral">&#39;f&#39;</span>: p_tensors[2]}</div>
<div class="line"><span class="lineno">  700</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  701</span>        zero = transformer.make_constant_tensor(</div>
<div class="line"><span class="lineno">  702</span>            np.zeros((hidden_size), dtype=dtype), <span class="stringliteral">&#39;zero_peephole&#39;</span>)</div>
<div class="line"><span class="lineno">  703</span>        P = {<span class="stringliteral">&#39;i&#39;</span>: zero, <span class="stringliteral">&#39;o&#39;</span>: zero, <span class="stringliteral">&#39;f&#39;</span>: zero}</div>
<div class="line"><span class="lineno">  704</span> </div>
<div class="line"><span class="lineno">  705</span>    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(seq_length):</div>
<div class="line"><span class="lineno">  706</span>        <span class="comment"># it = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Pi (.) Ct-1 + Wbi + Rbi)</span></div>
<div class="line"><span class="lineno">  707</span>        it = transformer.make_gemm(X[i], W[<span class="stringliteral">&#39;i&#39;</span>], B[<span class="stringliteral">&#39;i&#39;</span>], trans_b=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  708</span>        it = transformer.make_gemm(previous_h_state_tensor, R[<span class="stringliteral">&#39;i&#39;</span>], it, trans_b=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  709</span>        peephole_it = transformer.make_mul(P[<span class="stringliteral">&#39;i&#39;</span>], previous_c_state_tensor)</div>
<div class="line"><span class="lineno">  710</span>        it = transformer.make_add(it, peephole_it)</div>
<div class="line"><span class="lineno">  711</span>        <span class="keywordflow">if</span> clip <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  712</span>            it = transformer.make_clip(it, min=-clip, max=clip)</div>
<div class="line"><span class="lineno">  713</span>        it = transformer.make_act(it, act[<span class="stringliteral">&#39;f&#39;</span>])</div>
<div class="line"><span class="lineno">  714</span> </div>
<div class="line"><span class="lineno">  715</span>        <span class="comment"># ft = f(Xt*(Wf^T) + Ht-1*(Rf^T) + Pf (.) Ct-1 + Wbf + Rbf)</span></div>
<div class="line"><span class="lineno">  716</span>        ft = transformer.make_gemm(X[i], W[<span class="stringliteral">&#39;f&#39;</span>], B[<span class="stringliteral">&#39;f&#39;</span>], trans_b=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  717</span>        ft = transformer.make_gemm(previous_h_state_tensor, R[<span class="stringliteral">&#39;f&#39;</span>], ft, trans_b=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  718</span>        peephole_ft = transformer.make_mul(P[<span class="stringliteral">&#39;f&#39;</span>], previous_c_state_tensor)</div>
<div class="line"><span class="lineno">  719</span>        ft = transformer.make_add(ft, peephole_ft)</div>
<div class="line"><span class="lineno">  720</span>        <span class="keywordflow">if</span> clip <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  721</span>            ft = transformer.make_clip(ft, min=-clip, max=clip)</div>
<div class="line"><span class="lineno">  722</span>        ft = transformer.make_act(ft, act[<span class="stringliteral">&#39;f&#39;</span>])</div>
<div class="line"><span class="lineno">  723</span> </div>
<div class="line"><span class="lineno">  724</span>        <span class="comment"># ct = g(Xt*(Wc^T) + Ht-1*(Rc^T) + Wbc + Rbc)</span></div>
<div class="line"><span class="lineno">  725</span>        ct = transformer.make_gemm(X[i], W[<span class="stringliteral">&#39;c&#39;</span>], B[<span class="stringliteral">&#39;c&#39;</span>], trans_b=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  726</span>        ct = transformer.make_gemm(previous_h_state_tensor, R[<span class="stringliteral">&#39;c&#39;</span>], ct, trans_b=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  727</span>        <span class="keywordflow">if</span> clip <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  728</span>            ct = transformer.make_clip(ct, min=-clip, max=clip)</div>
<div class="line"><span class="lineno">  729</span>        ct = transformer.make_act(ct, act[<span class="stringliteral">&#39;g&#39;</span>])</div>
<div class="line"><span class="lineno">  730</span> </div>
<div class="line"><span class="lineno">  731</span>        <span class="comment"># Ct = ft (.) Ct-1 + it (.) ct</span></div>
<div class="line"><span class="lineno">  732</span>        ft_Ct = transformer.make_mul(ft, previous_c_state_tensor)</div>
<div class="line"><span class="lineno">  733</span>        it_ct = transformer.make_mul(it, ct)</div>
<div class="line"><span class="lineno">  734</span>        Ct = transformer.make_add(ft_Ct, it_ct)</div>
<div class="line"><span class="lineno">  735</span>        previous_c_state_tensor = Ct</div>
<div class="line"><span class="lineno">  736</span> </div>
<div class="line"><span class="lineno">  737</span>        <span class="comment"># ot = f(Xt*(Wo^T) + Ht-1*(Ro^T) + Po (.) Ct + Wbo + Rbo)</span></div>
<div class="line"><span class="lineno">  738</span>        ot = transformer.make_gemm(X[i], W[<span class="stringliteral">&#39;o&#39;</span>], B[<span class="stringliteral">&#39;o&#39;</span>], trans_b=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  739</span>        ot = transformer.make_gemm(previous_h_state_tensor, R[<span class="stringliteral">&#39;o&#39;</span>], ot, trans_b=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  740</span>        peephole_ot = transformer.make_mul(P[<span class="stringliteral">&#39;o&#39;</span>], Ct)</div>
<div class="line"><span class="lineno">  741</span>        ot = transformer.make_add(ot, peephole_ot)</div>
<div class="line"><span class="lineno">  742</span>        <span class="keywordflow">if</span> clip <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  743</span>            ot = transformer.make_clip(ot, min=-clip, max=clip)</div>
<div class="line"><span class="lineno">  744</span>        ot = transformer.make_act(ot, act[<span class="stringliteral">&#39;f&#39;</span>])</div>
<div class="line"><span class="lineno">  745</span> </div>
<div class="line"><span class="lineno">  746</span>        <span class="comment"># Ht = ot (.) h(Ct)</span></div>
<div class="line"><span class="lineno">  747</span>        Ht = transformer.make_act(Ct, act[<span class="stringliteral">&#39;h&#39;</span>])</div>
<div class="line"><span class="lineno">  748</span>        Ht = transformer.make_mul(ot, Ht)</div>
<div class="line"><span class="lineno">  749</span>        previous_h_state_tensor = Ht</div>
<div class="line"><span class="lineno">  750</span>        state_h_tensors += [Ht]</div>
<div class="line"><span class="lineno">  751</span> </div>
<div class="line"><span class="lineno">  752</span>    <span class="keywordflow">return</span> (state_h_tensors, previous_c_state_tensor)</div>
<div class="line"><span class="lineno">  753</span> </div>
<div class="line"><span class="lineno">  754</span> </div>
</div><!-- fragment -->
<p class="reference">Referenced by <a class="el" href="onnx__legalizer_8py_source.html#l00828">_transform_bidirectional_LSTM()</a>, and <a class="el" href="onnx__legalizer_8py_source.html#l00756">_transform_unidirectional_LSTM()</a>.</p>

</div>
</div>
<a id="ab181deaf1295e11f68feb087108e928a" name="ab181deaf1295e11f68feb087108e928a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab181deaf1295e11f68feb087108e928a">&#9670;&#160;</a></span>_generate_one_direction_RNN()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">onnx_legalizer._generate_one_direction_RNN </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>transformer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>W</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>R</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>B</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>initial_h</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>clip</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>activation_name</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Generate subgraph of one direction of unrolled RNN layer

Args:
    transformer (_ModelTransformerHelper): helper for model generation
    X (list of str): names of input tensors in sequence. Tensor shapes: [batch_size, input_size].
    W (str): name of weight tensor
    R (str): name of recurrence weight tensor
    B (str): name of bias tensor
    initial_h (str or None): name of tensor containing initial hidden state. Shape [batch_size, hidden_size]
    clip (float or None): range which clips input of activations
    act (str): activation function
</pre> 
<p class="definition">Definition at line <a class="el" href="onnx__legalizer_8py_source.html#l00344">344</a> of file <a class="el" href="onnx__legalizer_8py_source.html">onnx_legalizer.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  345</span>                                activation_name):</div>
<div class="line"><span class="lineno">  346</span>    <span class="stringliteral">&quot;&quot;&quot;Generate subgraph of one direction of unrolled RNN layer</span></div>
<div class="line"><span class="lineno">  347</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  348</span><span class="stringliteral">    Args:</span></div>
<div class="line"><span class="lineno">  349</span><span class="stringliteral">        transformer (_ModelTransformerHelper): helper for model generation</span></div>
<div class="line"><span class="lineno">  350</span><span class="stringliteral">        X (list of str): names of input tensors in sequence. Tensor shapes: [batch_size, input_size].</span></div>
<div class="line"><span class="lineno">  351</span><span class="stringliteral">        W (str): name of weight tensor</span></div>
<div class="line"><span class="lineno">  352</span><span class="stringliteral">        R (str): name of recurrence weight tensor</span></div>
<div class="line"><span class="lineno">  353</span><span class="stringliteral">        B (str): name of bias tensor</span></div>
<div class="line"><span class="lineno">  354</span><span class="stringliteral">        initial_h (str or None): name of tensor containing initial hidden state. Shape [batch_size, hidden_size]</span></div>
<div class="line"><span class="lineno">  355</span><span class="stringliteral">        clip (float or None): range which clips input of activations</span></div>
<div class="line"><span class="lineno">  356</span><span class="stringliteral">        act (str): activation function</span></div>
<div class="line"><span class="lineno">  357</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  358</span>    <span class="comment"># one direction RNN:</span></div>
<div class="line"><span class="lineno">  359</span>    <span class="comment">#</span></div>
<div class="line"><span class="lineno">  360</span>    <span class="comment"># For details see:</span></div>
<div class="line"><span class="lineno">  361</span>    <span class="comment"># https://github.com/onnx/onnx/blob/5cf5feef5ec3fd5527b2fdb6c29780e3b705059f/docs/Changelog.md#RNN-7</span></div>
<div class="line"><span class="lineno">  362</span>    <span class="comment">#</span></div>
<div class="line"><span class="lineno">  363</span>    <span class="comment"># H = f(X*(W^T) + h*(R^T) + B)</span></div>
<div class="line"><span class="lineno">  364</span>    <span class="comment">#</span></div>
<div class="line"><span class="lineno">  365</span>    <span class="comment"># H  - new hidden state</span></div>
<div class="line"><span class="lineno">  366</span>    <span class="comment"># h  - previous hidden state</span></div>
<div class="line"><span class="lineno">  367</span>    <span class="comment"># X  - current input</span></div>
<div class="line"><span class="lineno">  368</span>    <span class="comment"># W  - input weights matrix</span></div>
<div class="line"><span class="lineno">  369</span>    <span class="comment"># R  - reccurent weights matrix</span></div>
<div class="line"><span class="lineno">  370</span>    <span class="comment"># Wb - input weights matmul bias</span></div>
<div class="line"><span class="lineno">  371</span>    <span class="comment"># Rb - reccurent weights matmul bias</span></div>
<div class="line"><span class="lineno">  372</span>    <span class="comment"># f  - activation function</span></div>
<div class="line"><span class="lineno">  373</span> </div>
<div class="line"><span class="lineno">  374</span>    seq_length = len(X)</div>
<div class="line"><span class="lineno">  375</span>    first_iter = 0</div>
<div class="line"><span class="lineno">  376</span>    state_tensors = []</div>
<div class="line"><span class="lineno">  377</span>    <span class="keywordflow">if</span> initial_h <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  378</span>        previous_state_tensor = initial_h</div>
<div class="line"><span class="lineno">  379</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  380</span>        first_iter = 1</div>
<div class="line"><span class="lineno">  381</span>        state_tensor = transformer.make_gemm(X[0], W, B, trans_b=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  382</span>        <span class="keywordflow">if</span> clip != <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  383</span>            state_tensor = transformer.make_clip(state_tensor, min=-clip, max=clip)</div>
<div class="line"><span class="lineno">  384</span>        previous_state_tensor = transformer.make_act(state_tensor, activation_name)</div>
<div class="line"><span class="lineno">  385</span>        state_tensors += [previous_state_tensor]</div>
<div class="line"><span class="lineno">  386</span> </div>
<div class="line"><span class="lineno">  387</span>    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(first_iter, seq_length):</div>
<div class="line"><span class="lineno">  388</span>        state_tensor = transformer.make_gemm(X[i], W, B, trans_b=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  389</span>        state_tensor = transformer.make_gemm(</div>
<div class="line"><span class="lineno">  390</span>            previous_state_tensor, R, state_tensor, trans_b=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  391</span>        <span class="keywordflow">if</span> clip != <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  392</span>            state_tensor = transformer.make_clip(state_tensor, min=-clip, max=clip)</div>
<div class="line"><span class="lineno">  393</span>        previous_state_tensor = transformer.make_act(state_tensor, activation_name)</div>
<div class="line"><span class="lineno">  394</span>        state_tensors += [previous_state_tensor]</div>
<div class="line"><span class="lineno">  395</span>    <span class="keywordflow">return</span> state_tensors</div>
<div class="line"><span class="lineno">  396</span> </div>
<div class="line"><span class="lineno">  397</span> </div>
</div><!-- fragment -->
<p class="reference">Referenced by <a class="el" href="onnx__legalizer_8py_source.html#l00455">_transform_bidirectional_RNN()</a>, and <a class="el" href="onnx__legalizer_8py_source.html#l00399">_transform_unidirectional_RNN()</a>.</p>

</div>
</div>
<a id="a0fab3df298da4c943e9ca634f633e434" name="a0fab3df298da4c943e9ca634f633e434"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0fab3df298da4c943e9ca634f633e434">&#9670;&#160;</a></span>_get_tensor_infos()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">onnx_legalizer._get_tensor_infos </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Infer tensor shapes and dtypes
Args:
    model (onnx.onnx_ml_pb2.ModelProto): model to process

Returns:
    dict from str to _TensorInfo: maps tensor name to shape and dtype information
</pre> 
<p class="definition">Definition at line <a class="el" href="onnx__legalizer_8py_source.html#l00301">301</a> of file <a class="el" href="onnx__legalizer_8py_source.html">onnx_legalizer.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  301</span><span class="keyword">def </span>_get_tensor_infos(model):</div>
<div class="line"><span class="lineno">  302</span>    <span class="stringliteral">&quot;&quot;&quot;Infer tensor shapes and dtypes</span></div>
<div class="line"><span class="lineno">  303</span><span class="stringliteral">    Args:</span></div>
<div class="line"><span class="lineno">  304</span><span class="stringliteral">        model (onnx.onnx_ml_pb2.ModelProto): model to process</span></div>
<div class="line"><span class="lineno">  305</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  306</span><span class="stringliteral">    Returns:</span></div>
<div class="line"><span class="lineno">  307</span><span class="stringliteral">        dict from str to _TensorInfo: maps tensor name to shape and dtype information</span></div>
<div class="line"><span class="lineno">  308</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  309</span> </div>
<div class="line"><span class="lineno">  310</span>    inferred_shape_model = onnx.shape_inference.infer_shapes(model)</div>
<div class="line"><span class="lineno">  311</span> </div>
<div class="line"><span class="lineno">  312</span>    infos = {}</div>
<div class="line"><span class="lineno">  313</span>    <span class="keywordflow">for</span> tensor <span class="keywordflow">in</span> list(inferred_shape_model.graph.value_info) + list(</div>
<div class="line"><span class="lineno">  314</span>            inferred_shape_model.graph.input):</div>
<div class="line"><span class="lineno">  315</span>        info = _TensorInfo(tensor.type.tensor_type.elem_type, [])</div>
<div class="line"><span class="lineno">  316</span>        <span class="keywordflow">for</span> dim <span class="keywordflow">in</span> tensor.type.tensor_type.shape.dim:</div>
<div class="line"><span class="lineno">  317</span>            info.shape += [dim.dim_value]</div>
<div class="line"><span class="lineno">  318</span>        infos[tensor.name] = info</div>
<div class="line"><span class="lineno">  319</span> </div>
<div class="line"><span class="lineno">  320</span>    <span class="keywordflow">for</span> tensor <span class="keywordflow">in</span> list(model.graph.initializer):</div>
<div class="line"><span class="lineno">  321</span>        infos[tensor.name] = _TensorInfo(tensor.data_type, tensor.dims)</div>
<div class="line"><span class="lineno">  322</span>    <span class="keywordflow">return</span> infos</div>
<div class="line"><span class="lineno">  323</span> </div>
<div class="line"><span class="lineno">  324</span> </div>
</div><!-- fragment -->
<p class="reference">Referenced by <a class="el" href="onnx__legalizer_8py_source.html#l01009">legalize()</a>.</p>

</div>
</div>
<a id="a0e35c1dafe17a08559cb9cb6a263ba4e" name="a0e35c1dafe17a08559cb9cb6a263ba4e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0e35c1dafe17a08559cb9cb6a263ba4e">&#9670;&#160;</a></span>_legalize_LSTM()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">onnx_legalizer._legalize_LSTM </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>transformer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tensor_infos</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>node</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Unroll LSTM operation

Args:
    transformer (_ModelTransformerHelper): transformation helper
    tensor_infos (dict from str to _TensorInfo): dict maps tensor name to it's shape and dtype info
    node (onnx.onnx_ml_pb2.NodeProto): LSTM operation to unroll
</pre> 
<p class="definition">Definition at line <a class="el" href="onnx__legalizer_8py_source.html#l00935">935</a> of file <a class="el" href="onnx__legalizer_8py_source.html">onnx_legalizer.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  935</span><span class="keyword">def </span>_legalize_LSTM(transformer, tensor_infos, node):</div>
<div class="line"><span class="lineno">  936</span>    <span class="stringliteral">&quot;&quot;&quot;Unroll LSTM operation</span></div>
<div class="line"><span class="lineno">  937</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  938</span><span class="stringliteral">    Args:</span></div>
<div class="line"><span class="lineno">  939</span><span class="stringliteral">        transformer (_ModelTransformerHelper): transformation helper</span></div>
<div class="line"><span class="lineno">  940</span><span class="stringliteral">        tensor_infos (dict from str to _TensorInfo): dict maps tensor name to it&#39;s shape and dtype info</span></div>
<div class="line"><span class="lineno">  941</span><span class="stringliteral">        node (onnx.onnx_ml_pb2.NodeProto): LSTM operation to unroll</span></div>
<div class="line"><span class="lineno">  942</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  943</span>    inputs = node.input</div>
<div class="line"><span class="lineno">  944</span>    <span class="keywordflow">if</span> len(inputs) &gt; 4 <span class="keywordflow">and</span> inputs[4] != <span class="stringliteral">&#39;&#39;</span>:</div>
<div class="line"><span class="lineno">  945</span>        <span class="keywordflow">raise</span> NotImplementedError(<span class="stringliteral">&#39;Variadic length of output is not supported&#39;</span>)</div>
<div class="line"><span class="lineno">  946</span>    <span class="comment"># attributes</span></div>
<div class="line"><span class="lineno">  947</span>    activation_alpha = []</div>
<div class="line"><span class="lineno">  948</span>    activation_beta = []</div>
<div class="line"><span class="lineno">  949</span>    activations = [<span class="stringliteral">&#39;Sigmoid&#39;</span>, <span class="stringliteral">&#39;Tanh&#39;</span>, <span class="stringliteral">&#39;Tanh&#39;</span>] * 2</div>
<div class="line"><span class="lineno">  950</span>    clip = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  951</span>    direction = <span class="stringliteral">&#39;forward&#39;</span></div>
<div class="line"><span class="lineno">  952</span>    hidden_size = 0</div>
<div class="line"><span class="lineno">  953</span>    input_forget = 0</div>
<div class="line"><span class="lineno">  954</span>    layout = 0</div>
<div class="line"><span class="lineno">  955</span> </div>
<div class="line"><span class="lineno">  956</span>    <span class="keywordflow">for</span> attr <span class="keywordflow">in</span> node.attribute:</div>
<div class="line"><span class="lineno">  957</span>        <span class="keywordflow">if</span> attr.name == <span class="stringliteral">&#39;activation_alpha&#39;</span>:</div>
<div class="line"><span class="lineno">  958</span>            activation_alpha = attr.floats</div>
<div class="line"><span class="lineno">  959</span>        <span class="keywordflow">if</span> attr.name == <span class="stringliteral">&#39;activation_beta&#39;</span>:</div>
<div class="line"><span class="lineno">  960</span>            activation_beta = attr.floats</div>
<div class="line"><span class="lineno">  961</span>        <span class="keywordflow">if</span> attr.name == <span class="stringliteral">&#39;activations&#39;</span>:</div>
<div class="line"><span class="lineno">  962</span>            activations = list(map(<span class="keyword">lambda</span> item: item.decode(<span class="stringliteral">&#39;UTF-8&#39;</span>), list(attr.strings)))</div>
<div class="line"><span class="lineno">  963</span>        <span class="keywordflow">if</span> attr.name == <span class="stringliteral">&#39;clip&#39;</span>:</div>
<div class="line"><span class="lineno">  964</span>            clip = attr.f</div>
<div class="line"><span class="lineno">  965</span>        <span class="keywordflow">if</span> attr.name == <span class="stringliteral">&#39;direction&#39;</span>:</div>
<div class="line"><span class="lineno">  966</span>            direction = attr.s.decode(<span class="stringliteral">&#39;UTF-8&#39;</span>)</div>
<div class="line"><span class="lineno">  967</span>        <span class="keywordflow">if</span> attr.name == <span class="stringliteral">&#39;hidden_size&#39;</span>:</div>
<div class="line"><span class="lineno">  968</span>            hidden_size = attr.i</div>
<div class="line"><span class="lineno">  969</span>        <span class="keywordflow">if</span> attr.name == <span class="stringliteral">&#39;input_forget&#39;</span>:</div>
<div class="line"><span class="lineno">  970</span>            input_forget = attr.i</div>
<div class="line"><span class="lineno">  971</span>        <span class="keywordflow">if</span> attr.name == <span class="stringliteral">&#39;layout&#39;</span>:</div>
<div class="line"><span class="lineno">  972</span>            layout = attr.i</div>
<div class="line"><span class="lineno">  973</span> </div>
<div class="line"><span class="lineno">  974</span>    <span class="keywordflow">if</span> len(activation_alpha) &gt; 0 <span class="keywordflow">or</span> len(activation_beta) &gt; 0:</div>
<div class="line"><span class="lineno">  975</span>        <span class="keywordflow">raise</span> NotImplementedError(<span class="stringliteral">&#39;Unsupported parameters for LSTM activations&#39;</span>)</div>
<div class="line"><span class="lineno">  976</span> </div>
<div class="line"><span class="lineno">  977</span>    <span class="keywordflow">for</span> act <span class="keywordflow">in</span> activations:</div>
<div class="line"><span class="lineno">  978</span>        <span class="keywordflow">if</span> act <span class="keywordflow">not</span> <span class="keywordflow">in</span> [<span class="stringliteral">&#39;Relu&#39;</span>, <span class="stringliteral">&#39;Tanh&#39;</span>, <span class="stringliteral">&#39;Sigmoid&#39;</span>]:</div>
<div class="line"><span class="lineno">  979</span>            <span class="keywordflow">raise</span> NotImplementedError(<span class="stringliteral">&#39;Unsupported activation function&#39;</span>)</div>
<div class="line"><span class="lineno">  980</span> </div>
<div class="line"><span class="lineno">  981</span>    <span class="keywordflow">if</span> input_forget != 0:</div>
<div class="line"><span class="lineno">  982</span>        <span class="keywordflow">raise</span> NotImplementedError(<span class="stringliteral">&#39;Unsupported input_forget attribute value&#39;</span>)</div>
<div class="line"><span class="lineno">  983</span> </div>
<div class="line"><span class="lineno">  984</span>    seq_length_dim = layout</div>
<div class="line"><span class="lineno">  985</span>    seq_length = tensor_infos[inputs[0]].shape[seq_length_dim]</div>
<div class="line"><span class="lineno">  986</span>    <span class="keywordflow">if</span> hidden_size == 0:</div>
<div class="line"><span class="lineno">  987</span>        hidden_size = tensor_infos[inputs[2]].shape[2]</div>
<div class="line"><span class="lineno">  988</span> </div>
<div class="line"><span class="lineno">  989</span>    input_split_tensor = transformer.make_split(</div>
<div class="line"><span class="lineno">  990</span>        inputs[0], split_sizes=[1] * seq_length, axis=seq_length_dim)</div>
<div class="line"><span class="lineno">  991</span>    x = []</div>
<div class="line"><span class="lineno">  992</span>    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(len(input_split_tensor)):</div>
<div class="line"><span class="lineno">  993</span>        input_frame_tensor = input_split_tensor[i]</div>
<div class="line"><span class="lineno">  994</span>        squeezed_frame_tensor = transformer.make_squeeze(input_frame_tensor, axes=[0])</div>
<div class="line"><span class="lineno">  995</span>        x += [squeezed_frame_tensor]</div>
<div class="line"><span class="lineno">  996</span> </div>
<div class="line"><span class="lineno">  997</span>    <span class="keywordflow">if</span> direction <span class="keywordflow">in</span> [<span class="stringliteral">&#39;forward&#39;</span>, <span class="stringliteral">&#39;reverse&#39;</span>]:</div>
<div class="line"><span class="lineno">  998</span>        _transform_unidirectional_LSTM(transformer, node, x, tensor_infos, activations,</div>
<div class="line"><span class="lineno">  999</span>                                       clip, direction, hidden_size, layout)</div>
<div class="line"><span class="lineno"> 1000</span>    <span class="keywordflow">elif</span> direction == <span class="stringliteral">&#39;bidirectional&#39;</span>:</div>
<div class="line"><span class="lineno"> 1001</span>        _transform_bidirectional_LSTM(transformer, node, x, tensor_infos, activations,</div>
<div class="line"><span class="lineno"> 1002</span>                                      clip, hidden_size, layout)</div>
<div class="line"><span class="lineno"> 1003</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1004</span>        <span class="keywordflow">raise</span> RuntimeError(<span class="stringliteral">&#39;Unknown LSTM type&#39;</span>)</div>
<div class="line"><span class="lineno"> 1005</span> </div>
<div class="line"><span class="lineno"> 1006</span>    transformer.mark_for_deletion(node)</div>
<div class="line"><span class="lineno"> 1007</span> </div>
<div class="line"><span class="lineno"> 1008</span> </div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="onnx__legalizer_8py_source.html#l00828">_transform_bidirectional_LSTM()</a>, and <a class="el" href="onnx__legalizer_8py_source.html#l00756">_transform_unidirectional_LSTM()</a>.</p>

<p class="reference">Referenced by <a class="el" href="onnx__legalizer_8py_source.html#l01009">legalize()</a>.</p>

</div>
</div>
<a id="a46684478851b90ca545921590ddca1aa" name="a46684478851b90ca545921590ddca1aa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a46684478851b90ca545921590ddca1aa">&#9670;&#160;</a></span>_legalize_RNN()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">onnx_legalizer._legalize_RNN </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>transformer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tensor_infos</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>node</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Unroll RNN operation

Args:
    transformer (_ModelTransformerHelper): transformation helper
    tensor_infos (dict from str to _TensorInfo): dict maps tensor name to it's shape and dtype info
    node (onnx.onnx_ml_pb2.NodeProto): RNN operation to unroll
</pre> 
<p class="definition">Definition at line <a class="el" href="onnx__legalizer_8py_source.html#l00544">544</a> of file <a class="el" href="onnx__legalizer_8py_source.html">onnx_legalizer.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  544</span><span class="keyword">def </span>_legalize_RNN(transformer, tensor_infos, node):</div>
<div class="line"><span class="lineno">  545</span>    <span class="stringliteral">&quot;&quot;&quot;Unroll RNN operation</span></div>
<div class="line"><span class="lineno">  546</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  547</span><span class="stringliteral">    Args:</span></div>
<div class="line"><span class="lineno">  548</span><span class="stringliteral">        transformer (_ModelTransformerHelper): transformation helper</span></div>
<div class="line"><span class="lineno">  549</span><span class="stringliteral">        tensor_infos (dict from str to _TensorInfo): dict maps tensor name to it&#39;s shape and dtype info</span></div>
<div class="line"><span class="lineno">  550</span><span class="stringliteral">        node (onnx.onnx_ml_pb2.NodeProto): RNN operation to unroll</span></div>
<div class="line"><span class="lineno">  551</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  552</span>    inputs = node.input</div>
<div class="line"><span class="lineno">  553</span>    <span class="keywordflow">if</span> len(inputs) &gt; 4 <span class="keywordflow">and</span> inputs[4] != <span class="stringliteral">&#39;&#39;</span>:</div>
<div class="line"><span class="lineno">  554</span>        <span class="keywordflow">raise</span> NotImplementedError(<span class="stringliteral">&#39;Variadic length of output is not supported&#39;</span>)</div>
<div class="line"><span class="lineno">  555</span>    <span class="comment"># attributes</span></div>
<div class="line"><span class="lineno">  556</span>    activation_alpha = []</div>
<div class="line"><span class="lineno">  557</span>    activation_beta = []</div>
<div class="line"><span class="lineno">  558</span>    activations = [<span class="stringliteral">&#39;Tanh&#39;</span>, <span class="stringliteral">&#39;Tanh&#39;</span>]</div>
<div class="line"><span class="lineno">  559</span>    clip = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  560</span>    direction = <span class="stringliteral">&#39;forward&#39;</span></div>
<div class="line"><span class="lineno">  561</span>    hidden_size = 0</div>
<div class="line"><span class="lineno">  562</span>    layout = 0</div>
<div class="line"><span class="lineno">  563</span> </div>
<div class="line"><span class="lineno">  564</span>    <span class="keywordflow">for</span> attr <span class="keywordflow">in</span> node.attribute:</div>
<div class="line"><span class="lineno">  565</span>        <span class="keywordflow">if</span> attr.name == <span class="stringliteral">&#39;activation_alpha&#39;</span>:</div>
<div class="line"><span class="lineno">  566</span>            activation_alpha = attr.floats</div>
<div class="line"><span class="lineno">  567</span>        <span class="keywordflow">if</span> attr.name == <span class="stringliteral">&#39;activation_beta&#39;</span>:</div>
<div class="line"><span class="lineno">  568</span>            activation_beta = attr.floats</div>
<div class="line"><span class="lineno">  569</span>        <span class="keywordflow">if</span> attr.name == <span class="stringliteral">&#39;activations&#39;</span>:</div>
<div class="line"><span class="lineno">  570</span>            activations = list(map(<span class="keyword">lambda</span> item: item.decode(<span class="stringliteral">&#39;UTF-8&#39;</span>), list(attr.strings)))</div>
<div class="line"><span class="lineno">  571</span>        <span class="keywordflow">if</span> attr.name == <span class="stringliteral">&#39;clip&#39;</span>:</div>
<div class="line"><span class="lineno">  572</span>            clip = attr.f</div>
<div class="line"><span class="lineno">  573</span>        <span class="keywordflow">if</span> attr.name == <span class="stringliteral">&#39;direction&#39;</span>:</div>
<div class="line"><span class="lineno">  574</span>            direction = attr.s.decode(<span class="stringliteral">&#39;UTF-8&#39;</span>)</div>
<div class="line"><span class="lineno">  575</span>        <span class="keywordflow">if</span> attr.name == <span class="stringliteral">&#39;hidden_size&#39;</span>:</div>
<div class="line"><span class="lineno">  576</span>            hidden_size = attr.i</div>
<div class="line"><span class="lineno">  577</span>        <span class="keywordflow">if</span> attr.name == <span class="stringliteral">&#39;layout&#39;</span>:</div>
<div class="line"><span class="lineno">  578</span>            layout = attr.i</div>
<div class="line"><span class="lineno">  579</span> </div>
<div class="line"><span class="lineno">  580</span>    <span class="keywordflow">if</span> len(activation_alpha) &gt; 0 <span class="keywordflow">or</span> len(activation_beta) &gt; 0:</div>
<div class="line"><span class="lineno">  581</span>        <span class="keywordflow">raise</span> NotImplementedError(<span class="stringliteral">&#39;Unsupported parameters for LSTM activations&#39;</span>)</div>
<div class="line"><span class="lineno">  582</span> </div>
<div class="line"><span class="lineno">  583</span>    <span class="keywordflow">for</span> act <span class="keywordflow">in</span> activations:</div>
<div class="line"><span class="lineno">  584</span>        <span class="keywordflow">if</span> act <span class="keywordflow">not</span> <span class="keywordflow">in</span> [<span class="stringliteral">&#39;Relu&#39;</span>, <span class="stringliteral">&#39;Tanh&#39;</span>, <span class="stringliteral">&#39;Sigmoid&#39;</span>]:</div>
<div class="line"><span class="lineno">  585</span>            <span class="keywordflow">raise</span> NotImplementedError(<span class="stringliteral">&#39;Unsupported activation function&#39;</span>)</div>
<div class="line"><span class="lineno">  586</span> </div>
<div class="line"><span class="lineno">  587</span>    seq_length_dim = layout</div>
<div class="line"><span class="lineno">  588</span>    seq_length = tensor_infos[inputs[0]].shape[seq_length_dim]</div>
<div class="line"><span class="lineno">  589</span>    <span class="keywordflow">if</span> hidden_size == 0:</div>
<div class="line"><span class="lineno">  590</span>        hidden_size = tensor_infos[inputs[2]].shape[2]</div>
<div class="line"><span class="lineno">  591</span> </div>
<div class="line"><span class="lineno">  592</span>    input_split_tensor = transformer.make_split(</div>
<div class="line"><span class="lineno">  593</span>        inputs[0], split_sizes=[1] * seq_length, axis=seq_length_dim)</div>
<div class="line"><span class="lineno">  594</span>    x = []</div>
<div class="line"><span class="lineno">  595</span>    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(len(input_split_tensor)):</div>
<div class="line"><span class="lineno">  596</span>        input_frame_tensor = input_split_tensor[i]</div>
<div class="line"><span class="lineno">  597</span>        squeezed_frame_tensor = transformer.make_squeeze(input_frame_tensor, axes=[0])</div>
<div class="line"><span class="lineno">  598</span>        x += [squeezed_frame_tensor]</div>
<div class="line"><span class="lineno">  599</span> </div>
<div class="line"><span class="lineno">  600</span>    <span class="keywordflow">if</span> direction <span class="keywordflow">in</span> [<span class="stringliteral">&#39;forward&#39;</span>, <span class="stringliteral">&#39;reverse&#39;</span>]:</div>
<div class="line"><span class="lineno">  601</span>        _transform_unidirectional_RNN(transformer, node, x, tensor_infos, activations[0],</div>
<div class="line"><span class="lineno">  602</span>                                      clip, direction, hidden_size, layout)</div>
<div class="line"><span class="lineno">  603</span>    <span class="keywordflow">elif</span> direction == <span class="stringliteral">&#39;bidirectional&#39;</span>:</div>
<div class="line"><span class="lineno">  604</span>        _transform_bidirectional_RNN(transformer, node, x, tensor_infos, activations,</div>
<div class="line"><span class="lineno">  605</span>                                     clip, hidden_size, layout)</div>
<div class="line"><span class="lineno">  606</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  607</span>        <span class="keywordflow">raise</span> RuntimeError(<span class="stringliteral">&#39;Unknown RNN type&#39;</span>)</div>
<div class="line"><span class="lineno">  608</span> </div>
<div class="line"><span class="lineno">  609</span>    transformer.mark_for_deletion(node)</div>
<div class="line"><span class="lineno">  610</span> </div>
<div class="line"><span class="lineno">  611</span> </div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="onnx__legalizer_8py_source.html#l00455">_transform_bidirectional_RNN()</a>, and <a class="el" href="onnx__legalizer_8py_source.html#l00399">_transform_unidirectional_RNN()</a>.</p>

<p class="reference">Referenced by <a class="el" href="onnx__legalizer_8py_source.html#l01009">legalize()</a>.</p>

</div>
</div>
<a id="a1bd044e6391a3acdf2722c675408178b" name="a1bd044e6391a3acdf2722c675408178b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1bd044e6391a3acdf2722c675408178b">&#9670;&#160;</a></span>_parse_tensor_name()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">onnx_legalizer._parse_tensor_name </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Splits tensor name to base part and serial number

Most of tensor names have following format: "tensor_123".
This  function breaks name into two values: "tensor_" and 123.
Tensor names like this: "321" are broken into "" and 321.

Serial number is used to create unique tensor names using given base name.

Args:
    name (str): tensor name

Returns:
    tuple of str, int: base name and serial number of tensor
</pre> 
<p class="definition">Definition at line <a class="el" href="onnx__legalizer_8py_source.html#l00052">52</a> of file <a class="el" href="onnx__legalizer_8py_source.html">onnx_legalizer.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   52</span><span class="keyword">def </span>_parse_tensor_name(name):</div>
<div class="line"><span class="lineno">   53</span>    <span class="stringliteral">&quot;&quot;&quot;Splits tensor name to base part and serial number</span></div>
<div class="line"><span class="lineno">   54</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   55</span><span class="stringliteral">    Most of tensor names have following format: &quot;tensor_123&quot;.</span></div>
<div class="line"><span class="lineno">   56</span><span class="stringliteral">    This  function breaks name into two values: &quot;tensor_&quot; and 123.</span></div>
<div class="line"><span class="lineno">   57</span><span class="stringliteral">    Tensor names like this: &quot;321&quot; are broken into &quot;&quot; and 321.</span></div>
<div class="line"><span class="lineno">   58</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   59</span><span class="stringliteral">    Serial number is used to create unique tensor names using given base name.</span></div>
<div class="line"><span class="lineno">   60</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   61</span><span class="stringliteral">    Args:</span></div>
<div class="line"><span class="lineno">   62</span><span class="stringliteral">        name (str): tensor name</span></div>
<div class="line"><span class="lineno">   63</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   64</span><span class="stringliteral">    Returns:</span></div>
<div class="line"><span class="lineno">   65</span><span class="stringliteral">        tuple of str, int: base name and serial number of tensor</span></div>
<div class="line"><span class="lineno">   66</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   67</span>    rev = _reverse_str(name)</div>
<div class="line"><span class="lineno">   68</span>    m = re.match(<span class="stringliteral">&#39;(\d*)(.*)&#39;</span>, rev)</div>
<div class="line"><span class="lineno">   69</span>    <span class="keywordflow">if</span> m.groups()[0] != <span class="stringliteral">&#39;&#39;</span>:</div>
<div class="line"><span class="lineno">   70</span>        <span class="keywordflow">return</span> (_reverse_str(m.groups()[1]), int(_reverse_str(m.groups()[0])))</div>
<div class="line"><span class="lineno">   71</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">   72</span>        <span class="keywordflow">return</span> (_reverse_str(m.groups()[1]), 0)</div>
<div class="line"><span class="lineno">   73</span> </div>
<div class="line"><span class="lineno">   74</span> </div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="onnx__legalizer_8py_source.html#l00048">_reverse_str()</a>.</p>

</div>
</div>
<a id="acce4e92684340ba22f5db5f9f35b1811" name="acce4e92684340ba22f5db5f9f35b1811"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acce4e92684340ba22f5db5f9f35b1811">&#9670;&#160;</a></span>_reverse_str()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">onnx_legalizer._reverse_str </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>s</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="onnx__legalizer_8py_source.html#l00048">48</a> of file <a class="el" href="onnx__legalizer_8py_source.html">onnx_legalizer.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   48</span><span class="keyword">def </span>_reverse_str(s):</div>
<div class="line"><span class="lineno">   49</span>    <span class="keywordflow">return</span> <span class="stringliteral">&#39;&#39;</span>.join(reversed(s))</div>
<div class="line"><span class="lineno">   50</span> </div>
<div class="line"><span class="lineno">   51</span> </div>
</div><!-- fragment -->
<p class="reference">Referenced by <a class="el" href="onnx__legalizer_8py_source.html#l00052">_parse_tensor_name()</a>.</p>

</div>
</div>
<a id="a37047cc6aeedb2fd12739d9ae259ba97" name="a37047cc6aeedb2fd12739d9ae259ba97"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a37047cc6aeedb2fd12739d9ae259ba97">&#9670;&#160;</a></span>_transform_bidirectional_LSTM()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">onnx_legalizer._transform_bidirectional_LSTM </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>transformer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>original_node</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tensor_infos</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>activations</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>clip</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>hidden_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>layout</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Generate Bidirectional unrolled LSTM

Args:
    transformer (_ModelTransformerHelper): transformation helper
    original_node (onnx.onnx_ml_pb2.NodeProto): bidirectional LSTM operation to unroll
    x (list of str): list of input tensors (input tensor split along "time" dimension)
    tensor_infos (dict from str to _TensorInfo): dict maps tensor name to it's shape and dtype info
    activations (list of str): list of length 6, containing names of forward and reverse activations
    clip (float or None): range which clips input of activations
    hidden_size (int): size of hidden state
    layout (int): See attribute description:
        https://github.com/onnx/onnx/blob/5cf5feef5ec3fd5527b2fdb6c29780e3b705059f/docs/Operators.md#attributes-37
</pre> 
<p class="definition">Definition at line <a class="el" href="onnx__legalizer_8py_source.html#l00827">827</a> of file <a class="el" href="onnx__legalizer_8py_source.html">onnx_legalizer.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  828</span>                                  activations, clip, hidden_size, layout):</div>
<div class="line"><span class="lineno">  829</span>    <span class="stringliteral">&quot;&quot;&quot;Generate Bidirectional unrolled LSTM</span></div>
<div class="line"><span class="lineno">  830</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  831</span><span class="stringliteral">    Args:</span></div>
<div class="line"><span class="lineno">  832</span><span class="stringliteral">        transformer (_ModelTransformerHelper): transformation helper</span></div>
<div class="line"><span class="lineno">  833</span><span class="stringliteral">        original_node (onnx.onnx_ml_pb2.NodeProto): bidirectional LSTM operation to unroll</span></div>
<div class="line"><span class="lineno">  834</span><span class="stringliteral">        x (list of str): list of input tensors (input tensor split along &quot;time&quot; dimension)</span></div>
<div class="line"><span class="lineno">  835</span><span class="stringliteral">        tensor_infos (dict from str to _TensorInfo): dict maps tensor name to it&#39;s shape and dtype info</span></div>
<div class="line"><span class="lineno">  836</span><span class="stringliteral">        activations (list of str): list of length 6, containing names of forward and reverse activations</span></div>
<div class="line"><span class="lineno">  837</span><span class="stringliteral">        clip (float or None): range which clips input of activations</span></div>
<div class="line"><span class="lineno">  838</span><span class="stringliteral">        hidden_size (int): size of hidden state</span></div>
<div class="line"><span class="lineno">  839</span><span class="stringliteral">        layout (int): See attribute description:</span></div>
<div class="line"><span class="lineno">  840</span><span class="stringliteral">            https://github.com/onnx/onnx/blob/5cf5feef5ec3fd5527b2fdb6c29780e3b705059f/docs/Operators.md#attributes-37</span></div>
<div class="line"><span class="lineno">  841</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  842</span> </div>
<div class="line"><span class="lineno">  843</span>    inputs = original_node.input</div>
<div class="line"><span class="lineno">  844</span>    outputs = original_node.output</div>
<div class="line"><span class="lineno">  845</span> </div>
<div class="line"><span class="lineno">  846</span>    w = transformer.make_split(inputs[1], split_sizes=[1, 1], axis=0)</div>
<div class="line"><span class="lineno">  847</span>    r = transformer.make_split(inputs[2], split_sizes=[1, 1], axis=0)</div>
<div class="line"><span class="lineno">  848</span>    <span class="keywordflow">for</span> d <span class="keywordflow">in</span> range(2):</div>
<div class="line"><span class="lineno">  849</span>        w[d] = transformer.make_squeeze(w[d], axes=[0])</div>
<div class="line"><span class="lineno">  850</span>        r[d] = transformer.make_squeeze(r[d], axes=[0])</div>
<div class="line"><span class="lineno">  851</span> </div>
<div class="line"><span class="lineno">  852</span>    b = [<span class="keywordtype">None</span>, <span class="keywordtype">None</span>]</div>
<div class="line"><span class="lineno">  853</span>    <span class="keywordflow">if</span> len(inputs) &gt; 3 <span class="keywordflow">and</span> inputs[3] != <span class="stringliteral">&#39;&#39;</span>:</div>
<div class="line"><span class="lineno">  854</span>        b = transformer.make_split(inputs[3], split_sizes=[1, 1], axis=0)</div>
<div class="line"><span class="lineno">  855</span>        <span class="keywordflow">for</span> d <span class="keywordflow">in</span> range(2):</div>
<div class="line"><span class="lineno">  856</span>            b[d] = transformer.make_squeeze(b[d], axes=[0])</div>
<div class="line"><span class="lineno">  857</span> </div>
<div class="line"><span class="lineno">  858</span>    initial_h = [<span class="keywordtype">None</span>, <span class="keywordtype">None</span>]</div>
<div class="line"><span class="lineno">  859</span>    <span class="keywordflow">if</span> len(inputs) &gt; 5 <span class="keywordflow">and</span> inputs[5] != <span class="stringliteral">&#39;&#39;</span>:</div>
<div class="line"><span class="lineno">  860</span>        direction_dim = layout</div>
<div class="line"><span class="lineno">  861</span>        initial_h = transformer.make_split(</div>
<div class="line"><span class="lineno">  862</span>            inputs[5], split_sizes=[1, 1], axis=direction_dim)</div>
<div class="line"><span class="lineno">  863</span>        <span class="keywordflow">for</span> d <span class="keywordflow">in</span> range(2):</div>
<div class="line"><span class="lineno">  864</span>            initial_h[d] = transformer.make_squeeze(initial_h[d], axes=[direction_dim])</div>
<div class="line"><span class="lineno">  865</span> </div>
<div class="line"><span class="lineno">  866</span>    initial_c = [<span class="keywordtype">None</span>, <span class="keywordtype">None</span>]</div>
<div class="line"><span class="lineno">  867</span>    <span class="keywordflow">if</span> len(inputs) &gt; 6 <span class="keywordflow">and</span> inputs[6] != <span class="stringliteral">&#39;&#39;</span>:</div>
<div class="line"><span class="lineno">  868</span>        direction_dim = layout</div>
<div class="line"><span class="lineno">  869</span>        initial_c = transformer.make_split(</div>
<div class="line"><span class="lineno">  870</span>            inputs[6], split_sizes=[1, 1], axis=direction_dim)</div>
<div class="line"><span class="lineno">  871</span>        <span class="keywordflow">for</span> d <span class="keywordflow">in</span> range(2):</div>
<div class="line"><span class="lineno">  872</span>            initial_c[d] = transformer.make_squeeze(initial_c[d], axes=[direction_dim])</div>
<div class="line"><span class="lineno">  873</span> </div>
<div class="line"><span class="lineno">  874</span>    p = [<span class="keywordtype">None</span>, <span class="keywordtype">None</span>]</div>
<div class="line"><span class="lineno">  875</span>    <span class="keywordflow">if</span> len(inputs) &gt; 7 <span class="keywordflow">and</span> inputs[7] != <span class="stringliteral">&#39;&#39;</span>:</div>
<div class="line"><span class="lineno">  876</span>        p = transformer.make_split(inputs[7], split_sizes=[1, 1], axis=0)</div>
<div class="line"><span class="lineno">  877</span>        <span class="keywordflow">for</span> d <span class="keywordflow">in</span> range(2):</div>
<div class="line"><span class="lineno">  878</span>            p[d] = transformer.make_squeeze(p[d], axes=[0])</div>
<div class="line"><span class="lineno">  879</span> </div>
<div class="line"><span class="lineno">  880</span>    dtype = _dtype_to_np(tensor_infos[inputs[0]].dtype)</div>
<div class="line"><span class="lineno">  881</span>    batch_size = tensor_infos[inputs[0]].shape[1 - layout]</div>
<div class="line"><span class="lineno">  882</span> </div>
<div class="line"><span class="lineno">  883</span>    act = [{</div>
<div class="line"><span class="lineno">  884</span>        <span class="stringliteral">&#39;f&#39;</span>: activations[0],</div>
<div class="line"><span class="lineno">  885</span>        <span class="stringliteral">&#39;g&#39;</span>: activations[1],</div>
<div class="line"><span class="lineno">  886</span>        <span class="stringliteral">&#39;h&#39;</span>: activations[2]</div>
<div class="line"><span class="lineno">  887</span>    }, {</div>
<div class="line"><span class="lineno">  888</span>        <span class="stringliteral">&#39;f&#39;</span>: activations[3],</div>
<div class="line"><span class="lineno">  889</span>        <span class="stringliteral">&#39;g&#39;</span>: activations[4],</div>
<div class="line"><span class="lineno">  890</span>        <span class="stringliteral">&#39;h&#39;</span>: activations[5]</div>
<div class="line"><span class="lineno">  891</span>    }]</div>
<div class="line"><span class="lineno">  892</span> </div>
<div class="line"><span class="lineno">  893</span>    state_f_h_tensors, state_f_c_tensor = _generate_one_direction_LSTM(</div>
<div class="line"><span class="lineno">  894</span>        transformer, x, w[0], r[0], b[0], initial_h[0], initial_c[0], p[0], clip, act[0],</div>
<div class="line"><span class="lineno">  895</span>        dtype, hidden_size, batch_size)</div>
<div class="line"><span class="lineno">  896</span>    x.reverse()</div>
<div class="line"><span class="lineno">  897</span>    state_b_h_tensors, state_b_c_tensor = _generate_one_direction_LSTM(</div>
<div class="line"><span class="lineno">  898</span>        transformer, x, w[1], r[1], b[1], initial_h[1], initial_c[1], p[1], clip, act[1],</div>
<div class="line"><span class="lineno">  899</span>        dtype, hidden_size, batch_size)</div>
<div class="line"><span class="lineno">  900</span>    state_b_h_tensors.reverse()</div>
<div class="line"><span class="lineno">  901</span> </div>
<div class="line"><span class="lineno">  902</span>    y_direction_dim = layout + 1</div>
<div class="line"><span class="lineno">  903</span>    y_c_direction_dim = layout</div>
<div class="line"><span class="lineno">  904</span>    state_layout_tensors = []</div>
<div class="line"><span class="lineno">  905</span>    seq_length_dim = layout</div>
<div class="line"><span class="lineno">  906</span>    <span class="keywordflow">for</span> f_h_state, b_h_state <span class="keywordflow">in</span> zip(state_f_h_tensors, state_b_h_tensors):</div>
<div class="line"><span class="lineno">  907</span>        state_f_layout_tensors = transformer.make_unsqueeze(</div>
<div class="line"><span class="lineno">  908</span>            f_h_state, axes=[seq_length_dim, y_direction_dim])</div>
<div class="line"><span class="lineno">  909</span>        state_b_layout_tensors = transformer.make_unsqueeze(</div>
<div class="line"><span class="lineno">  910</span>            b_h_state, axes=[seq_length_dim, y_direction_dim])</div>
<div class="line"><span class="lineno">  911</span>        state_layout_tensors += [</div>
<div class="line"><span class="lineno">  912</span>            transformer.make_concat(</div>
<div class="line"><span class="lineno">  913</span>                [state_f_layout_tensors, state_b_layout_tensors], axis=y_direction_dim)</div>
<div class="line"><span class="lineno">  914</span>        ]</div>
<div class="line"><span class="lineno">  915</span> </div>
<div class="line"><span class="lineno">  916</span>    last_f_state_layout_tensor = transformer.make_unsqueeze(</div>
<div class="line"><span class="lineno">  917</span>        state_f_h_tensors[-1], axes=[y_c_direction_dim])</div>
<div class="line"><span class="lineno">  918</span>    last_b_state_layout_tensor = transformer.make_unsqueeze(</div>
<div class="line"><span class="lineno">  919</span>        state_b_h_tensors[0], axes=[y_c_direction_dim])</div>
<div class="line"><span class="lineno">  920</span> </div>
<div class="line"><span class="lineno">  921</span>    Y_h = outputs[1]</div>
<div class="line"><span class="lineno">  922</span>    transformer.make_node(</div>
<div class="line"><span class="lineno">  923</span>        <span class="stringliteral">&#39;Concat&#39;</span>, [last_f_state_layout_tensor, last_b_state_layout_tensor], [Y_h],</div>
<div class="line"><span class="lineno">  924</span>        axis=y_c_direction_dim)</div>
<div class="line"><span class="lineno">  925</span> </div>
<div class="line"><span class="lineno">  926</span>    Y_f_c = transformer.make_unsqueeze(state_f_c_tensor, axes=[y_c_direction_dim])</div>
<div class="line"><span class="lineno">  927</span>    Y_b_c = transformer.make_unsqueeze(state_b_c_tensor, axes=[y_c_direction_dim])</div>
<div class="line"><span class="lineno">  928</span>    Y_c = outputs[2]</div>
<div class="line"><span class="lineno">  929</span>    transformer.make_node(<span class="stringliteral">&#39;Concat&#39;</span>, [Y_f_c, Y_b_c], [Y_c], axis=y_c_direction_dim)</div>
<div class="line"><span class="lineno">  930</span> </div>
<div class="line"><span class="lineno">  931</span>    Y = outputs[0]</div>
<div class="line"><span class="lineno">  932</span>    transformer.make_node(<span class="stringliteral">&#39;Concat&#39;</span>, state_layout_tensors, [Y], axis=seq_length_dim)</div>
<div class="line"><span class="lineno">  933</span> </div>
<div class="line"><span class="lineno">  934</span> </div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="onnx__legalizer_8py_source.html#l00325">_dtype_to_np()</a>, and <a class="el" href="onnx__legalizer_8py_source.html#l00613">_generate_one_direction_LSTM()</a>.</p>

<p class="reference">Referenced by <a class="el" href="onnx__legalizer_8py_source.html#l00935">_legalize_LSTM()</a>.</p>

</div>
</div>
<a id="a7a40eb31811a44d036ea14c533c5f13a" name="a7a40eb31811a44d036ea14c533c5f13a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7a40eb31811a44d036ea14c533c5f13a">&#9670;&#160;</a></span>_transform_bidirectional_RNN()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">onnx_legalizer._transform_bidirectional_RNN </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>transformer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>original_node</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tensor_infos</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>activations</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>clip</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>hidden_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>layout</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Generate Bidirectional unrolled RNN

Args:
    transformer (_ModelTransformerHelper): transformation helper
    original_node (onnx.onnx_ml_pb2.NodeProto): bidirectional RNN operation to unroll
    x (list of str): list of input tensors (input tensor split along "time" dimension)
    tensor_infos (dict from str to _TensorInfo): dict maps tensor name to it's shape and dtype info
    activations (list of str): list of len (2) containing names of forward and reverse activations
    clip (float or None): range which clips input of activations
    hidden_size (int): size of hidden state
    layout (int): See attribute description:
        https://github.com/onnx/onnx/blob/5cf5feef5ec3fd5527b2fdb6c29780e3b705059f/docs/Operators.md#attributes-56
</pre> 
<p class="definition">Definition at line <a class="el" href="onnx__legalizer_8py_source.html#l00454">454</a> of file <a class="el" href="onnx__legalizer_8py_source.html">onnx_legalizer.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  455</span>                                 clip, hidden_size, layout):</div>
<div class="line"><span class="lineno">  456</span>    <span class="stringliteral">&quot;&quot;&quot;Generate Bidirectional unrolled RNN</span></div>
<div class="line"><span class="lineno">  457</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  458</span><span class="stringliteral">    Args:</span></div>
<div class="line"><span class="lineno">  459</span><span class="stringliteral">        transformer (_ModelTransformerHelper): transformation helper</span></div>
<div class="line"><span class="lineno">  460</span><span class="stringliteral">        original_node (onnx.onnx_ml_pb2.NodeProto): bidirectional RNN operation to unroll</span></div>
<div class="line"><span class="lineno">  461</span><span class="stringliteral">        x (list of str): list of input tensors (input tensor split along &quot;time&quot; dimension)</span></div>
<div class="line"><span class="lineno">  462</span><span class="stringliteral">        tensor_infos (dict from str to _TensorInfo): dict maps tensor name to it&#39;s shape and dtype info</span></div>
<div class="line"><span class="lineno">  463</span><span class="stringliteral">        activations (list of str): list of len (2) containing names of forward and reverse activations</span></div>
<div class="line"><span class="lineno">  464</span><span class="stringliteral">        clip (float or None): range which clips input of activations</span></div>
<div class="line"><span class="lineno">  465</span><span class="stringliteral">        hidden_size (int): size of hidden state</span></div>
<div class="line"><span class="lineno">  466</span><span class="stringliteral">        layout (int): See attribute description:</span></div>
<div class="line"><span class="lineno">  467</span><span class="stringliteral">            https://github.com/onnx/onnx/blob/5cf5feef5ec3fd5527b2fdb6c29780e3b705059f/docs/Operators.md#attributes-56</span></div>
<div class="line"><span class="lineno">  468</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  469</span> </div>
<div class="line"><span class="lineno">  470</span>    inputs = original_node.input</div>
<div class="line"><span class="lineno">  471</span>    outputs = original_node.output</div>
<div class="line"><span class="lineno">  472</span>    w_bi = transformer.make_split(inputs[1], split_sizes=[1, 1], axis=0)</div>
<div class="line"><span class="lineno">  473</span>    r_bi = transformer.make_split(inputs[2], split_sizes=[1, 1], axis=0)</div>
<div class="line"><span class="lineno">  474</span>    w = []</div>
<div class="line"><span class="lineno">  475</span>    r = []</div>
<div class="line"><span class="lineno">  476</span>    <span class="keywordflow">for</span> d <span class="keywordflow">in</span> range(2):</div>
<div class="line"><span class="lineno">  477</span>        w += [transformer.make_squeeze(w_bi[d], axes=[0])]</div>
<div class="line"><span class="lineno">  478</span>        r += [transformer.make_squeeze(r_bi[d], axes=[0])]</div>
<div class="line"><span class="lineno">  479</span> </div>
<div class="line"><span class="lineno">  480</span>    b = []</div>
<div class="line"><span class="lineno">  481</span>    <span class="keywordflow">if</span> len(inputs) &gt; 3 <span class="keywordflow">and</span> inputs[3] != <span class="stringliteral">&#39;&#39;</span>:</div>
<div class="line"><span class="lineno">  482</span>        raw_bias_tensors = transformer.make_split(inputs[3], split_sizes=[1, 1], axis=0)</div>
<div class="line"><span class="lineno">  483</span>        <span class="keywordflow">for</span> d <span class="keywordflow">in</span> range(2):</div>
<div class="line"><span class="lineno">  484</span>            raw_bias_tensors_squeezed = transformer.make_squeeze(</div>
<div class="line"><span class="lineno">  485</span>                raw_bias_tensors[d], axes=[0])</div>
<div class="line"><span class="lineno">  486</span>            splitted_bias_tensors = transformer.make_split(</div>
<div class="line"><span class="lineno">  487</span>                raw_bias_tensors_squeezed, split_sizes=[hidden_size] * 2, axis=0)</div>
<div class="line"><span class="lineno">  488</span>            b += [</div>
<div class="line"><span class="lineno">  489</span>                transformer.make_add(splitted_bias_tensors[0], splitted_bias_tensors[1])</div>
<div class="line"><span class="lineno">  490</span>            ]</div>
<div class="line"><span class="lineno">  491</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  492</span>        data_type = _dtype_to_np(tensor_infos[inputs[2]].dtype)</div>
<div class="line"><span class="lineno">  493</span>        b = [</div>
<div class="line"><span class="lineno">  494</span>            transformer.make_constant_tensor(</div>
<div class="line"><span class="lineno">  495</span>                np.zeros(hidden_size, dtype=data_type), <span class="stringliteral">&quot;zero_bias&quot;</span>)</div>
<div class="line"><span class="lineno">  496</span>        ] * 2</div>
<div class="line"><span class="lineno">  497</span>    initial_h = [<span class="keywordtype">None</span>, <span class="keywordtype">None</span>]</div>
<div class="line"><span class="lineno">  498</span>    <span class="keywordflow">if</span> len(inputs) &gt; 5 <span class="keywordflow">and</span> inputs[5] != <span class="stringliteral">&#39;&#39;</span>:</div>
<div class="line"><span class="lineno">  499</span>        direction_dim = layout</div>
<div class="line"><span class="lineno">  500</span>        initial_h = transformer.make_split(</div>
<div class="line"><span class="lineno">  501</span>            inputs[5], split_sizes=[1, 1], axis=direction_dim)</div>
<div class="line"><span class="lineno">  502</span>        <span class="keywordflow">for</span> d <span class="keywordflow">in</span> range(2):</div>
<div class="line"><span class="lineno">  503</span>            initial_h[d] = transformer.make_squeeze(initial_h[d], axes=[direction_dim])</div>
<div class="line"><span class="lineno">  504</span> </div>
<div class="line"><span class="lineno">  505</span>    state_f_tensors = _generate_one_direction_RNN(transformer, x, w[0], r[0], b[0],</div>
<div class="line"><span class="lineno">  506</span>                                                  initial_h[0], clip, activations[0])</div>
<div class="line"><span class="lineno">  507</span>    x.reverse()</div>
<div class="line"><span class="lineno">  508</span>    state_b_tensors = _generate_one_direction_RNN(transformer, x, w[1], r[1], b[1],</div>
<div class="line"><span class="lineno">  509</span>                                                  initial_h[1], clip, activations[1])</div>
<div class="line"><span class="lineno">  510</span>    state_b_tensors.reverse()</div>
<div class="line"><span class="lineno">  511</span> </div>
<div class="line"><span class="lineno">  512</span>    y_direction_dim = layout + 1</div>
<div class="line"><span class="lineno">  513</span>    y_h_direction_dim = layout</div>
<div class="line"><span class="lineno">  514</span>    state_layout_tensors = []</div>
<div class="line"><span class="lineno">  515</span>    seq_length_dim = layout</div>
<div class="line"><span class="lineno">  516</span>    seq_length = len(x)</div>
<div class="line"><span class="lineno">  517</span>    <span class="keywordflow">for</span> t <span class="keywordflow">in</span> range(seq_length):</div>
<div class="line"><span class="lineno">  518</span>        state_f = state_f_tensors[t]</div>
<div class="line"><span class="lineno">  519</span>        state_b = state_b_tensors[t]</div>
<div class="line"><span class="lineno">  520</span>        state_layout_tensors_f = transformer.make_unsqueeze(</div>
<div class="line"><span class="lineno">  521</span>            state_f, axes=[seq_length_dim, y_direction_dim])</div>
<div class="line"><span class="lineno">  522</span>        state_layout_tensors_b = transformer.make_unsqueeze(</div>
<div class="line"><span class="lineno">  523</span>            state_b, axes=[seq_length_dim, y_direction_dim])</div>
<div class="line"><span class="lineno">  524</span>        state_layout_tensors += [</div>
<div class="line"><span class="lineno">  525</span>            transformer.make_concat(</div>
<div class="line"><span class="lineno">  526</span>                [state_layout_tensors_f, state_layout_tensors_b], axis=y_direction_dim)</div>
<div class="line"><span class="lineno">  527</span>        ]</div>
<div class="line"><span class="lineno">  528</span> </div>
<div class="line"><span class="lineno">  529</span>    last_f_state_layout_tensor = transformer.make_unsqueeze(</div>
<div class="line"><span class="lineno">  530</span>        state_f_tensors[-1], axes=[y_h_direction_dim])</div>
<div class="line"><span class="lineno">  531</span>    last_b_state_layout_tensor = transformer.make_unsqueeze(</div>
<div class="line"><span class="lineno">  532</span>        state_b_tensors[0], axes=[y_h_direction_dim])</div>
<div class="line"><span class="lineno">  533</span> </div>
<div class="line"><span class="lineno">  534</span>    <span class="comment"># use low-level interface to attach to existing tensors</span></div>
<div class="line"><span class="lineno">  535</span>    Y_h = outputs[1]</div>
<div class="line"><span class="lineno">  536</span>    transformer.make_node(</div>
<div class="line"><span class="lineno">  537</span>        <span class="stringliteral">&#39;Concat&#39;</span>, [last_f_state_layout_tensor, last_b_state_layout_tensor], [Y_h],</div>
<div class="line"><span class="lineno">  538</span>        axis=y_h_direction_dim)</div>
<div class="line"><span class="lineno">  539</span> </div>
<div class="line"><span class="lineno">  540</span>    Y = outputs[0]</div>
<div class="line"><span class="lineno">  541</span>    transformer.make_node(<span class="stringliteral">&#39;Concat&#39;</span>, state_layout_tensors, [Y], axis=seq_length_dim)</div>
<div class="line"><span class="lineno">  542</span> </div>
<div class="line"><span class="lineno">  543</span> </div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="onnx__legalizer_8py_source.html#l00325">_dtype_to_np()</a>, and <a class="el" href="onnx__legalizer_8py_source.html#l00345">_generate_one_direction_RNN()</a>.</p>

<p class="reference">Referenced by <a class="el" href="onnx__legalizer_8py_source.html#l00544">_legalize_RNN()</a>.</p>

</div>
</div>
<a id="a8053415a9752c3f4d9401091fe7ec921" name="a8053415a9752c3f4d9401091fe7ec921"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8053415a9752c3f4d9401091fe7ec921">&#9670;&#160;</a></span>_transform_unidirectional_LSTM()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">onnx_legalizer._transform_unidirectional_LSTM </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>transformer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>original_node</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tensor_infos</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>activations</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>clip</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>direction</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>hidden_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>layout</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Generate Simple (forward or reverse) unrolled LSTM

Args:
    transformer (_ModelTransformerHelper): transformation helper
    original_node (onnx.onnx_ml_pb2.NodeProto): unidirectional LSTM operation to unroll
    x (list of str): list of input tensors (input tensor split along "time" dimension)
    tensor_infos (dict from str to _TensorInfo): dict maps tensor name to it's shape and dtype info
    activations (list of str): list of length 3 containing names of activation functions
    clip (float or None): range which clips input of activations
    direction (str): "forward" or "reverse"
    hidden_size (int): size of hidden state
    layout (int): See attribute description:
        https://github.com/onnx/onnx/blob/5cf5feef5ec3fd5527b2fdb6c29780e3b705059f/docs/Operators.md#attributes-37
</pre> 
<p class="definition">Definition at line <a class="el" href="onnx__legalizer_8py_source.html#l00755">755</a> of file <a class="el" href="onnx__legalizer_8py_source.html">onnx_legalizer.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  756</span>                                   activations, clip, direction, hidden_size, layout):</div>
<div class="line"><span class="lineno">  757</span>    <span class="stringliteral">&quot;&quot;&quot;Generate Simple (forward or reverse) unrolled LSTM</span></div>
<div class="line"><span class="lineno">  758</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  759</span><span class="stringliteral">    Args:</span></div>
<div class="line"><span class="lineno">  760</span><span class="stringliteral">        transformer (_ModelTransformerHelper): transformation helper</span></div>
<div class="line"><span class="lineno">  761</span><span class="stringliteral">        original_node (onnx.onnx_ml_pb2.NodeProto): unidirectional LSTM operation to unroll</span></div>
<div class="line"><span class="lineno">  762</span><span class="stringliteral">        x (list of str): list of input tensors (input tensor split along &quot;time&quot; dimension)</span></div>
<div class="line"><span class="lineno">  763</span><span class="stringliteral">        tensor_infos (dict from str to _TensorInfo): dict maps tensor name to it&#39;s shape and dtype info</span></div>
<div class="line"><span class="lineno">  764</span><span class="stringliteral">        activations (list of str): list of length 3 containing names of activation functions</span></div>
<div class="line"><span class="lineno">  765</span><span class="stringliteral">        clip (float or None): range which clips input of activations</span></div>
<div class="line"><span class="lineno">  766</span><span class="stringliteral">        direction (str): &quot;forward&quot; or &quot;reverse&quot;</span></div>
<div class="line"><span class="lineno">  767</span><span class="stringliteral">        hidden_size (int): size of hidden state</span></div>
<div class="line"><span class="lineno">  768</span><span class="stringliteral">        layout (int): See attribute description:</span></div>
<div class="line"><span class="lineno">  769</span><span class="stringliteral">            https://github.com/onnx/onnx/blob/5cf5feef5ec3fd5527b2fdb6c29780e3b705059f/docs/Operators.md#attributes-37</span></div>
<div class="line"><span class="lineno">  770</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  771</span> </div>
<div class="line"><span class="lineno">  772</span>    inputs = original_node.input</div>
<div class="line"><span class="lineno">  773</span>    outputs = original_node.output</div>
<div class="line"><span class="lineno">  774</span>    <span class="keywordflow">if</span> direction == <span class="stringliteral">&#39;reverse&#39;</span>:</div>
<div class="line"><span class="lineno">  775</span>        x.reverse()</div>
<div class="line"><span class="lineno">  776</span>    w = transformer.make_squeeze(inputs[1], axes=[0])</div>
<div class="line"><span class="lineno">  777</span>    r = transformer.make_squeeze(inputs[2], axes=[0])</div>
<div class="line"><span class="lineno">  778</span> </div>
<div class="line"><span class="lineno">  779</span>    b = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  780</span>    <span class="keywordflow">if</span> len(inputs) &gt; 3 <span class="keywordflow">and</span> inputs[3] != <span class="stringliteral">&#39;&#39;</span>:</div>
<div class="line"><span class="lineno">  781</span>        b = transformer.make_squeeze(inputs[3], axes=[0])</div>
<div class="line"><span class="lineno">  782</span> </div>
<div class="line"><span class="lineno">  783</span>    initial_h = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  784</span>    <span class="keywordflow">if</span> len(inputs) &gt; 5 <span class="keywordflow">and</span> inputs[5] != <span class="stringliteral">&#39;&#39;</span>:</div>
<div class="line"><span class="lineno">  785</span>        direction_dim = layout</div>
<div class="line"><span class="lineno">  786</span>        initial_h = transformer.make_squeeze(inputs[5], axes=[direction_dim])</div>
<div class="line"><span class="lineno">  787</span> </div>
<div class="line"><span class="lineno">  788</span>    initial_c = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  789</span>    <span class="keywordflow">if</span> len(inputs) &gt; 6 <span class="keywordflow">and</span> inputs[6] != <span class="stringliteral">&#39;&#39;</span>:</div>
<div class="line"><span class="lineno">  790</span>        direction_dim = layout</div>
<div class="line"><span class="lineno">  791</span>        initial_c = transformer.make_squeeze(inputs[6], axes=[direction_dim])</div>
<div class="line"><span class="lineno">  792</span> </div>
<div class="line"><span class="lineno">  793</span>    p = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  794</span>    <span class="keywordflow">if</span> len(inputs) &gt; 7 <span class="keywordflow">and</span> inputs[7] != <span class="stringliteral">&#39;&#39;</span>:</div>
<div class="line"><span class="lineno">  795</span>        p = transformer.make_squeeze(inputs[7], axes=[0])</div>
<div class="line"><span class="lineno">  796</span> </div>
<div class="line"><span class="lineno">  797</span>    dtype = _dtype_to_np(tensor_infos[inputs[0]].dtype)</div>
<div class="line"><span class="lineno">  798</span>    batch_size = tensor_infos[inputs[0]].shape[1 - layout]</div>
<div class="line"><span class="lineno">  799</span> </div>
<div class="line"><span class="lineno">  800</span>    act = {<span class="stringliteral">&#39;f&#39;</span>: activations[0], <span class="stringliteral">&#39;g&#39;</span>: activations[1], <span class="stringliteral">&#39;h&#39;</span>: activations[2]}</div>
<div class="line"><span class="lineno">  801</span> </div>
<div class="line"><span class="lineno">  802</span>    state_h_tensors, state_c_tensor = _generate_one_direction_LSTM(</div>
<div class="line"><span class="lineno">  803</span>        transformer, x, w, r, b, initial_h, initial_c, p, clip, act, dtype, hidden_size,</div>
<div class="line"><span class="lineno">  804</span>        batch_size)</div>
<div class="line"><span class="lineno">  805</span> </div>
<div class="line"><span class="lineno">  806</span>    y_direction_dim = layout + 1</div>
<div class="line"><span class="lineno">  807</span>    y_h_direction_dim = layout</div>
<div class="line"><span class="lineno">  808</span>    state_layout_tensors = []</div>
<div class="line"><span class="lineno">  809</span>    seq_length_dim = layout</div>
<div class="line"><span class="lineno">  810</span>    <span class="keywordflow">for</span> h_state <span class="keywordflow">in</span> state_h_tensors:</div>
<div class="line"><span class="lineno">  811</span>        state_layout_tensors += [</div>
<div class="line"><span class="lineno">  812</span>            transformer.make_unsqueeze(h_state, axes=[seq_length_dim, y_direction_dim])</div>
<div class="line"><span class="lineno">  813</span>        ]</div>
<div class="line"><span class="lineno">  814</span> </div>
<div class="line"><span class="lineno">  815</span>    <span class="comment"># use low-level interface to attach to existing tensors</span></div>
<div class="line"><span class="lineno">  816</span>    Y_h = outputs[1]</div>
<div class="line"><span class="lineno">  817</span>    transformer.make_node(</div>
<div class="line"><span class="lineno">  818</span>        <span class="stringliteral">&#39;Unsqueeze&#39;</span>, [state_h_tensors[-1]], [Y_h], axes=[y_h_direction_dim])</div>
<div class="line"><span class="lineno">  819</span>    Y_c = outputs[2]</div>
<div class="line"><span class="lineno">  820</span>    transformer.make_node(<span class="stringliteral">&#39;Unsqueeze&#39;</span>, [state_c_tensor], [Y_c], axes=[y_h_direction_dim])</div>
<div class="line"><span class="lineno">  821</span>    <span class="keywordflow">if</span> direction == <span class="stringliteral">&#39;reverse&#39;</span>:</div>
<div class="line"><span class="lineno">  822</span>        state_layout_tensors.reverse()</div>
<div class="line"><span class="lineno">  823</span>    Y = outputs[0]</div>
<div class="line"><span class="lineno">  824</span>    transformer.make_node(<span class="stringliteral">&#39;Concat&#39;</span>, state_layout_tensors, [Y], axis=seq_length_dim)</div>
<div class="line"><span class="lineno">  825</span> </div>
<div class="line"><span class="lineno">  826</span> </div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="onnx__legalizer_8py_source.html#l00325">_dtype_to_np()</a>, and <a class="el" href="onnx__legalizer_8py_source.html#l00613">_generate_one_direction_LSTM()</a>.</p>

<p class="reference">Referenced by <a class="el" href="onnx__legalizer_8py_source.html#l00935">_legalize_LSTM()</a>.</p>

</div>
</div>
<a id="a10267e7e63cd609e18c31d5d92f86c53" name="a10267e7e63cd609e18c31d5d92f86c53"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a10267e7e63cd609e18c31d5d92f86c53">&#9670;&#160;</a></span>_transform_unidirectional_RNN()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">onnx_legalizer._transform_unidirectional_RNN </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>transformer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>original_node</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tensor_infos</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>activation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>clip</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>direction</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>hidden_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>layout</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Generate Simple (forward or reverse) unrolled RNN

Args:
    transformer (_ModelTransformerHelper): transformation helper
    original_node (onnx.onnx_ml_pb2.NodeProto): unidirectional RNN operation to unroll
    x (list of str): list of input tensors (input tensor split along "time" dimension)
    tensor_infos (dict from str to _TensorInfo): dict maps tensor name to it's shape and dtype info
    activation (str): name of activation function
    clip (float or None): range which clips input of activations
    direction (str): "forward" or "reverse"
    hidden_size (int): size of hidden state
    layout (int): See attribute description:
        https://github.com/onnx/onnx/blob/5cf5feef5ec3fd5527b2fdb6c29780e3b705059f/docs/Operators.md#attributes-56
</pre> 
<p class="definition">Definition at line <a class="el" href="onnx__legalizer_8py_source.html#l00398">398</a> of file <a class="el" href="onnx__legalizer_8py_source.html">onnx_legalizer.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  399</span>                                  clip, direction, hidden_size, layout):</div>
<div class="line"><span class="lineno">  400</span>    <span class="stringliteral">&quot;&quot;&quot;Generate Simple (forward or reverse) unrolled RNN</span></div>
<div class="line"><span class="lineno">  401</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  402</span><span class="stringliteral">    Args:</span></div>
<div class="line"><span class="lineno">  403</span><span class="stringliteral">        transformer (_ModelTransformerHelper): transformation helper</span></div>
<div class="line"><span class="lineno">  404</span><span class="stringliteral">        original_node (onnx.onnx_ml_pb2.NodeProto): unidirectional RNN operation to unroll</span></div>
<div class="line"><span class="lineno">  405</span><span class="stringliteral">        x (list of str): list of input tensors (input tensor split along &quot;time&quot; dimension)</span></div>
<div class="line"><span class="lineno">  406</span><span class="stringliteral">        tensor_infos (dict from str to _TensorInfo): dict maps tensor name to it&#39;s shape and dtype info</span></div>
<div class="line"><span class="lineno">  407</span><span class="stringliteral">        activation (str): name of activation function</span></div>
<div class="line"><span class="lineno">  408</span><span class="stringliteral">        clip (float or None): range which clips input of activations</span></div>
<div class="line"><span class="lineno">  409</span><span class="stringliteral">        direction (str): &quot;forward&quot; or &quot;reverse&quot;</span></div>
<div class="line"><span class="lineno">  410</span><span class="stringliteral">        hidden_size (int): size of hidden state</span></div>
<div class="line"><span class="lineno">  411</span><span class="stringliteral">        layout (int): See attribute description:</span></div>
<div class="line"><span class="lineno">  412</span><span class="stringliteral">            https://github.com/onnx/onnx/blob/5cf5feef5ec3fd5527b2fdb6c29780e3b705059f/docs/Operators.md#attributes-56</span></div>
<div class="line"><span class="lineno">  413</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  414</span> </div>
<div class="line"><span class="lineno">  415</span>    inputs = original_node.input</div>
<div class="line"><span class="lineno">  416</span>    outputs = original_node.output</div>
<div class="line"><span class="lineno">  417</span>    <span class="keywordflow">if</span> direction == <span class="stringliteral">&#39;reverse&#39;</span>:</div>
<div class="line"><span class="lineno">  418</span>        x.reverse()</div>
<div class="line"><span class="lineno">  419</span>    w = transformer.make_squeeze(inputs[1], axes=[0])</div>
<div class="line"><span class="lineno">  420</span>    r = transformer.make_squeeze(inputs[2], axes=[0])</div>
<div class="line"><span class="lineno">  421</span>    <span class="keywordflow">if</span> len(inputs) &gt; 3 <span class="keywordflow">and</span> inputs[3] != <span class="stringliteral">&#39;&#39;</span>:</div>
<div class="line"><span class="lineno">  422</span>        raw_bias_tensor = transformer.make_squeeze(inputs[3], axes=[0])</div>
<div class="line"><span class="lineno">  423</span>        splitted_bias_tensors = transformer.make_split(</div>
<div class="line"><span class="lineno">  424</span>            raw_bias_tensor, split_sizes=[hidden_size] * 2, axis=0)</div>
<div class="line"><span class="lineno">  425</span>        b = transformer.make_add(splitted_bias_tensors[0], splitted_bias_tensors[1])</div>
<div class="line"><span class="lineno">  426</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  427</span>        data_type = _dtype_to_np(tensor_infos[inputs[2]].dtype)</div>
<div class="line"><span class="lineno">  428</span>        b = transformer.make_constant_tensor(</div>
<div class="line"><span class="lineno">  429</span>            np.zeros(hidden_size, dtype=data_type), <span class="stringliteral">&quot;zero_bias&quot;</span>)</div>
<div class="line"><span class="lineno">  430</span>    <span class="keywordflow">if</span> len(inputs) &gt; 5 <span class="keywordflow">and</span> inputs[5] != <span class="stringliteral">&#39;&#39;</span>:</div>
<div class="line"><span class="lineno">  431</span>        direction_dim = layout</div>
<div class="line"><span class="lineno">  432</span>        initial_h = transformer.make_squeeze(inputs[5], axes=[direction_dim])</div>
<div class="line"><span class="lineno">  433</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  434</span>        initial_h = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  435</span>    state_tensors = _generate_one_direction_RNN(transformer, x, w, r, b, initial_h, clip,</div>
<div class="line"><span class="lineno">  436</span>                                                activation)</div>
<div class="line"><span class="lineno">  437</span>    y_direction_dim = layout + 1</div>
<div class="line"><span class="lineno">  438</span>    y_h_direction_dim = layout</div>
<div class="line"><span class="lineno">  439</span>    state_layout_tensors = []</div>
<div class="line"><span class="lineno">  440</span>    seq_length_dim = layout</div>
<div class="line"><span class="lineno">  441</span>    <span class="keywordflow">for</span> state <span class="keywordflow">in</span> state_tensors:</div>
<div class="line"><span class="lineno">  442</span>        state_layout_tensors += [</div>
<div class="line"><span class="lineno">  443</span>            transformer.make_unsqueeze(state, axes=[seq_length_dim, y_direction_dim])</div>
<div class="line"><span class="lineno">  444</span>        ]</div>
<div class="line"><span class="lineno">  445</span> </div>
<div class="line"><span class="lineno">  446</span>    <span class="comment"># use low-level interface to attach to existing tensors</span></div>
<div class="line"><span class="lineno">  447</span>    Y_h = outputs[1]</div>
<div class="line"><span class="lineno">  448</span>    transformer.make_node(</div>
<div class="line"><span class="lineno">  449</span>        <span class="stringliteral">&#39;Unsqueeze&#39;</span>, [state_tensors[-1]], [Y_h], axes=[y_h_direction_dim])</div>
<div class="line"><span class="lineno">  450</span>    Y = outputs[0]</div>
<div class="line"><span class="lineno">  451</span>    transformer.make_node(<span class="stringliteral">&#39;Concat&#39;</span>, state_layout_tensors, [Y], axis=seq_length_dim)</div>
<div class="line"><span class="lineno">  452</span> </div>
<div class="line"><span class="lineno">  453</span> </div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="onnx__legalizer_8py_source.html#l00325">_dtype_to_np()</a>, and <a class="el" href="onnx__legalizer_8py_source.html#l00345">_generate_one_direction_RNN()</a>.</p>

<p class="reference">Referenced by <a class="el" href="onnx__legalizer_8py_source.html#l00544">_legalize_RNN()</a>.</p>

</div>
</div>
<a id="accc2392dcc041c6c26643e3e408d2402" name="accc2392dcc041c6c26643e3e408d2402"></a>
<h2 class="memtitle"><span class="permalink"><a href="#accc2392dcc041c6c26643e3e408d2402">&#9670;&#160;</a></span>legalize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">onnx_legalizer.legalize </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>options</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Replace selected operations in onnx model

Replaces operations, selected by given options with different operation sequences.
For example remove unsupported parts of graph with sequences of supported operations.

Note that graph is changes inplace.

Args:
    model (onnx.onnx_ml_pb2.ModelProto): target model
    options (LegalizeOptions):
</pre> 
<p class="definition">Definition at line <a class="el" href="onnx__legalizer_8py_source.html#l01009">1009</a> of file <a class="el" href="onnx__legalizer_8py_source.html">onnx_legalizer.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 1009</span><span class="keyword">def </span>legalize(model, options):</div>
<div class="line"><span class="lineno"> 1010</span>    <span class="stringliteral">&quot;&quot;&quot;Replace selected operations in onnx model</span></div>
<div class="line"><span class="lineno"> 1011</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1012</span><span class="stringliteral">    Replaces operations, selected by given options with different operation sequences.</span></div>
<div class="line"><span class="lineno"> 1013</span><span class="stringliteral">    For example remove unsupported parts of graph with sequences of supported operations.</span></div>
<div class="line"><span class="lineno"> 1014</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1015</span><span class="stringliteral">    Note that graph is changes inplace.</span></div>
<div class="line"><span class="lineno"> 1016</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1017</span><span class="stringliteral">    Args:</span></div>
<div class="line"><span class="lineno"> 1018</span><span class="stringliteral">        model (onnx.onnx_ml_pb2.ModelProto): target model</span></div>
<div class="line"><span class="lineno"> 1019</span><span class="stringliteral">        options (LegalizeOptions):</span></div>
<div class="line"><span class="lineno"> 1020</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1021</span>    tensor_infos = _get_tensor_infos(model)</div>
<div class="line"><span class="lineno"> 1022</span> </div>
<div class="line"><span class="lineno"> 1023</span>    transformer = _ModelTransformerHelper(model)</div>
<div class="line"><span class="lineno"> 1024</span> </div>
<div class="line"><span class="lineno"> 1025</span>    node_id = 0</div>
<div class="line"><span class="lineno"> 1026</span>    <span class="keywordflow">while</span> node_id &lt; len(model.graph.node):</div>
<div class="line"><span class="lineno"> 1027</span>        node = model.graph.node[node_id]</div>
<div class="line"><span class="lineno"> 1028</span>        <span class="keywordflow">if</span> node.op_type == <span class="stringliteral">&#39;RNN&#39;</span> <span class="keywordflow">and</span> options.unroll_rnn:</div>
<div class="line"><span class="lineno"> 1029</span>            <span class="comment"># opset version is required by split operation</span></div>
<div class="line"><span class="lineno"> 1030</span>            <span class="keywordflow">if</span> model.opset_import[0].version &gt;= 13:</div>
<div class="line"><span class="lineno"> 1031</span>                <span class="keywordflow">raise</span> NotImplementedError(</div>
<div class="line"><span class="lineno"> 1032</span>                    <span class="stringliteral">&#39;Can not generate code with opcode version 13 and greater&#39;</span>)</div>
<div class="line"><span class="lineno"> 1033</span>            transformer.set_insert_id(node_id)</div>
<div class="line"><span class="lineno"> 1034</span>            _legalize_RNN(transformer, tensor_infos, node)</div>
<div class="line"><span class="lineno"> 1035</span>            node_id = transformer.get_insert_id()</div>
<div class="line"><span class="lineno"> 1036</span>        <span class="keywordflow">elif</span> node.op_type == <span class="stringliteral">&#39;LSTM&#39;</span> <span class="keywordflow">and</span> options.unroll_lstm:</div>
<div class="line"><span class="lineno"> 1037</span>            <span class="keywordflow">if</span> model.opset_import[0].version &gt;= 13:</div>
<div class="line"><span class="lineno"> 1038</span>                <span class="keywordflow">raise</span> NotImplementedError(</div>
<div class="line"><span class="lineno"> 1039</span>                    <span class="stringliteral">&#39;Can not generate code with opcode version 13 and greater&#39;</span>)</div>
<div class="line"><span class="lineno"> 1040</span>            transformer.set_insert_id(node_id)</div>
<div class="line"><span class="lineno"> 1041</span>            _legalize_LSTM(transformer, tensor_infos, node)</div>
<div class="line"><span class="lineno"> 1042</span>            node_id = transformer.get_insert_id()</div>
<div class="line"><span class="lineno"> 1043</span>        node_id += 1</div>
<div class="line"><span class="lineno"> 1044</span> </div>
<div class="line"><span class="lineno"> 1045</span>    transformer.delete_marked_nodes()</div>
<div class="line"><span class="lineno"> 1046</span> </div>
<div class="line"><span class="lineno"> 1047</span> </div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="onnx__legalizer_8py_source.html#l00301">_get_tensor_infos()</a>, <a class="el" href="onnx__legalizer_8py_source.html#l00935">_legalize_LSTM()</a>, and <a class="el" href="onnx__legalizer_8py_source.html#l00544">_legalize_RNN()</a>.</p>

</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="a8485b6ddcea4daf81ebe90ecaf592971" name="a8485b6ddcea4daf81ebe90ecaf592971"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8485b6ddcea4daf81ebe90ecaf592971">&#9670;&#160;</a></span>model</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">onnx_legalizer.model = onnx.load(sys.argv[1])</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="onnx__legalizer_8py_source.html#l01060">1060</a> of file <a class="el" href="onnx__legalizer_8py_source.html">onnx_legalizer.py</a>.</p>

</div>
</div>
<a id="a5f63ff6f9c0c3e7103c2b9b88021555e" name="a5f63ff6f9c0c3e7103c2b9b88021555e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5f63ff6f9c0c3e7103c2b9b88021555e">&#9670;&#160;</a></span>options</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">onnx_legalizer.options = <a class="el" href="classonnx__legalizer_1_1_legalize_options.html">LegalizeOptions</a>()</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="onnx__legalizer_8py_source.html#l01057">1057</a> of file <a class="el" href="onnx__legalizer_8py_source.html">onnx_legalizer.py</a>.</p>

</div>
</div>
<a id="a4f5c3aed8975cb54f164b31f5c2cb319" name="a4f5c3aed8975cb54f164b31f5c2cb319"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4f5c3aed8975cb54f164b31f5c2cb319">&#9670;&#160;</a></span>unroll_lstm</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">onnx_legalizer.unroll_lstm</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="onnx__legalizer_8py_source.html#l01058">1058</a> of file <a class="el" href="onnx__legalizer_8py_source.html">onnx_legalizer.py</a>.</p>

</div>
</div>
<a id="a5389d22ca037325a27ca9f5afa583d5d" name="a5389d22ca037325a27ca9f5afa583d5d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5389d22ca037325a27ca9f5afa583d5d">&#9670;&#160;</a></span>unroll_rnn</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">onnx_legalizer.unroll_rnn</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="onnx__legalizer_8py_source.html#l01059">1059</a> of file <a class="el" href="onnx__legalizer_8py_source.html">onnx_legalizer.py</a>.</p>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespaceonnx__legalizer.html">onnx_legalizer</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
