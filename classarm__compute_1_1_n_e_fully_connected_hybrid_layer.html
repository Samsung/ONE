<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.5"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ONE - On-device Neural Engine: arm_compute::NEFullyConnectedHybridLayer Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">ONE - On-device Neural Engine
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.5 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-methods">Static Public Member Functions</a>  </div>
  <div class="headertitle"><div class="title">arm_compute::NEFullyConnectedHybridLayer Class Reference</div></div>
</div><!--header-->
<div class="contents">

<p><code>#include &lt;<a class="el" href="_n_e_fully_connected_hybrid_layer_8h_source.html">NEFullyConnectedHybridLayer.h</a>&gt;</code></p>
<div class="dynheader">
Collaboration diagram for arm_compute::NEFullyConnectedHybridLayer:</div>
<div class="dyncontent">
<div class="center"><img src="classarm__compute_1_1_n_e_fully_connected_hybrid_layer__coll__graph.png" border="0" usemap="#aarm__compute_1_1_n_e_fully_connected_hybrid_layer_coll__map" alt="Collaboration graph"/></div>
<map name="aarm__compute_1_1_n_e_fully_connected_hybrid_layer_coll__map" id="aarm__compute_1_1_n_e_fully_connected_hybrid_layer_coll__map">
<area shape="rect" title=" " alt="" coords="5,79,220,119"/>
<area shape="rect" title=" " alt="" coords="32,5,193,31"/>
</map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a7fca254ea431062df732fb8ad193e574"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html#a7fca254ea431062df732fb8ad193e574">NEFullyConnectedHybridLayer</a> (std::shared_ptr&lt; IMemoryManager &gt; memory_manager=nullptr)</td></tr>
<tr class="separator:a7fca254ea431062df732fb8ad193e574"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1109d6c4e407f0a05eb1f2b0bb0800cf"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html#a1109d6c4e407f0a05eb1f2b0bb0800cf">NEFullyConnectedHybridLayer</a> (const <a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html">NEFullyConnectedHybridLayer</a> &amp;)=delete</td></tr>
<tr class="separator:a1109d6c4e407f0a05eb1f2b0bb0800cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abfb38b19702033b01991907c8530ed69"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html#abfb38b19702033b01991907c8530ed69">NEFullyConnectedHybridLayer</a> (<a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html">NEFullyConnectedHybridLayer</a> &amp;&amp;)=default</td></tr>
<tr class="separator:abfb38b19702033b01991907c8530ed69"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa82da569230003331079b3bf03d2cf11"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html">NEFullyConnectedHybridLayer</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html#aa82da569230003331079b3bf03d2cf11">operator=</a> (const <a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html">NEFullyConnectedHybridLayer</a> &amp;)=delete</td></tr>
<tr class="separator:aa82da569230003331079b3bf03d2cf11"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1cd0141c099e5055e6c2fc05407a05a7"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html">NEFullyConnectedHybridLayer</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html#a1cd0141c099e5055e6c2fc05407a05a7">operator=</a> (<a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html">NEFullyConnectedHybridLayer</a> &amp;&amp;)=default</td></tr>
<tr class="separator:a1cd0141c099e5055e6c2fc05407a05a7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abaaee364b1eecbee2a3a50efce55367a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html#abaaee364b1eecbee2a3a50efce55367a">configure</a> (const ITensor *input, const ITensor *weights, const ITensor *biases, ITensor *output, FullyConnectedLayerInfo fc_info=FullyConnectedLayerInfo())</td></tr>
<tr class="separator:abaaee364b1eecbee2a3a50efce55367a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acbba87b26dd98e4d28c7c6812457b6b7"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html#acbba87b26dd98e4d28c7c6812457b6b7">run</a> () override</td></tr>
<tr class="separator:acbba87b26dd98e4d28c7c6812457b6b7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa95866c05a8c5b14b0ff5d4bc413405a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html#aa95866c05a8c5b14b0ff5d4bc413405a">prepare</a> () override</td></tr>
<tr class="separator:aa95866c05a8c5b14b0ff5d4bc413405a"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-static-methods" name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:a8ed5cbe7b0e7ba0b2141b7b96a0f2b22"><td class="memItemLeft" align="right" valign="top">static Status&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html#a8ed5cbe7b0e7ba0b2141b7b96a0f2b22">validate</a> (const ITensorInfo *input, const ITensorInfo *weights, const ITensorInfo *biases, const ITensorInfo *output, FullyConnectedLayerInfo fc_info=FullyConnectedLayerInfo())</td></tr>
<tr class="separator:a8ed5cbe7b0e7ba0b2141b7b96a0f2b22"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p >Basic function to compute a Fully Connected layer on NEON. This function calls the following NEON kernels:</p><ol type="1">
<li>NEIm2ColKernel (called when the input comes from a convolutional layer)</li>
<li><a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer_reshape_weights.html">NEFullyConnectedHybridLayerReshapeWeights</a> (if <code>are_weights_reshaped</code> is set to false and transpose_weights is set to true ) (called once)</li>
<li>NEGEMMMatrixMultiplyKernel or NEGEMMLowpMatrixMultiplyCore (if quantized asymmetric)</li>
<li><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_matrix_accumulate_biases_kernel.html">NEGEMMMatrixAccumulateBiasesKernel</a> or NEGEMMLowpQuantizeDownInt32ToUint8ScaleByFixedPoint (if quantized asymmetric) (if <code>biases</code> is not equal to nullptr)</li>
</ol>
<dl class="section note"><dt>Note</dt><dd>The fully connected layer accepts "weights" tensors only with 2 dimensions. </dd></dl>

<p class="definition">Definition at line <a class="el" href="_n_e_fully_connected_hybrid_layer_8h_source.html#l00097">97</a> of file <a class="el" href="_n_e_fully_connected_hybrid_layer_8h_source.html">NEFullyConnectedHybridLayer.h</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a7fca254ea431062df732fb8ad193e574" name="a7fca254ea431062df732fb8ad193e574"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7fca254ea431062df732fb8ad193e574">&#9670;&#160;</a></span>NEFullyConnectedHybridLayer() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">NEFullyConnectedHybridLayer::NEFullyConnectedHybridLayer </td>
          <td>(</td>
          <td class="paramtype">std::shared_ptr&lt; IMemoryManager &gt;&#160;</td>
          <td class="paramname"><em>memory_manager</em> = <code>nullptr</code></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Constructor </p>

<p class="definition">Definition at line <a class="el" href="_n_e_fully_connected_hybrid_layer_8cpp_source.html#l00080">80</a> of file <a class="el" href="_n_e_fully_connected_hybrid_layer_8cpp_source.html">NEFullyConnectedHybridLayer.cpp</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   82</span>  : _memory_group(std::move(memory_manager)), _reshape_weights_function(), _quant_input_kernel(),</div>
<div class="line"><span class="lineno">   83</span>    _mm_gemmlowp(), _accumulate_biases_kernel(), _reshape_weights_output(), _quantized_input(),</div>
<div class="line"><span class="lineno">   84</span>    _scale_factor(), _original_weights(<span class="keyword">nullptr</span>), _are_weights_reshaped(<span class="keyword">false</span>),</div>
<div class="line"><span class="lineno">   85</span>    _accumulate_biases(<span class="keyword">false</span>), _is_prepared(<span class="keyword">false</span>)</div>
<div class="line"><span class="lineno">   86</span>{</div>
<div class="line"><span class="lineno">   87</span>}</div>
</div><!-- fragment -->
</div>
</div>
<a id="a1109d6c4e407f0a05eb1f2b0bb0800cf" name="a1109d6c4e407f0a05eb1f2b0bb0800cf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1109d6c4e407f0a05eb1f2b0bb0800cf">&#9670;&#160;</a></span>NEFullyConnectedHybridLayer() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">arm_compute::NEFullyConnectedHybridLayer::NEFullyConnectedHybridLayer </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html">NEFullyConnectedHybridLayer</a> &amp;&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">delete</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p >Prevent instances of this class from being copied (As this class contains pointers) </p>

</div>
</div>
<a id="abfb38b19702033b01991907c8530ed69" name="abfb38b19702033b01991907c8530ed69"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abfb38b19702033b01991907c8530ed69">&#9670;&#160;</a></span>NEFullyConnectedHybridLayer() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">arm_compute::NEFullyConnectedHybridLayer::NEFullyConnectedHybridLayer </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html">NEFullyConnectedHybridLayer</a> &amp;&amp;&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">default</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p >Default move constructor </p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="abaaee364b1eecbee2a3a50efce55367a" name="abaaee364b1eecbee2a3a50efce55367a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abaaee364b1eecbee2a3a50efce55367a">&#9670;&#160;</a></span>configure()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void NEFullyConnectedHybridLayer::configure </td>
          <td>(</td>
          <td class="paramtype">const ITensor *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const ITensor *&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const ITensor *&#160;</td>
          <td class="paramname"><em>biases</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ITensor *&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">FullyConnectedLayerInfo&#160;</td>
          <td class="paramname"><em>fc_info</em> = <code>FullyConnectedLayerInfo()</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p >Set the input and output tensors.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">input</td><td>Source tensor. Data type supported: F16/F32. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">weights</td><td>Weights tensor. The weights must be 2 dimensional. If this function is called after a Convolution Layer, the (transposed) weights will have as many rows as the product of the first 3 input's dimensions. If it is called after another FullyConnected Layer, the (transposed) weights will have as many rows as the input's first dimension. Data type supported: S8. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">biases</td><td>Bias tensor. Can be nullptr. Data type supported:Same as <code>input</code>. </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">output</td><td>Destination tensor. Its shape should be equal to the output of a matrix multiplication between:<ul>
<li>The output of im2col on the input and the (transposed) 2D weights, if the function is called after a Convolution Layer</li>
<li>The input tensor and the (transposed) 2D weights, if the function is called after another FullyConnected Layer. Data type supported: Same as <code>input</code>. </li>
</ul>
</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">fc_info</td><td>(Optional) Fully connected layer additional info </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="_n_e_fully_connected_hybrid_layer_8cpp_source.html#l00098">98</a> of file <a class="el" href="_n_e_fully_connected_hybrid_layer_8cpp_source.html">NEFullyConnectedHybridLayer.cpp</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  101</span>{</div>
<div class="line"><span class="lineno">  102</span>  ARM_COMPUTE_ERROR_ON_NULLPTR(input, weights, output);</div>
<div class="line"><span class="lineno">  103</span> </div>
<div class="line"><span class="lineno">  104</span>  <span class="comment">// Perform validate step</span></div>
<div class="line"><span class="lineno">  105</span>  ARM_COMPUTE_ERROR_THROW_ON(<a class="code hl_function" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html#a8ed5cbe7b0e7ba0b2141b7b96a0f2b22">NEFullyConnectedHybridLayer::validate</a>(</div>
<div class="line"><span class="lineno">  106</span>    <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;info(), weights-&gt;info(), biases != <span class="keyword">nullptr</span> ? biases-&gt;info() : <span class="keyword">nullptr</span>, <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">output</a>-&gt;info(),</div>
<div class="line"><span class="lineno">  107</span>    fc_info));</div>
<div class="line"><span class="lineno">  108</span> </div>
<div class="line"><span class="lineno">  109</span>  _are_weights_reshaped = fc_info.transpose_weights ? fc_info.are_weights_reshaped : <span class="keyword">true</span>;</div>
<div class="line"><span class="lineno">  110</span>  _accumulate_biases = <span class="keyword">false</span>;</div>
<div class="line"><span class="lineno">  111</span>  _original_weights = weights;</div>
<div class="line"><span class="lineno">  112</span> </div>
<div class="line"><span class="lineno">  113</span>  <span class="comment">// Configure accumulate biases kernel for non quantized asymmetric types</span></div>
<div class="line"><span class="lineno">  114</span>  <span class="keywordflow">if</span> (biases != <span class="keyword">nullptr</span>)</div>
<div class="line"><span class="lineno">  115</span>  {</div>
<div class="line"><span class="lineno">  116</span>    _accumulate_biases = <span class="keyword">true</span>;</div>
<div class="line"><span class="lineno">  117</span> </div>
<div class="line"><span class="lineno">  118</span>    <span class="comment">// Configure accumulate biases kernel</span></div>
<div class="line"><span class="lineno">  119</span>    _accumulate_biases_kernel.<a class="code hl_function" href="classarm__compute_1_1_n_e_g_e_m_m_matrix_accumulate_biases_kernel.html#aadd2d8a6457eafa93cdd0d7cae8ad0f4">configure</a>(output, biases);</div>
<div class="line"><span class="lineno">  120</span>  }</div>
<div class="line"><span class="lineno">  121</span> </div>
<div class="line"><span class="lineno">  122</span>  <span class="comment">// With the Fully Connected layer we can have 4 different cases:</span></div>
<div class="line"><span class="lineno">  123</span>  <span class="comment">//  1) Convolution layer -&gt; Fully Connected layer without batches</span></div>
<div class="line"><span class="lineno">  124</span>  <span class="comment">//  2) Fully Connected layer -&gt; Fully Connected layer without batches</span></div>
<div class="line"><span class="lineno">  125</span>  <span class="comment">//  3) Convolution layer -&gt; Fully Connected layer with batches</span></div>
<div class="line"><span class="lineno">  126</span>  <span class="comment">//  4) Fully Connected layer -&gt; Fully Connected layer with batches</span></div>
<div class="line"><span class="lineno">  127</span> </div>
<div class="line"><span class="lineno">  128</span>  <span class="keyword">const</span> ITensor *weights_to_use = weights;</div>
<div class="line"><span class="lineno">  129</span> </div>
<div class="line"><span class="lineno">  130</span>  <span class="comment">// Check if we have a fully connected layer with batches</span></div>
<div class="line"><span class="lineno">  131</span>  <span class="keyword">const</span> <span class="keywordtype">bool</span> is_batched_fc_layer = <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">output</a>-&gt;info()-&gt;dimension(1) &gt; 1;</div>
<div class="line"><span class="lineno">  132</span>  <span class="keywordtype">bool</span> _is_fc_after_conv;</div>
<div class="line"><span class="lineno">  133</span>  <span class="keywordflow">if</span> (is_batched_fc_layer)</div>
<div class="line"><span class="lineno">  134</span>  {</div>
<div class="line"><span class="lineno">  135</span>    _is_fc_after_conv =</div>
<div class="line"><span class="lineno">  136</span>      (TensorShape::num_max_dimensions &gt;= 4) &amp;&amp;</div>
<div class="line"><span class="lineno">  137</span>      (std::equal(<a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;info()-&gt;tensor_shape().cbegin() + 3, <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;info()-&gt;tensor_shape().cend(),</div>
<div class="line"><span class="lineno">  138</span>                  <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">output</a>-&gt;info()-&gt;tensor_shape().cbegin() + 1));</div>
<div class="line"><span class="lineno">  139</span>  }</div>
<div class="line"><span class="lineno">  140</span>  <span class="keywordflow">else</span></div>
<div class="line"><span class="lineno">  141</span>  {</div>
<div class="line"><span class="lineno">  142</span>    _is_fc_after_conv = <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;info()-&gt;num_dimensions() &gt; 1 &amp;&amp; <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;info()-&gt;dimension(1) &gt; 1;</div>
<div class="line"><span class="lineno">  143</span>  }</div>
<div class="line"><span class="lineno">  144</span>  ARM_COMPUTE_ERROR_ON_MSG(_is_fc_after_conv,</div>
<div class="line"><span class="lineno">  145</span>                           <span class="stringliteral">&quot;NEFullyConnectedHybridLayer does not support after conv&quot;</span>);</div>
<div class="line"><span class="lineno">  146</span>  (void)_is_fc_after_conv;</div>
<div class="line"><span class="lineno">  147</span> </div>
<div class="line"><span class="lineno">  148</span>  <span class="comment">// Reshape weights if needed</span></div>
<div class="line"><span class="lineno">  149</span>  <span class="keywordflow">if</span> (!_are_weights_reshaped)</div>
<div class="line"><span class="lineno">  150</span>  {</div>
<div class="line"><span class="lineno">  151</span>    <span class="comment">// Reshape the weights</span></div>
<div class="line"><span class="lineno">  152</span>    _reshape_weights_output.allocator()-&gt;init(</div>
<div class="line"><span class="lineno">  153</span>      weights-&gt;info()-&gt;clone()-&gt;set_is_resizable(<span class="keyword">true</span>).reset_padding().set_tensor_shape(</div>
<div class="line"><span class="lineno">  154</span>        compute_transposed_shape(*weights-&gt;info())));</div>
<div class="line"><span class="lineno">  155</span>    _reshape_weights_function.<a class="code hl_function" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer_reshape_weights.html#ae8e1ed0c1c3dbc41bddb8bb916798206">configure</a>(weights_to_use, &amp;_reshape_weights_output);</div>
<div class="line"><span class="lineno">  156</span>    weights_to_use = &amp;_reshape_weights_output;</div>
<div class="line"><span class="lineno">  157</span>  }</div>
<div class="line"><span class="lineno">  158</span> </div>
<div class="line"><span class="lineno">  159</span>  <span class="comment">// Quantize input</span></div>
<div class="line"><span class="lineno">  160</span>  _quantized_input.allocator()-&gt;init(</div>
<div class="line"><span class="lineno">  161</span>    <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;info()-&gt;clone()-&gt;set_is_resizable(<span class="keyword">true</span>).reset_padding().set_data_type(</div>
<div class="line"><span class="lineno">  162</span>      DataType::QASYMM8_SIGNED));</div>
<div class="line"><span class="lineno">  163</span>  _scale_factor.allocator()-&gt;init(</div>
<div class="line"><span class="lineno">  164</span>    TensorInfo(TensorShape{<a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">output</a>-&gt;info()-&gt;dimension(1)}, 1, DataType::F32));</div>
<div class="line"><span class="lineno">  165</span>  _quant_input_kernel.<a class="code hl_function" href="classarm__compute_1_1_n_e_quantization_symmetric_kernel.html#a94acda7dc8e3a69ec5213b11fb223ef7">configure</a>(input, &amp;_quantized_input, &amp;_scale_factor);</div>
<div class="line"><span class="lineno">  166</span> </div>
<div class="line"><span class="lineno">  167</span>  <span class="comment">// GEMM</span></div>
<div class="line"><span class="lineno">  168</span>  _gemmlowp_output.allocator()-&gt;init(</div>
<div class="line"><span class="lineno">  169</span>    <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">output</a>-&gt;info()-&gt;clone()-&gt;set_is_resizable(<span class="keyword">true</span>).reset_padding().set_data_type(DataType::S32));</div>
<div class="line"><span class="lineno">  170</span>  configure_mm(&amp;_quantized_input, weights_to_use, &amp;_gemmlowp_output);</div>
<div class="line"><span class="lineno">  171</span> </div>
<div class="line"><span class="lineno">  172</span>  <span class="comment">// Multiply scale</span></div>
<div class="line"><span class="lineno">  173</span>  _multiply_scale_kernel.<a class="code hl_function" href="classarm__compute_1_1_n_e_multiply_scale_factor_kernel.html#adc3531fa5e42ca6b975f60ec9a668cb5">configure</a>(&amp;_gemmlowp_output, &amp;_scale_factor, output,</div>
<div class="line"><span class="lineno">  174</span>                                   weights-&gt;info()-&gt;quantization_info().uniform().scale);</div>
<div class="line"><span class="lineno">  175</span> </div>
<div class="line"><span class="lineno">  176</span>  _are_weights_reshaped = _are_weights_reshaped || fc_info.retain_internal_weights;</div>
<div class="line"><span class="lineno">  177</span> </div>
<div class="line"><span class="lineno">  178</span>  _quantized_input.allocator()-&gt;allocate();</div>
<div class="line"><span class="lineno">  179</span>  _scale_factor.allocator()-&gt;allocate();</div>
<div class="line"><span class="lineno">  180</span>  _gemmlowp_output.allocator()-&gt;allocate();</div>
<div class="line"><span class="lineno">  181</span>}</div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_fully_connected_hybrid_layer_html_a8ed5cbe7b0e7ba0b2141b7b96a0f2b22"><div class="ttname"><a href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html#a8ed5cbe7b0e7ba0b2141b7b96a0f2b22">arm_compute::NEFullyConnectedHybridLayer::validate</a></div><div class="ttdeci">static Status validate(const ITensorInfo *input, const ITensorInfo *weights, const ITensorInfo *biases, const ITensorInfo *output, FullyConnectedLayerInfo fc_info=FullyConnectedLayerInfo())</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_fully_connected_hybrid_layer_8cpp_source.html#l00183">NEFullyConnectedHybridLayer.cpp:183</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_fully_connected_hybrid_layer_reshape_weights_html_ae8e1ed0c1c3dbc41bddb8bb916798206"><div class="ttname"><a href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer_reshape_weights.html#ae8e1ed0c1c3dbc41bddb8bb916798206">arm_compute::NEFullyConnectedHybridLayerReshapeWeights::configure</a></div><div class="ttdeci">void configure(const ITensor *input, ITensor *output)</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_fully_connected_hybrid_layer_8cpp_source.html#l00067">NEFullyConnectedHybridLayer.cpp:67</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_g_e_m_m_matrix_accumulate_biases_kernel_html_aadd2d8a6457eafa93cdd0d7cae8ad0f4"><div class="ttname"><a href="classarm__compute_1_1_n_e_g_e_m_m_matrix_accumulate_biases_kernel.html#aadd2d8a6457eafa93cdd0d7cae8ad0f4">arm_compute::NEGEMMMatrixAccumulateBiasesKernel::configure</a></div><div class="ttdeci">void configure(ITensor *accum, const ITensor *biases)</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_g_e_m_m_matrix_accumulate_biases_kernel_8cpp_source.html#l00109">NEGEMMMatrixAccumulateBiasesKernel.cpp:109</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_multiply_scale_factor_kernel_html_adc3531fa5e42ca6b975f60ec9a668cb5"><div class="ttname"><a href="classarm__compute_1_1_n_e_multiply_scale_factor_kernel.html#adc3531fa5e42ca6b975f60ec9a668cb5">arm_compute::NEMultiplyScaleFactorKernel::configure</a></div><div class="ttdeci">void configure(const ITensor *input, const ITensor *scale_factor, ITensor *output, float multiplier=1.f)</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_multiply_scale_factor_kernel_8cpp_source.html#l00142">NEMultiplyScaleFactorKernel.cpp:142</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_quantization_symmetric_kernel_html_a94acda7dc8e3a69ec5213b11fb223ef7"><div class="ttname"><a href="classarm__compute_1_1_n_e_quantization_symmetric_kernel.html#a94acda7dc8e3a69ec5213b11fb223ef7">arm_compute::NEQuantizationSymmetricKernel::configure</a></div><div class="ttdeci">void configure(const ITensor *input, ITensor *output, ITensor *scale_factor)</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_quantization_symmetric_kernel_8cpp_source.html#l00135">NEQuantizationSymmetricKernel.cpp:135</a></div></div>
<div class="ttc" id="anamespacegen__h5__explicit__inputs_html_a48dd077479f23bb4552c2d7d6a7a4d37"><div class="ttname"><a href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">gen_h5_explicit_inputs.input</a></div><div class="ttdeci">input</div><div class="ttdef"><b>Definition:</b> <a href="gen__h5__explicit__inputs_8py_source.html#l00034">gen_h5_explicit_inputs.py:34</a></div></div>
<div class="ttc" id="anamespacegen__h5__explicit__inputs_html_acd1aa9ba45d45c6b619b723e6e34c576"><div class="ttname"><a href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">gen_h5_explicit_inputs.output</a></div><div class="ttdeci">output</div><div class="ttdef"><b>Definition:</b> <a href="gen__h5__explicit__inputs_8py_source.html#l00035">gen_h5_explicit_inputs.py:35</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="_n_e_multiply_scale_factor_kernel_8cpp_source.html#l00142">arm_compute::NEMultiplyScaleFactorKernel::configure()</a>, <a class="el" href="_n_e_fully_connected_hybrid_layer_8cpp_source.html#l00067">arm_compute::NEFullyConnectedHybridLayerReshapeWeights::configure()</a>, <a class="el" href="_n_e_quantization_symmetric_kernel_8cpp_source.html#l00135">arm_compute::NEQuantizationSymmetricKernel::configure()</a>, <a class="el" href="_n_e_g_e_m_m_matrix_accumulate_biases_kernel_8cpp_source.html#l00109">arm_compute::NEGEMMMatrixAccumulateBiasesKernel::configure()</a>, and <a class="el" href="_n_e_fully_connected_hybrid_layer_8cpp_source.html#l00183">validate()</a>.</p>

</div>
</div>
<a id="aa82da569230003331079b3bf03d2cf11" name="aa82da569230003331079b3bf03d2cf11"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa82da569230003331079b3bf03d2cf11">&#9670;&#160;</a></span>operator=() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html">NEFullyConnectedHybridLayer</a> &amp; arm_compute::NEFullyConnectedHybridLayer::operator= </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html">NEFullyConnectedHybridLayer</a> &amp;&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">delete</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p >Prevent instances of this class from being copied (As this class contains pointers) </p>

</div>
</div>
<a id="a1cd0141c099e5055e6c2fc05407a05a7" name="a1cd0141c099e5055e6c2fc05407a05a7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1cd0141c099e5055e6c2fc05407a05a7">&#9670;&#160;</a></span>operator=() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html">NEFullyConnectedHybridLayer</a> &amp; arm_compute::NEFullyConnectedHybridLayer::operator= </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html">NEFullyConnectedHybridLayer</a> &amp;&amp;&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">default</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p >Default move assignment operator </p>

<p class="reference">References <a class="el" href="_n_e_fully_connected_hybrid_layer_8cpp_source.html#l00183">validate()</a>.</p>

</div>
</div>
<a id="aa95866c05a8c5b14b0ff5d4bc413405a" name="aa95866c05a8c5b14b0ff5d4bc413405a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa95866c05a8c5b14b0ff5d4bc413405a">&#9670;&#160;</a></span>prepare()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void NEFullyConnectedHybridLayer::prepare </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="_n_e_fully_connected_hybrid_layer_8cpp_source.html#l00267">267</a> of file <a class="el" href="_n_e_fully_connected_hybrid_layer_8cpp_source.html">NEFullyConnectedHybridLayer.cpp</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  268</span>{</div>
<div class="line"><span class="lineno">  269</span>  <span class="keywordflow">if</span> (!_is_prepared)</div>
<div class="line"><span class="lineno">  270</span>  {</div>
<div class="line"><span class="lineno">  271</span>    ARM_COMPUTE_ERROR_ON(!_original_weights-&gt;is_used());</div>
<div class="line"><span class="lineno">  272</span> </div>
<div class="line"><span class="lineno">  273</span>    <span class="keyword">auto</span> release_unused = [](<a class="code hl_class" href="class_tensor.html">Tensor</a> *<a class="code hl_variable" href="namespacejpeg2hdf5.html#ac7eea56215106b0908497982f6eed453">w</a>) {</div>
<div class="line"><span class="lineno">  274</span>      <span class="keywordflow">if</span> (!<a class="code hl_variable" href="namespacejpeg2hdf5.html#ac7eea56215106b0908497982f6eed453">w</a>-&gt;is_used())</div>
<div class="line"><span class="lineno">  275</span>      {</div>
<div class="line"><span class="lineno">  276</span>        <a class="code hl_variable" href="namespacejpeg2hdf5.html#ac7eea56215106b0908497982f6eed453">w</a>-&gt;allocator()-&gt;free();</div>
<div class="line"><span class="lineno">  277</span>      }</div>
<div class="line"><span class="lineno">  278</span>    };</div>
<div class="line"><span class="lineno">  279</span> </div>
<div class="line"><span class="lineno">  280</span>    <span class="comment">// Reshape of the weights (happens only once)</span></div>
<div class="line"><span class="lineno">  281</span>    <span class="keywordflow">if</span> (!_are_weights_reshaped)</div>
<div class="line"><span class="lineno">  282</span>    {</div>
<div class="line"><span class="lineno">  283</span>      <span class="comment">// Run reshape weights kernel and mark weights as unused</span></div>
<div class="line"><span class="lineno">  284</span>      _reshape_weights_output.allocator()-&gt;allocate();</div>
<div class="line"><span class="lineno">  285</span>      _reshape_weights_function.run();</div>
<div class="line"><span class="lineno">  286</span> </div>
<div class="line"><span class="lineno">  287</span>      _are_weights_reshaped = <span class="keyword">true</span>;</div>
<div class="line"><span class="lineno">  288</span>      <span class="comment">// We can not release _original_weights because it can be used in other nodes</span></div>
<div class="line"><span class="lineno">  289</span>    }</div>
<div class="line"><span class="lineno">  290</span> </div>
<div class="line"><span class="lineno">  291</span>    <span class="comment">// Prepare GEMM prepare and release unused weights</span></div>
<div class="line"><span class="lineno">  292</span>    _mm_gemmlowp.prepare();</div>
<div class="line"><span class="lineno">  293</span> </div>
<div class="line"><span class="lineno">  294</span>    <span class="comment">// Release reshaped weights if unused</span></div>
<div class="line"><span class="lineno">  295</span>    release_unused(&amp;_reshape_weights_output);</div>
<div class="line"><span class="lineno">  296</span> </div>
<div class="line"><span class="lineno">  297</span>    _is_prepared = <span class="keyword">true</span>;</div>
<div class="line"><span class="lineno">  298</span>  }</div>
<div class="line"><span class="lineno">  299</span>}</div>
<div class="ttc" id="aclass_tensor_html"><div class="ttname"><a href="class_tensor.html">Tensor</a></div><div class="ttdef"><b>Definition:</b> <a href="tensor__gen_8cpp_source.html#l00031">tensor_gen.cpp:32</a></div></div>
<div class="ttc" id="anamespacejpeg2hdf5_html_ac7eea56215106b0908497982f6eed453"><div class="ttname"><a href="namespacejpeg2hdf5.html#ac7eea56215106b0908497982f6eed453">jpeg2hdf5.w</a></div><div class="ttdeci">w</div><div class="ttdef"><b>Definition:</b> <a href="jpeg2hdf5_8py_source.html#l00102">jpeg2hdf5.py:102</a></div></div>
</div><!-- fragment -->
<p class="reference">Referenced by <a class="el" href="_n_e_fully_connected_hybrid_layer_8cpp_source.html#l00245">run()</a>.</p>

</div>
</div>
<a id="acbba87b26dd98e4d28c7c6812457b6b7" name="acbba87b26dd98e4d28c7c6812457b6b7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acbba87b26dd98e4d28c7c6812457b6b7">&#9670;&#160;</a></span>run()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void NEFullyConnectedHybridLayer::run </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="_n_e_fully_connected_hybrid_layer_8cpp_source.html#l00245">245</a> of file <a class="el" href="_n_e_fully_connected_hybrid_layer_8cpp_source.html">NEFullyConnectedHybridLayer.cpp</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  246</span>{</div>
<div class="line"><span class="lineno">  247</span>  <a class="code hl_function" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html#aa95866c05a8c5b14b0ff5d4bc413405a">prepare</a>();</div>
<div class="line"><span class="lineno">  248</span> </div>
<div class="line"><span class="lineno">  249</span>  MemoryGroupResourceScope scope_mg(_memory_group);</div>
<div class="line"><span class="lineno">  250</span> </div>
<div class="line"><span class="lineno">  251</span>  <span class="comment">// Quantize input</span></div>
<div class="line"><span class="lineno">  252</span>  NEScheduler::get().schedule(&amp;_quant_input_kernel, Window::DimY);</div>
<div class="line"><span class="lineno">  253</span> </div>
<div class="line"><span class="lineno">  254</span>  <span class="comment">// Run matrix multiply</span></div>
<div class="line"><span class="lineno">  255</span>  _mm_gemmlowp.run();</div>
<div class="line"><span class="lineno">  256</span> </div>
<div class="line"><span class="lineno">  257</span>  <span class="comment">// Multiply scale factor</span></div>
<div class="line"><span class="lineno">  258</span>  NEScheduler::get().schedule(&amp;_multiply_scale_kernel, Window::DimY);</div>
<div class="line"><span class="lineno">  259</span> </div>
<div class="line"><span class="lineno">  260</span>  <span class="comment">// Accumulate biases if provided</span></div>
<div class="line"><span class="lineno">  261</span>  <span class="keywordflow">if</span> (_accumulate_biases)</div>
<div class="line"><span class="lineno">  262</span>  {</div>
<div class="line"><span class="lineno">  263</span>    NEScheduler::get().schedule(&amp;_accumulate_biases_kernel, Window::DimY);</div>
<div class="line"><span class="lineno">  264</span>  }</div>
<div class="line"><span class="lineno">  265</span>}</div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_fully_connected_hybrid_layer_html_aa95866c05a8c5b14b0ff5d4bc413405a"><div class="ttname"><a href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html#aa95866c05a8c5b14b0ff5d4bc413405a">arm_compute::NEFullyConnectedHybridLayer::prepare</a></div><div class="ttdeci">void prepare() override</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_fully_connected_hybrid_layer_8cpp_source.html#l00267">NEFullyConnectedHybridLayer.cpp:267</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="_n_e_fully_connected_hybrid_layer_8cpp_source.html#l00267">prepare()</a>.</p>

</div>
</div>
<a id="a8ed5cbe7b0e7ba0b2141b7b96a0f2b22" name="a8ed5cbe7b0e7ba0b2141b7b96a0f2b22"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8ed5cbe7b0e7ba0b2141b7b96a0f2b22">&#9670;&#160;</a></span>validate()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Status NEFullyConnectedHybridLayer::validate </td>
          <td>(</td>
          <td class="paramtype">const ITensorInfo *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const ITensorInfo *&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const ITensorInfo *&#160;</td>
          <td class="paramname"><em>biases</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const ITensorInfo *&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">FullyConnectedLayerInfo&#160;</td>
          <td class="paramname"><em>fc_info</em> = <code>FullyConnectedLayerInfo()</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p >Static function to check if given info will lead to a valid configuration of <a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html">NEFullyConnectedHybridLayer</a></p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">input</td><td>Source tensor info. Data type supported: F16/F32. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">weights</td><td>Weights tensor info. The weights must be 2 dimensional. If this function is called after a Convolution Layer, the (transposed) weights will have as many rows as the product of the first 3 input's dimensions. If it is called after another FullyConnected Layer, the (transposed) weights will have as many rows as the input's first dimension. Data type supported: S8. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">biases</td><td>Bias tensor info. Can be nullptr. Data type supported:Same as <code>input</code>. </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">output</td><td>Destination tensor info. Its shape should be equal to the output of a matrix multiplication between:<ul>
<li>The output of im2col on the input and the (transposed) 2D weights, if the function is called after a Convolution Layer</li>
<li>The input tensor and the (transposed) 2D weights, if the function is called after another FullyConnected Layer. Data type supported: Same as <code>input</code>. </li>
</ul>
</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">fc_info</td><td>(Optional) Fully connected layer additional info</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a status </dd></dl>

<p class="definition">Definition at line <a class="el" href="_n_e_fully_connected_hybrid_layer_8cpp_source.html#l00183">183</a> of file <a class="el" href="_n_e_fully_connected_hybrid_layer_8cpp_source.html">NEFullyConnectedHybridLayer.cpp</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  186</span>{</div>
<div class="line"><span class="lineno">  187</span>  ARM_COMPUTE_UNUSED(fc_info.retain_internal_weights);</div>
<div class="line"><span class="lineno">  188</span>  ARM_COMPUTE_RETURN_ERROR_ON_NULLPTR(input, weights, output);</div>
<div class="line"><span class="lineno">  189</span>  ARM_COMPUTE_RETURN_ERROR_ON_DATA_TYPE_CHANNEL_NOT_IN(input, 1, DataType::F16, DataType::F32);</div>
<div class="line"><span class="lineno">  190</span>  ARM_COMPUTE_RETURN_ERROR_ON_DATA_TYPE_CHANNEL_NOT_IN(weights, 1, DataType::QASYMM8_SIGNED);</div>
<div class="line"><span class="lineno">  191</span>  ARM_COMPUTE_RETURN_ERROR_ON_MISMATCHING_DATA_TYPES(input, output);</div>
<div class="line"><span class="lineno">  192</span>  ARM_COMPUTE_RETURN_ERROR_ON(weights-&gt;num_dimensions() &gt; 2);</div>
<div class="line"><span class="lineno">  193</span>  ARM_COMPUTE_RETURN_ERROR_ON(<a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">output</a>-&gt;num_dimensions() &gt; 2);</div>
<div class="line"><span class="lineno">  194</span> </div>
<div class="line"><span class="lineno">  195</span>  <span class="keywordtype">bool</span> weights_reshaped = fc_info.transpose_weights ? fc_info.are_weights_reshaped : <span class="keyword">true</span>;</div>
<div class="line"><span class="lineno">  196</span> </div>
<div class="line"><span class="lineno">  197</span>  <span class="keyword">const</span> ITensorInfo &amp;reshaped_weights =</div>
<div class="line"><span class="lineno">  198</span>    TensorInfo(weights-&gt;clone()-&gt;set_is_resizable(<span class="keyword">true</span>).reset_padding().set_tensor_shape(</div>
<div class="line"><span class="lineno">  199</span>      compute_transposed_shape(*weights)));</div>
<div class="line"><span class="lineno">  200</span> </div>
<div class="line"><span class="lineno">  201</span>  <span class="comment">// Configure accumulate biases kernel for non quantized asymmetric types</span></div>
<div class="line"><span class="lineno">  202</span>  <span class="keywordflow">if</span> (biases != <span class="keyword">nullptr</span>)</div>
<div class="line"><span class="lineno">  203</span>  {</div>
<div class="line"><span class="lineno">  204</span>    ARM_COMPUTE_RETURN_ERROR_ON_MISMATCHING_DATA_TYPES(input, biases);</div>
<div class="line"><span class="lineno">  205</span>    ARM_COMPUTE_RETURN_ON_ERROR(<a class="code hl_function" href="classarm__compute_1_1_n_e_g_e_m_m_matrix_accumulate_biases_kernel.html#ac1e699389d0d66079432ea110b2682a9">NEGEMMMatrixAccumulateBiasesKernel::validate</a>(output, biases));</div>
<div class="line"><span class="lineno">  206</span>  }</div>
<div class="line"><span class="lineno">  207</span> </div>
<div class="line"><span class="lineno">  208</span>  <span class="comment">// With the Fully Connected layer we can have 4 different cases:</span></div>
<div class="line"><span class="lineno">  209</span>  <span class="comment">//  1) Convolution layer -&gt; Fully Connected layer without batches</span></div>
<div class="line"><span class="lineno">  210</span>  <span class="comment">//  2) Fully Connected layer -&gt; Fully Connected layer without batches</span></div>
<div class="line"><span class="lineno">  211</span>  <span class="comment">//  3) Convolution layer -&gt; Fully Connected layer with batches</span></div>
<div class="line"><span class="lineno">  212</span>  <span class="comment">//  4) Fully Connected layer -&gt; Fully Connected layer with batches</span></div>
<div class="line"><span class="lineno">  213</span> </div>
<div class="line"><span class="lineno">  214</span>  <span class="keyword">const</span> ITensorInfo *weights_to_use = weights;</div>
<div class="line"><span class="lineno">  215</span> </div>
<div class="line"><span class="lineno">  216</span>  <span class="keywordflow">if</span> (!weights_reshaped)</div>
<div class="line"><span class="lineno">  217</span>  {</div>
<div class="line"><span class="lineno">  218</span>    <span class="comment">// Validate reshape weights kernel</span></div>
<div class="line"><span class="lineno">  219</span>    ARM_COMPUTE_RETURN_ON_ERROR(</div>
<div class="line"><span class="lineno">  220</span>      <a class="code hl_function" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer_reshape_weights.html#aa891cf8952d558b46f53e05621b57321">NEFullyConnectedHybridLayerReshapeWeights::validate</a>(weights_to_use, &amp;reshaped_weights));</div>
<div class="line"><span class="lineno">  221</span>    weights_to_use = &amp;reshaped_weights;</div>
<div class="line"><span class="lineno">  222</span>  }</div>
<div class="line"><span class="lineno">  223</span> </div>
<div class="line"><span class="lineno">  224</span>  <span class="comment">// Fully Connected layer after a Fully Connected Layer without batches</span></div>
<div class="line"><span class="lineno">  225</span>  ARM_COMPUTE_RETURN_ERROR_ON(<a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;dimension(0) != weights_to_use-&gt;dimension(1));</div>
<div class="line"><span class="lineno">  226</span> </div>
<div class="line"><span class="lineno">  227</span>  <span class="comment">// Validate quantization kernel</span></div>
<div class="line"><span class="lineno">  228</span>  <span class="keyword">const</span> ITensorInfo &amp;quantized_input = TensorInfo(</div>
<div class="line"><span class="lineno">  229</span>    <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#a48dd077479f23bb4552c2d7d6a7a4d37">input</a>-&gt;clone()-&gt;set_is_resizable(<span class="keyword">true</span>).reset_padding().set_data_type(DataType::QASYMM8_SIGNED));</div>
<div class="line"><span class="lineno">  230</span>  <span class="keyword">const</span> ITensorInfo &amp;scale_factor = TensorInfo(TensorShape{<a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">output</a>-&gt;dimension(1)}, 1, DataType::F32);</div>
<div class="line"><span class="lineno">  231</span>  ARM_COMPUTE_RETURN_ON_ERROR(</div>
<div class="line"><span class="lineno">  232</span>    <a class="code hl_function" href="classarm__compute_1_1_n_e_quantization_symmetric_kernel.html#af15ebf555b2b573931b5499396e9de66">NEQuantizationSymmetricKernel::validate</a>(input, &amp;quantized_input, &amp;scale_factor));</div>
<div class="line"><span class="lineno">  233</span> </div>
<div class="line"><span class="lineno">  234</span>  <span class="keyword">const</span> ITensorInfo &amp;gemmlowp_output = TensorInfo(</div>
<div class="line"><span class="lineno">  235</span>    <a class="code hl_variable" href="namespacegen__h5__explicit__inputs.html#acd1aa9ba45d45c6b619b723e6e34c576">output</a>-&gt;clone()-&gt;set_is_resizable(<span class="keyword">true</span>).reset_padding().set_data_type(DataType::S32));</div>
<div class="line"><span class="lineno">  236</span>  <span class="comment">// Validate matrix multiply kernel</span></div>
<div class="line"><span class="lineno">  237</span>  ARM_COMPUTE_RETURN_ON_ERROR(validate_mm(quantized_input, *weights_to_use, gemmlowp_output));</div>
<div class="line"><span class="lineno">  238</span> </div>
<div class="line"><span class="lineno">  239</span>  ARM_COMPUTE_RETURN_ON_ERROR(<a class="code hl_function" href="classarm__compute_1_1_n_e_multiply_scale_factor_kernel.html#aae2d361d497c05d9bece07692ed0dbab">NEMultiplyScaleFactorKernel::validate</a>(</div>
<div class="line"><span class="lineno">  240</span>    &amp;gemmlowp_output, &amp;scale_factor, output, weights-&gt;quantization_info().uniform().scale));</div>
<div class="line"><span class="lineno">  241</span> </div>
<div class="line"><span class="lineno">  242</span>  <span class="keywordflow">return</span> Status{};</div>
<div class="line"><span class="lineno">  243</span>}</div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_fully_connected_hybrid_layer_reshape_weights_html_aa891cf8952d558b46f53e05621b57321"><div class="ttname"><a href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer_reshape_weights.html#aa891cf8952d558b46f53e05621b57321">arm_compute::NEFullyConnectedHybridLayerReshapeWeights::validate</a></div><div class="ttdeci">static Status validate(const ITensorInfo *input, const ITensorInfo *output)</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_fully_connected_hybrid_layer_8cpp_source.html#l00074">NEFullyConnectedHybridLayer.cpp:74</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_g_e_m_m_matrix_accumulate_biases_kernel_html_ac1e699389d0d66079432ea110b2682a9"><div class="ttname"><a href="classarm__compute_1_1_n_e_g_e_m_m_matrix_accumulate_biases_kernel.html#ac1e699389d0d66079432ea110b2682a9">arm_compute::NEGEMMMatrixAccumulateBiasesKernel::validate</a></div><div class="ttdeci">static Status validate(const ITensorInfo *accum, const ITensorInfo *biases)</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_g_e_m_m_matrix_accumulate_biases_kernel_8cpp_source.html#l00125">NEGEMMMatrixAccumulateBiasesKernel.cpp:125</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_multiply_scale_factor_kernel_html_aae2d361d497c05d9bece07692ed0dbab"><div class="ttname"><a href="classarm__compute_1_1_n_e_multiply_scale_factor_kernel.html#aae2d361d497c05d9bece07692ed0dbab">arm_compute::NEMultiplyScaleFactorKernel::validate</a></div><div class="ttdeci">static Status validate(const ITensorInfo *input, const ITensorInfo *scale_factor, const ITensorInfo *output, float multiplier=1.f)</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_multiply_scale_factor_kernel_8cpp_source.html#l00164">NEMultiplyScaleFactorKernel.cpp:164</a></div></div>
<div class="ttc" id="aclassarm__compute_1_1_n_e_quantization_symmetric_kernel_html_af15ebf555b2b573931b5499396e9de66"><div class="ttname"><a href="classarm__compute_1_1_n_e_quantization_symmetric_kernel.html#af15ebf555b2b573931b5499396e9de66">arm_compute::NEQuantizationSymmetricKernel::validate</a></div><div class="ttdeci">static Status validate(const ITensorInfo *input, const ITensorInfo *output, const ITensorInfo *scale_factor)</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_quantization_symmetric_kernel_8cpp_source.html#l00156">NEQuantizationSymmetricKernel.cpp:156</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="_n_e_g_e_m_m_matrix_accumulate_biases_kernel_8cpp_source.html#l00125">arm_compute::NEGEMMMatrixAccumulateBiasesKernel::validate()</a>, <a class="el" href="_n_e_fully_connected_hybrid_layer_8cpp_source.html#l00074">arm_compute::NEFullyConnectedHybridLayerReshapeWeights::validate()</a>, <a class="el" href="_n_e_quantization_symmetric_kernel_8cpp_source.html#l00156">arm_compute::NEQuantizationSymmetricKernel::validate()</a>, and <a class="el" href="_n_e_multiply_scale_factor_kernel_8cpp_source.html#l00164">arm_compute::NEMultiplyScaleFactorKernel::validate()</a>.</p>

<p class="reference">Referenced by <a class="el" href="_n_e_fully_connected_hybrid_layer_8cpp_source.html#l00098">configure()</a>, and <a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html#a1cd0141c099e5055e6c2fc05407a05a7">operator=()</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>compute/ARMComputeEx/arm_compute/runtime/NEON/functions/<a class="el" href="_n_e_fully_connected_hybrid_layer_8h_source.html">NEFullyConnectedHybridLayer.h</a></li>
<li>compute/ARMComputeEx/src/runtime/NEON/functions/<a class="el" href="_n_e_fully_connected_hybrid_layer_8cpp_source.html">NEFullyConnectedHybridLayer.cpp</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespacearm__compute.html">arm_compute</a></li><li class="navelem"><a class="el" href="classarm__compute_1_1_n_e_fully_connected_hybrid_layer.html">NEFullyConnectedHybridLayer</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.5 </li>
  </ul>
</div>
</body>
</html>
