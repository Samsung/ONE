<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ONE - On-device Neural Engine: Transfer Learning</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">ONE - On-device Neural Engine
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('md_docs_2runtime_2transfer__learning.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Transfer Learning</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Let's classify dogs and cats using the pre-trained model. It will be <code>mobilenet v2</code> in our case.</p>
<h1>Preparing dataset</h1>
<p>The first step is conversion dataset (input data and expected outputs) to the binary format accepted by <code>ONE</code>. Note, that for many cases it can be achieved via <a href="https://github.com/Samsung/ONE/tree/master/tools/generate_datafile/tf_dataset_converter">tf_dataset_converter</a>.</p>
<div class="fragment"><div class="line"><span class="keyword">import</span> os</div>
<div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div>
<div class="line"><span class="keyword">import</span> pathlib</div>
<div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div>
<div class="line"> </div>
<div class="line">_URL = <span class="stringliteral">&#39;https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip&#39;</span></div>
<div class="line">path_to_zip = tf.keras.utils.get_file(<span class="stringliteral">&#39;cats_and_dogs.zip&#39;</span>, origin=_URL, extract=<span class="keyword">True</span>)</div>
<div class="line">PATH = os.path.join(os.path.dirname(path_to_zip), <span class="stringliteral">&#39;cats_and_dogs_filtered&#39;</span>)</div>
<div class="line"> </div>
<div class="line">train_dir = os.path.join(PATH, <span class="stringliteral">&#39;train&#39;</span>)</div>
<div class="line">validation_dir = os.path.join(PATH, <span class="stringliteral">&#39;validation&#39;</span>)</div>
<div class="line"> </div>
<div class="line">BATCH_SIZE = 32</div>
<div class="line">IMG_SIZE = (160, 160)</div>
<div class="line"> </div>
<div class="line"><span class="keyword">def </span>label_to_array(label):</div>
<div class="line">    arr = np.zeros(2, dtype=float)</div>
<div class="line">    arr[label] = 1.</div>
<div class="line">    tensor = tf.convert_to_tensor(arr, tf.float32)</div>
<div class="line">    <span class="keywordflow">return</span> tensor</div>
<div class="line"> </div>
<div class="line">train_dataset = tf.keras.preprocessing.image_dataset_from_directory(train_dir,</div>
<div class="line">                                                            shuffle=<span class="keyword">True</span>,</div>
<div class="line">                                                            batch_size=BATCH_SIZE,</div>
<div class="line">                                                            image_size=IMG_SIZE)</div>
<div class="line"> </div>
<div class="line">current_dir = pathlib.Path(__file__).parent</div>
<div class="line"><span class="keyword">with</span> open(current_dir/<span class="stringliteral">&#39;cats_and_dogs.input.bin&#39;</span>, <span class="stringliteral">&#39;wb&#39;</span>) <span class="keyword">as</span> in_stream:</div>
<div class="line">    <span class="keyword">with</span> open(current_dir/<span class="stringliteral">&#39;cats_and_dogs.output.bin&#39;</span>, <span class="stringliteral">&#39;wb&#39;</span>) <span class="keyword">as</span> out_stream:</div>
<div class="line">        <span class="keywordflow">for</span> image,label <span class="keywordflow">in</span> train_dataset:</div>
<div class="line">            in_stream.write(image.numpy().astype(np.float32).tobytes())</div>
<div class="line">            out_stream.write(label.numpy().astype(np.float32).tobytes())</div>
</div><!-- fragment --><h1>Prepare model for fine-tuning</h1>
<p>The first step to align the model to our problem is inserting custom operations on the top of the model. The base (with unchanged weights) remains the same.</p>
<div class="fragment"><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div>
<div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div>
<div class="line"> </div>
<div class="line">BATCH_SIZE = 32</div>
<div class="line">IMG_SIZE = (160, 160)</div>
<div class="line">IMG_SHAPE = IMG_SIZE + (3,)</div>
<div class="line"> </div>
<div class="line">base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,</div>
<div class="line">                                               include_top=<span class="keyword">False</span>,</div>
<div class="line">                                               weights=<span class="stringliteral">&#39;imagenet&#39;</span>)</div>
<div class="line"> </div>
<div class="line">base_model.trainable = <span class="keyword">False</span></div>
<div class="line">image_batch = tf.zeros([32, 160, 160, 3])</div>
<div class="line">feature_batch = base_model(image_batch)</div>
<div class="line"> </div>
<div class="line"><span class="comment"># define custom classification layers</span></div>
<div class="line">global_average_layer = tf.keras.layers.GlobalAveragePooling2D()</div>
<div class="line">prediction_layer = tf.keras.layers.Dense(1, activation=<span class="stringliteral">&#39;relu&#39;</span>)</div>
<div class="line"> </div>
<div class="line"><span class="comment"># applying preprocessing</span></div>
<div class="line">preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input</div>
<div class="line"> </div>
<div class="line">inputs = tf.keras.Input(shape=(160, 160, 3))</div>
<div class="line">x = preprocess_input(inputs)</div>
<div class="line">x = base_model(x, training=<span class="keyword">False</span>)</div>
<div class="line"> </div>
<div class="line"><span class="comment"># add additional layers on the top</span></div>
<div class="line">x = global_average_layer(x)</div>
<div class="line">outputs = prediction_layer(x)</div>
<div class="line">model = tf.keras.Model(inputs, outputs)</div>
<div class="line"> </div>
<div class="line"><span class="comment"># Convert to tflite</span></div>
<div class="line">converter = tf.lite.TFLiteConverter.from_keras_model(model)</div>
<div class="line">tflite_model = converter.convert()</div>
<div class="line"> </div>
<div class="line"><span class="comment"># Save tflite model model.</span></div>
<div class="line"><span class="keyword">with</span> open(<span class="stringliteral">&#39;customized_mobilenetv2.tflite&#39;</span>, <span class="stringliteral">&#39;wb&#39;</span>) <span class="keyword">as</span> f:</div>
<div class="line">  f.write(tflite_model)</div>
</div><!-- fragment --><p> For more information about feature extraction and fine tuning, please refer to <a href="https://www.tensorflow.org/tutorials/images/transfer_learning">transfer learning tutorial</a>.</p>
<h1>Convert tflite model to circle model</h1>
<p>In the moment of writing, the <code>circle+</code> format is developed but it will the other possibility to handle model training. Note that <code>one-import</code> can be found in the installation directory (determined by <code>-DCMAKE_INSTALL_PREFIX</code> cmake flag which can be added to <code>./nnfw configure</code> command). </p><div class="fragment"><div class="line">one-import tflite -i customized_mobilenetv2.tflite -o customized_mobilenetv2.circle</div>
</div><!-- fragment --><h1>Run training</h1>
<p>Let's train the model using <code>onert_train</code>. In this case we want to test only 2 last layers: <code>Mean</code> and <code>FullyConnected</code> (created from <code>GlobalAveragePooling2D</code> and <code>Dense</code> in TensorFlow). Note that the other possibility is using <code>circle+</code> capabilities. The crucial here is proper choosing value of <code>num_of_trainable_ops</code> to achieve tradeoff between training time and accuracy. It determines how many operations from the back of the graph will be trained. In our case, these are additionally added <code>Dense</code> with <code>Relu</code> activation, <code>GlobalAveragePooling</code> and some previous operations.</p>
<div class="fragment"><div class="line">onert_train \</div>
<div class="line">--modelfile customized_mobilenetv2.circle \</div>
<div class="line">--epoch 5 \</div>
<div class="line">--loss 1 \                # mean squared error</div>
<div class="line">--loss_reduction_type 1 \ # sum over batch size</div>
<div class="line">--optimizer 2 \           # adam</div>
<div class="line">--learning_rate 0.0001 \</div>
<div class="line">--batch_size 32 \</div>
<div class="line">--num_of_trainable_ops 5 \</div>
<div class="line">--load_expected:raw cats_and_dogs.output.bin \</div>
<div class="line">--load_input:raw cats_and_dogs.input.bin \</div>
<div class="line">--export_path customized_mobilenetv2_trained.circle</div>
</div><!-- fragment --><p> The result of training: </p><div class="fragment"><div class="line">Model Expected Filename cats_and_dogs.output.bin</div>
<div class="line">Model Input Filename cats_and_dogs.input.bin</div>
<div class="line">Model Filename customized_mobilenetv2.circle</div>
<div class="line">== training parameter ==</div>
<div class="line">- learning_rate        = 0.0001</div>
<div class="line">- batch_size           = 32</div>
<div class="line">- loss_info            = {loss = mean squared error, reduction = sum over batch size}</div>
<div class="line">- optimizer            = adam</div>
<div class="line">- num_of_trainable_ops = 10</div>
<div class="line">========================</div>
<div class="line">Epoch 1/5 - time: 532.378ms/step - loss: [0] 0.1567</div>
<div class="line">Epoch 2/5 - time: 531.966ms/step - loss: [0] 0.0417</div>
<div class="line">Epoch 3/5 - time: 532.795ms/step - loss: [0] 0.0104</div>
<div class="line">Epoch 4/5 - time: 532.607ms/step - loss: [0] 0.0053</div>
<div class="line">Epoch 5/5 - time: 532.567ms/step - loss: [0] 0.0049</div>
<div class="line">===================================</div>
<div class="line">MODEL_LOAD   takes 4.3720 ms</div>
<div class="line">PREPARE      takes 192.9690 ms</div>
<div class="line">EXECUTE      takes 165537.7600 ms</div>
<div class="line">- Epoch 1      takes 33007.4380 ms</div>
<div class="line">- Epoch 2      takes 32981.8970 ms</div>
<div class="line">- Epoch 3      takes 33033.2690 ms</div>
<div class="line">- Epoch 4      takes 33021.6380 ms</div>
<div class="line">- Epoch 5      takes 33019.1300 ms</div>
<div class="line">===================================</div>
</div><!-- fragment --> <h1>Test inference</h1>
<p>In this tutorial the inference will be launched via <code>Python API</code>. </p><h2>Convert the trained model to nnpackage format</h2>
<p>The current version of <code>Python API</code> expect models in Python <code>nnpackge</code> format. The conversion can be done with <code>tools/nnpackage_tool/model2nnpkg/model2nnpkg.py</code> script. </p><div class="fragment"><div class="line">python model2nnpkg.py -m customized_mobilenetv2_trained.circle -o mobilenet_package_dir</div>
</div><!-- fragment --> <h2>Run inference via Python API</h2>
<p>PRE: Install <code>nnfwapi</code> package </p><div class="fragment"><div class="line">pip install -i https://test.pypi.org/simple/ nnfwapi==0.1.1</div>
</div><!-- fragment --> <div class="fragment"><div class="line"><span class="keyword">from</span> <a class="code hl_namespace" href="namespacennfwapi_1_1libnnfw__api__pybind.html">nnfwapi.libnnfw_api_pybind</a> <span class="keyword">import</span> *</div>
<div class="line"> </div>
<div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div>
<div class="line"><span class="keyword">import</span> os</div>
<div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div>
<div class="line"> </div>
<div class="line">nnpackage_path = <span class="stringliteral">&#39;{mobilenet_package_dir}/customized_mobilenetv2_trained&#39;</span></div>
<div class="line">session = <a class="code hl_struct" href="structnnfw__session.html">nnfw_session</a>(nnpackage_path, <span class="stringliteral">&#39;cpu&#39;</span>)</div>
<div class="line"> </div>
<div class="line">_URL = <span class="stringliteral">&#39;https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip&#39;</span></div>
<div class="line">path_to_zip = tf.keras.utils.get_file(<span class="stringliteral">&#39;cats_and_dogs.zip&#39;</span>, origin=_URL, extract=<span class="keyword">True</span>)</div>
<div class="line">PATH = os.path.join(os.path.dirname(path_to_zip), <span class="stringliteral">&#39;cats_and_dogs_filtered&#39;</span>)</div>
<div class="line"> </div>
<div class="line">validation_dir = os.path.join(PATH, <span class="stringliteral">&#39;validation&#39;</span>)</div>
<div class="line"> </div>
<div class="line">BATCH_SIZE = 1 <span class="comment"># we take only a single image per inference</span></div>
<div class="line">IMG_SIZE = (160, 160)</div>
<div class="line"> </div>
<div class="line">validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,</div>
<div class="line">                                                                 shuffle=<span class="keyword">True</span>,</div>
<div class="line">                                                                 batch_size=BATCH_SIZE,</div>
<div class="line">                                                                 image_size=IMG_SIZE)</div>
<div class="line"> </div>
<div class="line">test_image,labels = next(x <span class="keywordflow">for</span> x <span class="keywordflow">in</span> validation_dataset)</div>
<div class="line">test_image = test_image.numpy()</div>
<div class="line">inputs = []</div>
<div class="line">inputs.append(test_image)</div>
<div class="line">input_size = session.input_size()</div>
<div class="line"> </div>
<div class="line">session.set_inputs(input_size, inputs)</div>
<div class="line">outputs = session.inference()</div>
<div class="line"> </div>
<div class="line"><span class="comment"># Note that the last layer of our model is Relu (which means &quot;0&quot; value for cats detection)</span></div>
<div class="line">plt.title(<span class="stringliteral">&quot;dogs&quot;</span> <span class="keywordflow">if</span> outputs[0] &gt; 0.01 <span class="keywordflow">else</span> <span class="stringliteral">&quot;cats&quot;</span>)</div>
<div class="line">plt.axis(<span class="stringliteral">&quot;off&quot;</span>)</div>
<div class="line">plt.imshow(test_image.squeeze().astype(<span class="stringliteral">&quot;uint8&quot;</span>))</div>
<div class="line">plt.savefig(<span class="stringliteral">&#39;transfer_learning_result.png&#39;</span>)</div>
<div class="ttc" id="anamespacennfwapi_1_1libnnfw__api__pybind_html"><div class="ttname"><a href="namespacennfwapi_1_1libnnfw__api__pybind.html">libnnfw_api_pybind</a></div></div>
<div class="ttc" id="astructnnfw__session_html"><div class="ttname"><a href="structnnfw__session.html">nnfw_session</a></div><div class="ttdef"><b>Definition</b> <a href="onert-micro_8cpp_source.html#l00066">onert-micro.cpp:67</a></div></div>
</div><!-- fragment --><p>Example output<br  />
 <img src="transfer_learning_result.png" alt="An example result of inference" class="inline"/></p>
<h1>References</h1>
<ul>
<li><a href="https://www.tensorflow.org/tutorials/images/transfer_learning">Transfer learning Tensorflow tutorial</a> </li>
</ul>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
