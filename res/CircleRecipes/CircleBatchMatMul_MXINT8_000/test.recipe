operand {
  name: "ifm1"
  type: FLOAT32
  shape { dim: 1 dim: 1 dim: 32 dim: 32 }
}
operand {
  name: "ifm2"
  type: FLOAT32
  shape { dim: 1 dim: 1 dim: 32 dim: 32 }
}
operand {
  name: "ifm1_mxint8"
  type: MXINT8
  shape { dim: 1 dim: 1 dim: 32 dim: 32 }
}
operand {
  name: "ifm2_mxint8"
  type: MXINT8
  shape { dim: 1 dim: 1 dim: 32 dim: 32 }
}
operand {
  name: "ofm_mxint8"
  type: MXINT8
  shape { dim: 1 dim: 1 dim: 32 dim: 32 }
}
operand {
  name: "ofm"
  type: FLOAT32
  shape { dim: 1 dim: 1 dim: 32 dim: 32 }
}
operation {
  type: "Quantize"
  input: "ifm1"
  output: "ifm1_mxint8"
}
operation {
  type: "Quantize"
  input: "ifm2"
  output: "ifm2_mxint8"
}
operation {
  type: "BatchMatMul"
  input: "ifm1_mxint8"
  input: "ifm2_mxint8"
  output: "ofm_mxint8"
  batch_matmul_options {
    adjoint_lhs: false
    adjoint_rhs: false
  }
}
operation {
  type: "Dequantize"
  input: "ofm_mxint8"
  output: "ofm"
}
input: "ifm1"
input: "ifm2"
output: "ofm"

