# To check model can be quantized without QuantizeDequantizeWeights.

RULE    "VERIFY_FILE_FORMAT"      $(verify_file_format) '=' 1

RULE    "INPUT_UINT8"             $(tensor_dtype ifm) '=' UINT8
RULE    "CONV_UINT8"              $(tensor_dtype ofm) '=' UINT8
RULE    "WEIGHTS_UINT8"           $(tensor_dtype filter) '=' UINT8
RULE    "BIAS_INT32"              $(tensor_dtype bias) '=' INT32
