<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.5"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ONE - On-device Neural Engine: nnfw::cker::reference Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">ONE - On-device Neural Engine
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.5 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('namespacennfw_1_1cker_1_1reference.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">nnfw::cker::reference Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:aca7021574af27880fcaa5f0bb62981e7"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacennfw_1_1cker_1_1reference.html#aca7021574af27880fcaa5f0bb62981e7">BatchMatMul</a> (const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;lhs_shape, const float *lhs_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;rhs_shape, const float *rhs_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;, float *output_data)</td></tr>
<tr class="separator:aca7021574af27880fcaa5f0bb62981e7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae7dd56ac62e8a99481b4874aae08836b"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:ae7dd56ac62e8a99481b4874aae08836b"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacennfw_1_1cker_1_1reference.html#ae7dd56ac62e8a99481b4874aae08836b">BinaryArithmeticOp</a> (const <a class="el" href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html">BinaryArithmeticOpParam</a> &amp;params, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;input1_shape, const T *input1_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;input2_shape, const T *input2_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;output_shape, T *output_data, const std::function&lt; T(const T &amp;, const T &amp;)&gt; &amp;fn)</td></tr>
<tr class="separator:ae7dd56ac62e8a99481b4874aae08836b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0ab57f1de7a3d7c735f732c550280f5b"><td class="memItemLeft" align="right" valign="top">template&lt;&gt; </td></tr>
<tr class="memitem:a0ab57f1de7a3d7c735f732c550280f5b"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacennfw_1_1cker_1_1reference.html#a0ab57f1de7a3d7c735f732c550280f5b">BinaryArithmeticOp</a> (const <a class="el" href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html">BinaryArithmeticOpParam</a> &amp;params, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;input1_shape, const float *input1_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;input2_shape, const float *input2_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;output_shape, float *output_data, const std::function&lt; float(const float &amp;, const float &amp;)&gt; &amp;fn)</td></tr>
<tr class="separator:a0ab57f1de7a3d7c735f732c550280f5b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa1d85bb7454deb60df52ee2c920746a4"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:aa1d85bb7454deb60df52ee2c920746a4"><td class="memTemplItemLeft" align="right" valign="top">std::enable_if_t&lt; <a class="el" href="structnnfw_1_1cker_1_1is__quant8.html">is_quant8</a>&lt; T &gt;::value &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacennfw_1_1cker_1_1reference.html#aa1d85bb7454deb60df52ee2c920746a4">BroadcastBinaryArithmeticOpSlow</a> (const <a class="el" href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html">BinaryArithmeticOpParam</a> &amp;params, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;input1_shape, const T *input1_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;input2_shape, const T *input2_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;output_shape, T *output_data, const std::function&lt; T(const <a class="el" href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html">BinaryArithmeticOpParam</a> &amp;params, const T &amp;, const T &amp;)&gt; &amp;fn)</td></tr>
<tr class="separator:aa1d85bb7454deb60df52ee2c920746a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af03169b7be90f5dddc977e41b8acaec5"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:af03169b7be90f5dddc977e41b8acaec5"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacennfw_1_1cker_1_1reference.html#af03169b7be90f5dddc977e41b8acaec5">BroadcastBinaryArithmeticOpSlow</a> (const <a class="el" href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html">BinaryArithmeticOpParam</a> &amp;params, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;input1_shape, const T *input1_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;input2_shape, const T *input2_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;output_shape, T *output_data, const std::function&lt; T(const T &amp;, const T &amp;)&gt; &amp;fn)</td></tr>
<tr class="separator:af03169b7be90f5dddc977e41b8acaec5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a225c0ef74f6e779c39130ec580e324"><td class="memItemLeft" align="right" valign="top">template&lt;&gt; </td></tr>
<tr class="memitem:a9a225c0ef74f6e779c39130ec580e324"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacennfw_1_1cker_1_1reference.html#a9a225c0ef74f6e779c39130ec580e324">BroadcastBinaryArithmeticOpSlow</a> (const <a class="el" href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html">BinaryArithmeticOpParam</a> &amp;params, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;input1_shape, const float *input1_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;input2_shape, const float *input2_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;output_shape, float *output_data, const std::function&lt; float(const float &amp;, const float &amp;)&gt; &amp;fn)</td></tr>
<tr class="separator:a9a225c0ef74f6e779c39130ec580e324"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a954de12511ee583ef0e6b01a0679d4d8"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacennfw_1_1cker_1_1reference.html#a954de12511ee583ef0e6b01a0679d4d8">Conv</a> (const <a class="el" href="structnnfw_1_1cker_1_1_conv_params.html">ConvParams</a> &amp;params, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;input_shape, const float *input_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;filter_shape, const float *filter_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;bias_shape, const float *bias_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;output_shape, float *output_data)</td></tr>
<tr class="separator:a954de12511ee583ef0e6b01a0679d4d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0a0b3958e4e76a04596178b1fdeea09b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacennfw_1_1cker_1_1reference.html#a0a0b3958e4e76a04596178b1fdeea09b">Conv</a> (const <a class="el" href="structnnfw_1_1cker_1_1_conv_params.html">ConvParams</a> &amp;params, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;input_shape, const uint8_t *input_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;filter_shape, const uint8_t *filter_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;bias_shape, const int32_t *bias_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;output_shape, uint8_t *output_data)</td></tr>
<tr class="separator:a0a0b3958e4e76a04596178b1fdeea09b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a68e86023ece236637b0dc8b131a16f70"><td class="memTemplParams" colspan="2">template&lt;typename T , bool is_asymmetric&gt; </td></tr>
<tr class="memitem:a68e86023ece236637b0dc8b131a16f70"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacennfw_1_1cker_1_1reference.html#a68e86023ece236637b0dc8b131a16f70">Conv</a> (const <a class="el" href="structnnfw_1_1cker_1_1_conv_params.html">ConvParams</a> &amp;params, const int32_t *output_multiplier, const int32_t *output_shift, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;input_shape, const T *input_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;filter_shape, const T *filter_data, const int32_t *filter_zeropoint, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;bias_shape, const int32_t *bias_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;output_shape, T *output_data)</td></tr>
<tr class="separator:a68e86023ece236637b0dc8b131a16f70"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab55312a313b1a6280c4fc9bafc80b05c"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacennfw_1_1cker_1_1reference.html#ab55312a313b1a6280c4fc9bafc80b05c">Softmax</a> (const <a class="el" href="structnnfw_1_1cker_1_1_softmax_params.html">SoftmaxParams</a> &amp;params, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;input_shape, const float *input_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;output_shape, float *output_data)</td></tr>
<tr class="separator:ab55312a313b1a6280c4fc9bafc80b05c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a77ee976f07a81db2abb12effb60384d7"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a77ee976f07a81db2abb12effb60384d7"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacennfw_1_1cker_1_1reference.html#a77ee976f07a81db2abb12effb60384d7">TransposeImpl</a> (const <a class="el" href="structnnfw_1_1cker_1_1_transpose_params.html">TransposeParams</a> &amp;params, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;unextended_input_shape, const T *input_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;unextended_output_shape, T *output_data)</td></tr>
<tr class="separator:a77ee976f07a81db2abb12effb60384d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a295888086391d908f57fa904c9d4544d"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a295888086391d908f57fa904c9d4544d"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespacennfw_1_1cker_1_1reference.html#a295888086391d908f57fa904c9d4544d">Transpose</a> (const <a class="el" href="structnnfw_1_1cker_1_1_transpose_params.html">TransposeParams</a> &amp;params, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;unextended_input_shape, const T *input_data, const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;unextended_output_shape, T *output_data)</td></tr>
<tr class="separator:a295888086391d908f57fa904c9d4544d"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="aca7021574af27880fcaa5f0bb62981e7" name="aca7021574af27880fcaa5f0bb62981e7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aca7021574af27880fcaa5f0bb62981e7">&#9670;&#160;</a></span>BatchMatMul()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void nnfw::cker::reference::BatchMatMul </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>lhs_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>lhs_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>rhs_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>rhs_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>output_data</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="compute_2cker_2include_2cker_2operation_2reference_2_batch_mat_mul_8h_source.html#l00031">31</a> of file <a class="el" href="compute_2cker_2include_2cker_2operation_2reference_2_batch_mat_mul_8h_source.html">BatchMatMul.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   33</span>{</div>
<div class="line"><span class="lineno">   34</span>  <span class="keyword">const</span> <a class="code hl_class" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> extended_lhs_shape = Shape::ExtendedShape(5, lhs_shape);</div>
<div class="line"><span class="lineno">   35</span>  <span class="keyword">const</span> <a class="code hl_class" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> extended_rhs_shape = Shape::ExtendedShape(5, rhs_shape);</div>
<div class="line"><span class="lineno">   36</span> </div>
<div class="line"><span class="lineno">   37</span>  <span class="comment">// Determine which dimension is the broadcast dimension.</span></div>
<div class="line"><span class="lineno">   38</span>  <span class="keyword">auto</span> broadcast_dim = [](<span class="keywordtype">int</span> lhs_dim, <span class="keywordtype">int</span> rhs_dim) {</div>
<div class="line"><span class="lineno">   39</span>    <span class="keywordflow">if</span> (lhs_dim == rhs_dim)</div>
<div class="line"><span class="lineno">   40</span>      <span class="keywordflow">return</span> lhs_dim;</div>
<div class="line"><span class="lineno">   41</span>    <span class="keywordflow">if</span> (lhs_dim == 1)</div>
<div class="line"><span class="lineno">   42</span>      <span class="keywordflow">return</span> rhs_dim;</div>
<div class="line"><span class="lineno">   43</span>    assert(rhs_dim == 1);</div>
<div class="line"><span class="lineno">   44</span>    <span class="keywordflow">return</span> lhs_dim;</div>
<div class="line"><span class="lineno">   45</span>  };</div>
<div class="line"><span class="lineno">   46</span> </div>
<div class="line"><span class="lineno">   47</span>  <span class="comment">// Compute the &quot;extent&quot; for iterating on this dimension.</span></div>
<div class="line"><span class="lineno">   48</span>  <span class="comment">// If we are broadcasting, then don&#39;t advance (i.e return 0).</span></div>
<div class="line"><span class="lineno">   49</span>  <span class="keyword">auto</span> extent = [](<span class="keyword">const</span> <a class="code hl_class" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;shape, <span class="keywordtype">int</span> x) {</div>
<div class="line"><span class="lineno">   50</span>    <span class="keywordflow">if</span> (shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(x) == 1)</div>
<div class="line"><span class="lineno">   51</span>    {</div>
<div class="line"><span class="lineno">   52</span>      <span class="keywordflow">return</span> 0;</div>
<div class="line"><span class="lineno">   53</span>    }</div>
<div class="line"><span class="lineno">   54</span>    <span class="keywordtype">int</span> prod = 1;</div>
<div class="line"><span class="lineno">   55</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = x + 1; i &lt; shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a01c6b5dc4b24d5c2567c47cb15318839">DimensionsCount</a>(); ++i)</div>
<div class="line"><span class="lineno">   56</span>    {</div>
<div class="line"><span class="lineno">   57</span>      prod *= shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(i);</div>
<div class="line"><span class="lineno">   58</span>    }</div>
<div class="line"><span class="lineno">   59</span>    <span class="keywordflow">return</span> prod;</div>
<div class="line"><span class="lineno">   60</span>  };</div>
<div class="line"><span class="lineno">   61</span> </div>
<div class="line"><span class="lineno">   62</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> batch_dim0 = broadcast_dim(extended_lhs_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(0), extended_rhs_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(0));</div>
<div class="line"><span class="lineno">   63</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> batch_dim1 = broadcast_dim(extended_lhs_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(1), extended_rhs_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(1));</div>
<div class="line"><span class="lineno">   64</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> batch_dim2 = broadcast_dim(extended_lhs_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(2), extended_rhs_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(2));</div>
<div class="line"><span class="lineno">   65</span> </div>
<div class="line"><span class="lineno">   66</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> lhs_ext0 = extent(extended_lhs_shape, 0);</div>
<div class="line"><span class="lineno">   67</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> lhs_ext1 = extent(extended_lhs_shape, 1);</div>
<div class="line"><span class="lineno">   68</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> lhs_ext2 = extent(extended_lhs_shape, 2);</div>
<div class="line"><span class="lineno">   69</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> rhs_ext0 = extent(extended_rhs_shape, 0);</div>
<div class="line"><span class="lineno">   70</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> rhs_ext1 = extent(extended_rhs_shape, 1);</div>
<div class="line"><span class="lineno">   71</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> rhs_ext2 = extent(extended_rhs_shape, 2);</div>
<div class="line"><span class="lineno">   72</span> </div>
<div class="line"><span class="lineno">   73</span>  <span class="comment">// Set params for each matrix multiply.</span></div>
<div class="line"><span class="lineno">   74</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> lhs_rows = extended_lhs_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(3);</div>
<div class="line"><span class="lineno">   75</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> rhs_cols = extended_rhs_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(4);</div>
<div class="line"><span class="lineno">   76</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> accum_depth = extended_lhs_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(4);</div>
<div class="line"><span class="lineno">   77</span> </div>
<div class="line"><span class="lineno">   78</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> b0 = 0; b0 &lt; batch_dim0; ++b0)</div>
<div class="line"><span class="lineno">   79</span>  {</div>
<div class="line"><span class="lineno">   80</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> *lhs_ptr0 = lhs_data + (b0 * lhs_ext0);</div>
<div class="line"><span class="lineno">   81</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> *rhs_ptr0 = rhs_data + (b0 * rhs_ext0);</div>
<div class="line"><span class="lineno">   82</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> b1 = 0; b1 &lt; batch_dim1; ++b1)</div>
<div class="line"><span class="lineno">   83</span>    {</div>
<div class="line"><span class="lineno">   84</span>      <span class="keyword">const</span> <span class="keywordtype">float</span> *lhs_ptr1 = lhs_ptr0 + b1 * lhs_ext1;</div>
<div class="line"><span class="lineno">   85</span>      <span class="keyword">const</span> <span class="keywordtype">float</span> *rhs_ptr1 = rhs_ptr0 + b1 * rhs_ext1;</div>
<div class="line"><span class="lineno">   86</span>      <span class="keywordflow">for</span> (<span class="keywordtype">int</span> b2 = 0; b2 &lt; batch_dim2; ++b2)</div>
<div class="line"><span class="lineno">   87</span>      {</div>
<div class="line"><span class="lineno">   88</span>        <span class="keyword">const</span> <span class="keywordtype">float</span> *lhs_ptr2 = lhs_ptr1 + b2 * lhs_ext2;</div>
<div class="line"><span class="lineno">   89</span>        <span class="keyword">const</span> <span class="keywordtype">float</span> *rhs_ptr2 = rhs_ptr1 + b2 * rhs_ext2;</div>
<div class="line"><span class="lineno">   90</span>        <span class="keywordtype">float</span> *out_ptr = <a class="code hl_variable" href="namespacepart__eval__one.html#aa659ec13c0dc14d487081c1a59b9ae70">output_data</a> + ((b0 * batch_dim1 * batch_dim2) + b1 * batch_dim2 + b2) *</div>
<div class="line"><span class="lineno">   91</span>                                         lhs_rows * rhs_cols;</div>
<div class="line"><span class="lineno">   92</span>        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> j = 0; j &lt; rhs_cols; ++j)</div>
<div class="line"><span class="lineno">   93</span>        {</div>
<div class="line"><span class="lineno">   94</span>          <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; lhs_rows; ++i)</div>
<div class="line"><span class="lineno">   95</span>          {</div>
<div class="line"><span class="lineno">   96</span>            <span class="keywordtype">float</span> total = 0.f;</div>
<div class="line"><span class="lineno">   97</span>            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> k = 0; k &lt; accum_depth; ++k)</div>
<div class="line"><span class="lineno">   98</span>            {</div>
<div class="line"><span class="lineno">   99</span>              total += lhs_ptr2[accum_depth * i + k] * rhs_ptr2[j * accum_depth + k];</div>
<div class="line"><span class="lineno">  100</span>            }</div>
<div class="line"><span class="lineno">  101</span>            <span class="keywordtype">int</span> idx = lhs_rows * j + i;</div>
<div class="line"><span class="lineno">  102</span>            out_ptr[idx] = total;</div>
<div class="line"><span class="lineno">  103</span>          }</div>
<div class="line"><span class="lineno">  104</span>        }</div>
<div class="line"><span class="lineno">  105</span>      }</div>
<div class="line"><span class="lineno">  106</span>    }</div>
<div class="line"><span class="lineno">  107</span>  }</div>
<div class="line"><span class="lineno">  108</span>}</div>
<div class="ttc" id="aclassnnfw_1_1cker_1_1_shape_html"><div class="ttname"><a href="classnnfw_1_1cker_1_1_shape.html">nnfw::cker::Shape</a></div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00033">Shape.h:34</a></div></div>
<div class="ttc" id="aclassnnfw_1_1cker_1_1_shape_html_a01c6b5dc4b24d5c2567c47cb15318839"><div class="ttname"><a href="classnnfw_1_1cker_1_1_shape.html#a01c6b5dc4b24d5c2567c47cb15318839">nnfw::cker::Shape::DimensionsCount</a></div><div class="ttdeci">int32_t DimensionsCount() const</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00093">Shape.h:93</a></div></div>
<div class="ttc" id="aclassnnfw_1_1cker_1_1_shape_html_a497180ee7844bbef51b36bd58e61fa31"><div class="ttname"><a href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">nnfw::cker::Shape::Dims</a></div><div class="ttdeci">int32_t Dims(int i) const</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00094">Shape.h:94</a></div></div>
<div class="ttc" id="anamespacepart__eval__one_html_aa659ec13c0dc14d487081c1a59b9ae70"><div class="ttname"><a href="namespacepart__eval__one.html#aa659ec13c0dc14d487081c1a59b9ae70">part_eval_one.output_data</a></div><div class="ttdeci">output_data</div><div class="ttdef"><b>Definition:</b> <a href="part__eval__one_8py_source.html#l00113">part_eval_one.py:113</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00093">nnfw::cker::Shape::DimensionsCount()</a>, and <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00094">nnfw::cker::Shape::Dims()</a>.</p>

<p class="reference">Referenced by <a class="el" href="compute_2cker_2include_2cker_2operation_2_batch_mat_mul_8h_source.html#l00079">nnfw::cker::BatchMatMul::operator()()</a>.</p>

</div>
</div>
<a id="a0ab57f1de7a3d7c735f732c550280f5b" name="a0ab57f1de7a3d7c735f732c550280f5b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0ab57f1de7a3d7c735f732c550280f5b">&#9670;&#160;</a></span>BinaryArithmeticOp() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void nnfw::cker::reference::BinaryArithmeticOp </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html">BinaryArithmeticOpParam</a> &amp;&#160;</td>
          <td class="paramname"><em>params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>input1_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>input1_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>input2_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>input2_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>output_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>output_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::function&lt; float(const float &amp;, const float &amp;)&gt; &amp;&#160;</td>
          <td class="paramname"><em>fn</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="reference_2_binary_arithmetic_ops_8h_source.html#l00050">50</a> of file <a class="el" href="reference_2_binary_arithmetic_ops_8h_source.html">BinaryArithmeticOps.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   55</span>{</div>
<div class="line"><span class="lineno">   56</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> size = <a class="code hl_function" href="namespacennfw_1_1cker.html#ab86126de4e835f9499051e43b841abca">MatchingElementsSize</a>(input1_shape, input2_shape, output_shape);</div>
<div class="line"><span class="lineno">   57</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; size; i++)</div>
<div class="line"><span class="lineno">   58</span>  {</div>
<div class="line"><span class="lineno">   59</span>    output_data[i] = <a class="code hl_function" href="namespacennfw_1_1cker.html#a86b83772dd83256abffc3a8f1426819b">ActivationFunctionWithMinMax</a>(</div>
<div class="line"><span class="lineno">   60</span>      fn(input1_data[i], input2_data[i]), params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html#af87d13f6f63a9d5eeb175c2db94bae92">float_activation_min</a>, params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html#ac8fdfaa8e3b43c341a0128857d3bcf20">float_activation_max</a>);</div>
<div class="line"><span class="lineno">   61</span>  }</div>
<div class="line"><span class="lineno">   62</span>}</div>
<div class="ttc" id="anamespacennfw_1_1cker_html_a86b83772dd83256abffc3a8f1426819b"><div class="ttname"><a href="namespacennfw_1_1cker.html#a86b83772dd83256abffc3a8f1426819b">nnfw::cker::ActivationFunctionWithMinMax</a></div><div class="ttdeci">T ActivationFunctionWithMinMax(T x, T output_activation_min, T output_activation_max)</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_utils_8h_source.html#l00040">Utils.h:40</a></div></div>
<div class="ttc" id="anamespacennfw_1_1cker_html_ab86126de4e835f9499051e43b841abca"><div class="ttname"><a href="namespacennfw_1_1cker.html#ab86126de4e835f9499051e43b841abca">nnfw::cker::MatchingElementsSize</a></div><div class="ttdeci">int MatchingElementsSize(const Shape &amp;shape, const Shape &amp;check_shape_0, const Shape &amp;check_shape_1)</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00337">Shape.h:337</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_binary_arithmetic_op_param_html_ac8fdfaa8e3b43c341a0128857d3bcf20"><div class="ttname"><a href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html#ac8fdfaa8e3b43c341a0128857d3bcf20">nnfw::cker::BinaryArithmeticOpParam::float_activation_max</a></div><div class="ttdeci">float float_activation_max</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00193">Types.h:193</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_binary_arithmetic_op_param_html_af87d13f6f63a9d5eeb175c2db94bae92"><div class="ttname"><a href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html#af87d13f6f63a9d5eeb175c2db94bae92">nnfw::cker::BinaryArithmeticOpParam::float_activation_min</a></div><div class="ttdeci">float float_activation_min</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00192">Types.h:192</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="compute_2cker_2include_2cker_2_utils_8h_source.html#l00040">nnfw::cker::ActivationFunctionWithMinMax()</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00193">nnfw::cker::BinaryArithmeticOpParam::float_activation_max</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00192">nnfw::cker::BinaryArithmeticOpParam::float_activation_min</a>, and <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00337">nnfw::cker::MatchingElementsSize()</a>.</p>

</div>
</div>
<a id="ae7dd56ac62e8a99481b4874aae08836b" name="ae7dd56ac62e8a99481b4874aae08836b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae7dd56ac62e8a99481b4874aae08836b">&#9670;&#160;</a></span>BinaryArithmeticOp() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void nnfw::cker::reference::BinaryArithmeticOp </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html">BinaryArithmeticOpParam</a> &amp;&#160;</td>
          <td class="paramname"><em>params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>input1_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>input1_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>input2_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>input2_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>output_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>output_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::function&lt; T(const T &amp;, const T &amp;)&gt; &amp;&#160;</td>
          <td class="paramname"><em>fn</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="reference_2_binary_arithmetic_ops_8h_source.html#l00035">35</a> of file <a class="el" href="reference_2_binary_arithmetic_ops_8h_source.html">BinaryArithmeticOps.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   39</span>{</div>
<div class="line"><span class="lineno">   40</span>  <span class="keyword">const</span> int32_t flat_size = <a class="code hl_function" href="namespacennfw_1_1cker.html#ab86126de4e835f9499051e43b841abca">MatchingElementsSize</a>(input1_shape, input2_shape, output_shape);</div>
<div class="line"><span class="lineno">   41</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; flat_size; ++i)</div>
<div class="line"><span class="lineno">   42</span>  {</div>
<div class="line"><span class="lineno">   43</span>    output_data[i] = <a class="code hl_function" href="namespacennfw_1_1cker.html#a86b83772dd83256abffc3a8f1426819b">ActivationFunctionWithMinMax</a>(fn(input1_data[i], input2_data[i]),</div>
<div class="line"><span class="lineno">   44</span>                                                  params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html#abb8ef3401fcae98626f1da50cda22b2f">quantized_activation_min</a>,</div>
<div class="line"><span class="lineno">   45</span>                                                  params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html#a20d919b6418bf302a97df426260bdec0">quantized_activation_max</a>);</div>
<div class="line"><span class="lineno">   46</span>  }</div>
<div class="line"><span class="lineno">   47</span>}</div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_binary_arithmetic_op_param_html_a20d919b6418bf302a97df426260bdec0"><div class="ttname"><a href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html#a20d919b6418bf302a97df426260bdec0">nnfw::cker::BinaryArithmeticOpParam::quantized_activation_max</a></div><div class="ttdeci">int32_t quantized_activation_max</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00190">Types.h:190</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_binary_arithmetic_op_param_html_abb8ef3401fcae98626f1da50cda22b2f"><div class="ttname"><a href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html#abb8ef3401fcae98626f1da50cda22b2f">nnfw::cker::BinaryArithmeticOpParam::quantized_activation_min</a></div><div class="ttdeci">int32_t quantized_activation_min</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00189">Types.h:189</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="compute_2cker_2include_2cker_2_utils_8h_source.html#l00040">nnfw::cker::ActivationFunctionWithMinMax()</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00337">nnfw::cker::MatchingElementsSize()</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00190">nnfw::cker::BinaryArithmeticOpParam::quantized_activation_max</a>, and <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00189">nnfw::cker::BinaryArithmeticOpParam::quantized_activation_min</a>.</p>

<p class="reference">Referenced by <a class="el" href="_binary_arithmetic_ops_8h_source.html#l00194">nnfw::cker::BinaryArithmeticOp()</a>, and <a class="el" href="optimized_2_binary_arithmetic_ops_8h_source.html#l01218">nnfw::cker::optimized::Div()</a>.</p>

</div>
</div>
<a id="a9a225c0ef74f6e779c39130ec580e324" name="a9a225c0ef74f6e779c39130ec580e324"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9a225c0ef74f6e779c39130ec580e324">&#9670;&#160;</a></span>BroadcastBinaryArithmeticOpSlow() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void nnfw::cker::reference::BroadcastBinaryArithmeticOpSlow </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html">BinaryArithmeticOpParam</a> &amp;&#160;</td>
          <td class="paramname"><em>params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>input1_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>input1_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>input2_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>input2_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>output_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>output_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::function&lt; float(const float &amp;, const float &amp;)&gt; &amp;&#160;</td>
          <td class="paramname"><em>fn</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="reference_2_binary_arithmetic_ops_8h_source.html#l00149">149</a> of file <a class="el" href="reference_2_binary_arithmetic_ops_8h_source.html">BinaryArithmeticOps.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  153</span>{</div>
<div class="line"><span class="lineno">  154</span>  <a class="code hl_struct" href="structnnfw_1_1cker_1_1_nd_array_desc.html">NdArrayDesc&lt;4&gt;</a> desc1;</div>
<div class="line"><span class="lineno">  155</span>  <a class="code hl_struct" href="structnnfw_1_1cker_1_1_nd_array_desc.html">NdArrayDesc&lt;4&gt;</a> desc2;</div>
<div class="line"><span class="lineno">  156</span>  <a class="code hl_function" href="_n_d_array_8h.html#a256945a34650c9e1803de88c828ef724">NdArrayDescsForElementwiseBroadcast</a>(input1_shape, input2_shape, &amp;desc1, &amp;desc2);</div>
<div class="line"><span class="lineno">  157</span>  <span class="keyword">const</span> <a class="code hl_class" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> extended_output_shape = Shape::ExtendedShape(4, output_shape);</div>
<div class="line"><span class="lineno">  158</span> </div>
<div class="line"><span class="lineno">  159</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> b = 0; b &lt; extended_output_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(0); ++b)</div>
<div class="line"><span class="lineno">  160</span>  {</div>
<div class="line"><span class="lineno">  161</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> y = 0; y &lt; extended_output_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(1); ++y)</div>
<div class="line"><span class="lineno">  162</span>    {</div>
<div class="line"><span class="lineno">  163</span>      <span class="keywordflow">for</span> (<span class="keywordtype">int</span> x = 0; x &lt; extended_output_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(2); ++x)</div>
<div class="line"><span class="lineno">  164</span>      {</div>
<div class="line"><span class="lineno">  165</span>        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> c = 0; c &lt; extended_output_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(3); ++c)</div>
<div class="line"><span class="lineno">  166</span>        {</div>
<div class="line"><span class="lineno">  167</span>          output_data[<a class="code hl_function" href="ann-ref_2src_2ops_2internal_2dims_8h.html#a1c037ff89c0da8b5cd52088b914b9c1d">Offset</a>(extended_output_shape, b, y, x, c)] =</div>
<div class="line"><span class="lineno">  168</span>            <a class="code hl_function" href="namespacennfw_1_1cker.html#a86b83772dd83256abffc3a8f1426819b">ActivationFunctionWithMinMax</a>(fn(input1_data[<a class="code hl_function" href="_n_d_array_8h.html#a635d76912989ba020d1eeada22742b0d">SubscriptToIndex</a>(desc1, b, y, x, c)],</div>
<div class="line"><span class="lineno">  169</span>                                            input2_data[<a class="code hl_function" href="_n_d_array_8h.html#a635d76912989ba020d1eeada22742b0d">SubscriptToIndex</a>(desc2, b, y, x, c)]),</div>
<div class="line"><span class="lineno">  170</span>                                         params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html#af87d13f6f63a9d5eeb175c2db94bae92">float_activation_min</a>, params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html#ac8fdfaa8e3b43c341a0128857d3bcf20">float_activation_max</a>);</div>
<div class="line"><span class="lineno">  171</span>        }</div>
<div class="line"><span class="lineno">  172</span>      }</div>
<div class="line"><span class="lineno">  173</span>    }</div>
<div class="line"><span class="lineno">  174</span>  }</div>
<div class="line"><span class="lineno">  175</span>}</div>
<div class="ttc" id="a_n_d_array_8h_html_a256945a34650c9e1803de88c828ef724"><div class="ttname"><a href="_n_d_array_8h.html#a256945a34650c9e1803de88c828ef724">NdArrayDescsForElementwiseBroadcast</a></div><div class="ttdeci">void NdArrayDescsForElementwiseBroadcast(const Dims&lt; N &gt; &amp;input0_dims, const Dims&lt; N &gt; &amp;input1_dims, NdArrayDesc&lt; N &gt; *desc0_out, NdArrayDesc&lt; N &gt; *desc1_out)</div><div class="ttdef"><b>Definition:</b> <a href="_n_d_array_8h_source.html#l00089">NDArray.h:89</a></div></div>
<div class="ttc" id="a_n_d_array_8h_html_a635d76912989ba020d1eeada22742b0d"><div class="ttname"><a href="_n_d_array_8h.html#a635d76912989ba020d1eeada22742b0d">SubscriptToIndex</a></div><div class="ttdeci">int SubscriptToIndex(const NdArrayDesc&lt; 4 &gt; &amp;desc, int i0, int i1, int i2, int i3)</div><div class="ttdef"><b>Definition:</b> <a href="_n_d_array_8h_source.html#l00054">NDArray.h:54</a></div></div>
<div class="ttc" id="aann-ref_2src_2ops_2internal_2dims_8h_html_a1c037ff89c0da8b5cd52088b914b9c1d"><div class="ttname"><a href="ann-ref_2src_2ops_2internal_2dims_8h.html#a1c037ff89c0da8b5cd52088b914b9c1d">Offset</a></div><div class="ttdeci">int Offset(const Dims&lt; 4 &gt; &amp;dims, int i0, int i1, int i2, int i3)</div><div class="ttdef"><b>Definition:</b> <a href="ann-ref_2src_2ops_2internal_2dims_8h_source.html#l00064">Dims.h:64</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_nd_array_desc_html"><div class="ttname"><a href="structnnfw_1_1cker_1_1_nd_array_desc.html">nnfw::cker::NdArrayDesc</a></div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_utils_8h_source.html#l00235">Utils.h:236</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="compute_2cker_2include_2cker_2_utils_8h_source.html#l00040">nnfw::cker::ActivationFunctionWithMinMax()</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00094">nnfw::cker::Shape::Dims()</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00193">nnfw::cker::BinaryArithmeticOpParam::float_activation_max</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00192">nnfw::cker::BinaryArithmeticOpParam::float_activation_min</a>, <a class="el" href="compute_2cker_2include_2cker_2_utils_8h_source.html#l00287">nnfw::cker::NdArrayDescsForElementwiseBroadcast()</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00241">nnfw::cker::Offset()</a>, and <a class="el" href="compute_2cker_2include_2cker_2_utils_8h_source.html#l00252">nnfw::cker::SubscriptToIndex()</a>.</p>

</div>
</div>
<a id="aa1d85bb7454deb60df52ee2c920746a4" name="aa1d85bb7454deb60df52ee2c920746a4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa1d85bb7454deb60df52ee2c920746a4">&#9670;&#160;</a></span>BroadcastBinaryArithmeticOpSlow() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::enable_if_t&lt; <a class="el" href="structnnfw_1_1cker_1_1is__quant8.html">is_quant8</a>&lt; T &gt;::value &gt; nnfw::cker::reference::BroadcastBinaryArithmeticOpSlow </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html">BinaryArithmeticOpParam</a> &amp;&#160;</td>
          <td class="paramname"><em>params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>input1_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>input1_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>input2_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>input2_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>output_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>output_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::function&lt; T(const <a class="el" href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html">BinaryArithmeticOpParam</a> &amp;params, const T &amp;, const T &amp;)&gt; &amp;&#160;</td>
          <td class="paramname"><em>fn</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="reference_2_binary_arithmetic_ops_8h_source.html#l00065">65</a> of file <a class="el" href="reference_2_binary_arithmetic_ops_8h_source.html">BinaryArithmeticOps.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   69</span>{</div>
<div class="line"><span class="lineno">   70</span>  <a class="code hl_struct" href="structnnfw_1_1cker_1_1_nd_array_desc.html">NdArrayDesc&lt;4&gt;</a> desc1;</div>
<div class="line"><span class="lineno">   71</span>  <a class="code hl_struct" href="structnnfw_1_1cker_1_1_nd_array_desc.html">NdArrayDesc&lt;4&gt;</a> desc2;</div>
<div class="line"><span class="lineno">   72</span>  <a class="code hl_function" href="_n_d_array_8h.html#a256945a34650c9e1803de88c828ef724">NdArrayDescsForElementwiseBroadcast</a>(input1_shape, input2_shape, &amp;desc1, &amp;desc2);</div>
<div class="line"><span class="lineno">   73</span>  <span class="keyword">const</span> <a class="code hl_class" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> extended_output_shape = Shape::ExtendedShape(4, output_shape);</div>
<div class="line"><span class="lineno">   74</span> </div>
<div class="line"><span class="lineno">   75</span>  <span class="comment">// Comment from tensorflow lite:</span></div>
<div class="line"><span class="lineno">   76</span>  <span class="comment">//</span></div>
<div class="line"><span class="lineno">   77</span>  <span class="comment">// In Tensorflow, the dimensions are canonically named (batch_number, row,</span></div>
<div class="line"><span class="lineno">   78</span>  <span class="comment">// col, channel), with extents (batches, height, width, depth), with the</span></div>
<div class="line"><span class="lineno">   79</span>  <span class="comment">// trailing dimension changing most rapidly (channels has the smallest stride,</span></div>
<div class="line"><span class="lineno">   80</span>  <span class="comment">// typically 1 element).</span></div>
<div class="line"><span class="lineno">   81</span>  <span class="comment">//</span></div>
<div class="line"><span class="lineno">   82</span>  <span class="comment">// In generated C code, we store arrays with the dimensions reversed. The</span></div>
<div class="line"><span class="lineno">   83</span>  <span class="comment">// first dimension has smallest stride.</span></div>
<div class="line"><span class="lineno">   84</span>  <span class="comment">//</span></div>
<div class="line"><span class="lineno">   85</span>  <span class="comment">// We name our variables by their Tensorflow convention, but generate C code</span></div>
<div class="line"><span class="lineno">   86</span>  <span class="comment">// nesting loops such that the innermost loop has the smallest stride for the</span></div>
<div class="line"><span class="lineno">   87</span>  <span class="comment">// best cache behavior.</span></div>
<div class="line"><span class="lineno">   88</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> b = 0; b &lt; extended_output_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(0); ++b)</div>
<div class="line"><span class="lineno">   89</span>  {</div>
<div class="line"><span class="lineno">   90</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> y = 0; y &lt; extended_output_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(1); ++y)</div>
<div class="line"><span class="lineno">   91</span>    {</div>
<div class="line"><span class="lineno">   92</span>      <span class="keywordflow">for</span> (<span class="keywordtype">int</span> x = 0; x &lt; extended_output_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(2); ++x)</div>
<div class="line"><span class="lineno">   93</span>      {</div>
<div class="line"><span class="lineno">   94</span>        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> c = 0; c &lt; extended_output_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(3); ++c)</div>
<div class="line"><span class="lineno">   95</span>        {</div>
<div class="line"><span class="lineno">   96</span>          output_data[<a class="code hl_function" href="ann-ref_2src_2ops_2internal_2dims_8h.html#a1c037ff89c0da8b5cd52088b914b9c1d">Offset</a>(extended_output_shape, b, y, x, c)] = ActivationFunctionWithMinMax&lt;T&gt;(</div>
<div class="line"><span class="lineno">   97</span>            fn(params, input1_data[<a class="code hl_function" href="_n_d_array_8h.html#a635d76912989ba020d1eeada22742b0d">SubscriptToIndex</a>(desc1, b, y, x, c)],</div>
<div class="line"><span class="lineno">   98</span>               input2_data[<a class="code hl_function" href="_n_d_array_8h.html#a635d76912989ba020d1eeada22742b0d">SubscriptToIndex</a>(desc2, b, y, x, c)]),</div>
<div class="line"><span class="lineno">   99</span>            params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html#abb8ef3401fcae98626f1da50cda22b2f">quantized_activation_min</a>, params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html#a20d919b6418bf302a97df426260bdec0">quantized_activation_max</a>);</div>
<div class="line"><span class="lineno">  100</span>        }</div>
<div class="line"><span class="lineno">  101</span>      }</div>
<div class="line"><span class="lineno">  102</span>    }</div>
<div class="line"><span class="lineno">  103</span>  }</div>
<div class="line"><span class="lineno">  104</span>}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00094">nnfw::cker::Shape::Dims()</a>, <a class="el" href="compute_2cker_2include_2cker_2_utils_8h_source.html#l00287">nnfw::cker::NdArrayDescsForElementwiseBroadcast()</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00241">nnfw::cker::Offset()</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00190">nnfw::cker::BinaryArithmeticOpParam::quantized_activation_max</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00189">nnfw::cker::BinaryArithmeticOpParam::quantized_activation_min</a>, and <a class="el" href="compute_2cker_2include_2cker_2_utils_8h_source.html#l00252">nnfw::cker::SubscriptToIndex()</a>.</p>

<p class="reference">Referenced by <a class="el" href="optimized_2_binary_arithmetic_ops_8h_source.html#l00812">nnfw::cker::optimized::BroadcastAddDispatch()</a>, <a class="el" href="_binary_arithmetic_ops_8h_source.html#l00260">nnfw::cker::BroadcastBinaryArithmeticOp()</a>, <a class="el" href="optimized_2_binary_arithmetic_ops_8h_source.html#l01234">nnfw::cker::optimized::BroadcastDivDispatch()</a>, <a class="el" href="optimized_2_binary_arithmetic_ops_8h_source.html#l01177">nnfw::cker::optimized::BroadcastMulDispatch()</a>, and <a class="el" href="optimized_2_binary_arithmetic_ops_8h_source.html#l00867">nnfw::cker::optimized::BroadcastSubDispatch()</a>.</p>

</div>
</div>
<a id="af03169b7be90f5dddc977e41b8acaec5" name="af03169b7be90f5dddc977e41b8acaec5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af03169b7be90f5dddc977e41b8acaec5">&#9670;&#160;</a></span>BroadcastBinaryArithmeticOpSlow() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void nnfw::cker::reference::BroadcastBinaryArithmeticOpSlow </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html">BinaryArithmeticOpParam</a> &amp;&#160;</td>
          <td class="paramname"><em>params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>input1_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>input1_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>input2_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>input2_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>output_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>output_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::function&lt; T(const T &amp;, const T &amp;)&gt; &amp;&#160;</td>
          <td class="paramname"><em>fn</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="reference_2_binary_arithmetic_ops_8h_source.html#l00106">106</a> of file <a class="el" href="reference_2_binary_arithmetic_ops_8h_source.html">BinaryArithmeticOps.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  111</span>{</div>
<div class="line"><span class="lineno">  112</span>  <a class="code hl_struct" href="structnnfw_1_1cker_1_1_nd_array_desc.html">NdArrayDesc&lt;4&gt;</a> desc1;</div>
<div class="line"><span class="lineno">  113</span>  <a class="code hl_struct" href="structnnfw_1_1cker_1_1_nd_array_desc.html">NdArrayDesc&lt;4&gt;</a> desc2;</div>
<div class="line"><span class="lineno">  114</span>  <a class="code hl_function" href="_n_d_array_8h.html#a256945a34650c9e1803de88c828ef724">NdArrayDescsForElementwiseBroadcast</a>(input1_shape, input2_shape, &amp;desc1, &amp;desc2);</div>
<div class="line"><span class="lineno">  115</span>  <span class="keyword">const</span> <a class="code hl_class" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> extended_output_shape = Shape::ExtendedShape(4, output_shape);</div>
<div class="line"><span class="lineno">  116</span> </div>
<div class="line"><span class="lineno">  117</span>  <span class="comment">// Comment from tensorflow lite:</span></div>
<div class="line"><span class="lineno">  118</span>  <span class="comment">//</span></div>
<div class="line"><span class="lineno">  119</span>  <span class="comment">// In Tensorflow, the dimensions are canonically named (batch_number, row,</span></div>
<div class="line"><span class="lineno">  120</span>  <span class="comment">// col, channel), with extents (batches, height, width, depth), with the</span></div>
<div class="line"><span class="lineno">  121</span>  <span class="comment">// trailing dimension changing most rapidly (channels has the smallest stride,</span></div>
<div class="line"><span class="lineno">  122</span>  <span class="comment">// typically 1 element).</span></div>
<div class="line"><span class="lineno">  123</span>  <span class="comment">//</span></div>
<div class="line"><span class="lineno">  124</span>  <span class="comment">// In generated C code, we store arrays with the dimensions reversed. The</span></div>
<div class="line"><span class="lineno">  125</span>  <span class="comment">// first dimension has smallest stride.</span></div>
<div class="line"><span class="lineno">  126</span>  <span class="comment">//</span></div>
<div class="line"><span class="lineno">  127</span>  <span class="comment">// We name our variables by their Tensorflow convention, but generate C code</span></div>
<div class="line"><span class="lineno">  128</span>  <span class="comment">// nesting loops such that the innermost loop has the smallest stride for the</span></div>
<div class="line"><span class="lineno">  129</span>  <span class="comment">// best cache behavior.</span></div>
<div class="line"><span class="lineno">  130</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> b = 0; b &lt; extended_output_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(0); ++b)</div>
<div class="line"><span class="lineno">  131</span>  {</div>
<div class="line"><span class="lineno">  132</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> y = 0; y &lt; extended_output_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(1); ++y)</div>
<div class="line"><span class="lineno">  133</span>    {</div>
<div class="line"><span class="lineno">  134</span>      <span class="keywordflow">for</span> (<span class="keywordtype">int</span> x = 0; x &lt; extended_output_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(2); ++x)</div>
<div class="line"><span class="lineno">  135</span>      {</div>
<div class="line"><span class="lineno">  136</span>        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> c = 0; c &lt; extended_output_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(3); ++c)</div>
<div class="line"><span class="lineno">  137</span>        {</div>
<div class="line"><span class="lineno">  138</span>          output_data[<a class="code hl_function" href="ann-ref_2src_2ops_2internal_2dims_8h.html#a1c037ff89c0da8b5cd52088b914b9c1d">Offset</a>(extended_output_shape, b, y, x, c)] = ActivationFunctionWithMinMax&lt;T&gt;(</div>
<div class="line"><span class="lineno">  139</span>            fn(input1_data[<a class="code hl_function" href="_n_d_array_8h.html#a635d76912989ba020d1eeada22742b0d">SubscriptToIndex</a>(desc1, b, y, x, c)],</div>
<div class="line"><span class="lineno">  140</span>               input2_data[<a class="code hl_function" href="_n_d_array_8h.html#a635d76912989ba020d1eeada22742b0d">SubscriptToIndex</a>(desc2, b, y, x, c)]),</div>
<div class="line"><span class="lineno">  141</span>            params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html#abb8ef3401fcae98626f1da50cda22b2f">quantized_activation_min</a>, params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_binary_arithmetic_op_param.html#a20d919b6418bf302a97df426260bdec0">quantized_activation_max</a>);</div>
<div class="line"><span class="lineno">  142</span>        }</div>
<div class="line"><span class="lineno">  143</span>      }</div>
<div class="line"><span class="lineno">  144</span>    }</div>
<div class="line"><span class="lineno">  145</span>  }</div>
<div class="line"><span class="lineno">  146</span>}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00094">nnfw::cker::Shape::Dims()</a>, <a class="el" href="compute_2cker_2include_2cker_2_utils_8h_source.html#l00287">nnfw::cker::NdArrayDescsForElementwiseBroadcast()</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00241">nnfw::cker::Offset()</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00190">nnfw::cker::BinaryArithmeticOpParam::quantized_activation_max</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00189">nnfw::cker::BinaryArithmeticOpParam::quantized_activation_min</a>, and <a class="el" href="compute_2cker_2include_2cker_2_utils_8h_source.html#l00252">nnfw::cker::SubscriptToIndex()</a>.</p>

</div>
</div>
<a id="a68e86023ece236637b0dc8b131a16f70" name="a68e86023ece236637b0dc8b131a16f70"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a68e86023ece236637b0dc8b131a16f70">&#9670;&#160;</a></span>Conv() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T , bool is_asymmetric&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void nnfw::cker::reference::Conv </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structnnfw_1_1cker_1_1_conv_params.html">ConvParams</a> &amp;&#160;</td>
          <td class="paramname"><em>params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>output_multiplier</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>output_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>input_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>input_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>filter_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>filter_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>filter_zeropoint</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>bias_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>bias_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>output_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>output_data</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="compute_2cker_2include_2cker_2operation_2reference_2_conv_8h_source.html#l00194">194</a> of file <a class="el" href="compute_2cker_2include_2cker_2operation_2reference_2_conv_8h_source.html">Conv.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  200</span>{</div>
<div class="line"><span class="lineno">  201</span>  <a class="code hl_define" href="compute_2cker_2include_2cker_2_shape_8h.html#a044d7f999713173dd3360b0aa40370fd">UNUSED_RELEASE</a>(bias_shape);</div>
<div class="line"><span class="lineno">  202</span>  <span class="comment">// Get parameters.</span></div>
<div class="line"><span class="lineno">  203</span>  <span class="keyword">const</span> int32_t input_offset = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a435e0fcf2622a161fe913f6098b2dd1e">input_offset</a>; <span class="comment">// r = s(q - Z)</span></div>
<div class="line"><span class="lineno">  204</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> stride_width = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a273ecef205d663377502d9dcaa77f1b4">stride_width</a>;</div>
<div class="line"><span class="lineno">  205</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> stride_height = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a0878ee74c474c8a82a574727a2a3048e">stride_height</a>;</div>
<div class="line"><span class="lineno">  206</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> dilation_width_factor = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a8ff1e952b2e7627e11b47a22da0883cb">dilation_width_factor</a>;</div>
<div class="line"><span class="lineno">  207</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> dilation_height_factor = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#ad47b94004b5b1718979775edaa9eee70">dilation_height_factor</a>;</div>
<div class="line"><span class="lineno">  208</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> pad_width = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a0a3450e62d20d27c2638d197f1fd2bb2">padding_values</a>.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_padding_values.html#a2a3dd79d28c30c5da865290160601fd1">width</a>;</div>
<div class="line"><span class="lineno">  209</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> pad_height = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a0a3450e62d20d27c2638d197f1fd2bb2">padding_values</a>.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_padding_values.html#a1dc41a9ebbd61a7c34ed2b5dd2ec10eb">height</a>;</div>
<div class="line"><span class="lineno">  210</span>  <span class="keyword">const</span> int32_t output_offset = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a7fef4d3c76b386c35ec04adfd931f991">output_offset</a>;</div>
<div class="line"><span class="lineno">  211</span> </div>
<div class="line"><span class="lineno">  212</span>  <span class="comment">// Set min and max value of the output.</span></div>
<div class="line"><span class="lineno">  213</span>  <span class="keyword">const</span> int32_t output_activation_min = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#ad4f74d8bfaa34bd1f44a690e7b77fc5f">quantized_activation_min</a>;</div>
<div class="line"><span class="lineno">  214</span>  <span class="keyword">const</span> int32_t output_activation_max = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#aadb8981e614d4834abc8318f406c5462">quantized_activation_max</a>;</div>
<div class="line"><span class="lineno">  215</span> </div>
<div class="line"><span class="lineno">  216</span>  <span class="comment">// Consistency check.</span></div>
<div class="line"><span class="lineno">  217</span>  assert(output_activation_min &lt; output_activation_max);</div>
<div class="line"><span class="lineno">  218</span>  assert(input_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a01c6b5dc4b24d5c2567c47cb15318839">DimensionsCount</a>() == 4);</div>
<div class="line"><span class="lineno">  219</span>  assert(filter_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a01c6b5dc4b24d5c2567c47cb15318839">DimensionsCount</a>() == 4);</div>
<div class="line"><span class="lineno">  220</span>  assert(output_shape.DimensionsCount() == 4);</div>
<div class="line"><span class="lineno">  221</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> batches = <a class="code hl_function" href="namespacennfw_1_1cker.html#a0a74e72b1bffcb6519de7fc224416ff9">MatchingDim</a>(input_shape, 0, output_shape, 0);</div>
<div class="line"><span class="lineno">  222</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> input_depth = <a class="code hl_function" href="namespacennfw_1_1cker.html#a0a74e72b1bffcb6519de7fc224416ff9">MatchingDim</a>(input_shape, 3, filter_shape, 3);</div>
<div class="line"><span class="lineno">  223</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> output_depth = <a class="code hl_function" href="namespacennfw_1_1cker.html#a0a74e72b1bffcb6519de7fc224416ff9">MatchingDim</a>(filter_shape, 0, output_shape, 3);</div>
<div class="line"><span class="lineno">  224</span>  <span class="keywordflow">if</span> (bias_data)</div>
<div class="line"><span class="lineno">  225</span>  {</div>
<div class="line"><span class="lineno">  226</span>    assert(bias_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#ac7e29fd510111992fbd44906e2080f12">FlatSize</a>() == output_depth);</div>
<div class="line"><span class="lineno">  227</span>  }</div>
<div class="line"><span class="lineno">  228</span> </div>
<div class="line"><span class="lineno">  229</span>  <span class="comment">// Check dimensions of the tensors.</span></div>
<div class="line"><span class="lineno">  230</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> input_height = input_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(1);</div>
<div class="line"><span class="lineno">  231</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> input_width = input_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(2);</div>
<div class="line"><span class="lineno">  232</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> filter_height = filter_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(1);</div>
<div class="line"><span class="lineno">  233</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> filter_width = filter_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(2);</div>
<div class="line"><span class="lineno">  234</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> output_height = output_shape.Dims(1);</div>
<div class="line"><span class="lineno">  235</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> output_width = output_shape.Dims(2);</div>
<div class="line"><span class="lineno">  236</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> batch = 0; batch &lt; batches; ++batch)</div>
<div class="line"><span class="lineno">  237</span>  {</div>
<div class="line"><span class="lineno">  238</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> out_y = 0; out_y &lt; output_height; ++out_y)</div>
<div class="line"><span class="lineno">  239</span>    {</div>
<div class="line"><span class="lineno">  240</span>      <span class="keyword">const</span> <span class="keywordtype">int</span> in_y_origin = (out_y * stride_height) - pad_height;</div>
<div class="line"><span class="lineno">  241</span>      <span class="keywordflow">for</span> (<span class="keywordtype">int</span> out_x = 0; out_x &lt; output_width; ++out_x)</div>
<div class="line"><span class="lineno">  242</span>      {</div>
<div class="line"><span class="lineno">  243</span>        <span class="keyword">const</span> <span class="keywordtype">int</span> in_x_origin = (out_x * stride_width) - pad_width;</div>
<div class="line"><span class="lineno">  244</span>        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> out_channel = 0; out_channel &lt; output_depth; ++out_channel)</div>
<div class="line"><span class="lineno">  245</span>        {</div>
<div class="line"><span class="lineno">  246</span>          int32_t acc = 0;</div>
<div class="line"><span class="lineno">  247</span>          <span class="keywordflow">for</span> (<span class="keywordtype">int</span> filter_y = 0; filter_y &lt; filter_height; ++filter_y)</div>
<div class="line"><span class="lineno">  248</span>          {</div>
<div class="line"><span class="lineno">  249</span>            <span class="keyword">const</span> <span class="keywordtype">int</span> in_y = in_y_origin + dilation_height_factor * filter_y;</div>
<div class="line"><span class="lineno">  250</span>            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> filter_x = 0; filter_x &lt; filter_width; ++filter_x)</div>
<div class="line"><span class="lineno">  251</span>            {</div>
<div class="line"><span class="lineno">  252</span>              <span class="keyword">const</span> <span class="keywordtype">int</span> in_x = in_x_origin + dilation_width_factor * filter_x;</div>
<div class="line"><span class="lineno">  253</span> </div>
<div class="line"><span class="lineno">  254</span>              <span class="comment">// Zero padding by omitting the areas outside the image.</span></div>
<div class="line"><span class="lineno">  255</span>              <span class="keyword">const</span> <span class="keywordtype">bool</span> is_point_inside_image =</div>
<div class="line"><span class="lineno">  256</span>                (in_x &gt;= 0) &amp;&amp; (in_x &lt; input_width) &amp;&amp; (in_y &gt;= 0) &amp;&amp; (in_y &lt; input_height);</div>
<div class="line"><span class="lineno">  257</span> </div>
<div class="line"><span class="lineno">  258</span>              <span class="keywordflow">if</span> (!is_point_inside_image)</div>
<div class="line"><span class="lineno">  259</span>              {</div>
<div class="line"><span class="lineno">  260</span>                <span class="keywordflow">continue</span>;</div>
<div class="line"><span class="lineno">  261</span>              }</div>
<div class="line"><span class="lineno">  262</span> </div>
<div class="line"><span class="lineno">  263</span>              <span class="keywordflow">for</span> (<span class="keywordtype">int</span> in_channel = 0; in_channel &lt; input_depth; ++in_channel)</div>
<div class="line"><span class="lineno">  264</span>              {</div>
<div class="line"><span class="lineno">  265</span>                <span class="keyword">const</span> T input_val = input_data[<a class="code hl_function" href="ann-ref_2src_2ops_2internal_2dims_8h.html#a1c037ff89c0da8b5cd52088b914b9c1d">Offset</a>(input_shape, batch, in_y, in_x, in_channel)];</div>
<div class="line"><span class="lineno">  266</span>                <span class="keyword">const</span> T filter_val =</div>
<div class="line"><span class="lineno">  267</span>                  filter_data[<a class="code hl_function" href="ann-ref_2src_2ops_2internal_2dims_8h.html#a1c037ff89c0da8b5cd52088b914b9c1d">Offset</a>(filter_shape, out_channel, filter_y, filter_x, in_channel)];</div>
<div class="line"><span class="lineno">  268</span>                <span class="keywordflow">if</span> (is_asymmetric)</div>
<div class="line"><span class="lineno">  269</span>                {</div>
<div class="line"><span class="lineno">  270</span>                  <span class="keyword">const</span> int32_t filter_offset = -filter_zeropoint[out_channel];</div>
<div class="line"><span class="lineno">  271</span>                  acc += (filter_val + filter_offset) * (input_val + input_offset);</div>
<div class="line"><span class="lineno">  272</span>                }</div>
<div class="line"><span class="lineno">  273</span>                <span class="keywordflow">else</span></div>
<div class="line"><span class="lineno">  274</span>                {</div>
<div class="line"><span class="lineno">  275</span>                  <span class="comment">// Accumulate with 32 bits accumulator.</span></div>
<div class="line"><span class="lineno">  276</span>                  <span class="comment">// In the nudging process during model quantization, we force</span></div>
<div class="line"><span class="lineno">  277</span>                  <span class="comment">// real value of 0.0 be represented by a quantized value. This</span></div>
<div class="line"><span class="lineno">  278</span>                  <span class="comment">// guarantees that the input_offset is a int8_t, even though</span></div>
<div class="line"><span class="lineno">  279</span>                  <span class="comment">// it is represented using int32_t. int32_t += int8_t *</span></div>
<div class="line"><span class="lineno">  280</span>                  <span class="comment">// (int8_t - int8_t) so the highest value we can get from each</span></div>
<div class="line"><span class="lineno">  281</span>                  <span class="comment">// accumulation is [-127, 127] * ([-128, 127] -</span></div>
<div class="line"><span class="lineno">  282</span>                  <span class="comment">// [-128, 127]), which is [-32512, 32512]. log2(32512)</span></div>
<div class="line"><span class="lineno">  283</span>                  <span class="comment">// = 14.98, which means we can accumulate at least 2^16</span></div>
<div class="line"><span class="lineno">  284</span>                  <span class="comment">// multiplications without overflow. The accumulator is</span></div>
<div class="line"><span class="lineno">  285</span>                  <span class="comment">// applied to a filter so the accumulation logic will hold as</span></div>
<div class="line"><span class="lineno">  286</span>                  <span class="comment">// long as the filter size (filter_y * filter_x * in_channel)</span></div>
<div class="line"><span class="lineno">  287</span>                  <span class="comment">// does not exceed 2^16, which is the case in all the models</span></div>
<div class="line"><span class="lineno">  288</span>                  <span class="comment">// we have seen so far.</span></div>
<div class="line"><span class="lineno">  289</span>                  <span class="comment">// TODO(jianlijianli): Add a check to make sure the</span></div>
<div class="line"><span class="lineno">  290</span>                  <span class="comment">// accumulator depth is smaller than 2^16.</span></div>
<div class="line"><span class="lineno">  291</span>                  acc += filter_val * (input_val + input_offset);</div>
<div class="line"><span class="lineno">  292</span>                  <a class="code hl_define" href="compute_2cker_2include_2cker_2_shape_8h.html#a044d7f999713173dd3360b0aa40370fd">UNUSED_RELEASE</a>(filter_zeropoint);</div>
<div class="line"><span class="lineno">  293</span>                }</div>
<div class="line"><span class="lineno">  294</span>              }</div>
<div class="line"><span class="lineno">  295</span>            }</div>
<div class="line"><span class="lineno">  296</span>          }</div>
<div class="line"><span class="lineno">  297</span> </div>
<div class="line"><span class="lineno">  298</span>          <span class="keywordflow">if</span> (bias_data)</div>
<div class="line"><span class="lineno">  299</span>          {</div>
<div class="line"><span class="lineno">  300</span>            acc += bias_data[out_channel];</div>
<div class="line"><span class="lineno">  301</span>          }</div>
<div class="line"><span class="lineno">  302</span>          acc = <a class="code hl_function" href="namespacennfw_1_1cker.html#af6b33a8f0c1d60e578337bdb8dcb3673">MultiplyByQuantizedMultiplier</a>(acc, output_multiplier[out_channel],</div>
<div class="line"><span class="lineno">  303</span>                                              output_shift[out_channel]);</div>
<div class="line"><span class="lineno">  304</span>          acc += output_offset;</div>
<div class="line"><span class="lineno">  305</span>          acc = std::max(acc, output_activation_min);</div>
<div class="line"><span class="lineno">  306</span>          acc = std::min(acc, output_activation_max);</div>
<div class="line"><span class="lineno">  307</span>          <a class="code hl_variable" href="namespacepart__eval__one.html#aa659ec13c0dc14d487081c1a59b9ae70">output_data</a>[<a class="code hl_function" href="ann-ref_2src_2ops_2internal_2dims_8h.html#a1c037ff89c0da8b5cd52088b914b9c1d">Offset</a>(output_shape, batch, out_y, out_x, out_channel)] = <span class="keyword">static_cast&lt;</span>T<span class="keyword">&gt;</span>(acc);</div>
<div class="line"><span class="lineno">  308</span>        }</div>
<div class="line"><span class="lineno">  309</span>      }</div>
<div class="line"><span class="lineno">  310</span>    }</div>
<div class="line"><span class="lineno">  311</span>  }</div>
<div class="line"><span class="lineno">  312</span>}</div>
<div class="ttc" id="aclassnnfw_1_1cker_1_1_shape_html_ac7e29fd510111992fbd44906e2080f12"><div class="ttname"><a href="classnnfw_1_1cker_1_1_shape.html#ac7e29fd510111992fbd44906e2080f12">nnfw::cker::Shape::FlatSize</a></div><div class="ttdeci">int FlatSize() const</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00183">Shape.h:183</a></div></div>
<div class="ttc" id="acompute_2cker_2include_2cker_2_shape_8h_html_a044d7f999713173dd3360b0aa40370fd"><div class="ttname"><a href="compute_2cker_2include_2cker_2_shape_8h.html#a044d7f999713173dd3360b0aa40370fd">UNUSED_RELEASE</a></div><div class="ttdeci">#define UNUSED_RELEASE(a)</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00026">Shape.h:26</a></div></div>
<div class="ttc" id="anamespacennfw_1_1cker_html_a0a74e72b1bffcb6519de7fc224416ff9"><div class="ttname"><a href="namespacennfw_1_1cker.html#a0a74e72b1bffcb6519de7fc224416ff9">nnfw::cker::MatchingDim</a></div><div class="ttdeci">int MatchingDim(const Shape &amp;shape1, int index1, const Shape &amp;shape2, int index2)</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00222">Shape.h:222</a></div></div>
<div class="ttc" id="anamespacennfw_1_1cker_html_af6b33a8f0c1d60e578337bdb8dcb3673"><div class="ttname"><a href="namespacennfw_1_1cker.html#af6b33a8f0c1d60e578337bdb8dcb3673">nnfw::cker::MultiplyByQuantizedMultiplier</a></div><div class="ttdeci">int32_t MultiplyByQuantizedMultiplier(int32_t x, int32_t quantized_multiplier, int shift)</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_utils_8h_source.html#l00093">Utils.h:93</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_conv_params_html_a0878ee74c474c8a82a574727a2a3048e"><div class="ttname"><a href="structnnfw_1_1cker_1_1_conv_params.html#a0878ee74c474c8a82a574727a2a3048e">nnfw::cker::ConvParams::stride_height</a></div><div class="ttdeci">int16_t stride_height</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00140">Types.h:140</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_conv_params_html_a0a3450e62d20d27c2638d197f1fd2bb2"><div class="ttname"><a href="structnnfw_1_1cker_1_1_conv_params.html#a0a3450e62d20d27c2638d197f1fd2bb2">nnfw::cker::ConvParams::padding_values</a></div><div class="ttdeci">PaddingValues padding_values</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00137">Types.h:137</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_conv_params_html_a273ecef205d663377502d9dcaa77f1b4"><div class="ttname"><a href="structnnfw_1_1cker_1_1_conv_params.html#a273ecef205d663377502d9dcaa77f1b4">nnfw::cker::ConvParams::stride_width</a></div><div class="ttdeci">int16_t stride_width</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00139">Types.h:139</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_conv_params_html_a435e0fcf2622a161fe913f6098b2dd1e"><div class="ttname"><a href="structnnfw_1_1cker_1_1_conv_params.html#a435e0fcf2622a161fe913f6098b2dd1e">nnfw::cker::ConvParams::input_offset</a></div><div class="ttdeci">int32_t input_offset</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00145">Types.h:145</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_conv_params_html_a7fef4d3c76b386c35ec04adfd931f991"><div class="ttname"><a href="structnnfw_1_1cker_1_1_conv_params.html#a7fef4d3c76b386c35ec04adfd931f991">nnfw::cker::ConvParams::output_offset</a></div><div class="ttdeci">int32_t output_offset</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00147">Types.h:147</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_conv_params_html_a8ff1e952b2e7627e11b47a22da0883cb"><div class="ttname"><a href="structnnfw_1_1cker_1_1_conv_params.html#a8ff1e952b2e7627e11b47a22da0883cb">nnfw::cker::ConvParams::dilation_width_factor</a></div><div class="ttdeci">int16_t dilation_width_factor</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00141">Types.h:141</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_conv_params_html_aadb8981e614d4834abc8318f406c5462"><div class="ttname"><a href="structnnfw_1_1cker_1_1_conv_params.html#aadb8981e614d4834abc8318f406c5462">nnfw::cker::ConvParams::quantized_activation_max</a></div><div class="ttdeci">int32_t quantized_activation_max</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00152">Types.h:152</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_conv_params_html_ad47b94004b5b1718979775edaa9eee70"><div class="ttname"><a href="structnnfw_1_1cker_1_1_conv_params.html#ad47b94004b5b1718979775edaa9eee70">nnfw::cker::ConvParams::dilation_height_factor</a></div><div class="ttdeci">int16_t dilation_height_factor</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00142">Types.h:142</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_conv_params_html_ad4f74d8bfaa34bd1f44a690e7b77fc5f"><div class="ttname"><a href="structnnfw_1_1cker_1_1_conv_params.html#ad4f74d8bfaa34bd1f44a690e7b77fc5f">nnfw::cker::ConvParams::quantized_activation_min</a></div><div class="ttdeci">int32_t quantized_activation_min</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00151">Types.h:151</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_padding_values_html_a1dc41a9ebbd61a7c34ed2b5dd2ec10eb"><div class="ttname"><a href="structnnfw_1_1cker_1_1_padding_values.html#a1dc41a9ebbd61a7c34ed2b5dd2ec10eb">nnfw::cker::PaddingValues::height</a></div><div class="ttdeci">int16_t height</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00069">Types.h:69</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_padding_values_html_a2a3dd79d28c30c5da865290160601fd1"><div class="ttname"><a href="structnnfw_1_1cker_1_1_padding_values.html#a2a3dd79d28c30c5da865290160601fd1">nnfw::cker::PaddingValues::width</a></div><div class="ttdeci">int16_t width</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00068">Types.h:68</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00142">nnfw::cker::ConvParams::dilation_height_factor</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00141">nnfw::cker::ConvParams::dilation_width_factor</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00093">nnfw::cker::Shape::DimensionsCount()</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00094">nnfw::cker::Shape::Dims()</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00183">nnfw::cker::Shape::FlatSize()</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00069">nnfw::cker::PaddingValues::height</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00145">nnfw::cker::ConvParams::input_offset</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00222">nnfw::cker::MatchingDim()</a>, <a class="el" href="compute_2cker_2include_2cker_2_utils_8h_source.html#l00093">nnfw::cker::MultiplyByQuantizedMultiplier()</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00241">nnfw::cker::Offset()</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00147">nnfw::cker::ConvParams::output_offset</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00137">nnfw::cker::ConvParams::padding_values</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00152">nnfw::cker::ConvParams::quantized_activation_max</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00151">nnfw::cker::ConvParams::quantized_activation_min</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00140">nnfw::cker::ConvParams::stride_height</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00139">nnfw::cker::ConvParams::stride_width</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00026">UNUSED_RELEASE</a>, and <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00068">nnfw::cker::PaddingValues::width</a>.</p>

</div>
</div>
<a id="a954de12511ee583ef0e6b01a0679d4d8" name="a954de12511ee583ef0e6b01a0679d4d8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a954de12511ee583ef0e6b01a0679d4d8">&#9670;&#160;</a></span>Conv() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void nnfw::cker::reference::Conv </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structnnfw_1_1cker_1_1_conv_params.html">ConvParams</a> &amp;&#160;</td>
          <td class="paramname"><em>params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>input_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>input_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>filter_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>filter_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>bias_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>bias_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>output_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>output_data</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="compute_2cker_2include_2cker_2operation_2reference_2_conv_8h_source.html#l00033">33</a> of file <a class="el" href="compute_2cker_2include_2cker_2operation_2reference_2_conv_8h_source.html">Conv.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   36</span>{</div>
<div class="line"><span class="lineno">   37</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> stride_width = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a273ecef205d663377502d9dcaa77f1b4">stride_width</a>;</div>
<div class="line"><span class="lineno">   38</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> stride_height = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a0878ee74c474c8a82a574727a2a3048e">stride_height</a>;</div>
<div class="line"><span class="lineno">   39</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> dilation_width_factor = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a8ff1e952b2e7627e11b47a22da0883cb">dilation_width_factor</a>;</div>
<div class="line"><span class="lineno">   40</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> dilation_height_factor = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#ad47b94004b5b1718979775edaa9eee70">dilation_height_factor</a>;</div>
<div class="line"><span class="lineno">   41</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> pad_width = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a0a3450e62d20d27c2638d197f1fd2bb2">padding_values</a>.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_padding_values.html#a2a3dd79d28c30c5da865290160601fd1">width</a>;</div>
<div class="line"><span class="lineno">   42</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> pad_height = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a0a3450e62d20d27c2638d197f1fd2bb2">padding_values</a>.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_padding_values.html#a1dc41a9ebbd61a7c34ed2b5dd2ec10eb">height</a>;</div>
<div class="line"><span class="lineno">   43</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> output_activation_min = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#aad1d68e02303baf27dd6d03f6a6765e1">float_activation_min</a>;</div>
<div class="line"><span class="lineno">   44</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> output_activation_max = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a2ddc6701e8ee0b57d71c9487b2c3e209">float_activation_max</a>;</div>
<div class="line"><span class="lineno">   45</span>  assert(input_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a01c6b5dc4b24d5c2567c47cb15318839">DimensionsCount</a>() == 4);</div>
<div class="line"><span class="lineno">   46</span>  assert(filter_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a01c6b5dc4b24d5c2567c47cb15318839">DimensionsCount</a>() == 4);</div>
<div class="line"><span class="lineno">   47</span>  assert(output_shape.DimensionsCount() == 4);</div>
<div class="line"><span class="lineno">   48</span>  <a class="code hl_define" href="compute_2cker_2include_2cker_2_shape_8h.html#a044d7f999713173dd3360b0aa40370fd">UNUSED_RELEASE</a>(bias_shape);</div>
<div class="line"><span class="lineno">   49</span> </div>
<div class="line"><span class="lineno">   50</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> batches = <a class="code hl_function" href="namespacennfw_1_1cker.html#a0a74e72b1bffcb6519de7fc224416ff9">MatchingDim</a>(input_shape, 0, output_shape, 0);</div>
<div class="line"><span class="lineno">   51</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> input_depth = <a class="code hl_function" href="namespacennfw_1_1cker.html#a0a74e72b1bffcb6519de7fc224416ff9">MatchingDim</a>(input_shape, 3, filter_shape, 3);</div>
<div class="line"><span class="lineno">   52</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> output_depth = <a class="code hl_function" href="namespacennfw_1_1cker.html#a0a74e72b1bffcb6519de7fc224416ff9">MatchingDim</a>(filter_shape, 0, output_shape, 3);</div>
<div class="line"><span class="lineno">   53</span>  <span class="keywordflow">if</span> (bias_data)</div>
<div class="line"><span class="lineno">   54</span>  {</div>
<div class="line"><span class="lineno">   55</span>    assert(bias_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#ac7e29fd510111992fbd44906e2080f12">FlatSize</a>() == output_depth);</div>
<div class="line"><span class="lineno">   56</span>  }</div>
<div class="line"><span class="lineno">   57</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> input_height = input_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(1);</div>
<div class="line"><span class="lineno">   58</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> input_width = input_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(2);</div>
<div class="line"><span class="lineno">   59</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> filter_height = filter_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(1);</div>
<div class="line"><span class="lineno">   60</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> filter_width = filter_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(2);</div>
<div class="line"><span class="lineno">   61</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> output_height = output_shape.Dims(1);</div>
<div class="line"><span class="lineno">   62</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> output_width = output_shape.Dims(2);</div>
<div class="line"><span class="lineno">   63</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> batch = 0; batch &lt; batches; ++batch)</div>
<div class="line"><span class="lineno">   64</span>  {</div>
<div class="line"><span class="lineno">   65</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> out_y = 0; out_y &lt; output_height; ++out_y)</div>
<div class="line"><span class="lineno">   66</span>    {</div>
<div class="line"><span class="lineno">   67</span>      <span class="keywordflow">for</span> (<span class="keywordtype">int</span> out_x = 0; out_x &lt; output_width; ++out_x)</div>
<div class="line"><span class="lineno">   68</span>      {</div>
<div class="line"><span class="lineno">   69</span>        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> out_channel = 0; out_channel &lt; output_depth; ++out_channel)</div>
<div class="line"><span class="lineno">   70</span>        {</div>
<div class="line"><span class="lineno">   71</span>          <span class="keyword">const</span> <span class="keywordtype">int</span> in_x_origin = (out_x * stride_width) - pad_width;</div>
<div class="line"><span class="lineno">   72</span>          <span class="keyword">const</span> <span class="keywordtype">int</span> in_y_origin = (out_y * stride_height) - pad_height;</div>
<div class="line"><span class="lineno">   73</span>          <span class="keywordtype">float</span> total = 0.f;</div>
<div class="line"><span class="lineno">   74</span>          <span class="keywordflow">for</span> (<span class="keywordtype">int</span> filter_y = 0; filter_y &lt; filter_height; ++filter_y)</div>
<div class="line"><span class="lineno">   75</span>          {</div>
<div class="line"><span class="lineno">   76</span>            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> filter_x = 0; filter_x &lt; filter_width; ++filter_x)</div>
<div class="line"><span class="lineno">   77</span>            {</div>
<div class="line"><span class="lineno">   78</span>              <span class="keyword">const</span> <span class="keywordtype">int</span> in_x = in_x_origin + dilation_width_factor * filter_x;</div>
<div class="line"><span class="lineno">   79</span>              <span class="keyword">const</span> <span class="keywordtype">int</span> in_y = in_y_origin + dilation_height_factor * filter_y;</div>
<div class="line"><span class="lineno">   80</span>              <span class="comment">// If the location is outside the bounds of the input image,</span></div>
<div class="line"><span class="lineno">   81</span>              <span class="comment">// use zero as a default value.</span></div>
<div class="line"><span class="lineno">   82</span>              <span class="keywordflow">if</span> ((in_x &gt;= 0) &amp;&amp; (in_x &lt; input_width) &amp;&amp; (in_y &gt;= 0) &amp;&amp; (in_y &lt; input_height))</div>
<div class="line"><span class="lineno">   83</span>              {</div>
<div class="line"><span class="lineno">   84</span>                <span class="keyword">const</span> <span class="keywordtype">int</span> in_offset = <a class="code hl_function" href="ann-ref_2src_2ops_2internal_2dims_8h.html#a1c037ff89c0da8b5cd52088b914b9c1d">Offset</a>(input_shape, batch, in_y, in_x, 0);</div>
<div class="line"><span class="lineno">   85</span>                <span class="keyword">const</span> <span class="keywordtype">int</span> filter_offset = <a class="code hl_function" href="ann-ref_2src_2ops_2internal_2dims_8h.html#a1c037ff89c0da8b5cd52088b914b9c1d">Offset</a>(filter_shape, out_channel, filter_y, filter_x, 0);</div>
<div class="line"><span class="lineno">   86</span>                <span class="keywordflow">for</span> (<span class="keywordtype">int</span> in_channel = 0; in_channel &lt; input_depth; ++in_channel)</div>
<div class="line"><span class="lineno">   87</span>                {</div>
<div class="line"><span class="lineno">   88</span>                  <span class="keywordtype">float</span> input_value = input_data[in_offset + in_channel];</div>
<div class="line"><span class="lineno">   89</span>                  <span class="keywordtype">float</span> filter_value = filter_data[filter_offset + in_channel];</div>
<div class="line"><span class="lineno">   90</span>                  total += (input_value * filter_value);</div>
<div class="line"><span class="lineno">   91</span>                }</div>
<div class="line"><span class="lineno">   92</span>              }</div>
<div class="line"><span class="lineno">   93</span>            }</div>
<div class="line"><span class="lineno">   94</span>          }</div>
<div class="line"><span class="lineno">   95</span>          <span class="keywordtype">float</span> bias_value = 0.0f;</div>
<div class="line"><span class="lineno">   96</span>          <span class="keywordflow">if</span> (bias_data)</div>
<div class="line"><span class="lineno">   97</span>          {</div>
<div class="line"><span class="lineno">   98</span>            bias_value = bias_data[out_channel];</div>
<div class="line"><span class="lineno">   99</span>          }</div>
<div class="line"><span class="lineno">  100</span>          <a class="code hl_variable" href="namespacepart__eval__one.html#aa659ec13c0dc14d487081c1a59b9ae70">output_data</a>[<a class="code hl_function" href="ann-ref_2src_2ops_2internal_2dims_8h.html#a1c037ff89c0da8b5cd52088b914b9c1d">Offset</a>(output_shape, batch, out_y, out_x, out_channel)] =</div>
<div class="line"><span class="lineno">  101</span>            <a class="code hl_function" href="namespacennfw_1_1cker.html#a86b83772dd83256abffc3a8f1426819b">ActivationFunctionWithMinMax</a>(total + bias_value, output_activation_min,</div>
<div class="line"><span class="lineno">  102</span>                                         output_activation_max);</div>
<div class="line"><span class="lineno">  103</span>        }</div>
<div class="line"><span class="lineno">  104</span>      }</div>
<div class="line"><span class="lineno">  105</span>    }</div>
<div class="line"><span class="lineno">  106</span>  }</div>
<div class="line"><span class="lineno">  107</span>}</div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_conv_params_html_a2ddc6701e8ee0b57d71c9487b2c3e209"><div class="ttname"><a href="structnnfw_1_1cker_1_1_conv_params.html#a2ddc6701e8ee0b57d71c9487b2c3e209">nnfw::cker::ConvParams::float_activation_max</a></div><div class="ttdeci">float float_activation_max</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00155">Types.h:155</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_conv_params_html_aad1d68e02303baf27dd6d03f6a6765e1"><div class="ttname"><a href="structnnfw_1_1cker_1_1_conv_params.html#aad1d68e02303baf27dd6d03f6a6765e1">nnfw::cker::ConvParams::float_activation_min</a></div><div class="ttdeci">float float_activation_min</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00154">Types.h:154</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="compute_2cker_2include_2cker_2_utils_8h_source.html#l00040">nnfw::cker::ActivationFunctionWithMinMax()</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00142">nnfw::cker::ConvParams::dilation_height_factor</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00141">nnfw::cker::ConvParams::dilation_width_factor</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00093">nnfw::cker::Shape::DimensionsCount()</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00094">nnfw::cker::Shape::Dims()</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00183">nnfw::cker::Shape::FlatSize()</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00155">nnfw::cker::ConvParams::float_activation_max</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00154">nnfw::cker::ConvParams::float_activation_min</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00069">nnfw::cker::PaddingValues::height</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00222">nnfw::cker::MatchingDim()</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00241">nnfw::cker::Offset()</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00137">nnfw::cker::ConvParams::padding_values</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00140">nnfw::cker::ConvParams::stride_height</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00139">nnfw::cker::ConvParams::stride_width</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00026">UNUSED_RELEASE</a>, and <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00068">nnfw::cker::PaddingValues::width</a>.</p>

<p class="reference">Referenced by <a class="el" href="compute_2cker_2include_2cker_2operation_2_conv_8h_source.html#l00086">nnfw::cker::Conv::operator()()</a>.</p>

</div>
</div>
<a id="a0a0b3958e4e76a04596178b1fdeea09b" name="a0a0b3958e4e76a04596178b1fdeea09b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0a0b3958e4e76a04596178b1fdeea09b">&#9670;&#160;</a></span>Conv() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void nnfw::cker::reference::Conv </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structnnfw_1_1cker_1_1_conv_params.html">ConvParams</a> &amp;&#160;</td>
          <td class="paramname"><em>params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>input_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint8_t *&#160;</td>
          <td class="paramname"><em>input_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>filter_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint8_t *&#160;</td>
          <td class="paramname"><em>filter_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>bias_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>bias_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>output_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint8_t *&#160;</td>
          <td class="paramname"><em>output_data</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="compute_2cker_2include_2cker_2operation_2reference_2_conv_8h_source.html#l00109">109</a> of file <a class="el" href="compute_2cker_2include_2cker_2operation_2reference_2_conv_8h_source.html">Conv.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  112</span>{</div>
<div class="line"><span class="lineno">  113</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> stride_width = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a273ecef205d663377502d9dcaa77f1b4">stride_width</a>;</div>
<div class="line"><span class="lineno">  114</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> stride_height = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a0878ee74c474c8a82a574727a2a3048e">stride_height</a>;</div>
<div class="line"><span class="lineno">  115</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> dilation_width_factor = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a8ff1e952b2e7627e11b47a22da0883cb">dilation_width_factor</a>;</div>
<div class="line"><span class="lineno">  116</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> dilation_height_factor = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#ad47b94004b5b1718979775edaa9eee70">dilation_height_factor</a>;</div>
<div class="line"><span class="lineno">  117</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> pad_width = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a0a3450e62d20d27c2638d197f1fd2bb2">padding_values</a>.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_padding_values.html#a2a3dd79d28c30c5da865290160601fd1">width</a>;</div>
<div class="line"><span class="lineno">  118</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> pad_height = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a0a3450e62d20d27c2638d197f1fd2bb2">padding_values</a>.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_padding_values.html#a1dc41a9ebbd61a7c34ed2b5dd2ec10eb">height</a>;</div>
<div class="line"><span class="lineno">  119</span>  <span class="keyword">const</span> int32_t input_offset = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a435e0fcf2622a161fe913f6098b2dd1e">input_offset</a>;</div>
<div class="line"><span class="lineno">  120</span>  <span class="keyword">const</span> int32_t filter_offset = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a7a4237fa84247ed20ecb16119e1ec589">weights_offset</a>;</div>
<div class="line"><span class="lineno">  121</span>  <span class="keyword">const</span> int32_t output_offset = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a7fef4d3c76b386c35ec04adfd931f991">output_offset</a>;</div>
<div class="line"><span class="lineno">  122</span>  <span class="keyword">const</span> int32_t output_multiplier = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a636e1132f40731ba32f9060ae7f4dd44">output_multiplier</a>;</div>
<div class="line"><span class="lineno">  123</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> output_shift = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#a1b36fc4cd87255a5e67218c4504db9b9">output_shift</a>;</div>
<div class="line"><span class="lineno">  124</span>  <span class="keyword">const</span> int32_t output_activation_min = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#ad4f74d8bfaa34bd1f44a690e7b77fc5f">quantized_activation_min</a>;</div>
<div class="line"><span class="lineno">  125</span>  <span class="keyword">const</span> int32_t output_activation_max = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_conv_params.html#aadb8981e614d4834abc8318f406c5462">quantized_activation_max</a>;</div>
<div class="line"><span class="lineno">  126</span>  assert(output_activation_min &lt;= output_activation_max);</div>
<div class="line"><span class="lineno">  127</span> </div>
<div class="line"><span class="lineno">  128</span>  assert(input_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a01c6b5dc4b24d5c2567c47cb15318839">DimensionsCount</a>() == 4);</div>
<div class="line"><span class="lineno">  129</span>  assert(filter_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a01c6b5dc4b24d5c2567c47cb15318839">DimensionsCount</a>() == 4);</div>
<div class="line"><span class="lineno">  130</span>  assert(output_shape.DimensionsCount() == 4);</div>
<div class="line"><span class="lineno">  131</span>  <a class="code hl_define" href="compute_2cker_2include_2cker_2_shape_8h.html#a044d7f999713173dd3360b0aa40370fd">UNUSED_RELEASE</a>(bias_shape);</div>
<div class="line"><span class="lineno">  132</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> batches = <a class="code hl_function" href="namespacennfw_1_1cker.html#a0a74e72b1bffcb6519de7fc224416ff9">MatchingDim</a>(input_shape, 0, output_shape, 0);</div>
<div class="line"><span class="lineno">  133</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> input_depth = <a class="code hl_function" href="namespacennfw_1_1cker.html#a0a74e72b1bffcb6519de7fc224416ff9">MatchingDim</a>(input_shape, 3, filter_shape, 3);</div>
<div class="line"><span class="lineno">  134</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> output_depth = <a class="code hl_function" href="namespacennfw_1_1cker.html#a0a74e72b1bffcb6519de7fc224416ff9">MatchingDim</a>(filter_shape, 0, output_shape, 3);</div>
<div class="line"><span class="lineno">  135</span>  <span class="keywordflow">if</span> (bias_data)</div>
<div class="line"><span class="lineno">  136</span>  {</div>
<div class="line"><span class="lineno">  137</span>    assert(bias_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#ac7e29fd510111992fbd44906e2080f12">FlatSize</a>() == output_depth);</div>
<div class="line"><span class="lineno">  138</span>  }</div>
<div class="line"><span class="lineno">  139</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> input_height = input_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(1);</div>
<div class="line"><span class="lineno">  140</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> input_width = input_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(2);</div>
<div class="line"><span class="lineno">  141</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> filter_height = filter_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(1);</div>
<div class="line"><span class="lineno">  142</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> filter_width = filter_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a497180ee7844bbef51b36bd58e61fa31">Dims</a>(2);</div>
<div class="line"><span class="lineno">  143</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> output_height = output_shape.Dims(1);</div>
<div class="line"><span class="lineno">  144</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> output_width = output_shape.Dims(2);</div>
<div class="line"><span class="lineno">  145</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> batch = 0; batch &lt; batches; ++batch)</div>
<div class="line"><span class="lineno">  146</span>  {</div>
<div class="line"><span class="lineno">  147</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> out_y = 0; out_y &lt; output_height; ++out_y)</div>
<div class="line"><span class="lineno">  148</span>    {</div>
<div class="line"><span class="lineno">  149</span>      <span class="keywordflow">for</span> (<span class="keywordtype">int</span> out_x = 0; out_x &lt; output_width; ++out_x)</div>
<div class="line"><span class="lineno">  150</span>      {</div>
<div class="line"><span class="lineno">  151</span>        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> out_channel = 0; out_channel &lt; output_depth; ++out_channel)</div>
<div class="line"><span class="lineno">  152</span>        {</div>
<div class="line"><span class="lineno">  153</span>          <span class="keyword">const</span> <span class="keywordtype">int</span> in_x_origin = (out_x * stride_width) - pad_width;</div>
<div class="line"><span class="lineno">  154</span>          <span class="keyword">const</span> <span class="keywordtype">int</span> in_y_origin = (out_y * stride_height) - pad_height;</div>
<div class="line"><span class="lineno">  155</span>          int32_t acc = 0;</div>
<div class="line"><span class="lineno">  156</span>          <span class="keywordflow">for</span> (<span class="keywordtype">int</span> filter_y = 0; filter_y &lt; filter_height; ++filter_y)</div>
<div class="line"><span class="lineno">  157</span>          {</div>
<div class="line"><span class="lineno">  158</span>            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> filter_x = 0; filter_x &lt; filter_width; ++filter_x)</div>
<div class="line"><span class="lineno">  159</span>            {</div>
<div class="line"><span class="lineno">  160</span>              <span class="keyword">const</span> <span class="keywordtype">int</span> in_x = in_x_origin + dilation_width_factor * filter_x;</div>
<div class="line"><span class="lineno">  161</span>              <span class="keyword">const</span> <span class="keywordtype">int</span> in_y = in_y_origin + dilation_height_factor * filter_y;</div>
<div class="line"><span class="lineno">  162</span>              <span class="comment">// If the location is outside the bounds of the input image,</span></div>
<div class="line"><span class="lineno">  163</span>              <span class="comment">// use zero as a default value.</span></div>
<div class="line"><span class="lineno">  164</span>              <span class="keywordflow">if</span> ((in_x &gt;= 0) &amp;&amp; (in_x &lt; input_width) &amp;&amp; (in_y &gt;= 0) &amp;&amp; (in_y &lt; input_height))</div>
<div class="line"><span class="lineno">  165</span>              {</div>
<div class="line"><span class="lineno">  166</span>                <span class="keyword">const</span> <span class="keywordtype">int</span> in_base = <a class="code hl_function" href="ann-ref_2src_2ops_2internal_2dims_8h.html#a1c037ff89c0da8b5cd52088b914b9c1d">Offset</a>(input_shape, batch, in_y, in_x, 0);</div>
<div class="line"><span class="lineno">  167</span>                <span class="keyword">const</span> <span class="keywordtype">int</span> filter_base = <a class="code hl_function" href="ann-ref_2src_2ops_2internal_2dims_8h.html#a1c037ff89c0da8b5cd52088b914b9c1d">Offset</a>(filter_shape, out_channel, filter_y, filter_x, 0);</div>
<div class="line"><span class="lineno">  168</span>                <span class="keywordflow">for</span> (<span class="keywordtype">int</span> in_channel = 0; in_channel &lt; input_depth; in_channel++)</div>
<div class="line"><span class="lineno">  169</span>                {</div>
<div class="line"><span class="lineno">  170</span>                  int32_t input_val = input_data[in_channel + in_base];</div>
<div class="line"><span class="lineno">  171</span>                  int32_t filter_val = filter_data[in_channel + filter_base];</div>
<div class="line"><span class="lineno">  172</span>                  acc += (filter_val + filter_offset) * (input_val + input_offset);</div>
<div class="line"><span class="lineno">  173</span>                }</div>
<div class="line"><span class="lineno">  174</span>              }</div>
<div class="line"><span class="lineno">  175</span>            }</div>
<div class="line"><span class="lineno">  176</span>          }</div>
<div class="line"><span class="lineno">  177</span>          <span class="keywordflow">if</span> (bias_data)</div>
<div class="line"><span class="lineno">  178</span>          {</div>
<div class="line"><span class="lineno">  179</span>            acc += bias_data[out_channel];</div>
<div class="line"><span class="lineno">  180</span>          }</div>
<div class="line"><span class="lineno">  181</span>          acc = <a class="code hl_function" href="namespacennfw_1_1cker.html#af6b33a8f0c1d60e578337bdb8dcb3673">MultiplyByQuantizedMultiplier</a>(acc, output_multiplier, output_shift);</div>
<div class="line"><span class="lineno">  182</span>          acc += output_offset;</div>
<div class="line"><span class="lineno">  183</span>          acc = std::max(acc, output_activation_min);</div>
<div class="line"><span class="lineno">  184</span>          acc = std::min(acc, output_activation_max);</div>
<div class="line"><span class="lineno">  185</span>          <a class="code hl_variable" href="namespacepart__eval__one.html#aa659ec13c0dc14d487081c1a59b9ae70">output_data</a>[<a class="code hl_function" href="ann-ref_2src_2ops_2internal_2dims_8h.html#a1c037ff89c0da8b5cd52088b914b9c1d">Offset</a>(output_shape, batch, out_y, out_x, out_channel)] =</div>
<div class="line"><span class="lineno">  186</span>            <span class="keyword">static_cast&lt;</span>uint8_t<span class="keyword">&gt;</span>(acc);</div>
<div class="line"><span class="lineno">  187</span>        }</div>
<div class="line"><span class="lineno">  188</span>      }</div>
<div class="line"><span class="lineno">  189</span>    }</div>
<div class="line"><span class="lineno">  190</span>  }</div>
<div class="line"><span class="lineno">  191</span>}</div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_conv_params_html_a1b36fc4cd87255a5e67218c4504db9b9"><div class="ttname"><a href="structnnfw_1_1cker_1_1_conv_params.html#a1b36fc4cd87255a5e67218c4504db9b9">nnfw::cker::ConvParams::output_shift</a></div><div class="ttdeci">int output_shift</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00149">Types.h:149</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_conv_params_html_a636e1132f40731ba32f9060ae7f4dd44"><div class="ttname"><a href="structnnfw_1_1cker_1_1_conv_params.html#a636e1132f40731ba32f9060ae7f4dd44">nnfw::cker::ConvParams::output_multiplier</a></div><div class="ttdeci">int32_t output_multiplier</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00148">Types.h:148</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_conv_params_html_a7a4237fa84247ed20ecb16119e1ec589"><div class="ttname"><a href="structnnfw_1_1cker_1_1_conv_params.html#a7a4237fa84247ed20ecb16119e1ec589">nnfw::cker::ConvParams::weights_offset</a></div><div class="ttdeci">int32_t weights_offset</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00146">Types.h:146</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00142">nnfw::cker::ConvParams::dilation_height_factor</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00141">nnfw::cker::ConvParams::dilation_width_factor</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00093">nnfw::cker::Shape::DimensionsCount()</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00094">nnfw::cker::Shape::Dims()</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00183">nnfw::cker::Shape::FlatSize()</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00069">nnfw::cker::PaddingValues::height</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00145">nnfw::cker::ConvParams::input_offset</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00222">nnfw::cker::MatchingDim()</a>, <a class="el" href="compute_2cker_2include_2cker_2_utils_8h_source.html#l00093">nnfw::cker::MultiplyByQuantizedMultiplier()</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00241">nnfw::cker::Offset()</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00148">nnfw::cker::ConvParams::output_multiplier</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00147">nnfw::cker::ConvParams::output_offset</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00149">nnfw::cker::ConvParams::output_shift</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00137">nnfw::cker::ConvParams::padding_values</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00152">nnfw::cker::ConvParams::quantized_activation_max</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00151">nnfw::cker::ConvParams::quantized_activation_min</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00140">nnfw::cker::ConvParams::stride_height</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00139">nnfw::cker::ConvParams::stride_width</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00026">UNUSED_RELEASE</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00146">nnfw::cker::ConvParams::weights_offset</a>, and <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00068">nnfw::cker::PaddingValues::width</a>.</p>

</div>
</div>
<a id="ab55312a313b1a6280c4fc9bafc80b05c" name="ab55312a313b1a6280c4fc9bafc80b05c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab55312a313b1a6280c4fc9bafc80b05c">&#9670;&#160;</a></span>Softmax()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void nnfw::cker::reference::Softmax </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structnnfw_1_1cker_1_1_softmax_params.html">SoftmaxParams</a> &amp;&#160;</td>
          <td class="paramname"><em>params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>input_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const float *&#160;</td>
          <td class="paramname"><em>input_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>output_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&#160;</td>
          <td class="paramname"><em>output_data</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="compute_2cker_2include_2cker_2operation_2_soft_max_8h_source.html#l00043">43</a> of file <a class="el" href="compute_2cker_2include_2cker_2operation_2_soft_max_8h_source.html">SoftMax.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   45</span>{</div>
<div class="line"><span class="lineno">   46</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> trailing_dim = input_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a01c6b5dc4b24d5c2567c47cb15318839">DimensionsCount</a>() - 1;</div>
<div class="line"><span class="lineno">   47</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> outer_size = <a class="code hl_function" href="namespacennfw_1_1cker.html#aabf0edca9e5984799338bb320bf6eb90">MatchingFlatSizeSkipDim</a>(input_shape, trailing_dim, output_shape);</div>
<div class="line"><span class="lineno">   48</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> depth = <a class="code hl_function" href="namespacennfw_1_1cker.html#a0a74e72b1bffcb6519de7fc224416ff9">MatchingDim</a>(input_shape, trailing_dim, output_shape, trailing_dim);</div>
<div class="line"><span class="lineno">   49</span> </div>
<div class="line"><span class="lineno">   50</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; outer_size; ++i)</div>
<div class="line"><span class="lineno">   51</span>  {</div>
<div class="line"><span class="lineno">   52</span>    <span class="comment">// Find max element value which we&#39;ll use to ensure numerical stability</span></div>
<div class="line"><span class="lineno">   53</span>    <span class="comment">// taking advantage of the following equality:</span></div>
<div class="line"><span class="lineno">   54</span>    <span class="comment">// exp(x[i])/sum(exp(x[i])) == exp(x[i]+C)/sum(exp(x[i]+C))</span></div>
<div class="line"><span class="lineno">   55</span>    <span class="keywordtype">float</span> max = std::numeric_limits&lt;float&gt;::lowest();</div>
<div class="line"><span class="lineno">   56</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> c = 0; c &lt; depth; ++c)</div>
<div class="line"><span class="lineno">   57</span>    {</div>
<div class="line"><span class="lineno">   58</span>      max = std::max(max, input_data[i * depth + c]);</div>
<div class="line"><span class="lineno">   59</span>    }</div>
<div class="line"><span class="lineno">   60</span> </div>
<div class="line"><span class="lineno">   61</span>    <span class="comment">// Compute sum.</span></div>
<div class="line"><span class="lineno">   62</span>    <span class="keywordtype">float</span> sum = 0.f;</div>
<div class="line"><span class="lineno">   63</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> c = 0; c &lt; depth; ++c)</div>
<div class="line"><span class="lineno">   64</span>    {</div>
<div class="line"><span class="lineno">   65</span>      sum += std::exp((input_data[i * depth + c] - max) * <span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>(params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_softmax_params.html#ab0944f3827962b0e769a4aa47424ae68">beta</a>));</div>
<div class="line"><span class="lineno">   66</span>    }</div>
<div class="line"><span class="lineno">   67</span> </div>
<div class="line"><span class="lineno">   68</span>    <span class="comment">// Compute result.</span></div>
<div class="line"><span class="lineno">   69</span>    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> c = 0; c &lt; depth; ++c)</div>
<div class="line"><span class="lineno">   70</span>    {</div>
<div class="line"><span class="lineno">   71</span>      output_data[i * depth + c] =</div>
<div class="line"><span class="lineno">   72</span>        std::exp((input_data[i * depth + c] - max) * <span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>(params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_softmax_params.html#ab0944f3827962b0e769a4aa47424ae68">beta</a>)) / sum;</div>
<div class="line"><span class="lineno">   73</span>    }</div>
<div class="line"><span class="lineno">   74</span>  }</div>
<div class="line"><span class="lineno">   75</span>}</div>
<div class="ttc" id="anamespacennfw_1_1cker_html_aabf0edca9e5984799338bb320bf6eb90"><div class="ttname"><a href="namespacennfw_1_1cker.html#aabf0edca9e5984799338bb320bf6eb90">nnfw::cker::MatchingFlatSizeSkipDim</a></div><div class="ttdeci">int MatchingFlatSizeSkipDim(const Shape &amp;shape, int skip_dim, const Shape &amp;check_shape_0)</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00308">Shape.h:308</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_softmax_params_html_ab0944f3827962b0e769a4aa47424ae68"><div class="ttname"><a href="structnnfw_1_1cker_1_1_softmax_params.html#ab0944f3827962b0e769a4aa47424ae68">nnfw::cker::SoftmaxParams::beta</a></div><div class="ttdeci">double beta</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00100">Types.h:100</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00100">nnfw::cker::SoftmaxParams::beta</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00093">nnfw::cker::Shape::DimensionsCount()</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00222">nnfw::cker::MatchingDim()</a>, and <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00308">nnfw::cker::MatchingFlatSizeSkipDim()</a>.</p>

<p class="reference">Referenced by <a class="el" href="_soft_max_layer_8cc_source.html#l00037">onert::backend::cpu::ops::SoftMaxLayer::softmaxFloat32()</a>.</p>

</div>
</div>
<a id="a295888086391d908f57fa904c9d4544d" name="a295888086391d908f57fa904c9d4544d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a295888086391d908f57fa904c9d4544d">&#9670;&#160;</a></span>Transpose()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void nnfw::cker::reference::Transpose </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structnnfw_1_1cker_1_1_transpose_params.html">TransposeParams</a> &amp;&#160;</td>
          <td class="paramname"><em>params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>unextended_input_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>input_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>unextended_output_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>output_data</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="compute_2cker_2include_2cker_2operation_2_transpose_8h_source.html#l00088">88</a> of file <a class="el" href="compute_2cker_2include_2cker_2operation_2_transpose_8h_source.html">Transpose.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   90</span>{</div>
<div class="line"><span class="lineno">   91</span>  <span class="comment">// Transpose kernel only does rearranging values not numeric evaluations on</span></div>
<div class="line"><span class="lineno">   92</span>  <span class="comment">// each cell. It&#39;s safe to implement per size of scalar type and this trick</span></div>
<div class="line"><span class="lineno">   93</span>  <span class="comment">// keeps the total code size in a reasonable range.</span></div>
<div class="line"><span class="lineno">   94</span>  <span class="keywordflow">switch</span> (<span class="keyword">sizeof</span>(T))</div>
<div class="line"><span class="lineno">   95</span>  {</div>
<div class="line"><span class="lineno">   96</span>    <span class="keywordflow">case</span> 1:</div>
<div class="line"><span class="lineno">   97</span>      TransposeImpl&lt;int8_t&gt;(params, unextended_input_shape,</div>
<div class="line"><span class="lineno">   98</span>                            <span class="keyword">reinterpret_cast&lt;</span><span class="keyword">const </span>int8_t *<span class="keyword">&gt;</span>(input_data), unextended_output_shape,</div>
<div class="line"><span class="lineno">   99</span>                            <span class="keyword">reinterpret_cast&lt;</span>int8_t *<span class="keyword">&gt;</span>(output_data));</div>
<div class="line"><span class="lineno">  100</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><span class="lineno">  101</span>    <span class="keywordflow">case</span> 2:</div>
<div class="line"><span class="lineno">  102</span>      TransposeImpl&lt;int16_t&gt;(params, unextended_input_shape,</div>
<div class="line"><span class="lineno">  103</span>                             <span class="keyword">reinterpret_cast&lt;</span><span class="keyword">const </span>int16_t *<span class="keyword">&gt;</span>(input_data), unextended_output_shape,</div>
<div class="line"><span class="lineno">  104</span>                             <span class="keyword">reinterpret_cast&lt;</span>int16_t *<span class="keyword">&gt;</span>(output_data));</div>
<div class="line"><span class="lineno">  105</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><span class="lineno">  106</span> </div>
<div class="line"><span class="lineno">  107</span>    <span class="keywordflow">case</span> 4:</div>
<div class="line"><span class="lineno">  108</span>      TransposeImpl&lt;int32_t&gt;(params, unextended_input_shape,</div>
<div class="line"><span class="lineno">  109</span>                             <span class="keyword">reinterpret_cast&lt;</span><span class="keyword">const </span>int32_t *<span class="keyword">&gt;</span>(input_data), unextended_output_shape,</div>
<div class="line"><span class="lineno">  110</span>                             <span class="keyword">reinterpret_cast&lt;</span>int32_t *<span class="keyword">&gt;</span>(output_data));</div>
<div class="line"><span class="lineno">  111</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><span class="lineno">  112</span>    <span class="keywordflow">case</span> 8:</div>
<div class="line"><span class="lineno">  113</span>      TransposeImpl&lt;int64_t&gt;(params, unextended_input_shape,</div>
<div class="line"><span class="lineno">  114</span>                             <span class="keyword">reinterpret_cast&lt;</span><span class="keyword">const </span>int64_t *<span class="keyword">&gt;</span>(input_data), unextended_output_shape,</div>
<div class="line"><span class="lineno">  115</span>                             <span class="keyword">reinterpret_cast&lt;</span>int64_t *<span class="keyword">&gt;</span>(output_data));</div>
<div class="line"><span class="lineno">  116</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><span class="lineno">  117</span>  }</div>
<div class="line"><span class="lineno">  118</span>}</div>
</div><!-- fragment -->
<p class="reference">Referenced by <a class="el" href="compute_2cker_2include_2cker_2operation_2_transpose_8h_source.html#l00476">nnfw::cker::TransposeImpl()</a>.</p>

</div>
</div>
<a id="a77ee976f07a81db2abb12effb60384d7" name="a77ee976f07a81db2abb12effb60384d7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a77ee976f07a81db2abb12effb60384d7">&#9670;&#160;</a></span>TransposeImpl()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void nnfw::cker::reference::TransposeImpl </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structnnfw_1_1cker_1_1_transpose_params.html">TransposeParams</a> &amp;&#160;</td>
          <td class="paramname"><em>params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>unextended_input_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T *&#160;</td>
          <td class="paramname"><em>input_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> &amp;&#160;</td>
          <td class="paramname"><em>unextended_output_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>output_data</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="compute_2cker_2include_2cker_2operation_2_transpose_8h_source.html#l00033">33</a> of file <a class="el" href="compute_2cker_2include_2cker_2operation_2_transpose_8h_source.html">Transpose.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   35</span>{</div>
<div class="line"><span class="lineno">   36</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> unextended_output_size = unextended_output_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a01c6b5dc4b24d5c2567c47cb15318839">DimensionsCount</a>();</div>
<div class="line"><span class="lineno">   37</span>  assert(unextended_input_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a01c6b5dc4b24d5c2567c47cb15318839">DimensionsCount</a>() &lt;= 4);</div>
<div class="line"><span class="lineno">   38</span>  assert(unextended_output_size &lt;= 4);</div>
<div class="line"><span class="lineno">   39</span>  assert(unextended_output_size == params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_transpose_params.html#afc9f2a98af7f384482355576589671f0">perm_count</a>);</div>
<div class="line"><span class="lineno">   40</span>  <span class="keyword">const</span> <a class="code hl_class" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> input_shape = Shape::ExtendedShape(4, unextended_input_shape);</div>
<div class="line"><span class="lineno">   41</span>  <span class="keyword">const</span> <a class="code hl_class" href="classnnfw_1_1cker_1_1_shape.html">Shape</a> output_shape = Shape::ExtendedShape(4, unextended_output_shape);</div>
<div class="line"><span class="lineno">   42</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> input_ext_size = 4 - unextended_input_shape.<a class="code hl_function" href="classnnfw_1_1cker_1_1_shape.html#a01c6b5dc4b24d5c2567c47cb15318839">DimensionsCount</a>();</div>
<div class="line"><span class="lineno">   43</span>  <span class="keyword">const</span> <span class="keywordtype">int</span> output_ext_size = 4 - unextended_output_size;</div>
<div class="line"><span class="lineno">   44</span> </div>
<div class="line"><span class="lineno">   45</span>  <span class="comment">// The perm data is extended to match the output, each index incremented by</span></div>
<div class="line"><span class="lineno">   46</span>  <span class="comment">// the amount of front padding of the input shape.</span></div>
<div class="line"><span class="lineno">   47</span>  <span class="keywordtype">int</span> extended_perm[4];</div>
<div class="line"><span class="lineno">   48</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; output_ext_size; ++i)</div>
<div class="line"><span class="lineno">   49</span>  {</div>
<div class="line"><span class="lineno">   50</span>    extended_perm[i] = i;</div>
<div class="line"><span class="lineno">   51</span>  }</div>
<div class="line"><span class="lineno">   52</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; unextended_output_size; ++i)</div>
<div class="line"><span class="lineno">   53</span>  {</div>
<div class="line"><span class="lineno">   54</span>    extended_perm[i + output_ext_size] = params.<a class="code hl_variable" href="structnnfw_1_1cker_1_1_transpose_params.html#a8cffe02d521411a44e650d7edf660fa9">perm</a>[i] + input_ext_size;</div>
<div class="line"><span class="lineno">   55</span>  }</div>
<div class="line"><span class="lineno">   56</span> </div>
<div class="line"><span class="lineno">   57</span>  <span class="keywordtype">int</span> out_sizes[4];</div>
<div class="line"><span class="lineno">   58</span>  <span class="comment">// Compute the inverse permutation array so we can do an output centered</span></div>
<div class="line"><span class="lineno">   59</span>  <span class="comment">// transpose. Also, check to make sure output_dims is matching input_dims.</span></div>
<div class="line"><span class="lineno">   60</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> k = 0; k &lt; 4; k++)</div>
<div class="line"><span class="lineno">   61</span>  {</div>
<div class="line"><span class="lineno">   62</span>    out_sizes[k] = MatchingDim(input_shape, extended_perm[k], output_shape, k);</div>
<div class="line"><span class="lineno">   63</span>  }</div>
<div class="line"><span class="lineno">   64</span> </div>
<div class="line"><span class="lineno">   65</span>  <span class="comment">// Naive transpose loop (iterate on output index and compute input index).</span></div>
<div class="line"><span class="lineno">   66</span>  <span class="keywordtype">int</span> o[4]; <span class="comment">// loop index (on output).</span></div>
<div class="line"><span class="lineno">   67</span>  <span class="keywordtype">int</span> i[4];</div>
<div class="line"><span class="lineno">   68</span>  <span class="keywordflow">for</span> (o[3] = 0; o[3] &lt; out_sizes[3]; o[3]++)</div>
<div class="line"><span class="lineno">   69</span>  {</div>
<div class="line"><span class="lineno">   70</span>    i[extended_perm[3]] = o[3];</div>
<div class="line"><span class="lineno">   71</span>    <span class="keywordflow">for</span> (o[2] = 0; o[2] &lt; out_sizes[2]; o[2]++)</div>
<div class="line"><span class="lineno">   72</span>    {</div>
<div class="line"><span class="lineno">   73</span>      i[extended_perm[2]] = o[2];</div>
<div class="line"><span class="lineno">   74</span>      <span class="keywordflow">for</span> (o[1] = 0; o[1] &lt; out_sizes[1]; o[1]++)</div>
<div class="line"><span class="lineno">   75</span>      {</div>
<div class="line"><span class="lineno">   76</span>        i[extended_perm[1]] = o[1];</div>
<div class="line"><span class="lineno">   77</span>        <span class="keywordflow">for</span> (o[0] = 0; o[0] &lt; out_sizes[0]; o[0]++)</div>
<div class="line"><span class="lineno">   78</span>        {</div>
<div class="line"><span class="lineno">   79</span>          i[extended_perm[0]] = o[0];</div>
<div class="line"><span class="lineno">   80</span>          output_data[<a class="code hl_function" href="ann-ref_2src_2ops_2internal_2dims_8h.html#a1c037ff89c0da8b5cd52088b914b9c1d">Offset</a>(output_shape, o)] = input_data[<a class="code hl_function" href="ann-ref_2src_2ops_2internal_2dims_8h.html#a1c037ff89c0da8b5cd52088b914b9c1d">Offset</a>(input_shape, i)];</div>
<div class="line"><span class="lineno">   81</span>        }</div>
<div class="line"><span class="lineno">   82</span>      }</div>
<div class="line"><span class="lineno">   83</span>    }</div>
<div class="line"><span class="lineno">   84</span>  }</div>
<div class="line"><span class="lineno">   85</span>}</div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_transpose_params_html_a8cffe02d521411a44e650d7edf660fa9"><div class="ttname"><a href="structnnfw_1_1cker_1_1_transpose_params.html#a8cffe02d521411a44e650d7edf660fa9">nnfw::cker::TransposeParams::perm</a></div><div class="ttdeci">int32_t perm[4]</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00210">Types.h:210</a></div></div>
<div class="ttc" id="astructnnfw_1_1cker_1_1_transpose_params_html_afc9f2a98af7f384482355576589671f0"><div class="ttname"><a href="structnnfw_1_1cker_1_1_transpose_params.html#afc9f2a98af7f384482355576589671f0">nnfw::cker::TransposeParams::perm_count</a></div><div class="ttdeci">int8_t perm_count</div><div class="ttdef"><b>Definition:</b> <a href="compute_2cker_2include_2cker_2_types_8h_source.html#l00209">Types.h:209</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00093">nnfw::cker::Shape::DimensionsCount()</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00222">nnfw::cker::MatchingDim()</a>, <a class="el" href="compute_2cker_2include_2cker_2_shape_8h_source.html#l00241">nnfw::cker::Offset()</a>, <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00210">nnfw::cker::TransposeParams::perm</a>, and <a class="el" href="compute_2cker_2include_2cker_2_types_8h_source.html#l00209">nnfw::cker::TransposeParams::perm_count</a>.</p>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespacennfw.html">nnfw</a></li><li class="navelem"><a class="el" href="namespacennfw_1_1cker.html">cker</a></li><li class="navelem"><a class="el" href="namespacennfw_1_1cker_1_1reference.html">reference</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.5 </li>
  </ul>
</div>
</body>
</html>
